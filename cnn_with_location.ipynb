{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea73044-bd95-4949-8bbb-54344c18fd14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp = 'C:/Users/vjosv/master/top_100_images_with_location_data.csv'\n",
    "import time\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import ast\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from averagemeter import *\n",
    "from models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 150\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "best_prec1 = 0\n",
    "classes = []\n",
    "\n",
    "train_dat = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv')\n",
    "test_dat = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv')\n",
    "df_comb = pd.concat([train_dat,test_dat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ef4b37-da9b-4719-b269-16aac411ae57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = [T.ToTensor(),T.Resize((INPUT_SIZE,INPUT_SIZE))]\n",
    "\n",
    "composed = T.Compose(transforms)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "landscape_val = df_comb['landscape'].unique()\n",
    "\n",
    "\n",
    "one_hot_landscape_dict = {}\n",
    "for i,lv in enumerate(landscape_val):\n",
    "    zero = np.zeros(len(landscape_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_landscape_dict[str(lv)]= zero\n",
    "\n",
    "artreslag_val =df_comb['artreslag'].unique()\n",
    "one_hot_artreslag_dict = {}\n",
    "for i,av in enumerate(artreslag_val):\n",
    "    zero = np.zeros(len(artreslag_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_artreslag_dict[str(av)]= zero\n",
    "\n",
    "arjordbr_val =df_comb['arjordbr'].unique()\n",
    "one_hot_arjordbr_dict = {}\n",
    "for i,av in enumerate(arjordbr_val):\n",
    "    zero = np.zeros(len(arjordbr_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_arjordbr_dict[str(av)]= zero\n",
    "    \n",
    "    \n",
    "\n",
    "arskogbon_val =df_comb['arskogbon'].unique()\n",
    "one_hot_arskogbon_dict = {}\n",
    "for i,av in enumerate(arskogbon_val):\n",
    "    zero = np.zeros(len(arskogbon_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_arskogbon_dict[str(av)]= zero\n",
    "    \n",
    "treeline_val =df_comb['treeline'].unique()\n",
    "one_hot_treeline_dict = {}\n",
    "for i,av in enumerate(treeline_val):\n",
    "    zero = np.zeros(len(treeline_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_treeline_dict[str(av)]= zero\n",
    "    \n",
    "\n",
    "square_10x10_val =df_comb['square_10x10'].unique()\n",
    "one_hot_square_10x10_dict = {}\n",
    "for i,av in enumerate(square_10x10_val):\n",
    "    zero = np.zeros(len(square_10x10_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_square_10x10_dict[str(av)]= zero\n",
    "\n",
    "\n",
    "arveget_val =df_comb['arveget'].unique()\n",
    "one_hot_arveget_dict = {}\n",
    "for i,av in enumerate(arveget_val):\n",
    "    zero = np.zeros(len(arveget_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_arveget_dict[str(av)]= zero\n",
    "\n",
    "artype_val =df_comb['artype'].unique()\n",
    "one_hot_artype_dict = {}\n",
    "for i,av in enumerate(artype_val):\n",
    "    zero = np.zeros(len(artype_val))\n",
    "    zero[i]=1 \n",
    "    one_hot_artype_dict[str(av)]= zero\n",
    "\n",
    "\n",
    "class ImagesWithLocationDataset(Dataset):\n",
    "    \"\"\"Plant images with location data.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "    \n",
    "\n",
    "        self.location_dataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.location_dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.location_dataframe['path'].iloc[idx]\n",
    "        \n",
    "        image = io.imread(img_name)\n",
    "        location_data = np.array(ast.literal_eval(self.location_dataframe['in_1000'].iloc[idx]))\n",
    "        landscape = str(self.location_dataframe['landscape'].iloc[idx])\n",
    "        artreslag = str(self.location_dataframe['artreslag'].iloc[idx])\n",
    "        arjordbr = str(self.location_dataframe['arjordbr'].iloc[idx])\n",
    "        target = np.array(self.location_dataframe['target'].iloc[idx])\n",
    "        height = self.location_dataframe['height'].iloc[idx]\n",
    "        north = self.location_dataframe['Nordkoordinat'].iloc[idx]\n",
    "        artype = str(self.location_dataframe['artype'].iloc[idx])\n",
    "        treeline = str(self.location_dataframe['treeline'].iloc[idx])\n",
    "        square_10x10 =self.location_dataframe['square_10x10'].iloc[idx]\n",
    "        arveget = str(self.location_dataframe['arveget'].iloc[idx])\n",
    "        arskogbon =  str(self.location_dataframe['arskogbon'].iloc[idx])\n",
    "        # landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        # landmarks = np.array([landmarks], dtype=float).reshape(-1, 2)\n",
    "        sample = {'image': image, 'location_data': location_data, 'target':target, 'landscape':landscape,\n",
    "                 'artreslag':artreslag, 'arjordbr':arjordbr, 'height':height,'north':north,\n",
    "                 'artype':artype,'treeline':treeline, 'square_10x10':square_10x10, 'arveget':arveget,\n",
    "                 'arskogbon':arskogbon}\n",
    "        # sample = {'image': image, 'target':target}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            sample['target'] = torch.from_numpy(sample['target'])\n",
    "            sample['location_data'] = torch.from_numpy(location_data).float()\n",
    "            sample['landscape'] = torch.from_numpy(one_hot_landscape_dict[landscape]).float()\n",
    "            sample['artreslag'] = torch.from_numpy(one_hot_artreslag_dict[artreslag]).float()\n",
    "            sample['arjordbr'] = torch.from_numpy(one_hot_arjordbr_dict[arjordbr]).float()\n",
    "            sample['artype'] = torch.from_numpy(one_hot_artype_dict[artype]).float()\n",
    "            sample['treeline'] = torch.from_numpy(one_hot_treeline_dict[treeline]).float()\n",
    "            sample['square_10x10'] = torch.from_numpy(one_hot_square_10x10_dict[square_10x10]).float()\n",
    "            sample['arveget'] = torch.from_numpy(one_hot_arveget_dict[arveget]).float()\n",
    "            sample['arskogbon'] = torch.from_numpy(one_hot_arskogbon_dict[arskogbon]).float()\n",
    "            sample['height'] = torch.from_numpy(np.array([height])).float()\n",
    "            sample['north'] = torch.from_numpy(np.array([north])).float()\n",
    "        return sample\n",
    "    \n",
    "    def from_np_array(self,array_string):\n",
    "        array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "        return np.array(ast.literal_eval(array_string))\n",
    "    \n",
    "    def name(self):\n",
    "        return 'ImagesWithLocationDataset'\n",
    "\n",
    "class ImagesWithLocationDataset_conv(Dataset):\n",
    "    \"\"\"Plant images with location data.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "    \n",
    "\n",
    "        self.location_dataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.location_dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.location_dataframe['path'].iloc[idx]\n",
    "        \n",
    "        image = io.imread(img_name)\n",
    "        location_data = self.from_np_array(self.location_dataframe['count_in_1000'].iloc[idx])\n",
    "        \n",
    "        map_square = self.split_map_square(location_dataframe['map_square'].iloc[idx])\n",
    "        \n",
    " \n",
    "        target = np.array(self.location_dataframe['target'].iloc[idx])\n",
    "        \n",
    "        \n",
    "\n",
    "        # landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        # landmarks = np.array([landmarks], dtype=float).reshape(-1, 2)\n",
    "        sample = {'image': image, 'location_data': location_data, 'map_square': map_square,'target':target}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            sample['target'] = torch.from_numpy(sample['target'])\n",
    "            sample['location_data'] = torch.from_numpy(location_data).float()\n",
    "            \n",
    "            for t in self.transform.transforms:\n",
    "                if isinstance(t,torchvision.transforms.transforms.Resize):\n",
    "                    input_size = t.size[0]\n",
    "            map_s = np.zeros((input_size,input_size))\n",
    "            map_s[:input_size//2]=map_square[0]\n",
    "            map_s[input_size//2:]=map_square[1]\n",
    "            map_s = torch.from_numpy(map_s).float()\n",
    "            map_s = map_s.expand(1,input_size,input_size)\n",
    "            sample['map_square'] = map_s\n",
    "        return sample\n",
    "    \n",
    "    def from_np_array(self,array_string):\n",
    "        array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "        return np.array(ast.literal_eval(array_string))\n",
    "    \n",
    "    def split_map_square(self,list_string):\n",
    "        v = list_string.split(',')\n",
    "        return [int(v[0][1:]),int(v[1][:-1])]\n",
    "\n",
    "    def name(self):\n",
    "        return 'ImagesWithLocationDataset_conv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb107e-272d-452a-b513-bef032b5ae66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1f2916-b3b1-4a72-93fa-8588a3a9dc22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This file provides a long_running decorator to indicate that a function needs a long amount of time to complete and\n",
    "# the computer should not enter standby. This file currently only works on Windows and is a no-op on other platforms.\n",
    "\n",
    "#copied from Kevin Barnes/kbarnes3: https://gist.github.com/kbarnes3/3fb7d353e9bdd3efccd5\n",
    "\n",
    "import ctypes\n",
    "import platform\n",
    "\n",
    "ES_CONTINUOUS = 0x80000000\n",
    "ES_SYSTEM_REQUIRED = 0x00000001\n",
    "\n",
    "\n",
    "def _set_thread_execution(state):\n",
    "    ctypes.windll.kernel32.SetThreadExecutionState(state)\n",
    "\n",
    "\n",
    "def prevent_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS | ES_SYSTEM_REQUIRED)\n",
    "\n",
    "\n",
    "def allow_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS)\n",
    "\n",
    "\n",
    "def long_running(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        prevent_standby()\n",
    "        result = func(*args, **kwargs)\n",
    "        allow_standby()\n",
    "        return result\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf65f88-b6e2-4de1-acc1-46da7d862029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df = pd.read_csv('C:/Users/vjosv/master/top_100_images_with_location_data.csv')\n",
    "path_list = list(image_df['path'])\n",
    "\n",
    "non_existing_files = []\n",
    "for i,pl in enumerate(path_list):\n",
    "    if not os.path.isfile(pl):\n",
    "        non_existing_files.append((i,pl))\n",
    "        \n",
    "non_existing_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e230ed7-bddd-465b-ad11-a260da6131b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dat = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv')\n",
    "test_dat = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv')\n",
    "df_comb = pd.concat([train_dat,test_dat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a33a1-8d26-462d-90ac-e92f0879b027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bef6f-e2e6-46ce-b21c-436b27cb3d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72d892-41bd-41c0-91dd-6933d4495efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb83f90e-f30d-4a1b-8bb9-5dc1c92bb28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dat = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv')\n",
    "\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv','s',transform=composed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1524d6db-8f8e-4dd9-aa53-1fdec377a85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(image_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b45fe7f-8a0a-4e99-a88a-59ce004bb957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,input in enumerate(train_loader):\n",
    "    \n",
    "    # print(input)\n",
    "    l = ['image','target']\n",
    "    a = torch.cat([input[k] for k in input if k not in l],1 )\n",
    "    a\n",
    "    break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18bb5622-24a2-4356-89b1-70cda205776f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 170])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "220a9af9-1b12-45e8-9df6-59a783a88b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        # print(input['image'].shape)\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            \n",
    "            l = ['image','target']\n",
    "            location_data = torch.cat([input[k].cuda(non_blocking=True) for k in input if k not in l],1 )\n",
    "            \n",
    "            # l = ['height','north']\n",
    "            # location_data = torch.cat([input[k] for k in input if k not in l],1 )\n",
    "\n",
    "            # location_data = torch.cat([input[k].cuda(non_blocking=True) for k in input if k in l],1 )\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            l = ['image','target']\n",
    "            l = ['height','north']\n",
    "            # location_data = torch.cat([input[k] for k in input if k not in l],1 )\n",
    "\n",
    "            location_data = torch.cat([input[k] for k in input if k in l],1 )\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "        \n",
    "        \n",
    "\n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        location_data_var = torch.autograd.Variable(location_data)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "\n",
    "        output = model(input_var,location_data_var)\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        \n",
    "        # compute output\n",
    "        # print(input_var.shape)\n",
    "        # print(output)\n",
    "\n",
    "        loss = criterion(output, target_var)\n",
    "        # print(loss)\n",
    "        # if i >10:\n",
    "        #     break\n",
    "        \n",
    "        save_output_target_train(model,output,target_var,epoch,i)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5,conf = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  '\\Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "            \n",
    "def validate(val_loader, model, criterion,epoch,save_output=False):\n",
    "    # global output_aug_kde001, sample_pos, within_square, weight_tensor_kde001,zero_tensor_kde001,tt\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "\n",
    "    conf = AverageMeter()\n",
    "    class_correct = list(0. for i in range(200))\n",
    "    class_total = list(0. for i in range(200))\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(val_loader):\n",
    "        \n",
    "\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            l = ['image','target']\n",
    "            location_data = torch.cat([input[k].cuda(non_blocking=True) for k in input if k not in l],1 )\n",
    "            location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "            # l = ['height','north']\n",
    "            # location_data = torch.cat([input[k] for k in input if k not in l],1 )\n",
    "\n",
    "            # location_data = torch.cat([input[k].cuda(non_blocking=True) for k in input if k in l],1 )\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            l = ['image','target']\n",
    "            location_data = torch.cat([input[k] for k in input if k not in l],1 )\n",
    "            \n",
    "            # l = ['height','north']\n",
    "            # location_data = torch.cat([input[k] for k in input if k in l],1 )\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        location_data_var = torch.autograd.Variable(location_data)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var,location_data_var)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        save_output_target_validate(model,output,target,epoch,i)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        \n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        \n",
    "\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        \n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "\n",
    "\n",
    "        conf.update(conf1,1)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            print('Test: [{0}/{1}]\\n'.format(i, len(val_loader)))\n",
    "            print('Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\n'.format(batch_time=batch_time))\n",
    "            print('Loss {loss.val:.4f} ({loss.avg:.4f})\\n'.format(loss=losses))\n",
    "            print('Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\n'.format(top1=top1))\n",
    "            print('Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\n'.format(top5=top5))\n",
    "\n",
    "        # print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "        #       .format(top1=top1, top5=top5))\n",
    "        \n",
    "\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f62ef5f-2db6-410a-aebf-6da53c1b85c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, adjust_now, LEARNING_RATE=LEARNING_RATE):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LEARNING_RATE\n",
    "    if (epoch-1) < 0:\n",
    "        former_lr=optimizer.param_groups[0]['lr']\n",
    "\n",
    "    former_lr = copy.copy(optimizer.param_groups[0]['lr'])\n",
    "    if adjust_now:\n",
    "        former_lr = copy.copy(optimizer.param_groups[0]['lr'])\n",
    "        LEARNING_RATE = LEARNING_RATE*0.1\n",
    "        lr = LEARNING_RATE\n",
    "    print('\\n[Learning Rate] {:0.6f}'.format(lr))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr != former_lr, LEARNING_RATE\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, model):\n",
    "    filename=f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('\\n[INFO] Saved Model to model_best.pth.tar')\n",
    "        shutil.copyfile(filename, f'saved_models/{model.name}_model_best.pth.tar')\n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = output.shape[1]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6743e8ea-80d5-49b1-95c0-5ecc7633f5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(state, is_best, model):\n",
    "    filename=f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('\\n[INFO] Saved Model to model_best.pth.tar')\n",
    "        shutil.copyfile(filename, f'saved_models/{model.name}_model_best.pth.tar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bc3b92f-3ab8-4bb8-9946-7b60f17a54c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_output_target_validate(model,output,target,epoch,batch):\n",
    "        torch.save(output,f'saved_output/{model.name}_validating_output/output_e{epoch}_b{batch}')\n",
    "        torch.save(target,f'saved_output/{model.name}_validating_output/target_b{batch}')\n",
    "        \n",
    "def save_output_target_train(model,output,target,epoch,batch):\n",
    "        torch.save(output,f'saved_output/{model.name}_training_output/output_e{epoch}_b{batch}')\n",
    "\n",
    "        torch.save(target,f'saved_output/{model.name}_training_output/target_e_{epoch}_b{batch}')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a213e8b9-6d74-45a3-a79c-6e4193816546",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/resnet101_with_full_loc_dat_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 235\u001b[0m\n\u001b[0;32m    232\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m train_model(model,LEARNING_RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-7\u001b[39m,NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m, in \u001b[0;36mlong_running.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     prevent_standby()\n\u001b[1;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     31\u001b[0m     allow_standby()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[18], line 102\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, LEARNING_RATE, NUM_EPOCHS)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=> loaded checkpoint \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m           \u001b[38;5;241m.\u001b[39mformat(args_resume, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m train(train_loader, model, criterion, optimizer, epoch)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[0;32m    104\u001b[0m prec1 \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion,epoch,save_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m     44\u001b[0m location_data_var \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(location_data)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# map_square_var = torch.autograd.Variable(map_square)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# location_data_var = torch.autograd.Variable(location_data)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# output = model(input_var,map_square)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_var,location_data_var)\n\u001b[0;32m     51\u001b[0m data_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# print(input_var.shape)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# print(output)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 190\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, x, x2)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, x2: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# x = self.location_fc1(x)\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# x = self.linear_add(x,x5)\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_fc1(x2)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = models.resnet101(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "test_path ='C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_path =  'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv'\n",
    "# test_dat_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# train_size = int(split_train*0.01 * len(image_dataset))\n",
    "# test_size = len(image_dataset) - train_size\n",
    "# data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    " \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    \n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "        \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            print('Adjusted Learning rate resume from best model')\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# args_resume = f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/{model.name}_model_best.pth.tar'\n",
    "# print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "# checkpoint = torch.load(args_resume)\n",
    "# best_prec1 = checkpoint['best_prec1']\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "#       .format(args_resume, checkpoint['epoch']))\n",
    "# epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "\n",
    "model.name = f'resnet101_with_full_loc_dat'\n",
    "\n",
    "\n",
    "numb_targets = 100\n",
    "location_vals = 170\n",
    "location_fc = nn.Sequential(\n",
    "          nn.Linear(numb_targets+location_vals, (numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          # nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          # nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "              nn.ReLU(inplace=True),\n",
    "          # nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),numb_targets),\n",
    "        )\n",
    "\n",
    "model.add_module('location_fc',location_fc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "location_fc1 = nn.Sequential(\n",
    "          nn.Linear(170, 170*2),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear(170*2,170),\n",
    "            nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear(170,170),\n",
    "        )\n",
    "\n",
    "model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "\n",
    "location_fc2 = nn.Sequential(\n",
    "\n",
    "          nn.Linear(100,100),\n",
    "          nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(100,100),\n",
    "        )\n",
    "\n",
    "# lin_add = LinearAddLayer(100,100)\n",
    "\n",
    "# model.add_module('linear_add',lin_add)\n",
    "# model.add_module('location_fc',location_fc)\n",
    "# model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "# model.add_module('location_fc2',location_fc2)\n",
    "\n",
    "def forward(self, x: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    # Reshape and permute the input tensor\n",
    "    x = self._forward_impl(x)\n",
    "    # x = self.location_fc1(x)\n",
    "    # x = self.linear_add(x,x5)\n",
    "    \n",
    "    x2 = self.location_fc1(x2)\n",
    "    \n",
    "    combined = torch.cat((x.view(x.size(0), -1),\n",
    "                      x2.view(x2.size(0), -1)),\n",
    "                      dim=1)\n",
    "    x = self.location_fc(combined)\n",
    "    return x\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "# model.forward = forward\n",
    "model.forward = functools.partial(forward, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "#freezing transformer part\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.location_fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "\n",
    "for param in model.location_fc1.parameters():\n",
    "    param.requires_grad = True  \n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\n",
    "\n",
    "train_model(model,LEARNING_RATE = 1e-7,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91337bcd-6e8d-481c-a31a-0aa017f5018b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 17)\n",
      "=> no checkpoint found at 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_location4_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "Epoch: [0][0/1334]\t\\Time 0.671 (0.671)\tData 0.511 (0.511)\tLoss 38443.2383 (38443.2383)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/1334]\t\\Time 0.271 (0.289)\tData 0.196 (0.221)\tLoss 4.8937 (1294.6233)\tPrec@1 0.000 (1.073)\tPrec@5 0.000 (4.868)\n",
      "Epoch: [0][200/1334]\t\\Time 0.335 (0.290)\tData 0.257 (0.220)\tLoss 4.5914 (652.8622)\tPrec@1 0.000 (0.912)\tPrec@5 8.333 (4.643)\n",
      "Epoch: [0][300/1334]\t\\Time 0.319 (0.288)\tData 0.254 (0.218)\tLoss 4.6345 (437.5163)\tPrec@1 0.000 (0.969)\tPrec@5 0.000 (4.734)\n",
      "Epoch: [0][400/1334]\t\\Time 0.283 (0.289)\tData 0.213 (0.219)\tLoss 4.5177 (329.5721)\tPrec@1 0.000 (1.101)\tPrec@5 16.667 (4.946)\n",
      "Epoch: [0][500/1334]\t\\Time 0.346 (0.292)\tData 0.269 (0.221)\tLoss 4.5855 (264.7218)\tPrec@1 0.000 (1.065)\tPrec@5 0.000 (4.724)\n",
      "Epoch: [0][600/1334]\t\\Time 0.302 (0.294)\tData 0.220 (0.223)\tLoss 4.6912 (221.4547)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (4.770)\n",
      "Epoch: [0][700/1334]\t\\Time 0.324 (0.298)\tData 0.254 (0.227)\tLoss 4.6547 (190.5278)\tPrec@1 8.333 (1.224)\tPrec@5 8.333 (4.838)\n",
      "Epoch: [0][800/1334]\t\\Time 0.407 (0.303)\tData 0.335 (0.231)\tLoss 4.6736 (167.3249)\tPrec@1 0.000 (1.165)\tPrec@5 0.000 (4.786)\n",
      "Epoch: [0][900/1334]\t\\Time 0.344 (0.303)\tData 0.271 (0.231)\tLoss 4.8213 (149.2724)\tPrec@1 0.000 (1.119)\tPrec@5 0.000 (4.726)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.302 (0.303)\tData 0.232 (0.231)\tLoss 4.9846 (134.8279)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (4.637)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.385 (0.305)\tData 0.303 (0.234)\tLoss 4.7109 (123.0073)\tPrec@1 0.000 (1.075)\tPrec@5 0.000 (4.723)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.369 (0.307)\tData 0.292 (0.236)\tLoss 4.8931 (113.1545)\tPrec@1 0.000 (1.075)\tPrec@5 0.000 (4.753)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.289 (0.307)\tData 0.214 (0.236)\tLoss 4.6440 (104.8158)\tPrec@1 0.000 (1.095)\tPrec@5 8.333 (4.874)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (12x100 and 170x170)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 228\u001b[0m\n\u001b[0;32m    226\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m train_model(model,LEARNING_RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m,NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m, in \u001b[0;36mlong_running.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     prevent_standby()\n\u001b[1;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     31\u001b[0m     allow_standby()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[19], line 104\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, LEARNING_RATE, NUM_EPOCHS)\u001b[0m\n\u001b[0;32m    102\u001b[0m train(train_loader, model, criterion, optimizer, epoch)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m prec1 \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion,epoch,save_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    106\u001b[0m is_best \u001b[38;5;241m=\u001b[39m prec1 \u001b[38;5;241m>\u001b[39m best_prec1\n\u001b[0;32m    107\u001b[0m best_prec1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(prec1, best_prec1)\n",
      "Cell \u001b[1;32mIn[10], line 137\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(val_loader, model, criterion, epoch, save_output)\u001b[0m\n\u001b[0;32m    132\u001b[0m location_data_var \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(location_data)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# location_data_var = torch.autograd.Variable(location_data)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# map_square_var = torch.autograd.Variable(map_square)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# output = model(input_var,map_square)\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_var,location_data_var)\n\u001b[0;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m    140\u001b[0m save_output_target_validate(model,output,target,epoch,i)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 190\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, x, x2)\u001b[0m\n\u001b[0;32m    186\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# x = self.location_fc1(x)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# x = self.linear_add(x,x5)\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_fc1(x2)\n\u001b[0;32m    191\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    192\u001b[0m                   x2\u001b[38;5;241m.\u001b[39mview(x2\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m    193\u001b[0m                   dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    194\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_fc(combined)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (12x100 and 170x170)"
     ]
    }
   ],
   "source": [
    "\n",
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101')\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "test_path ='C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_path =  'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv'\n",
    "# test_dat_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# train_size = int(split_train*0.01 * len(image_dataset))\n",
    "# test_size = len(image_dataset) - train_size\n",
    "# data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    " \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    \n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "        \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            print('Adjusted Learning rate resume from best model')\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "args_resume = f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/{model.name}_model_best.pth.tar'\n",
    "print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "checkpoint = torch.load(args_resume)\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "      .format(args_resume, checkpoint['epoch']))\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2_location4'\n",
    "\n",
    "\n",
    "numb_targets = 100\n",
    "location_vals = 170\n",
    "location_fc = nn.Sequential(\n",
    "          nn.Linear(numb_targets+location_vals, (numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "              nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),numb_targets),\n",
    "        )\n",
    "\n",
    "model.add_module('location_fc',location_fc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "location_fc1 = nn.Sequential(\n",
    "          nn.Linear(170, 170),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear(170,170),\n",
    "        )\n",
    "model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "\n",
    "location_fc2 = nn.Sequential(\n",
    "\n",
    "          nn.Linear(100,100),\n",
    "          nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(100,100),\n",
    "        )\n",
    "\n",
    "# lin_add = LinearAddLayer(100,100)\n",
    "\n",
    "# model.add_module('linear_add',lin_add)\n",
    "model.add_module('location_fc',location_fc)\n",
    "# model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "# model.add_module('location_fc2',location_fc2)\n",
    "\n",
    "def forward(self, x: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    # Reshape and permute the input tensor\n",
    "    x = self._forward_impl(x)\n",
    "    # x = self.location_fc1(x)\n",
    "    # x = self.linear_add(x,x5)\n",
    "    \n",
    "    x2 = self.location_fc1(x2)\n",
    "    combined = torch.cat((x.view(x.size(0), -1),\n",
    "                      x2.view(x2.size(0), -1)),\n",
    "                      dim=1)\n",
    "    x = self.location_fc(combined)\n",
    "    return x\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "# model.forward = forward\n",
    "model.forward = functools.partial(forward, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "# freezing trained part\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.location_fc.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.location_fc1.parameters():\n",
    "    param.requires_grad = True\n",
    "      \n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\n",
    "train_model(model,LEARNING_RATE = 1e-6,NUM_EPOCHS = 10)\n",
    "# train_model(model,LEARNING_RATE = 1e-6,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87ce7eec-f609-4ddd-b85f-06afd12080ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 17)\n",
      "=> no checkpoint found at 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_location3_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "Epoch: [0][0/1334]\t\\Time 0.434 (0.434)\tData 0.255 (0.255)\tLoss 38443.2383 (38443.2383)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/1334]\t\\Time 0.296 (0.310)\tData 0.224 (0.242)\tLoss 4.8937 (1294.6233)\tPrec@1 0.000 (1.073)\tPrec@5 0.000 (4.868)\n",
      "Epoch: [0][200/1334]\t\\Time 0.389 (0.320)\tData 0.316 (0.251)\tLoss 4.5914 (652.8622)\tPrec@1 0.000 (0.912)\tPrec@5 8.333 (4.643)\n",
      "Epoch: [0][300/1334]\t\\Time 0.599 (0.326)\tData 0.530 (0.257)\tLoss 4.6345 (437.5163)\tPrec@1 0.000 (0.969)\tPrec@5 0.000 (4.734)\n",
      "Epoch: [0][400/1334]\t\\Time 0.329 (0.330)\tData 0.261 (0.262)\tLoss 4.5177 (329.5721)\tPrec@1 0.000 (1.101)\tPrec@5 16.667 (4.946)\n",
      "Epoch: [0][500/1334]\t\\Time 0.387 (0.336)\tData 0.316 (0.266)\tLoss 4.5855 (264.7218)\tPrec@1 0.000 (1.065)\tPrec@5 0.000 (4.724)\n",
      "Epoch: [0][600/1334]\t\\Time 0.333 (0.336)\tData 0.255 (0.266)\tLoss 4.6912 (221.4547)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (4.770)\n",
      "Epoch: [0][700/1334]\t\\Time 0.341 (0.336)\tData 0.274 (0.267)\tLoss 4.6547 (190.5278)\tPrec@1 8.333 (1.224)\tPrec@5 8.333 (4.838)\n",
      "Epoch: [0][800/1334]\t\\Time 0.381 (0.338)\tData 0.314 (0.269)\tLoss 4.6736 (167.3249)\tPrec@1 0.000 (1.165)\tPrec@5 0.000 (4.786)\n",
      "Epoch: [0][900/1334]\t\\Time 0.447 (0.341)\tData 0.378 (0.271)\tLoss 4.8213 (149.2724)\tPrec@1 0.000 (1.119)\tPrec@5 0.000 (4.726)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.343 (0.343)\tData 0.275 (0.273)\tLoss 4.9846 (134.8279)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (4.637)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.368 (0.343)\tData 0.296 (0.274)\tLoss 4.7109 (123.0073)\tPrec@1 0.000 (1.075)\tPrec@5 0.000 (4.723)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.372 (0.342)\tData 0.301 (0.273)\tLoss 4.8931 (113.1545)\tPrec@1 0.000 (1.075)\tPrec@5 0.000 (4.753)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.341 (0.343)\tData 0.274 (0.274)\tLoss 4.6440 (104.8158)\tPrec@1 0.000 (1.095)\tPrec@5 8.333 (4.874)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.382 (0.382)\n",
      "\n",
      "Loss 4.6127 (4.6127)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 0.000 (0.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.448 (0.402)\n",
      "\n",
      "Loss 4.6470 (4.6283)\n",
      "\n",
      "Prec@1 0.000 (0.413)\n",
      "\n",
      "Prec@5 8.333 (4.125)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.116 (0.367)\n",
      "\n",
      "Loss 4.5669 (4.6270)\n",
      "\n",
      "Prec@1 0.000 (0.622)\n",
      "\n",
      "Prec@5 0.000 (5.473)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.126 (0.361)\n",
      "\n",
      "Loss 4.5266 (4.6170)\n",
      "\n",
      "Prec@1 0.000 (0.609)\n",
      "\n",
      "Prec@5 0.000 (5.509)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "Epoch: [1][0/1334]\t\\Time 0.255 (0.255)\tData 0.220 (0.220)\tLoss 4.7930 (4.7930)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [1][100/1334]\t\\Time 0.444 (0.350)\tData 0.379 (0.282)\tLoss 4.6481 (4.6748)\tPrec@1 8.333 (1.073)\tPrec@5 8.333 (4.703)\n",
      "Epoch: [1][200/1334]\t\\Time 0.404 (0.395)\tData 0.338 (0.330)\tLoss 4.6129 (4.6691)\tPrec@1 0.000 (1.161)\tPrec@5 0.000 (4.229)\n",
      "Epoch: [1][300/1334]\t\\Time 0.350 (0.385)\tData 0.283 (0.319)\tLoss 4.6300 (4.6675)\tPrec@1 0.000 (1.163)\tPrec@5 0.000 (4.900)\n",
      "Epoch: [1][400/1334]\t\\Time 0.335 (0.375)\tData 0.263 (0.307)\tLoss 4.6601 (4.6665)\tPrec@1 0.000 (1.226)\tPrec@5 0.000 (4.946)\n",
      "Epoch: [1][500/1334]\t\\Time 0.315 (0.375)\tData 0.248 (0.308)\tLoss 4.8174 (4.6652)\tPrec@1 0.000 (1.164)\tPrec@5 0.000 (4.940)\n",
      "Epoch: [1][600/1334]\t\\Time 0.315 (0.383)\tData 0.247 (0.316)\tLoss 4.6165 (4.6641)\tPrec@1 0.000 (1.109)\tPrec@5 0.000 (5.019)\n",
      "Epoch: [1][700/1334]\t\\Time 0.269 (0.390)\tData 0.244 (0.323)\tLoss 4.8007 (4.6679)\tPrec@1 0.000 (1.129)\tPrec@5 0.000 (5.040)\n",
      "Epoch: [1][800/1334]\t\\Time 0.410 (0.385)\tData 0.342 (0.318)\tLoss 4.8570 (4.6685)\tPrec@1 0.000 (1.134)\tPrec@5 8.333 (5.025)\n",
      "Epoch: [1][900/1334]\t\\Time 0.491 (0.381)\tData 0.399 (0.314)\tLoss 4.6641 (4.6688)\tPrec@1 0.000 (1.091)\tPrec@5 8.333 (5.022)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.334 (0.382)\tData 0.266 (0.315)\tLoss 4.5838 (4.6695)\tPrec@1 0.000 (1.074)\tPrec@5 16.667 (4.995)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.558 (0.385)\tData 0.533 (0.317)\tLoss 4.6251 (4.6705)\tPrec@1 0.000 (1.052)\tPrec@5 8.333 (4.988)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.268 (0.385)\tData 0.198 (0.318)\tLoss 4.6624 (4.6706)\tPrec@1 0.000 (1.082)\tPrec@5 8.333 (5.024)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.337 (0.380)\tData 0.268 (0.313)\tLoss 4.8010 (4.6704)\tPrec@1 0.000 (1.076)\tPrec@5 0.000 (4.958)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.329 (0.329)\n",
      "\n",
      "Loss 4.6137 (4.6137)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 0.000 (0.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.434 (0.414)\n",
      "\n",
      "Loss 4.6492 (4.6241)\n",
      "\n",
      "Prec@1 0.000 (0.413)\n",
      "\n",
      "Prec@5 8.333 (4.373)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.124 (0.383)\n",
      "\n",
      "Loss 4.5746 (4.6228)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (5.846)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.112 (0.360)\n",
      "\n",
      "Loss 4.5280 (4.6137)\n",
      "\n",
      "Prec@1 0.000 (0.664)\n",
      "\n",
      "Prec@5 0.000 (5.703)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "Epoch: [2][0/1334]\t\\Time 0.292 (0.292)\tData 0.255 (0.255)\tLoss 4.6983 (4.6983)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [2][100/1334]\t\\Time 0.364 (0.356)\tData 0.299 (0.287)\tLoss 4.6967 (4.6534)\tPrec@1 0.000 (1.403)\tPrec@5 8.333 (5.528)\n",
      "Epoch: [2][200/1334]\t\\Time 0.462 (0.406)\tData 0.404 (0.337)\tLoss 4.7135 (4.6650)\tPrec@1 0.000 (1.368)\tPrec@5 8.333 (5.556)\n",
      "Epoch: [2][300/1334]\t\\Time 0.347 (0.417)\tData 0.283 (0.348)\tLoss 4.7223 (4.6652)\tPrec@1 0.000 (1.274)\tPrec@5 8.333 (5.814)\n",
      "Epoch: [2][400/1334]\t\\Time 0.347 (0.408)\tData 0.277 (0.339)\tLoss 4.6774 (4.6663)\tPrec@1 0.000 (1.164)\tPrec@5 8.333 (5.694)\n",
      "Epoch: [2][500/1334]\t\\Time 0.731 (0.423)\tData 0.576 (0.354)\tLoss 4.5351 (4.6706)\tPrec@1 16.667 (1.131)\tPrec@5 16.667 (5.256)\n",
      "Epoch: [2][600/1334]\t\\Time 0.332 (0.426)\tData 0.261 (0.358)\tLoss 4.5515 (4.6698)\tPrec@1 0.000 (1.054)\tPrec@5 8.333 (5.311)\n",
      "Epoch: [2][700/1334]\t\\Time 0.423 (0.428)\tData 0.367 (0.361)\tLoss 4.6982 (4.6670)\tPrec@1 0.000 (1.094)\tPrec@5 0.000 (5.302)\n",
      "Epoch: [2][800/1334]\t\\Time 0.369 (0.421)\tData 0.300 (0.353)\tLoss 4.7010 (4.6705)\tPrec@1 0.000 (1.092)\tPrec@5 16.667 (5.264)\n",
      "Epoch: [2][900/1334]\t\\Time 0.424 (0.418)\tData 0.356 (0.350)\tLoss 4.8057 (4.6705)\tPrec@1 0.000 (1.101)\tPrec@5 0.000 (5.244)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.448 (0.418)\tData 0.379 (0.350)\tLoss 4.6611 (4.6703)\tPrec@1 0.000 (1.116)\tPrec@5 0.000 (5.203)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.427 (0.422)\tData 0.361 (0.354)\tLoss 4.5290 (4.6693)\tPrec@1 0.000 (1.120)\tPrec@5 16.667 (5.207)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.368 (0.422)\tData 0.301 (0.354)\tLoss 4.5966 (4.6692)\tPrec@1 8.333 (1.124)\tPrec@5 8.333 (5.218)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.535 (0.430)\tData 0.472 (0.362)\tLoss 4.6606 (4.6693)\tPrec@1 0.000 (1.108)\tPrec@5 0.000 (5.227)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.370 (0.370)\n",
      "\n",
      "Loss 4.6104 (4.6104)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 0.000 (0.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.436 (0.454)\n",
      "\n",
      "Loss 4.6462 (4.6257)\n",
      "\n",
      "Prec@1 0.000 (0.495)\n",
      "\n",
      "Prec@5 8.333 (4.620)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.127 (0.408)\n",
      "\n",
      "Loss 4.5669 (4.6245)\n",
      "\n",
      "Prec@1 0.000 (0.788)\n",
      "\n",
      "Prec@5 0.000 (5.929)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.124 (0.386)\n",
      "\n",
      "Loss 4.5260 (4.6147)\n",
      "\n",
      "Prec@1 0.000 (0.720)\n",
      "\n",
      "Prec@5 0.000 (5.869)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "Epoch: [3][0/1334]\t\\Time 0.393 (0.393)\tData 0.333 (0.333)\tLoss 4.7545 (4.7545)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [3][100/1334]\t\\Time 0.388 (0.396)\tData 0.322 (0.326)\tLoss 4.6121 (4.6758)\tPrec@1 8.333 (0.908)\tPrec@5 8.333 (4.703)\n",
      "Epoch: [3][200/1334]\t\\Time 0.465 (0.401)\tData 0.396 (0.332)\tLoss 4.6267 (4.6688)\tPrec@1 0.000 (0.954)\tPrec@5 8.333 (4.768)\n",
      "Epoch: [3][300/1334]\t\\Time 0.286 (0.401)\tData 0.218 (0.331)\tLoss 4.7536 (4.6618)\tPrec@1 8.333 (1.107)\tPrec@5 8.333 (5.094)\n",
      "Epoch: [3][400/1334]\t\\Time 0.417 (0.396)\tData 0.345 (0.326)\tLoss 4.5919 (4.6612)\tPrec@1 0.000 (1.122)\tPrec@5 0.000 (5.195)\n",
      "Epoch: [3][500/1334]\t\\Time 0.314 (0.399)\tData 0.248 (0.329)\tLoss 4.8075 (4.6603)\tPrec@1 0.000 (1.181)\tPrec@5 0.000 (5.206)\n",
      "Epoch: [3][600/1334]\t\\Time 0.247 (0.400)\tData 0.176 (0.330)\tLoss 4.6784 (4.6605)\tPrec@1 0.000 (1.151)\tPrec@5 0.000 (5.172)\n",
      "Epoch: [3][700/1334]\t\\Time 0.493 (0.395)\tData 0.424 (0.326)\tLoss 4.7752 (4.6615)\tPrec@1 0.000 (1.058)\tPrec@5 8.333 (5.029)\n",
      "Epoch: [3][800/1334]\t\\Time 0.406 (0.397)\tData 0.337 (0.327)\tLoss 4.4052 (4.6620)\tPrec@1 0.000 (1.061)\tPrec@5 33.333 (5.119)\n",
      "Epoch: [3][900/1334]\t\\Time 0.475 (0.400)\tData 0.403 (0.330)\tLoss 4.5522 (4.6649)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (5.078)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.348 (0.397)\tData 0.277 (0.327)\tLoss 4.4665 (4.6654)\tPrec@1 8.333 (1.107)\tPrec@5 8.333 (5.153)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.491 (0.398)\tData 0.423 (0.328)\tLoss 4.7680 (4.6641)\tPrec@1 0.000 (1.082)\tPrec@5 8.333 (5.185)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.576 (0.410)\tData 0.565 (0.341)\tLoss 4.7093 (4.6651)\tPrec@1 8.333 (1.075)\tPrec@5 16.667 (5.155)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.333 (0.414)\tData 0.262 (0.344)\tLoss 4.6675 (4.6643)\tPrec@1 0.000 (1.140)\tPrec@5 16.667 (5.169)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.403 (0.403)\n",
      "\n",
      "Loss 4.6102 (4.6102)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 0.000 (0.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.539 (0.547)\n",
      "\n",
      "Loss 4.6479 (4.6229)\n",
      "\n",
      "Prec@1 0.000 (0.495)\n",
      "\n",
      "Prec@5 8.333 (4.538)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.171 (0.479)\n",
      "\n",
      "Loss 4.5630 (4.6213)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (5.763)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.111 (0.435)\n",
      "\n",
      "Loss 4.5309 (4.6124)\n",
      "\n",
      "Prec@1 0.000 (0.775)\n",
      "\n",
      "Prec@5 0.000 (5.731)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "Epoch: [4][0/1334]\t\\Time 0.281 (0.281)\tData 0.242 (0.242)\tLoss 4.6684 (4.6684)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [4][100/1334]\t\\Time 0.361 (0.347)\tData 0.297 (0.279)\tLoss 4.6457 (4.6792)\tPrec@1 0.000 (0.908)\tPrec@5 0.000 (5.198)\n",
      "Epoch: [4][200/1334]\t\\Time 0.484 (0.377)\tData 0.418 (0.307)\tLoss 4.8019 (4.6696)\tPrec@1 0.000 (1.078)\tPrec@5 0.000 (5.514)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 228\u001b[0m\n\u001b[0;32m    226\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m train_model(model,LEARNING_RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m,NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[77], line 30\u001b[0m, in \u001b[0;36mlong_running.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     prevent_standby()\n\u001b[1;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     31\u001b[0m     allow_standby()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[109], line 102\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, LEARNING_RATE, NUM_EPOCHS)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=> loaded checkpoint \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m           \u001b[38;5;241m.\u001b[39mformat(args_resume, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m train(train_loader, model, criterion, optimizer, epoch)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[0;32m    104\u001b[0m prec1 \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion,epoch,save_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[94], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# measure data loading time\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# print(input['image'].shape)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_CUDA:\n\u001b[0;32m     17\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[76], line 91\u001b[0m, in \u001b[0;36mImagesWithLocationDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     87\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     89\u001b[0m img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m---> 91\u001b[0m image \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(img_name)\n\u001b[0;32m     92\u001b[0m location_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ast\u001b[38;5;241m.\u001b[39mliteral_eval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_1000\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]))\n\u001b[0;32m     93\u001b[0m landscape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandscape\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m call_plugin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimread\u001b[39m\u001b[38;5;124m'\u001b[39m, fname, plugin\u001b[38;5;241m=\u001b[39mplugin, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_args)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(imageio_imread(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\imageio\\v3.py:54\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_kwargs) \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\imageio\\plugins\\pillow.py:231\u001b[0m, in \u001b[0;36mPillowPlugin.read\u001b[1;34m(self, index, mode, rotate, apply_gamma, writeable_output, pilmode, exifrotate, as_gray)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m# will raise IO error if index >= number of frames in image\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mseek(index)\n\u001b[1;32m--> 231\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_transforms(\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image, mode, rotate, apply_gamma, writeable_output\n\u001b[0;32m    233\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\n\u001b[0;32m    236\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    237\u001b[0m         rotate\u001b[38;5;241m=\u001b[39mrotate,\n\u001b[0;32m    238\u001b[0m         apply_gamma\u001b[38;5;241m=\u001b[39mapply_gamma,\n\u001b[0;32m    239\u001b[0m         writeable_output\u001b[38;5;241m=\u001b[39mwriteable_output,\n\u001b[0;32m    240\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\imageio\\plugins\\pillow.py:314\u001b[0m, in \u001b[0;36mPillowPlugin._apply_transforms\u001b[1;34m(self, image, mode, rotate, apply_gamma, writeable_output)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;66;03m# Let pillow know that it is okay to return 16-bit\u001b[39;00m\n\u001b[0;32m    312\u001b[0m         image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m desired_mode\n\u001b[1;32m--> 314\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(image)\n\u001b[0;32m    316\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mtell(), exclude_applied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rotate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrientation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m meta:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\PIL\\Image.py:701\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    699\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 701\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\PIL\\Image.py:758\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    756\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m--> 758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101')\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "test_path ='C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_path =  'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv'\n",
    "# test_dat_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# train_size = int(split_train*0.01 * len(image_dataset))\n",
    "# test_size = len(image_dataset) - train_size\n",
    "# data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    " \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    \n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "        \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            print('Adjusted Learning rate resume from best model')\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "args_resume = f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/{model.name}_model_best.pth.tar'\n",
    "print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "checkpoint = torch.load(args_resume)\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "      .format(args_resume, checkpoint['epoch']))\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2_location3'\n",
    "\n",
    "\n",
    "numb_targets = 100\n",
    "location_vals = 170\n",
    "location_fc = nn.Sequential(\n",
    "          nn.Linear(numb_targets+location_vals, (numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "              nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),numb_targets),\n",
    "        )\n",
    "\n",
    "model.add_module('location_fc',location_fc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "location_fc1 = nn.Sequential(\n",
    "          nn.Linear(170, 170),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear(170,170),\n",
    "        )\n",
    "model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "\n",
    "location_fc2 = nn.Sequential(\n",
    "\n",
    "          nn.Linear(100,100),\n",
    "          nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(100,100),\n",
    "        )\n",
    "\n",
    "# lin_add = LinearAddLayer(100,100)\n",
    "\n",
    "# model.add_module('linear_add',lin_add)\n",
    "model.add_module('location_fc',location_fc)\n",
    "# model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "# model.add_module('location_fc2',location_fc2)\n",
    "\n",
    "def forward(self, x: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    # Reshape and permute the input tensor\n",
    "    x = self._forward_impl(x)\n",
    "    # x = self.location_fc1(x)\n",
    "    # x = self.linear_add(x,x5)\n",
    "    \n",
    "    x2 = self.location_fc1(x2)\n",
    "    combined = torch.cat((x.view(x.size(0), -1),\n",
    "                      x2.view(x2.size(0), -1)),\n",
    "                      dim=1)\n",
    "    x = self.location_fc(combined)\n",
    "    return x\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "# model.forward = forward\n",
    "model.forward = functools.partial(forward, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "# freezing trained part\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.location_fc.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.location_fc1.parameters():\n",
    "    param.requires_grad = True\n",
    "      \n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\n",
    "train_model(model,LEARNING_RATE = 1e-6,NUM_EPOCHS = 10)\n",
    "# train_model(model,LEARNING_RATE = 1e-6,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "821dc0bb-a00b-4159-b20b-f1cc45a96f88",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 17)\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "1.0000000000000002e-07\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "1.0000000000000002e-07\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "1.0000000000000002e-07\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/1334]\t\\Time 0.493 (0.493)\tData 0.323 (0.323)\tLoss 4.5686 (4.5686)\tPrec@1 8.333 (8.333)\tPrec@5 25.000 (25.000)\n",
      "Epoch: [10][100/1334]\t\\Time 0.349 (0.412)\tData 0.202 (0.261)\tLoss 4.6027 (4.6055)\tPrec@1 0.000 (1.320)\tPrec@5 0.000 (5.611)\n",
      "Epoch: [10][200/1334]\t\\Time 0.462 (0.408)\tData 0.304 (0.259)\tLoss 4.5971 (4.6054)\tPrec@1 0.000 (1.285)\tPrec@5 8.333 (5.307)\n",
      "Epoch: [10][300/1334]\t\\Time 0.460 (0.415)\tData 0.305 (0.266)\tLoss 4.5950 (4.6054)\tPrec@1 8.333 (1.190)\tPrec@5 16.667 (5.648)\n",
      "Epoch: [10][400/1334]\t\\Time 0.490 (0.417)\tData 0.329 (0.269)\tLoss 4.6283 (4.6056)\tPrec@1 0.000 (1.205)\tPrec@5 0.000 (5.424)\n",
      "Epoch: [10][500/1334]\t\\Time 0.437 (0.419)\tData 0.287 (0.270)\tLoss 4.5965 (4.6053)\tPrec@1 0.000 (1.248)\tPrec@5 0.000 (5.589)\n",
      "Epoch: [10][600/1334]\t\\Time 0.458 (0.421)\tData 0.309 (0.272)\tLoss 4.6119 (4.6056)\tPrec@1 0.000 (1.137)\tPrec@5 0.000 (5.491)\n",
      "Epoch: [10][700/1334]\t\\Time 0.388 (0.429)\tData 0.288 (0.280)\tLoss 4.6131 (4.6056)\tPrec@1 0.000 (1.106)\tPrec@5 0.000 (5.421)\n",
      "Epoch: [10][800/1334]\t\\Time 0.453 (0.432)\tData 0.300 (0.284)\tLoss 4.5947 (4.6058)\tPrec@1 0.000 (1.030)\tPrec@5 16.667 (5.358)\n",
      "Epoch: [10][900/1334]\t\\Time 0.422 (0.447)\tData 0.270 (0.297)\tLoss 4.6092 (4.6058)\tPrec@1 0.000 (0.999)\tPrec@5 0.000 (5.300)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.491 (0.449)\tData 0.332 (0.299)\tLoss 4.6092 (4.6058)\tPrec@1 0.000 (1.007)\tPrec@5 8.333 (5.186)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.470 (0.455)\tData 0.310 (0.304)\tLoss 4.6006 (4.6058)\tPrec@1 0.000 (0.992)\tPrec@5 8.333 (5.071)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.420 (0.469)\tData 0.270 (0.316)\tLoss 4.6016 (4.6057)\tPrec@1 0.000 (0.999)\tPrec@5 0.000 (5.072)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.431 (0.469)\tData 0.281 (0.315)\tLoss 4.6002 (4.6058)\tPrec@1 0.000 (1.018)\tPrec@5 8.333 (5.118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1196: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/334]\n",
      "\n",
      "Time 0.318 (0.318)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.412 (0.505)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.156 (0.462)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.144 (0.462)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "\n",
      "Epoch: [11][0/1334]\t\\Time 0.960 (0.960)\tData 0.321 (0.321)\tLoss 4.6127 (4.6127)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.482 (0.539)\tData 0.332 (0.268)\tLoss 4.6101 (4.6071)\tPrec@1 0.000 (0.825)\tPrec@5 0.000 (4.950)\n",
      "Epoch: [11][200/1334]\t\\Time 0.495 (0.550)\tData 0.338 (0.274)\tLoss 4.5960 (4.6062)\tPrec@1 0.000 (0.871)\tPrec@5 8.333 (5.431)\n",
      "Epoch: [11][300/1334]\t\\Time 0.404 (0.558)\tData 0.255 (0.273)\tLoss 4.6148 (4.6062)\tPrec@1 0.000 (0.941)\tPrec@5 8.333 (5.122)\n",
      "Epoch: [11][400/1334]\t\\Time 0.336 (0.565)\tData 0.186 (0.269)\tLoss 4.6156 (4.6062)\tPrec@1 0.000 (0.977)\tPrec@5 0.000 (4.904)\n",
      "Epoch: [11][500/1334]\t\\Time 0.419 (0.549)\tData 0.274 (0.269)\tLoss 4.6043 (4.6063)\tPrec@1 0.000 (1.015)\tPrec@5 0.000 (4.907)\n",
      "Epoch: [11][600/1334]\t\\Time 0.388 (0.547)\tData 0.238 (0.269)\tLoss 4.6081 (4.6063)\tPrec@1 0.000 (0.998)\tPrec@5 0.000 (4.853)\n",
      "Epoch: [11][700/1334]\t\\Time 0.375 (0.555)\tData 0.231 (0.268)\tLoss 4.5969 (4.6061)\tPrec@1 0.000 (0.999)\tPrec@5 8.333 (4.922)\n",
      "Epoch: [11][800/1334]\t\\Time 0.471 (0.559)\tData 0.321 (0.268)\tLoss 4.5949 (4.6062)\tPrec@1 0.000 (1.051)\tPrec@5 16.667 (4.775)\n",
      "Epoch: [11][900/1334]\t\\Time 0.411 (0.565)\tData 0.271 (0.268)\tLoss 4.6060 (4.6062)\tPrec@1 0.000 (1.036)\tPrec@5 0.000 (4.763)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.359 (0.563)\tData 0.199 (0.268)\tLoss 4.6106 (4.6060)\tPrec@1 8.333 (1.032)\tPrec@5 8.333 (4.887)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.313 (0.571)\tData 0.151 (0.267)\tLoss 4.6029 (4.6060)\tPrec@1 0.000 (1.029)\tPrec@5 8.333 (4.829)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.384 (0.574)\tData 0.224 (0.267)\tLoss 4.6060 (4.6061)\tPrec@1 0.000 (1.013)\tPrec@5 0.000 (4.829)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.411 (0.578)\tData 0.250 (0.266)\tLoss 4.6058 (4.6060)\tPrec@1 0.000 (1.025)\tPrec@5 0.000 (4.855)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.314 (0.314)\n",
      "\n",
      "Loss 4.6027 (4.6027)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.760 (0.484)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.959 (0.456)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.141 (0.448)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "\n",
      "Epoch: [12][0/1334]\t\\Time 0.437 (0.437)\tData 0.251 (0.251)\tLoss 4.6116 (4.6116)\tPrec@1 0.000 (0.000)\tPrec@5 16.667 (16.667)\n",
      "Epoch: [12][100/1334]\t\\Time 0.417 (0.447)\tData 0.263 (0.277)\tLoss 4.6061 (4.6053)\tPrec@1 0.000 (1.403)\tPrec@5 0.000 (6.271)\n",
      "Epoch: [12][200/1334]\t\\Time 0.473 (0.466)\tData 0.325 (0.276)\tLoss 4.6051 (4.6048)\tPrec@1 0.000 (1.285)\tPrec@5 8.333 (6.136)\n",
      "Epoch: [12][300/1334]\t\\Time 0.451 (0.493)\tData 0.291 (0.271)\tLoss 4.6101 (4.6055)\tPrec@1 0.000 (1.024)\tPrec@5 8.333 (5.454)\n",
      "Epoch: [12][400/1334]\t\\Time 0.436 (0.495)\tData 0.284 (0.272)\tLoss 4.5986 (4.6053)\tPrec@1 0.000 (1.039)\tPrec@5 16.667 (5.445)\n",
      "Epoch: [12][500/1334]\t\\Time 0.447 (0.488)\tData 0.327 (0.273)\tLoss 4.6108 (4.6051)\tPrec@1 0.000 (1.114)\tPrec@5 8.333 (5.439)\n",
      "Epoch: [12][600/1334]\t\\Time 0.323 (0.482)\tData 0.163 (0.274)\tLoss 4.5962 (4.6054)\tPrec@1 0.000 (0.998)\tPrec@5 0.000 (5.144)\n",
      "Epoch: [12][700/1334]\t\\Time 0.431 (0.479)\tData 0.271 (0.276)\tLoss 4.6173 (4.6055)\tPrec@1 0.000 (1.010)\tPrec@5 0.000 (5.147)\n",
      "Epoch: [12][800/1334]\t\\Time 0.479 (0.477)\tData 0.328 (0.276)\tLoss 4.6044 (4.6056)\tPrec@1 0.000 (0.999)\tPrec@5 0.000 (5.119)\n",
      "Epoch: [12][900/1334]\t\\Time 0.384 (0.477)\tData 0.233 (0.276)\tLoss 4.5978 (4.6057)\tPrec@1 0.000 (1.008)\tPrec@5 0.000 (5.170)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.410 (0.474)\tData 0.250 (0.277)\tLoss 4.6115 (4.6058)\tPrec@1 0.000 (1.024)\tPrec@5 0.000 (5.153)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.453 (0.472)\tData 0.292 (0.278)\tLoss 4.6208 (4.6058)\tPrec@1 0.000 (1.007)\tPrec@5 0.000 (5.071)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.520 (0.469)\tData 0.360 (0.278)\tLoss 4.6160 (4.6058)\tPrec@1 0.000 (1.027)\tPrec@5 0.000 (5.058)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.458 (0.469)\tData 0.277 (0.279)\tLoss 4.6098 (4.6059)\tPrec@1 0.000 (0.999)\tPrec@5 16.667 (5.003)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 4.6027 (4.6027)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.430 (0.443)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.130 (0.402)\n",
      "\n",
      "Loss 4.6015 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.127 (0.383)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "\n",
      "Epoch: [13][0/1334]\t\\Time 0.493 (0.493)\tData 0.336 (0.336)\tLoss 4.6173 (4.6173)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.418 (0.437)\tData 0.265 (0.283)\tLoss 4.5735 (4.6077)\tPrec@1 8.333 (0.825)\tPrec@5 25.000 (4.455)\n",
      "Epoch: [13][200/1334]\t\\Time 0.400 (0.433)\tData 0.239 (0.280)\tLoss 4.5948 (4.6057)\tPrec@1 0.000 (1.036)\tPrec@5 0.000 (5.556)\n",
      "Epoch: [13][300/1334]\t\\Time 0.451 (0.436)\tData 0.282 (0.282)\tLoss 4.6152 (4.6060)\tPrec@1 0.000 (0.969)\tPrec@5 16.667 (4.983)\n",
      "Epoch: [13][400/1334]\t\\Time 0.290 (0.453)\tData 0.170 (0.280)\tLoss 4.6085 (4.6059)\tPrec@1 0.000 (0.873)\tPrec@5 8.333 (4.925)\n",
      "Epoch: [13][500/1334]\t\\Time 0.396 (0.465)\tData 0.236 (0.278)\tLoss 4.6102 (4.6058)\tPrec@1 0.000 (0.815)\tPrec@5 8.333 (4.790)\n",
      "Epoch: [13][600/1334]\t\\Time 5.111 (0.528)\tData 0.280 (0.279)\tLoss 4.6167 (4.6061)\tPrec@1 0.000 (0.776)\tPrec@5 0.000 (4.603)\n",
      "Epoch: [13][700/1334]\t\\Time 5.132 (0.672)\tData 0.281 (0.275)\tLoss 4.6100 (4.6061)\tPrec@1 0.000 (0.785)\tPrec@5 8.333 (4.648)\n",
      "Epoch: [13][800/1334]\t\\Time 8.057 (0.830)\tData 0.330 (0.272)\tLoss 4.6133 (4.6062)\tPrec@1 0.000 (0.770)\tPrec@5 0.000 (4.619)\n",
      "Epoch: [13][900/1334]\t\\Time 0.429 (0.872)\tData 0.288 (0.270)\tLoss 4.6053 (4.6062)\tPrec@1 0.000 (0.805)\tPrec@5 0.000 (4.680)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.684 (0.990)\tData 0.262 (0.266)\tLoss 4.5880 (4.6060)\tPrec@1 8.333 (0.841)\tPrec@5 8.333 (4.737)\n",
      "Epoch: [13][1100/1334]\t\\Time 1.277 (1.064)\tData 0.217 (0.264)\tLoss 4.5982 (4.6059)\tPrec@1 0.000 (0.855)\tPrec@5 0.000 (4.927)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.548 (1.140)\tData 0.270 (0.295)\tLoss 4.5909 (4.6059)\tPrec@1 8.333 (0.853)\tPrec@5 8.333 (4.920)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.423 (1.116)\tData 0.260 (0.307)\tLoss 4.6299 (4.6059)\tPrec@1 0.000 (0.865)\tPrec@5 0.000 (4.926)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.321 (0.321)\n",
      "\n",
      "Loss 4.6028 (4.6028)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.422 (0.379)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.132 (0.357)\n",
      "\n",
      "Loss 4.6015 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.161 (0.342)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000001\n",
      "\n",
      "Epoch: [14][0/1334]\t\\Time 0.411 (0.411)\tData 0.251 (0.251)\tLoss 4.6182 (4.6182)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [14][100/1334]\t\\Time 0.411 (0.416)\tData 0.260 (0.266)\tLoss 4.5782 (4.6051)\tPrec@1 0.000 (1.073)\tPrec@5 8.333 (5.941)\n",
      "Epoch: [14][200/1334]\t\\Time 0.458 (0.425)\tData 0.308 (0.274)\tLoss 4.6067 (4.6063)\tPrec@1 0.000 (0.995)\tPrec@5 0.000 (4.975)\n",
      "Epoch: [14][300/1334]\t\\Time 0.421 (0.425)\tData 0.271 (0.275)\tLoss 4.6095 (4.6059)\tPrec@1 0.000 (0.941)\tPrec@5 0.000 (4.790)\n",
      "Epoch: [14][400/1334]\t\\Time 0.421 (0.426)\tData 0.261 (0.275)\tLoss 4.6220 (4.6055)\tPrec@1 0.000 (1.060)\tPrec@5 0.000 (5.175)\n",
      "Epoch: [14][500/1334]\t\\Time 0.390 (0.427)\tData 0.230 (0.276)\tLoss 4.6025 (4.6057)\tPrec@1 0.000 (1.065)\tPrec@5 0.000 (5.190)\n",
      "Epoch: [14][600/1334]\t\\Time 0.405 (0.426)\tData 0.245 (0.276)\tLoss 4.6137 (4.6058)\tPrec@1 0.000 (1.095)\tPrec@5 8.333 (5.130)\n",
      "Epoch: [14][700/1334]\t\\Time 0.430 (0.427)\tData 0.280 (0.276)\tLoss 4.6075 (4.6057)\tPrec@1 0.000 (1.034)\tPrec@5 8.333 (5.147)\n",
      "Epoch: [14][800/1334]\t\\Time 0.411 (0.428)\tData 0.251 (0.277)\tLoss 4.5989 (4.6058)\tPrec@1 0.000 (1.020)\tPrec@5 8.333 (5.098)\n",
      "Epoch: [14][900/1334]\t\\Time 0.390 (0.429)\tData 0.240 (0.278)\tLoss 4.6077 (4.6056)\tPrec@1 0.000 (1.054)\tPrec@5 8.333 (5.050)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.420 (0.428)\tData 0.270 (0.277)\tLoss 4.6231 (4.6057)\tPrec@1 0.000 (1.107)\tPrec@5 0.000 (5.020)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.466 (0.428)\tData 0.306 (0.277)\tLoss 4.5912 (4.6057)\tPrec@1 0.000 (1.082)\tPrec@5 16.667 (5.026)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.450 (0.429)\tData 0.300 (0.278)\tLoss 4.5993 (4.6058)\tPrec@1 0.000 (1.034)\tPrec@5 0.000 (4.975)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.429 (0.427)\tData 0.278 (0.276)\tLoss 4.6094 (4.6058)\tPrec@1 0.000 (1.025)\tPrec@5 0.000 (4.945)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.320 (0.320)\n",
      "\n",
      "Loss 4.6029 (4.6029)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.419 (0.391)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.150 (0.368)\n",
      "\n",
      "Loss 4.6015 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.144 (0.350)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [15][0/1334]\t\\Time 0.469 (0.469)\tData 0.309 (0.309)\tLoss 4.6142 (4.6142)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [15][100/1334]\t\\Time 0.430 (0.424)\tData 0.270 (0.271)\tLoss 4.6212 (4.6056)\tPrec@1 0.000 (0.908)\tPrec@5 0.000 (4.043)\n",
      "Epoch: [15][200/1334]\t\\Time 0.434 (0.431)\tData 0.274 (0.278)\tLoss 4.6043 (4.6057)\tPrec@1 0.000 (0.995)\tPrec@5 0.000 (4.809)\n",
      "Epoch: [15][300/1334]\t\\Time 0.461 (0.428)\tData 0.312 (0.275)\tLoss 4.6007 (4.6052)\tPrec@1 0.000 (1.107)\tPrec@5 0.000 (4.762)\n",
      "Epoch: [15][400/1334]\t\\Time 0.350 (0.428)\tData 0.200 (0.275)\tLoss 4.6030 (4.6060)\tPrec@1 8.333 (1.101)\tPrec@5 8.333 (4.717)\n",
      "Epoch: [15][500/1334]\t\\Time 0.424 (0.429)\tData 0.281 (0.275)\tLoss 4.6025 (4.6063)\tPrec@1 0.000 (1.048)\tPrec@5 0.000 (4.607)\n",
      "Epoch: [15][600/1334]\t\\Time 0.420 (0.428)\tData 0.290 (0.274)\tLoss 4.5904 (4.6061)\tPrec@1 0.000 (1.165)\tPrec@5 16.667 (4.798)\n",
      "Epoch: [15][700/1334]\t\\Time 0.401 (0.428)\tData 0.250 (0.275)\tLoss 4.5939 (4.6061)\tPrec@1 0.000 (1.129)\tPrec@5 8.333 (4.826)\n",
      "Epoch: [15][800/1334]\t\\Time 0.410 (0.429)\tData 0.270 (0.275)\tLoss 4.5974 (4.6061)\tPrec@1 0.000 (1.124)\tPrec@5 8.333 (4.859)\n",
      "Epoch: [15][900/1334]\t\\Time 0.400 (0.427)\tData 0.280 (0.274)\tLoss 4.6122 (4.6061)\tPrec@1 0.000 (1.138)\tPrec@5 0.000 (4.902)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.490 (0.428)\tData 0.330 (0.275)\tLoss 4.6041 (4.6058)\tPrec@1 0.000 (1.166)\tPrec@5 16.667 (4.995)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.412 (0.429)\tData 0.261 (0.275)\tLoss 4.6061 (4.6059)\tPrec@1 0.000 (1.158)\tPrec@5 8.333 (4.935)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.461 (0.429)\tData 0.301 (0.276)\tLoss 4.6002 (4.6060)\tPrec@1 0.000 (1.117)\tPrec@5 16.667 (4.906)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.509 (0.435)\tData 0.348 (0.276)\tLoss 4.6045 (4.6059)\tPrec@1 8.333 (1.115)\tPrec@5 16.667 (4.823)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.327 (0.327)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 1.204 (0.453)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.119 (1.086)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.142 (1.237)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [16][0/1334]\t\\Time 0.656 (0.656)\tData 0.241 (0.241)\tLoss 4.6234 (4.6234)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.379 (1.645)\tData 0.250 (0.251)\tLoss 4.6157 (4.6065)\tPrec@1 0.000 (0.578)\tPrec@5 0.000 (4.043)\n",
      "Epoch: [16][200/1334]\t\\Time 1.378 (1.497)\tData 0.194 (0.248)\tLoss 4.6090 (4.6063)\tPrec@1 0.000 (0.995)\tPrec@5 0.000 (4.892)\n",
      "Epoch: [16][300/1334]\t\\Time 0.409 (1.613)\tData 0.259 (0.248)\tLoss 4.5980 (4.6066)\tPrec@1 0.000 (0.914)\tPrec@5 0.000 (4.900)\n",
      "Epoch: [16][400/1334]\t\\Time 0.440 (1.316)\tData 0.290 (0.252)\tLoss 4.5991 (4.6067)\tPrec@1 0.000 (0.894)\tPrec@5 8.333 (4.842)\n",
      "Epoch: [16][500/1334]\t\\Time 2.409 (1.235)\tData 0.285 (0.255)\tLoss 4.6107 (4.6064)\tPrec@1 0.000 (0.931)\tPrec@5 0.000 (4.790)\n",
      "Epoch: [16][600/1334]\t\\Time 0.427 (1.289)\tData 0.221 (0.254)\tLoss 4.6001 (4.6064)\tPrec@1 0.000 (0.915)\tPrec@5 8.333 (4.950)\n",
      "Epoch: [16][700/1334]\t\\Time 0.389 (1.297)\tData 0.239 (0.253)\tLoss 4.6121 (4.6065)\tPrec@1 0.000 (1.022)\tPrec@5 8.333 (5.040)\n",
      "Epoch: [16][800/1334]\t\\Time 0.389 (1.212)\tData 0.229 (0.253)\tLoss 4.6029 (4.6064)\tPrec@1 0.000 (1.040)\tPrec@5 0.000 (5.171)\n",
      "Epoch: [16][900/1334]\t\\Time 0.400 (1.137)\tData 0.251 (0.255)\tLoss 4.5963 (4.6064)\tPrec@1 0.000 (1.054)\tPrec@5 8.333 (5.105)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.730 (1.082)\tData 0.311 (0.257)\tLoss 4.6079 (4.6063)\tPrec@1 0.000 (1.099)\tPrec@5 0.000 (5.020)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.448 (1.045)\tData 0.217 (0.257)\tLoss 4.5966 (4.6060)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (4.995)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.785 (1.023)\tData 0.248 (0.258)\tLoss 4.5981 (4.6061)\tPrec@1 0.000 (1.069)\tPrec@5 0.000 (5.044)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.484 (1.000)\tData 0.329 (0.259)\tLoss 4.6035 (4.6060)\tPrec@1 0.000 (1.063)\tPrec@5 0.000 (4.990)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.292 (0.292)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.411 (2.245)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.140 (1.891)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.393 (1.446)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [17][0/1334]\t\\Time 0.697 (0.697)\tData 0.317 (0.317)\tLoss 4.6074 (4.6074)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [17][100/1334]\t\\Time 0.457 (1.302)\tData 0.308 (0.322)\tLoss 4.5989 (4.6053)\tPrec@1 0.000 (0.990)\tPrec@5 0.000 (5.363)\n",
      "Epoch: [17][200/1334]\t\\Time 1.384 (1.004)\tData 0.279 (0.323)\tLoss 4.5796 (4.6060)\tPrec@1 8.333 (1.244)\tPrec@5 25.000 (5.390)\n",
      "Epoch: [17][300/1334]\t\\Time 3.125 (0.910)\tData 0.335 (0.327)\tLoss 4.6125 (4.6058)\tPrec@1 8.333 (1.080)\tPrec@5 8.333 (5.122)\n",
      "Epoch: [17][400/1334]\t\\Time 0.799 (1.305)\tData 0.310 (0.501)\tLoss 4.6204 (4.6059)\tPrec@1 0.000 (1.185)\tPrec@5 0.000 (5.154)\n",
      "Epoch: [17][500/1334]\t\\Time 0.485 (1.143)\tData 0.374 (0.461)\tLoss 4.5855 (4.6061)\tPrec@1 0.000 (1.131)\tPrec@5 16.667 (5.057)\n",
      "Epoch: [17][600/1334]\t\\Time 0.422 (1.072)\tData 0.267 (0.452)\tLoss 4.6117 (4.6058)\tPrec@1 0.000 (1.068)\tPrec@5 8.333 (5.116)\n",
      "Epoch: [17][700/1334]\t\\Time 0.462 (0.982)\tData 0.312 (0.429)\tLoss 4.5885 (4.6057)\tPrec@1 8.333 (1.046)\tPrec@5 8.333 (5.147)\n",
      "Epoch: [17][800/1334]\t\\Time 0.437 (0.914)\tData 0.290 (0.411)\tLoss 4.6112 (4.6055)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (5.202)\n",
      "Epoch: [17][900/1334]\t\\Time 0.406 (0.858)\tData 0.250 (0.394)\tLoss 4.6108 (4.6058)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (5.105)\n",
      "Epoch: [17][1000/1334]\t\\Time 0.370 (0.814)\tData 0.220 (0.381)\tLoss 4.5938 (4.6057)\tPrec@1 0.000 (1.057)\tPrec@5 8.333 (5.053)\n",
      "Epoch: [17][1100/1334]\t\\Time 0.492 (0.778)\tData 0.338 (0.371)\tLoss 4.6064 (4.6057)\tPrec@1 0.000 (1.037)\tPrec@5 8.333 (4.980)\n",
      "Epoch: [17][1200/1334]\t\\Time 0.419 (0.749)\tData 0.261 (0.363)\tLoss 4.6217 (4.6058)\tPrec@1 0.000 (1.048)\tPrec@5 0.000 (5.072)\n",
      "Epoch: [17][1300/1334]\t\\Time 0.387 (0.725)\tData 0.230 (0.357)\tLoss 4.6043 (4.6058)\tPrec@1 0.000 (1.050)\tPrec@5 0.000 (5.105)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.320 (0.320)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.431 (0.400)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.147 (0.374)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.140 (0.354)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [18][0/1334]\t\\Time 0.400 (0.400)\tData 0.240 (0.240)\tLoss 4.6223 (4.6223)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [18][100/1334]\t\\Time 0.370 (0.432)\tData 0.260 (0.281)\tLoss 4.6121 (4.6071)\tPrec@1 0.000 (0.743)\tPrec@5 0.000 (5.446)\n",
      "Epoch: [18][200/1334]\t\\Time 0.360 (0.429)\tData 0.210 (0.277)\tLoss 4.6105 (4.6074)\tPrec@1 0.000 (0.912)\tPrec@5 0.000 (5.100)\n",
      "Epoch: [18][300/1334]\t\\Time 0.405 (0.429)\tData 0.255 (0.277)\tLoss 4.5817 (4.6069)\tPrec@1 8.333 (1.024)\tPrec@5 16.667 (5.011)\n",
      "Epoch: [18][400/1334]\t\\Time 0.360 (0.430)\tData 0.230 (0.278)\tLoss 4.5954 (4.6065)\tPrec@1 8.333 (1.039)\tPrec@5 8.333 (4.946)\n",
      "Epoch: [18][500/1334]\t\\Time 0.441 (0.430)\tData 0.291 (0.278)\tLoss 4.6058 (4.6062)\tPrec@1 0.000 (1.114)\tPrec@5 0.000 (5.040)\n",
      "Epoch: [18][600/1334]\t\\Time 0.440 (0.427)\tData 0.290 (0.276)\tLoss 4.5985 (4.6060)\tPrec@1 8.333 (1.068)\tPrec@5 8.333 (5.089)\n",
      "Epoch: [18][700/1334]\t\\Time 0.440 (0.428)\tData 0.297 (0.276)\tLoss 4.6236 (4.6059)\tPrec@1 0.000 (0.987)\tPrec@5 0.000 (5.100)\n",
      "Epoch: [18][800/1334]\t\\Time 0.440 (0.428)\tData 0.290 (0.276)\tLoss 4.5941 (4.6058)\tPrec@1 0.000 (0.947)\tPrec@5 8.333 (5.087)\n",
      "Epoch: [18][900/1334]\t\\Time 0.450 (0.428)\tData 0.300 (0.276)\tLoss 4.6135 (4.6060)\tPrec@1 8.333 (0.916)\tPrec@5 8.333 (4.985)\n",
      "Epoch: [18][1000/1334]\t\\Time 0.402 (0.428)\tData 0.252 (0.276)\tLoss 4.5784 (4.6058)\tPrec@1 0.000 (0.907)\tPrec@5 16.667 (5.020)\n",
      "Epoch: [18][1100/1334]\t\\Time 0.480 (0.429)\tData 0.320 (0.277)\tLoss 4.6015 (4.6058)\tPrec@1 0.000 (0.946)\tPrec@5 0.000 (5.003)\n",
      "Epoch: [18][1200/1334]\t\\Time 0.402 (0.429)\tData 0.252 (0.277)\tLoss 4.6024 (4.6059)\tPrec@1 0.000 (0.916)\tPrec@5 0.000 (4.961)\n",
      "Epoch: [18][1300/1334]\t\\Time 0.450 (0.434)\tData 0.300 (0.282)\tLoss 4.6094 (4.6058)\tPrec@1 0.000 (0.929)\tPrec@5 0.000 (5.035)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.420 (0.398)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.149 (0.373)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.140 (0.353)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [19][0/1334]\t\\Time 0.411 (0.411)\tData 0.251 (0.251)\tLoss 4.6155 (4.6155)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [19][100/1334]\t\\Time 0.350 (0.423)\tData 0.190 (0.270)\tLoss 4.5880 (4.6046)\tPrec@1 8.333 (1.238)\tPrec@5 8.333 (5.116)\n",
      "Epoch: [19][200/1334]\t\\Time 0.420 (0.423)\tData 0.270 (0.271)\tLoss 4.6166 (4.6052)\tPrec@1 0.000 (1.244)\tPrec@5 0.000 (5.182)\n",
      "Epoch: [19][300/1334]\t\\Time 0.360 (0.425)\tData 0.220 (0.272)\tLoss 4.6062 (4.6056)\tPrec@1 0.000 (1.163)\tPrec@5 16.667 (4.845)\n",
      "Epoch: [19][400/1334]\t\\Time 0.448 (0.428)\tData 0.283 (0.275)\tLoss 4.5959 (4.6057)\tPrec@1 0.000 (1.039)\tPrec@5 8.333 (4.967)\n",
      "Epoch: [19][500/1334]\t\\Time 0.310 (0.429)\tData 0.150 (0.277)\tLoss 4.5986 (4.6057)\tPrec@1 0.000 (0.931)\tPrec@5 0.000 (4.923)\n",
      "Epoch: [19][600/1334]\t\\Time 0.383 (0.429)\tData 0.262 (0.277)\tLoss 4.6154 (4.6057)\tPrec@1 0.000 (0.887)\tPrec@5 0.000 (5.075)\n",
      "Epoch: [19][700/1334]\t\\Time 0.456 (0.429)\tData 0.326 (0.277)\tLoss 4.6159 (4.6056)\tPrec@1 0.000 (0.892)\tPrec@5 0.000 (5.147)\n",
      "Epoch: [19][800/1334]\t\\Time 0.402 (0.428)\tData 0.243 (0.276)\tLoss 4.5986 (4.6055)\tPrec@1 0.000 (0.895)\tPrec@5 8.333 (5.046)\n",
      "Epoch: [19][900/1334]\t\\Time 0.430 (0.428)\tData 0.300 (0.276)\tLoss 4.5999 (4.6055)\tPrec@1 0.000 (0.897)\tPrec@5 0.000 (5.004)\n",
      "Epoch: [19][1000/1334]\t\\Time 0.391 (0.427)\tData 0.232 (0.276)\tLoss 4.5867 (4.6055)\tPrec@1 0.000 (0.941)\tPrec@5 0.000 (5.012)\n",
      "Epoch: [19][1100/1334]\t\\Time 0.435 (0.427)\tData 0.275 (0.276)\tLoss 4.6140 (4.6056)\tPrec@1 0.000 (0.916)\tPrec@5 0.000 (5.026)\n",
      "Epoch: [19][1200/1334]\t\\Time 0.480 (0.427)\tData 0.325 (0.276)\tLoss 4.6000 (4.6056)\tPrec@1 8.333 (0.902)\tPrec@5 8.333 (5.024)\n",
      "Epoch: [19][1300/1334]\t\\Time 0.397 (0.428)\tData 0.237 (0.277)\tLoss 4.6146 (4.6059)\tPrec@1 0.000 (0.871)\tPrec@5 0.000 (5.003)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.324 (0.324)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.431 (0.390)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.137 (0.369)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.122 (0.352)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_checkpoint.pth.tar' (epoch 20)\n",
      "\n",
      "[INFO] Training Started\n",
      "1.0000000000000003e-11\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [20][0/1334]\t\\Time 0.443 (0.443)\tData 0.270 (0.270)\tLoss 4.6119 (4.6119)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [20][100/1334]\t\\Time 0.482 (0.419)\tData 0.324 (0.269)\tLoss 4.6031 (4.6057)\tPrec@1 0.000 (1.155)\tPrec@5 8.333 (5.363)\n",
      "Epoch: [20][200/1334]\t\\Time 0.411 (0.420)\tData 0.261 (0.269)\tLoss 4.6018 (4.6051)\tPrec@1 0.000 (1.119)\tPrec@5 0.000 (5.514)\n",
      "Epoch: [20][300/1334]\t\\Time 0.453 (0.423)\tData 0.303 (0.272)\tLoss 4.6093 (4.6055)\tPrec@1 0.000 (1.135)\tPrec@5 0.000 (5.454)\n",
      "Epoch: [20][400/1334]\t\\Time 0.482 (0.424)\tData 0.322 (0.273)\tLoss 4.5904 (4.6056)\tPrec@1 8.333 (1.018)\tPrec@5 8.333 (5.299)\n",
      "Epoch: [20][500/1334]\t\\Time 0.480 (0.427)\tData 0.325 (0.276)\tLoss 4.5942 (4.6055)\tPrec@1 0.000 (0.981)\tPrec@5 0.000 (5.106)\n",
      "Epoch: [20][600/1334]\t\\Time 0.423 (0.428)\tData 0.264 (0.277)\tLoss 4.6098 (4.6059)\tPrec@1 0.000 (0.943)\tPrec@5 0.000 (5.006)\n",
      "Epoch: [20][700/1334]\t\\Time 0.488 (0.428)\tData 0.328 (0.276)\tLoss 4.5963 (4.6060)\tPrec@1 0.000 (0.987)\tPrec@5 16.667 (5.195)\n",
      "Epoch: [20][800/1334]\t\\Time 0.374 (0.428)\tData 0.224 (0.277)\tLoss 4.6016 (4.6060)\tPrec@1 0.000 (0.968)\tPrec@5 0.000 (5.150)\n",
      "Epoch: [20][900/1334]\t\\Time 0.421 (0.429)\tData 0.271 (0.278)\tLoss 4.6153 (4.6060)\tPrec@1 0.000 (1.008)\tPrec@5 0.000 (5.161)\n",
      "Epoch: [20][1000/1334]\t\\Time 0.509 (0.429)\tData 0.349 (0.277)\tLoss 4.6071 (4.6060)\tPrec@1 0.000 (1.007)\tPrec@5 0.000 (5.078)\n",
      "Epoch: [20][1100/1334]\t\\Time 0.428 (0.429)\tData 0.271 (0.278)\tLoss 4.6109 (4.6058)\tPrec@1 0.000 (0.992)\tPrec@5 0.000 (5.094)\n",
      "Epoch: [20][1200/1334]\t\\Time 0.444 (0.429)\tData 0.283 (0.278)\tLoss 4.6254 (4.6058)\tPrec@1 0.000 (1.027)\tPrec@5 0.000 (5.100)\n",
      "Epoch: [20][1300/1334]\t\\Time 0.483 (0.429)\tData 0.322 (0.278)\tLoss 4.6049 (4.6058)\tPrec@1 0.000 (1.006)\tPrec@5 0.000 (5.067)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.440 (0.395)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.141 (0.367)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.131 (0.349)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "Epoch: [21][0/1334]\t\\Time 0.465 (0.465)\tData 0.290 (0.290)\tLoss 4.5934 (4.5934)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [21][100/1334]\t\\Time 0.413 (0.418)\tData 0.264 (0.271)\tLoss 4.6144 (4.6059)\tPrec@1 0.000 (0.908)\tPrec@5 0.000 (4.785)\n",
      "Epoch: [21][200/1334]\t\\Time 0.418 (0.423)\tData 0.258 (0.273)\tLoss 4.6015 (4.6058)\tPrec@1 0.000 (0.912)\tPrec@5 8.333 (4.726)\n",
      "Epoch: [21][300/1334]\t\\Time 0.332 (0.426)\tData 0.212 (0.276)\tLoss 4.6174 (4.6057)\tPrec@1 0.000 (0.997)\tPrec@5 8.333 (5.066)\n",
      "Epoch: [21][400/1334]\t\\Time 0.495 (0.426)\tData 0.334 (0.275)\tLoss 4.5973 (4.6055)\tPrec@1 0.000 (0.977)\tPrec@5 0.000 (5.029)\n",
      "Epoch: [21][500/1334]\t\\Time 0.460 (0.427)\tData 0.307 (0.277)\tLoss 4.5943 (4.6056)\tPrec@1 0.000 (0.965)\tPrec@5 8.333 (4.907)\n",
      "Epoch: [21][600/1334]\t\\Time 0.411 (0.427)\tData 0.282 (0.277)\tLoss 4.5954 (4.6053)\tPrec@1 16.667 (1.040)\tPrec@5 16.667 (5.130)\n",
      "Epoch: [21][700/1334]\t\\Time 0.419 (0.426)\tData 0.269 (0.276)\tLoss 4.6061 (4.6055)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (5.112)\n",
      "Epoch: [21][800/1334]\t\\Time 0.441 (0.427)\tData 0.293 (0.277)\tLoss 4.5808 (4.6056)\tPrec@1 0.000 (1.020)\tPrec@5 0.000 (5.056)\n",
      "Epoch: [21][900/1334]\t\\Time 0.452 (0.427)\tData 0.302 (0.276)\tLoss 4.6114 (4.6058)\tPrec@1 0.000 (1.008)\tPrec@5 8.333 (5.096)\n",
      "Epoch: [21][1000/1334]\t\\Time 0.404 (0.428)\tData 0.284 (0.277)\tLoss 4.5863 (4.6059)\tPrec@1 8.333 (0.999)\tPrec@5 8.333 (5.020)\n",
      "Epoch: [21][1100/1334]\t\\Time 0.426 (0.428)\tData 0.302 (0.278)\tLoss 4.6182 (4.6059)\tPrec@1 0.000 (1.029)\tPrec@5 0.000 (5.011)\n",
      "Epoch: [21][1200/1334]\t\\Time 0.432 (0.428)\tData 0.277 (0.278)\tLoss 4.5945 (4.6060)\tPrec@1 0.000 (1.020)\tPrec@5 8.333 (5.010)\n",
      "Epoch: [21][1300/1334]\t\\Time 0.462 (0.428)\tData 0.315 (0.278)\tLoss 4.6110 (4.6060)\tPrec@1 0.000 (1.012)\tPrec@5 0.000 (4.977)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.301 (0.301)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.443 (0.402)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.132 (0.375)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.131 (0.356)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "Epoch: [22][0/1334]\t\\Time 0.511 (0.511)\tData 0.361 (0.361)\tLoss 4.6057 (4.6057)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [22][100/1334]\t\\Time 0.471 (0.422)\tData 0.321 (0.270)\tLoss 4.6203 (4.6058)\tPrec@1 0.000 (0.825)\tPrec@5 8.333 (5.033)\n",
      "Epoch: [22][200/1334]\t\\Time 0.441 (0.427)\tData 0.281 (0.276)\tLoss 4.6055 (4.6053)\tPrec@1 0.000 (0.954)\tPrec@5 0.000 (5.017)\n",
      "Epoch: [22][300/1334]\t\\Time 0.413 (0.426)\tData 0.251 (0.275)\tLoss 4.6014 (4.6051)\tPrec@1 0.000 (1.052)\tPrec@5 0.000 (5.094)\n",
      "Epoch: [22][400/1334]\t\\Time 0.463 (0.427)\tData 0.302 (0.276)\tLoss 4.5972 (4.6053)\tPrec@1 0.000 (1.143)\tPrec@5 8.333 (4.884)\n",
      "Epoch: [22][500/1334]\t\\Time 0.442 (0.429)\tData 0.292 (0.278)\tLoss 4.6164 (4.6053)\tPrec@1 0.000 (1.214)\tPrec@5 0.000 (5.057)\n",
      "Epoch: [22][600/1334]\t\\Time 0.421 (0.429)\tData 0.251 (0.277)\tLoss 4.6136 (4.6054)\tPrec@1 0.000 (1.234)\tPrec@5 0.000 (5.047)\n",
      "Epoch: [22][700/1334]\t\\Time 0.511 (0.429)\tData 0.349 (0.278)\tLoss 4.6087 (4.6056)\tPrec@1 0.000 (1.189)\tPrec@5 0.000 (4.945)\n",
      "Epoch: [22][800/1334]\t\\Time 0.416 (0.429)\tData 0.271 (0.277)\tLoss 4.5877 (4.6059)\tPrec@1 0.000 (1.124)\tPrec@5 8.333 (4.765)\n",
      "Epoch: [22][900/1334]\t\\Time 0.432 (0.429)\tData 0.282 (0.277)\tLoss 4.6032 (4.6060)\tPrec@1 0.000 (1.064)\tPrec@5 0.000 (4.800)\n",
      "Epoch: [22][1000/1334]\t\\Time 0.388 (0.428)\tData 0.232 (0.277)\tLoss 4.6118 (4.6059)\tPrec@1 0.000 (1.049)\tPrec@5 16.667 (4.845)\n",
      "Epoch: [22][1100/1334]\t\\Time 0.435 (0.429)\tData 0.274 (0.277)\tLoss 4.5947 (4.6060)\tPrec@1 0.000 (1.052)\tPrec@5 16.667 (4.874)\n",
      "Epoch: [22][1200/1334]\t\\Time 0.401 (0.428)\tData 0.249 (0.277)\tLoss 4.6061 (4.6059)\tPrec@1 0.000 (1.048)\tPrec@5 0.000 (4.947)\n",
      "Epoch: [22][1300/1334]\t\\Time 0.405 (0.429)\tData 0.260 (0.278)\tLoss 4.6092 (4.6059)\tPrec@1 0.000 (1.050)\tPrec@5 8.333 (4.996)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.342 (0.342)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.425 (0.400)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.151 (0.375)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.111 (0.353)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "Epoch: [23][0/1334]\t\\Time 0.411 (0.411)\tData 0.251 (0.251)\tLoss 4.6258 (4.6258)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [23][100/1334]\t\\Time 0.430 (0.418)\tData 0.280 (0.265)\tLoss 4.5998 (4.6055)\tPrec@1 0.000 (1.485)\tPrec@5 0.000 (5.693)\n",
      "Epoch: [23][200/1334]\t\\Time 0.430 (0.420)\tData 0.270 (0.268)\tLoss 4.5962 (4.6060)\tPrec@1 0.000 (1.285)\tPrec@5 8.333 (5.514)\n",
      "Epoch: [23][300/1334]\t\\Time 0.431 (0.427)\tData 0.280 (0.275)\tLoss 4.6214 (4.6055)\tPrec@1 0.000 (1.301)\tPrec@5 0.000 (5.509)\n",
      "Epoch: [23][400/1334]\t\\Time 0.460 (0.428)\tData 0.310 (0.276)\tLoss 4.6131 (4.6055)\tPrec@1 0.000 (1.288)\tPrec@5 0.000 (5.466)\n",
      "Epoch: [23][500/1334]\t\\Time 0.370 (0.429)\tData 0.220 (0.277)\tLoss 4.6281 (4.6059)\tPrec@1 0.000 (1.148)\tPrec@5 0.000 (5.173)\n",
      "Epoch: [23][600/1334]\t\\Time 0.520 (0.430)\tData 0.350 (0.278)\tLoss 4.5950 (4.6060)\tPrec@1 8.333 (1.109)\tPrec@5 8.333 (5.200)\n",
      "Epoch: [23][700/1334]\t\\Time 0.380 (0.430)\tData 0.233 (0.279)\tLoss 4.5975 (4.6059)\tPrec@1 0.000 (1.070)\tPrec@5 8.333 (5.017)\n",
      "Epoch: [23][800/1334]\t\\Time 0.460 (0.430)\tData 0.310 (0.279)\tLoss 4.6013 (4.6061)\tPrec@1 0.000 (0.968)\tPrec@5 8.333 (4.983)\n",
      "Epoch: [23][900/1334]\t\\Time 0.416 (0.429)\tData 0.256 (0.278)\tLoss 4.6010 (4.6060)\tPrec@1 0.000 (1.036)\tPrec@5 0.000 (5.105)\n",
      "Epoch: [23][1000/1334]\t\\Time 0.500 (0.429)\tData 0.350 (0.278)\tLoss 4.6136 (4.6059)\tPrec@1 0.000 (0.991)\tPrec@5 0.000 (5.062)\n",
      "Epoch: [23][1100/1334]\t\\Time 0.435 (0.429)\tData 0.285 (0.278)\tLoss 4.6150 (4.6059)\tPrec@1 0.000 (1.022)\tPrec@5 8.333 (5.117)\n",
      "Epoch: [23][1200/1334]\t\\Time 0.371 (0.429)\tData 0.221 (0.278)\tLoss 4.6028 (4.6059)\tPrec@1 0.000 (0.992)\tPrec@5 8.333 (5.093)\n",
      "Epoch: [23][1300/1334]\t\\Time 0.430 (0.429)\tData 0.270 (0.278)\tLoss 4.6026 (4.6058)\tPrec@1 0.000 (0.980)\tPrec@5 0.000 (5.099)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.341 (0.341)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.430 (0.400)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.150 (0.374)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.140 (0.355)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "Epoch: [24][0/1334]\t\\Time 0.454 (0.454)\tData 0.281 (0.281)\tLoss 4.5883 (4.5883)\tPrec@1 8.333 (8.333)\tPrec@5 16.667 (16.667)\n",
      "Epoch: [24][100/1334]\t\\Time 0.438 (0.428)\tData 0.281 (0.277)\tLoss 4.5903 (4.6051)\tPrec@1 0.000 (1.403)\tPrec@5 8.333 (5.116)\n",
      "Epoch: [24][200/1334]\t\\Time 0.460 (0.427)\tData 0.300 (0.274)\tLoss 4.6061 (4.6065)\tPrec@1 0.000 (1.078)\tPrec@5 0.000 (5.224)\n",
      "Epoch: [24][300/1334]\t\\Time 0.396 (0.425)\tData 0.236 (0.273)\tLoss 4.6250 (4.6067)\tPrec@1 8.333 (1.024)\tPrec@5 8.333 (4.790)\n",
      "Epoch: [24][400/1334]\t\\Time 0.431 (0.425)\tData 0.291 (0.273)\tLoss 4.5991 (4.6063)\tPrec@1 0.000 (1.164)\tPrec@5 8.333 (5.237)\n",
      "Epoch: [24][500/1334]\t\\Time 0.444 (0.427)\tData 0.284 (0.275)\tLoss 4.6022 (4.6063)\tPrec@1 0.000 (1.098)\tPrec@5 0.000 (5.023)\n",
      "Epoch: [24][600/1334]\t\\Time 0.430 (0.428)\tData 0.290 (0.276)\tLoss 4.6175 (4.6064)\tPrec@1 0.000 (1.068)\tPrec@5 8.333 (5.006)\n",
      "Epoch: [24][700/1334]\t\\Time 0.408 (0.427)\tData 0.278 (0.275)\tLoss 4.6089 (4.6063)\tPrec@1 0.000 (1.070)\tPrec@5 8.333 (5.005)\n",
      "Epoch: [24][800/1334]\t\\Time 0.400 (0.427)\tData 0.260 (0.276)\tLoss 4.6097 (4.6062)\tPrec@1 0.000 (1.124)\tPrec@5 0.000 (5.129)\n",
      "Epoch: [24][900/1334]\t\\Time 0.410 (0.428)\tData 0.260 (0.277)\tLoss 4.6037 (4.6060)\tPrec@1 0.000 (1.101)\tPrec@5 0.000 (5.087)\n",
      "Epoch: [24][1000/1334]\t\\Time 0.400 (0.428)\tData 0.270 (0.277)\tLoss 4.6035 (4.6060)\tPrec@1 0.000 (1.091)\tPrec@5 8.333 (5.045)\n",
      "Epoch: [24][1100/1334]\t\\Time 0.400 (0.428)\tData 0.240 (0.276)\tLoss 4.6221 (4.6059)\tPrec@1 0.000 (1.060)\tPrec@5 8.333 (5.041)\n",
      "Epoch: [24][1200/1334]\t\\Time 0.490 (0.428)\tData 0.330 (0.277)\tLoss 4.5849 (4.6059)\tPrec@1 0.000 (1.075)\tPrec@5 8.333 (5.065)\n",
      "Epoch: [24][1300/1334]\t\\Time 0.400 (0.429)\tData 0.250 (0.277)\tLoss 4.5975 (4.6059)\tPrec@1 0.000 (1.025)\tPrec@5 8.333 (4.977)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.350 (0.350)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.430 (0.399)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.156 (0.373)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.160 (0.353)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [25][0/1334]\t\\Time 0.460 (0.460)\tData 0.300 (0.300)\tLoss 4.5962 (4.5962)\tPrec@1 8.333 (8.333)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [25][100/1334]\t\\Time 0.351 (0.426)\tData 0.211 (0.276)\tLoss 4.6116 (4.6061)\tPrec@1 0.000 (0.743)\tPrec@5 16.667 (4.868)\n",
      "Epoch: [25][200/1334]\t\\Time 0.320 (0.426)\tData 0.170 (0.276)\tLoss 4.5999 (4.6059)\tPrec@1 0.000 (0.829)\tPrec@5 8.333 (4.519)\n",
      "Epoch: [25][300/1334]\t\\Time 0.471 (0.429)\tData 0.321 (0.277)\tLoss 4.6031 (4.6053)\tPrec@1 0.000 (1.135)\tPrec@5 0.000 (4.762)\n",
      "Epoch: [25][400/1334]\t\\Time 0.440 (0.428)\tData 0.294 (0.276)\tLoss 4.6023 (4.6056)\tPrec@1 0.000 (1.101)\tPrec@5 8.333 (4.800)\n",
      "Epoch: [25][500/1334]\t\\Time 0.372 (0.428)\tData 0.210 (0.276)\tLoss 4.5911 (4.6058)\tPrec@1 0.000 (1.065)\tPrec@5 16.667 (4.757)\n",
      "Epoch: [25][600/1334]\t\\Time 0.521 (0.428)\tData 0.360 (0.277)\tLoss 4.5981 (4.6058)\tPrec@1 8.333 (0.971)\tPrec@5 16.667 (4.839)\n",
      "Epoch: [25][700/1334]\t\\Time 0.440 (0.426)\tData 0.290 (0.275)\tLoss 4.6146 (4.6058)\tPrec@1 0.000 (1.010)\tPrec@5 0.000 (4.850)\n",
      "Epoch: [25][800/1334]\t\\Time 0.435 (0.426)\tData 0.280 (0.275)\tLoss 4.5986 (4.6056)\tPrec@1 0.000 (1.009)\tPrec@5 0.000 (4.994)\n",
      "Epoch: [25][900/1334]\t\\Time 0.551 (0.427)\tData 0.380 (0.275)\tLoss 4.5984 (4.6058)\tPrec@1 0.000 (1.008)\tPrec@5 8.333 (4.948)\n",
      "Epoch: [25][1000/1334]\t\\Time 0.390 (0.427)\tData 0.240 (0.276)\tLoss 4.6051 (4.6057)\tPrec@1 0.000 (1.074)\tPrec@5 8.333 (5.062)\n",
      "Epoch: [25][1100/1334]\t\\Time 0.422 (0.428)\tData 0.260 (0.276)\tLoss 4.6131 (4.6057)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (5.109)\n",
      "Epoch: [25][1200/1334]\t\\Time 0.440 (0.428)\tData 0.290 (0.276)\tLoss 4.5899 (4.6060)\tPrec@1 0.000 (1.069)\tPrec@5 16.667 (4.996)\n",
      "Epoch: [25][1300/1334]\t\\Time 0.448 (0.427)\tData 0.328 (0.276)\tLoss 4.5983 (4.6059)\tPrec@1 0.000 (1.083)\tPrec@5 0.000 (4.971)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.300 (0.300)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.441 (0.397)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.161 (0.370)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.136 (0.351)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [26][0/1334]\t\\Time 0.471 (0.471)\tData 0.310 (0.310)\tLoss 4.6298 (4.6298)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [26][100/1334]\t\\Time 0.395 (0.424)\tData 0.235 (0.273)\tLoss 4.5806 (4.6079)\tPrec@1 0.000 (1.238)\tPrec@5 16.667 (4.538)\n",
      "Epoch: [26][200/1334]\t\\Time 0.422 (0.431)\tData 0.292 (0.280)\tLoss 4.6203 (4.6073)\tPrec@1 0.000 (0.995)\tPrec@5 0.000 (4.643)\n",
      "Epoch: [26][300/1334]\t\\Time 0.351 (0.432)\tData 0.201 (0.280)\tLoss 4.6204 (4.6069)\tPrec@1 0.000 (1.024)\tPrec@5 0.000 (4.651)\n",
      "Epoch: [26][400/1334]\t\\Time 0.431 (0.433)\tData 0.271 (0.281)\tLoss 4.6133 (4.6063)\tPrec@1 8.333 (1.039)\tPrec@5 8.333 (4.884)\n",
      "Epoch: [26][500/1334]\t\\Time 0.469 (0.432)\tData 0.313 (0.280)\tLoss 4.5948 (4.6060)\tPrec@1 0.000 (1.198)\tPrec@5 8.333 (5.106)\n",
      "Epoch: [26][600/1334]\t\\Time 0.447 (0.432)\tData 0.287 (0.280)\tLoss 4.6321 (4.6062)\tPrec@1 0.000 (1.082)\tPrec@5 0.000 (4.978)\n",
      "Epoch: [26][700/1334]\t\\Time 0.440 (0.431)\tData 0.290 (0.280)\tLoss 4.6012 (4.6062)\tPrec@1 0.000 (1.070)\tPrec@5 0.000 (4.945)\n",
      "Epoch: [26][800/1334]\t\\Time 0.453 (0.431)\tData 0.321 (0.280)\tLoss 4.6022 (4.6061)\tPrec@1 8.333 (1.072)\tPrec@5 16.667 (5.004)\n",
      "Epoch: [26][900/1334]\t\\Time 0.382 (0.431)\tData 0.232 (0.279)\tLoss 4.5964 (4.6060)\tPrec@1 0.000 (1.054)\tPrec@5 16.667 (5.022)\n",
      "Epoch: [26][1000/1334]\t\\Time 0.412 (0.430)\tData 0.253 (0.279)\tLoss 4.6036 (4.6059)\tPrec@1 0.000 (1.066)\tPrec@5 8.333 (5.045)\n",
      "Epoch: [26][1100/1334]\t\\Time 0.441 (0.429)\tData 0.291 (0.278)\tLoss 4.6186 (4.6060)\tPrec@1 0.000 (1.060)\tPrec@5 8.333 (5.003)\n",
      "Epoch: [26][1200/1334]\t\\Time 0.481 (0.428)\tData 0.321 (0.277)\tLoss 4.6073 (4.6060)\tPrec@1 0.000 (1.020)\tPrec@5 8.333 (4.996)\n",
      "Epoch: [26][1300/1334]\t\\Time 0.392 (0.429)\tData 0.241 (0.277)\tLoss 4.6106 (4.6058)\tPrec@1 0.000 (1.038)\tPrec@5 0.000 (5.009)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.331 (0.331)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.441 (0.401)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.148 (0.375)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.156 (0.355)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [27][0/1334]\t\\Time 0.491 (0.491)\tData 0.337 (0.337)\tLoss 4.6055 (4.6055)\tPrec@1 0.000 (0.000)\tPrec@5 16.667 (16.667)\n",
      "Epoch: [27][100/1334]\t\\Time 0.380 (0.421)\tData 0.230 (0.273)\tLoss 4.6187 (4.6054)\tPrec@1 0.000 (0.990)\tPrec@5 0.000 (5.858)\n",
      "Epoch: [27][200/1334]\t\\Time 0.450 (0.425)\tData 0.290 (0.275)\tLoss 4.5994 (4.6059)\tPrec@1 0.000 (1.036)\tPrec@5 0.000 (5.887)\n",
      "Epoch: [27][300/1334]\t\\Time 0.471 (0.427)\tData 0.312 (0.276)\tLoss 4.6021 (4.6062)\tPrec@1 8.333 (1.024)\tPrec@5 16.667 (5.592)\n",
      "Epoch: [27][400/1334]\t\\Time 0.490 (0.428)\tData 0.340 (0.277)\tLoss 4.6150 (4.6065)\tPrec@1 0.000 (0.998)\tPrec@5 8.333 (5.424)\n",
      "Epoch: [27][500/1334]\t\\Time 0.421 (0.428)\tData 0.272 (0.278)\tLoss 4.6125 (4.6066)\tPrec@1 0.000 (1.081)\tPrec@5 8.333 (5.306)\n",
      "Epoch: [27][600/1334]\t\\Time 0.501 (0.430)\tData 0.341 (0.278)\tLoss 4.6207 (4.6064)\tPrec@1 0.000 (1.095)\tPrec@5 0.000 (5.158)\n",
      "Epoch: [27][700/1334]\t\\Time 0.440 (0.429)\tData 0.290 (0.277)\tLoss 4.6253 (4.6063)\tPrec@1 0.000 (1.117)\tPrec@5 8.333 (5.112)\n",
      "Epoch: [27][800/1334]\t\\Time 0.415 (0.429)\tData 0.265 (0.277)\tLoss 4.6077 (4.6062)\tPrec@1 0.000 (1.061)\tPrec@5 16.667 (5.087)\n",
      "Epoch: [27][900/1334]\t\\Time 0.396 (0.428)\tData 0.246 (0.277)\tLoss 4.5980 (4.6063)\tPrec@1 0.000 (1.045)\tPrec@5 0.000 (5.004)\n",
      "Epoch: [27][1000/1334]\t\\Time 0.380 (0.428)\tData 0.220 (0.277)\tLoss 4.6000 (4.6061)\tPrec@1 0.000 (1.082)\tPrec@5 8.333 (5.012)\n",
      "Epoch: [27][1100/1334]\t\\Time 0.526 (0.429)\tData 0.381 (0.277)\tLoss 4.6136 (4.6060)\tPrec@1 0.000 (1.052)\tPrec@5 0.000 (4.980)\n",
      "Epoch: [27][1200/1334]\t\\Time 0.380 (0.429)\tData 0.230 (0.277)\tLoss 4.6084 (4.6059)\tPrec@1 0.000 (1.048)\tPrec@5 0.000 (5.003)\n",
      "Epoch: [27][1300/1334]\t\\Time 0.426 (0.429)\tData 0.270 (0.277)\tLoss 4.6209 (4.6060)\tPrec@1 0.000 (1.057)\tPrec@5 0.000 (4.990)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.300 (0.300)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.440 (0.401)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.160 (0.375)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.140 (0.355)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [28][0/1334]\t\\Time 0.420 (0.420)\tData 0.260 (0.260)\tLoss 4.6053 (4.6053)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [28][100/1334]\t\\Time 0.450 (0.429)\tData 0.290 (0.277)\tLoss 4.5964 (4.6069)\tPrec@1 0.000 (0.908)\tPrec@5 0.000 (4.290)\n",
      "Epoch: [28][200/1334]\t\\Time 0.380 (0.425)\tData 0.250 (0.274)\tLoss 4.6209 (4.6054)\tPrec@1 0.000 (1.119)\tPrec@5 0.000 (5.224)\n",
      "Epoch: [28][300/1334]\t\\Time 0.484 (0.426)\tData 0.334 (0.276)\tLoss 4.6071 (4.6056)\tPrec@1 0.000 (1.024)\tPrec@5 0.000 (5.205)\n",
      "Epoch: [28][400/1334]\t\\Time 0.430 (0.427)\tData 0.270 (0.276)\tLoss 4.6110 (4.6058)\tPrec@1 0.000 (0.956)\tPrec@5 0.000 (4.821)\n",
      "Epoch: [28][500/1334]\t\\Time 0.440 (0.425)\tData 0.280 (0.275)\tLoss 4.5915 (4.6058)\tPrec@1 0.000 (0.931)\tPrec@5 16.667 (4.973)\n",
      "Epoch: [28][600/1334]\t\\Time 0.460 (0.426)\tData 0.310 (0.275)\tLoss 4.6145 (4.6060)\tPrec@1 0.000 (0.915)\tPrec@5 0.000 (4.839)\n",
      "Epoch: [28][700/1334]\t\\Time 0.488 (0.428)\tData 0.342 (0.277)\tLoss 4.6111 (4.6059)\tPrec@1 0.000 (0.880)\tPrec@5 8.333 (4.850)\n",
      "Epoch: [28][800/1334]\t\\Time 0.488 (0.428)\tData 0.325 (0.277)\tLoss 4.5951 (4.6060)\tPrec@1 0.000 (0.864)\tPrec@5 8.333 (4.879)\n",
      "Epoch: [28][900/1334]\t\\Time 0.504 (0.428)\tData 0.345 (0.277)\tLoss 4.6109 (4.6059)\tPrec@1 0.000 (0.869)\tPrec@5 0.000 (4.920)\n",
      "Epoch: [28][1000/1334]\t\\Time 0.461 (0.428)\tData 0.301 (0.277)\tLoss 4.5965 (4.6061)\tPrec@1 0.000 (0.857)\tPrec@5 8.333 (4.829)\n",
      "Epoch: [28][1100/1334]\t\\Time 0.538 (0.428)\tData 0.384 (0.277)\tLoss 4.5921 (4.6059)\tPrec@1 0.000 (0.886)\tPrec@5 0.000 (4.958)\n",
      "Epoch: [28][1200/1334]\t\\Time 0.401 (0.428)\tData 0.241 (0.277)\tLoss 4.6176 (4.6060)\tPrec@1 0.000 (0.881)\tPrec@5 0.000 (4.878)\n",
      "Epoch: [28][1300/1334]\t\\Time 0.479 (0.428)\tData 0.320 (0.277)\tLoss 4.6141 (4.6061)\tPrec@1 0.000 (0.871)\tPrec@5 0.000 (4.842)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.334 (0.334)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.427 (0.402)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.140 (0.376)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.121 (0.355)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v6_100targets_weights_seed1711_split8020_attempt2_location_model_best.pth.tar' (epoch 1)\n",
      "Epoch: [29][0/1334]\t\\Time 0.472 (0.472)\tData 0.312 (0.312)\tLoss 4.6160 (4.6160)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [29][100/1334]\t\\Time 0.464 (0.419)\tData 0.314 (0.270)\tLoss 4.5937 (4.6049)\tPrec@1 8.333 (1.320)\tPrec@5 16.667 (6.271)\n",
      "Epoch: [29][200/1334]\t\\Time 0.393 (0.425)\tData 0.242 (0.275)\tLoss 4.5972 (4.6052)\tPrec@1 0.000 (1.036)\tPrec@5 0.000 (4.975)\n",
      "Epoch: [29][300/1334]\t\\Time 0.339 (0.427)\tData 0.184 (0.276)\tLoss 4.5932 (4.6058)\tPrec@1 0.000 (0.969)\tPrec@5 16.667 (4.734)\n",
      "Epoch: [29][400/1334]\t\\Time 0.397 (0.429)\tData 0.237 (0.277)\tLoss 4.5935 (4.6062)\tPrec@1 16.667 (0.956)\tPrec@5 16.667 (4.821)\n",
      "Epoch: [29][500/1334]\t\\Time 0.481 (0.429)\tData 0.321 (0.277)\tLoss 4.5839 (4.6066)\tPrec@1 0.000 (0.915)\tPrec@5 16.667 (4.807)\n",
      "Epoch: [29][600/1334]\t\\Time 0.434 (0.429)\tData 0.282 (0.277)\tLoss 4.5962 (4.6062)\tPrec@1 0.000 (0.860)\tPrec@5 0.000 (4.770)\n",
      "Epoch: [29][700/1334]\t\\Time 0.411 (0.429)\tData 0.255 (0.277)\tLoss 4.5921 (4.6061)\tPrec@1 0.000 (0.856)\tPrec@5 8.333 (4.779)\n",
      "Epoch: [29][800/1334]\t\\Time 0.432 (0.428)\tData 0.320 (0.277)\tLoss 4.6082 (4.6058)\tPrec@1 0.000 (0.853)\tPrec@5 0.000 (4.786)\n",
      "Epoch: [29][900/1334]\t\\Time 0.391 (0.428)\tData 0.240 (0.277)\tLoss 4.5960 (4.6058)\tPrec@1 0.000 (0.879)\tPrec@5 8.333 (4.930)\n",
      "Epoch: [29][1000/1334]\t\\Time 0.408 (0.427)\tData 0.254 (0.276)\tLoss 4.6053 (4.6057)\tPrec@1 0.000 (0.866)\tPrec@5 0.000 (4.995)\n",
      "Epoch: [29][1100/1334]\t\\Time 0.506 (0.428)\tData 0.355 (0.276)\tLoss 4.6193 (4.6058)\tPrec@1 0.000 (0.901)\tPrec@5 0.000 (5.026)\n",
      "Epoch: [29][1200/1334]\t\\Time 0.414 (0.429)\tData 0.254 (0.278)\tLoss 4.6010 (4.6058)\tPrec@1 0.000 (0.916)\tPrec@5 8.333 (4.961)\n",
      "Epoch: [29][1300/1334]\t\\Time 0.420 (0.430)\tData 0.270 (0.278)\tLoss 4.6193 (4.6057)\tPrec@1 0.000 (0.942)\tPrec@5 0.000 (5.092)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 4.6026 (4.6026)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 8.333 (8.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.430 (0.401)\n",
      "\n",
      "Loss 4.6166 (4.6069)\n",
      "\n",
      "Prec@1 0.000 (0.825)\n",
      "\n",
      "Prec@5 0.000 (4.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.160 (0.375)\n",
      "\n",
      "Loss 4.6014 (4.6040)\n",
      "\n",
      "Prec@1 0.000 (0.746)\n",
      "\n",
      "Prec@5 0.000 (6.385)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.154 (0.355)\n",
      "\n",
      "Loss 4.6007 (4.6052)\n",
      "\n",
      "Prec@1 0.000 (0.969)\n",
      "\n",
      "Prec@5 0.000 (5.371)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = 'ViT_B_16_Weights.IMAGENET1K_V1')\n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "model.heads[0] =nn.Linear(768 , 100, bias = True)\n",
    "\n",
    "\n",
    "model.name = f'vit_b_16_v6_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# args_resume = f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/{model.name}_model_best.pth.tar'\n",
    "# print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "# checkpoint = torch.load(args_resume)\n",
    "# best_prec1 = checkpoint['best_prec1']\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "#       .format(args_resume, checkpoint['epoch']))\n",
    "# epoch = checkpoint['epoch']\n",
    "\n",
    "test_path ='C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_path =  'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_train.csv'\n",
    "# test_dat_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_landscape_kde_test.csv'\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "# train_size = int(split_train*0.01 * len(image_dataset))\n",
    "# test_size = len(image_dataset) - train_size\n",
    "# data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        print()\n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "        # prec1 = top1.avg\n",
    "        # prec5 = top5.avg\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "args_resume = f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/{model.name}_model_best.pth.tar'\n",
    "print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "checkpoint = torch.load(args_resume)\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "      .format(args_resume, checkpoint['epoch']))\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "model.name = f'vit_b_16_v6_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2_location'\n",
    "\n",
    "            \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "             \n",
    "            \n",
    "numb_targets = 100\n",
    "location_vals = 170\n",
    "location_fc = nn.Sequential(\n",
    "          nn.Linear(numb_targets+location_vals, (numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),(numb_targets+location_vals)),\n",
    "              nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear((numb_targets+location_vals),numb_targets),\n",
    "        )\n",
    "\n",
    "model.add_module('location_fc',location_fc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "location_fc1 = nn.Sequential(\n",
    "          nn.Linear(100, 100),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Dropout(p=0.5, inplace=False),\n",
    "          nn.Linear(100,100),\n",
    "        )\n",
    "\n",
    "location_fc2 = nn.Sequential(\n",
    "\n",
    "          nn.Linear(100,100),\n",
    "          nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(100,100),\n",
    "        )\n",
    "\n",
    "# lin_add = LinearAddLayer(100,100)\n",
    "\n",
    "# model.add_module('linear_add',lin_add)\n",
    "model.add_module('location_fc',location_fc)\n",
    "# model.add_module('location_fc1',location_fc1)\n",
    "\n",
    "# model.add_module('location_fc2',location_fc2)\n",
    "\n",
    "def forward(self, x: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    # Reshape and permute the input tensor\n",
    "    x = self._process_input(x)\n",
    "    n = x.shape[0]\n",
    "\n",
    "    # Expand the class token to the full batch\n",
    "    batch_class_token = self.class_token.expand(n, -1, -1)\n",
    "    x = torch.cat([batch_class_token, x], dim=1)\n",
    "\n",
    "    x = self.encoder(x)\n",
    "\n",
    "    # Classifier \"token\" as used by standard language architectures\n",
    "    x = x[:, 0]\n",
    "\n",
    "    x = self.heads(x)\n",
    "\n",
    "    \n",
    "    combined = torch.cat((x.view(x.size(0), -1),\n",
    "                      x2.view(x2.size(0), -1)),\n",
    "                      dim=1)\n",
    "\n",
    "    x = self.location_fc(combined)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "# model.forward = forward\n",
    "model.forward = functools.partial(forward, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "#freezing transformer part\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.location_fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "# train_model_square(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 1)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 1)\n",
    "train_model(model,LEARNING_RATE = 1e-5,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-6,NUM_EPOCHS = 20) \n",
    "train_model(model,LEARNING_RATE = 1e-7,NUM_EPOCHS = 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6577e6-63a9-42e3-a370-06c4a9fce70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.forward??25188\n",
    "model.classifier[0] = nn.Linear(25188, 4096)\n",
    "\n",
    "model.classifier[-1] = nn.Linear(4096, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100eae3b-ed6e-4342-82eb-12a60e2d4079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        combined = torch.cat((x.view(x.size(0), -1),\n",
    "                          y.view(y.size(0), -1)), dim=1)\n",
    "        x = self.classifier(combined)\n",
    "        return x\n",
    "import functools\n",
    "\n",
    "\n",
    "model.forward = functools.partial(forward, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c84784c5-f03b-47cb-b0fc-dbd839953c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(data_val, batch_size=16, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18bd31-2f36-41f7-8a1f-89c0cbd9c0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_dataframe = pd.read_csv('C:/Users/vjosv/master/top_100_images_with_location_data.csv')\n",
    "target = np.array(location_dataframe['map_square'].iloc[4])\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb8875-d3b4-46ef-9e68-73fedf980918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, j in enumerate(data_train):\n",
    "    \n",
    "    if i ==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6bc1f-2c9f-46f2-a5ce-3c3b9d8e1bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "j['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea476be-55e9-4ddd-a21e-9c6d22d5e98f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d54fba-264a-4b96-80eb-91849d8aba79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = [T.ToTensor(),T.Resize((INPUT_SIZE,INPUT_SIZE))]\n",
    "\n",
    "for t in transforms:\n",
    "\n",
    "    if isinstance(t,torchvision.transforms.transforms.Resize):\n",
    "        print('v')\n",
    "        input_size = t.size[0]\n",
    "\n",
    "s = torchvision.transforms.transforms.Resize((64,64))\n",
    "\n",
    "s.size[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339f907-c003-44d1-ac62-72d90c81dc72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.name='vgg19_artsobservasjoner64_with_location_data1'\n",
    "# model.classifier.ins\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2babe805-9550-458b-830a-f7ee5d07d1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE,\n\u001b[0;32m      2\u001b[0m                       momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAverageMeter\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = output.shape[1]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e4baae-74bf-4630-858b-9d81c6ed464c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m args_resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model_best.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# if args_resume:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     if os.path.isfile(args_resume):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print('\\n[INFO] Training Started')\u001b[39;00m\n\u001b[0;32m     20\u001b[0m args_resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "args_resume = f'{model.name}_model_best.pth.tar'\n",
    "# args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "# if args_resume:\n",
    "#     if os.path.isfile(args_resume):\n",
    "#         print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "#         checkpoint = torch.load(args_resume)\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#         best_prec1 = checkpoint['best_prec1']\n",
    "#         model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#         print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "#               .format(args_resume, checkpoint['epoch']))\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#     else:\n",
    "#         print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "# print('\\n[INFO] Training Started')\n",
    "args_resume = None\n",
    "\n",
    "start_epoch =0\n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "        \n",
    "# train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60daafd7-2cd9-4557-a468-5f716601b2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg19(pretrained=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d969433-0af7-4c74-ba0b-036bf6be497f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.name='vgg19_artsobservasjoner64_with_location_data2'\n",
    "# model.classifier.ins\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7882d40a-9efe-4257-9fcc-e01882096ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VisionTransformer' object has no attribute 'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#modify vgg19\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model.forward??25188\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m25188\u001b[39m, \u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4096\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      8\u001b[0m location_fc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      9\u001b[0m           nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m     10\u001b[0m           nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m           nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1696\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1696\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VisionTransformer' object has no attribute 'classifier'"
     ]
    }
   ],
   "source": [
    "#modify vgg19\n",
    "\n",
    "# model.forward??25188\n",
    "model.classifier[0] = nn.Linear(25188, 4096)\n",
    "\n",
    "model.classifier[-1] = nn.Linear(4096, 100)\n",
    "\n",
    "location_fc = nn.Sequential(\n",
    "          nn.Linear(100, 100),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.Linear(100,100),\n",
    "          nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,100),\n",
    "          nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "model.add_module('location_fc',location_fc)\n",
    "\n",
    "\n",
    "def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        y = self.location_fc(y)\n",
    "        combined = torch.cat((x.view(x.size(0), -1),\n",
    "                          y.view(y.size(0), -1)), dim=1)\n",
    "        x = self.classifier(combined)\n",
    "        return x\n",
    "import functools\n",
    "\n",
    "\n",
    "model.forward = functools.partial(forward, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363b279-4709-4a0b-9809-4f803631153e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06c1c4-a53c-4945-8654-f3dc30e23a51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b48b5-5ce3-4876-9dee-6aae1b38daa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325a225-ef9a-4802-b1bf-c6fffc58654a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099b7d9-6bfd-4fcd-b1ec-dcd09b29a1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c129a6-ff91-4ee6-b772-8063fbe46e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfe64b-87bd-42f5-9ec7-08f60f7ba937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = torchvision.models.resnet101(weights=None)\n",
    "\n",
    "model.name='resnet101_artsobservasjoner64_with_location_data'\n",
    "# model.classifier.ins\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "model.fc = nn.Linear(2048, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035cd2f-751c-4424-a9f8-dea145dd109d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882005e-ccf8-46bb-aad1-c23bb6dc635f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x = torch.cat((x,y),1)\n",
    "        \n",
    "        return self._forward_impl(x)\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "model.forward = functools.partial(forward, model)\n",
    "\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51333343-73e1-443f-8285-16e4fe9ab031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        # print(input['image'].shape)\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "            \n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "        # compute output\n",
    "        # print(input_var.shape)\n",
    "        # print(output)\n",
    "\n",
    "        loss = criterion(output, target_var)\n",
    "        # print(loss)\n",
    "        # if i >10:\n",
    "        #     break\n",
    "        \n",
    "        # save_output_target(model,output,target_var,epoch,i)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5,conf = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  '\\Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "def validate(val_loader, model, criterion,epoch,save_output=False):\n",
    "    # global output_aug_kde001, sample_pos, within_square, weight_tensor_kde001,zero_tensor_kde001,tt\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "\n",
    "    conf = AverageMeter()\n",
    "    class_correct = list(0. for i in range(185))\n",
    "    class_total = list(0. for i in range(185))\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(val_loader):\n",
    "        \n",
    "\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        save_output_target_validate(model,output,target,epoch,i)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        \n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        \n",
    "\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        \n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "\n",
    "\n",
    "        conf.update(conf1,1)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "\n",
    "            print('Test: [{0}/{1}]\\n'.format(i, len(val_loader)))\n",
    "            print('Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\n'.format(batch_time=batch_time))\n",
    "            print('Loss {loss.val:.4f} ({loss.avg:.4f})\\n'.format(loss=losses))\n",
    "            print('Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\n'.format(top1=top1))\n",
    "            print('Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\n'.format(top5=top5))\n",
    "\n",
    "        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "        \n",
    "\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee9929c-7aae-4341-a086-ffb8a395222c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dataset = ImagesWithLocationDataset_conv('C:/Users/vjosv/master/top_100_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "start_epoch =0\n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best, LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b1f16-b56d-4f0e-8b82-cd36ae05b700",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b05d5-1419-4638-a43f-81c3b0993f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e618a6-6ff6-49c1-bbb5-472cb30d27df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b41a3923-eebc-4404-914e-8efa44c15d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_16(weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fbc1a42-e507-4ee1-81c0-6a53d8668190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.heads[0] = nn.Linear(768 , 150, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_150targets'\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b3e758-5ea7-4c7b-9f76-d729274dc8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_22400\\3414169806.py:13: DtypeWarning: Columns (54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.location_dataframe = pd.read_csv(csv_file)\n"
     ]
    }
   ],
   "source": [
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_150_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2f1512a-1f96-48a5-a66a-ff110b09e6da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = output.shape[1]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e8d72f-0cd9-4f5e-8f10-bec621deb9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        # print(input['image'].shape)\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "            \n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "        # compute output\n",
    "        # print(input_var.shape)\n",
    "        # print(output)\n",
    "\n",
    "        loss = criterion(output, target_var)\n",
    "        # print(loss)\n",
    "        # if i >10:\n",
    "        #     break\n",
    "        \n",
    "        # save_output_target(model,output,target_var,epoch,i)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5,conf = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  '\\Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "def validate(val_loader, model, criterion,epoch,save_output=False):\n",
    "    # global output_aug_kde001, sample_pos, within_square, weight_tensor_kde001,zero_tensor_kde001,tt\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "\n",
    "    conf = AverageMeter()\n",
    "    class_correct = list(0. for i in range(185))\n",
    "    class_total = list(0. for i in range(185))\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(val_loader):\n",
    "        \n",
    "\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        save_output_target_validate(model,output,target,epoch,i)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        \n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        \n",
    "\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        \n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "\n",
    "\n",
    "        conf.update(conf1,1)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "\n",
    "            print('Test: [{0}/{1}]\\n'.format(i, len(val_loader)))\n",
    "            print('Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\n'.format(batch_time=batch_time))\n",
    "            print('Loss {loss.val:.4f} ({loss.avg:.4f})\\n'.format(loss=losses))\n",
    "            print('Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\n'.format(top1=top1))\n",
    "            print('Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\n'.format(top5=top5))\n",
    "\n",
    "        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "        \n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, adjust_now, LEARNING_RATE=LEARNING_RATE):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LEARNING_RATE\n",
    "    if (epoch-1) < 0:\n",
    "        former_lr=LEARNING_RATE\n",
    "    # else:\n",
    "        # former_lr = LEARNING_RATE * (0.1 ** ((epoch-1) // 10))\n",
    "    # lr = LEARNING_RATE * (0.1 ** (epoch // 10))\n",
    "    former_lr = copy.copy(LEARNING_RATE)\n",
    "    if adjust_now:\n",
    "        former_lr = copy.copy(LEARNING_RATE)\n",
    "        LEARNING_RATE = LEARNING_RATE*0.1\n",
    "        lr = LEARNING_RATE\n",
    "    if (lr <= 0.0001):\n",
    "        lr = 0.0001\n",
    "    print('\\n[Learning Rate] {:0.6f}'.format(lr))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr != former_lr, LEARNING_RATE\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, model):\n",
    "    filename=f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('\\n[INFO] Saved Model to model_best.pth.tar')\n",
    "        shutil.copyfile(filename, f'saved_models/{model.name}_model_best.pth.tar')\n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = output.shape[1]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "672df677-8fc4-46f2-9fc1-db6b175d32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch =0\n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS,init_learning_rate = None,load_best=False ):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    first_run = True \n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "        \n",
    "        if first_run and init_learning_rate:\n",
    "            LEARNING_RATE = init_learning_rate\n",
    "            print(LEARNING_RATE)\n",
    "            adjusted_rate= False\n",
    "        else:\n",
    "            adjusted_rate, LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE=LEARNING_RATE)\n",
    "            five_epochs_since_best = False\n",
    "        if adjusted_rate or (load_best and first_run):\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "        first_run = False\n",
    "\n",
    "def save_output_target_validate(model,output,target,epoch,batch):\n",
    "        torch.save(output,f'saved_output/{model.name}_validating_output/output_e{epoch}_b{batch}')\n",
    "        torch.save(target,f'saved_output/{model.name}_validating_output/target_b{batch}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28baf71c-ebc6-4e97-8a5f-f15a56330435",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'saved_models/vit_b_16_artsobservasjoner224_100targets_weights_Noneseed2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_artsobservasjoner224_100targets_weights_Noneseed2_checkpoint.pth.tar' (epoch 24)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_CUDA:\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m----> 3\u001b[0m train_model(model)\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mlong_running.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     prevent_standby()\n\u001b[1;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     31\u001b[0m     allow_standby()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[23], line 56\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, LEARNING_RATE, NUM_EPOCHS, init_learning_rate, load_best)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=> loaded checkpoint \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m           \u001b[38;5;241m.\u001b[39mformat(args_resume, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m train(train_loader, model, criterion, optimizer, epoch)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[0;32m     58\u001b[0m prec1 \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion,epoch,save_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[20], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m     28\u001b[0m target_var \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(target)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# map_square_var = torch.autograd.Variable(map_square)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# location_data_var = torch.autograd.Variable(location_data)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# output = model(input_var,map_square)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_var)\n\u001b[0;32m     34\u001b[0m data_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# print(input_var.shape)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# print(output)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\vision_transformer.py:291\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_input(x)\n\u001b[0;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# Expand the class token to the full batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\vision_transformer.py:277\u001b[0m, in \u001b[0;36mVisionTransformer._process_input\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m n_w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m p\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# (n, c, h, w) -> (n, hidden_dim, n_h, n_w)\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_proj(x)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# (n, hidden_dim, n_h, n_w) -> (n, hidden_dim, (n_h * n_w))\u001b[39;00m\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim, n_h \u001b[38;5;241m*\u001b[39m n_w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605b2e1-7aee-4187-992c-7c8f0679836b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "model.heads[0] = nn.Linear(768 , 150, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_150targets_weights_None'\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520485db-cc0f-42a4-8cdd-897a358bac64",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "model.heads[0] = nn.Linear(768 , 100, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_100targets_pretrained'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_100_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe9d55-2c7f-4147-bb60-400966d49ccb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "model.heads[0] = nn.Linear(768 , 125, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_125targets_pretrained'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_125_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a89c833-5aba-4888-a5db-e5b1d50ed9c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/vit_b_16_artsobservasjoner224_100targets_weights_seed0802split_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/558]\t\\Time 0.795 (0.795)\tData 0.421 (0.421)\tLoss 4.8819 (4.8819)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/558]\t\\Time 0.499 (0.500)\tData 0.410 (0.399)\tLoss 4.6533 (4.6105)\tPrec@1 0.000 (2.413)\tPrec@5 6.250 (10.891)\n",
      "Epoch: [0][200/558]\t\\Time 0.574 (0.512)\tData 0.464 (0.411)\tLoss 4.7186 (4.5698)\tPrec@1 0.000 (2.736)\tPrec@5 0.000 (12.002)\n",
      "Epoch: [0][300/558]\t\\Time 0.532 (0.524)\tData 0.422 (0.422)\tLoss 4.4500 (4.5452)\tPrec@1 0.000 (2.845)\tPrec@5 6.250 (12.334)\n",
      "Epoch: [0][400/558]\t\\Time 0.581 (0.530)\tData 0.471 (0.427)\tLoss 4.2562 (4.5192)\tPrec@1 6.250 (2.993)\tPrec@5 25.000 (12.703)\n",
      "Epoch: [0][500/558]\t\\Time 0.559 (0.533)\tData 0.449 (0.431)\tLoss 4.7800 (4.4873)\tPrec@1 0.000 (3.293)\tPrec@5 6.250 (13.373)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.530 (0.530)\n",
      "\n",
      "Loss 4.7040 (4.7040)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 6.250 (6.250)\n",
      "\n",
      " * Prec@1 0.000 Prec@5 6.250\n",
      " * Prec@1 3.125 Prec@5 15.625\n",
      " * Prec@1 2.083 Prec@5 22.917\n",
      " * Prec@1 1.562 Prec@5 20.312\n",
      " * Prec@1 1.250 Prec@5 20.000\n",
      " * Prec@1 1.042 Prec@5 18.750\n",
      " * Prec@1 0.893 Prec@5 17.857\n",
      " * Prec@1 1.562 Prec@5 17.969\n",
      " * Prec@1 1.389 Prec@5 15.972\n",
      " * Prec@1 1.250 Prec@5 16.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.536 (0.542)\n",
      "\n",
      "Loss 4.0082 (4.4637)\n",
      "\n",
      "Prec@1 12.500 (2.273)\n",
      "\n",
      "Prec@5 37.500 (18.182)\n",
      "\n",
      " * Prec@1 2.273 Prec@5 18.182\n",
      " * Prec@1 2.604 Prec@5 17.708\n",
      " * Prec@1 2.404 Prec@5 16.827\n",
      " * Prec@1 2.679 Prec@5 16.964\n",
      " * Prec@1 2.917 Prec@5 16.250\n",
      " * Prec@1 2.734 Prec@5 17.578\n",
      " * Prec@1 3.676 Prec@5 18.015\n",
      " * Prec@1 3.819 Prec@5 17.708\n",
      " * Prec@1 3.947 Prec@5 17.763\n",
      " * Prec@1 4.062 Prec@5 17.812\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.573 (0.543)\n",
      "\n",
      "Loss 4.6505 (4.4163)\n",
      "\n",
      "Prec@1 0.000 (3.869)\n",
      "\n",
      "Prec@5 12.500 (17.560)\n",
      "\n",
      " * Prec@1 3.869 Prec@5 17.560\n",
      " * Prec@1 3.693 Prec@5 17.614\n",
      " * Prec@1 3.804 Prec@5 17.935\n",
      " * Prec@1 3.906 Prec@5 17.448\n",
      " * Prec@1 3.750 Prec@5 17.000\n",
      " * Prec@1 3.606 Prec@5 17.067\n",
      " * Prec@1 3.472 Prec@5 16.667\n",
      " * Prec@1 3.571 Prec@5 16.741\n",
      " * Prec@1 3.448 Prec@5 16.595\n",
      " * Prec@1 3.333 Prec@5 16.042\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.497 (0.544)\n",
      "\n",
      "Loss 4.3134 (4.4397)\n",
      "\n",
      "Prec@1 0.000 (3.226)\n",
      "\n",
      "Prec@5 18.750 (16.129)\n",
      "\n",
      " * Prec@1 3.226 Prec@5 16.129\n",
      " * Prec@1 3.125 Prec@5 15.625\n",
      " * Prec@1 3.030 Prec@5 15.152\n",
      " * Prec@1 2.941 Prec@5 14.890\n",
      " * Prec@1 2.857 Prec@5 14.464\n",
      " * Prec@1 2.778 Prec@5 14.410\n",
      " * Prec@1 2.872 Prec@5 14.358\n",
      " * Prec@1 2.961 Prec@5 14.145\n",
      " * Prec@1 3.045 Prec@5 14.103\n",
      " * Prec@1 3.125 Prec@5 14.062\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.478 (0.541)\n",
      "\n",
      "Loss 4.5175 (4.4601)\n",
      "\n",
      "Prec@1 0.000 (3.049)\n",
      "\n",
      "Prec@5 6.250 (13.872)\n",
      "\n",
      " * Prec@1 3.049 Prec@5 13.872\n",
      " * Prec@1 3.125 Prec@5 14.435\n",
      " * Prec@1 3.198 Prec@5 14.390\n",
      " * Prec@1 3.409 Prec@5 14.489\n",
      " * Prec@1 3.472 Prec@5 14.583\n",
      " * Prec@1 3.397 Prec@5 14.402\n",
      " * Prec@1 3.457 Prec@5 14.495\n",
      " * Prec@1 3.385 Prec@5 14.323\n",
      " * Prec@1 3.316 Prec@5 14.541\n",
      " * Prec@1 3.375 Prec@5 14.500\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.578 (0.543)\n",
      "\n",
      "Loss 4.3736 (4.4398)\n",
      "\n",
      "Prec@1 0.000 (3.309)\n",
      "\n",
      "Prec@5 12.500 (14.461)\n",
      "\n",
      " * Prec@1 3.309 Prec@5 14.461\n",
      " * Prec@1 3.365 Prec@5 14.543\n",
      " * Prec@1 3.656 Prec@5 14.741\n",
      " * Prec@1 3.704 Prec@5 14.931\n",
      " * Prec@1 3.750 Prec@5 14.886\n",
      " * Prec@1 3.795 Prec@5 14.844\n",
      " * Prec@1 3.838 Prec@5 14.693\n",
      " * Prec@1 3.772 Prec@5 14.547\n",
      " * Prec@1 3.814 Prec@5 14.619\n",
      " * Prec@1 3.750 Prec@5 14.375\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.462 (0.537)\n",
      "\n",
      "Loss 4.5218 (4.4473)\n",
      "\n",
      "Prec@1 6.250 (3.791)\n",
      "\n",
      "Prec@5 6.250 (14.242)\n",
      "\n",
      " * Prec@1 3.791 Prec@5 14.242\n",
      " * Prec@1 3.831 Prec@5 14.415\n",
      " * Prec@1 3.770 Prec@5 14.385\n",
      " * Prec@1 3.711 Prec@5 14.453\n",
      " * Prec@1 3.750 Prec@5 14.615\n",
      " * Prec@1 3.693 Prec@5 14.489\n",
      " * Prec@1 3.731 Prec@5 14.459\n",
      " * Prec@1 3.768 Prec@5 14.522\n",
      " * Prec@1 3.714 Prec@5 14.402\n",
      " * Prec@1 3.661 Prec@5 14.464\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.513 (0.529)\n",
      "\n",
      "Loss 4.4239 (4.4530)\n",
      "\n",
      "Prec@1 0.000 (3.609)\n",
      "\n",
      "Prec@5 18.750 (14.525)\n",
      "\n",
      " * Prec@1 3.609 Prec@5 14.525\n",
      " * Prec@1 3.559 Prec@5 14.410\n",
      " * Prec@1 3.510 Prec@5 14.469\n",
      " * Prec@1 3.463 Prec@5 14.780\n",
      " * Prec@1 3.417 Prec@5 14.750\n",
      " * Prec@1 3.372 Prec@5 14.556\n",
      " * Prec@1 3.328 Prec@5 14.448\n",
      " * Prec@1 3.285 Prec@5 14.503\n",
      " * Prec@1 3.244 Prec@5 14.478\n",
      " * Prec@1 3.281 Prec@5 14.453\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.535 (0.525)\n",
      "\n",
      "Loss 4.3939 (4.4689)\n",
      "\n",
      "Prec@1 6.250 (3.318)\n",
      "\n",
      "Prec@5 31.250 (14.660)\n",
      "\n",
      " * Prec@1 3.318 Prec@5 14.660\n",
      " * Prec@1 3.277 Prec@5 14.558\n",
      " * Prec@1 3.313 Prec@5 14.608\n",
      " * Prec@1 3.348 Prec@5 14.658\n",
      " * Prec@1 3.382 Prec@5 14.559\n",
      " * Prec@1 3.343 Prec@5 14.535\n",
      " * Prec@1 3.305 Prec@5 14.440\n",
      " * Prec@1 3.267 Prec@5 14.276\n",
      " * Prec@1 3.230 Prec@5 14.185\n",
      " * Prec@1 3.333 Prec@5 14.167\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.497 (0.522)\n",
      "\n",
      "Loss 4.6247 (4.4757)\n",
      "\n",
      "Prec@1 0.000 (3.297)\n",
      "\n",
      "Prec@5 0.000 (14.011)\n",
      "\n",
      " * Prec@1 3.297 Prec@5 14.011\n",
      " * Prec@1 3.261 Prec@5 13.995\n",
      " * Prec@1 3.293 Prec@5 13.911\n",
      " * Prec@1 3.391 Prec@5 13.963\n",
      " * Prec@1 3.421 Prec@5 14.145\n",
      " * Prec@1 3.385 Prec@5 14.062\n",
      " * Prec@1 3.351 Prec@5 14.175\n",
      " * Prec@1 3.316 Prec@5 14.094\n",
      " * Prec@1 3.283 Prec@5 14.015\n",
      " * Prec@1 3.250 Prec@5 13.938\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.483 (0.518)\n",
      "\n",
      "Loss 4.5239 (4.4748)\n",
      "\n",
      "Prec@1 6.250 (3.280)\n",
      "\n",
      "Prec@5 12.500 (13.923)\n",
      "\n",
      " * Prec@1 3.280 Prec@5 13.923\n",
      " * Prec@1 3.248 Prec@5 13.848\n",
      " * Prec@1 3.277 Prec@5 13.896\n",
      " * Prec@1 3.245 Prec@5 14.183\n",
      " * Prec@1 3.274 Prec@5 14.226\n",
      " * Prec@1 3.243 Prec@5 14.151\n",
      " * Prec@1 3.213 Prec@5 14.019\n",
      " * Prec@1 3.241 Prec@5 14.120\n",
      " * Prec@1 3.211 Prec@5 14.048\n",
      " * Prec@1 3.239 Prec@5 14.148\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.479 (0.516)\n",
      "\n",
      "Loss 4.5461 (4.4735)\n",
      "\n",
      "Prec@1 6.250 (3.266)\n",
      "\n",
      "Prec@5 12.500 (14.133)\n",
      "\n",
      " * Prec@1 3.266 Prec@5 14.133\n",
      " * Prec@1 3.348 Prec@5 14.118\n",
      " * Prec@1 3.374 Prec@5 14.104\n",
      " * Prec@1 3.399 Prec@5 14.145\n",
      " * Prec@1 3.370 Prec@5 14.076\n",
      " * Prec@1 3.394 Prec@5 14.062\n",
      " * Prec@1 3.419 Prec@5 13.996\n",
      " * Prec@1 3.390 Prec@5 14.089\n",
      " * Prec@1 3.361 Prec@5 14.076\n",
      " * Prec@1 3.438 Prec@5 14.115\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.516 (0.516)\n",
      "\n",
      "Loss 4.5976 (4.4748)\n",
      "\n",
      "Prec@1 6.250 (3.461)\n",
      "\n",
      "Prec@5 6.250 (14.050)\n",
      "\n",
      " * Prec@1 3.461 Prec@5 14.050\n",
      " * Prec@1 3.432 Prec@5 14.139\n",
      " * Prec@1 3.506 Prec@5 14.278\n",
      " * Prec@1 3.478 Prec@5 14.365\n",
      " * Prec@1 3.450 Prec@5 14.300\n",
      " * Prec@1 3.472 Prec@5 14.286\n",
      " * Prec@1 3.445 Prec@5 14.272\n",
      " * Prec@1 3.467 Prec@5 14.258\n",
      " * Prec@1 3.488 Prec@5 14.341\n",
      " * Prec@1 3.462 Prec@5 14.327\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.495 (0.513)\n",
      "\n",
      "Loss 4.7177 (4.4782)\n",
      "\n",
      "Prec@1 0.000 (3.435)\n",
      "\n",
      "Prec@5 12.500 (14.313)\n",
      "\n",
      " * Prec@1 3.435 Prec@5 14.313\n",
      " * Prec@1 3.409 Prec@5 14.299\n",
      " * Prec@1 3.383 Prec@5 14.286\n",
      " * Prec@1 3.358 Prec@5 14.366\n",
      " * Prec@1 3.333 Prec@5 14.306\n",
      " * Prec@1 3.355 Prec@5 14.338\n",
      " * Prec@1 3.422 Prec@5 14.325\n",
      " * Prec@1 3.397 Prec@5 14.357\n",
      " * Prec@1 3.372 Prec@5 14.254\n",
      " * Prec@1 3.360 Prec@5 14.203\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/558]\t\\Time 0.582 (0.582)\tData 0.463 (0.463)\tLoss 4.6669 (4.6669)\tPrec@1 0.000 (0.000)\tPrec@5 12.500 (12.500)\n",
      "Epoch: [1][100/558]\t\\Time 0.501 (0.557)\tData 0.431 (0.452)\tLoss 4.2157 (4.3236)\tPrec@1 6.250 (3.713)\tPrec@5 12.500 (17.698)\n",
      "Epoch: [1][200/558]\t\\Time 0.554 (0.555)\tData 0.444 (0.450)\tLoss 4.0238 (4.2152)\tPrec@1 0.000 (4.509)\tPrec@5 25.000 (21.051)\n",
      "Epoch: [1][300/558]\t\\Time 0.559 (0.553)\tData 0.479 (0.449)\tLoss 3.4065 (4.1303)\tPrec@1 18.750 (6.105)\tPrec@5 50.000 (23.214)\n",
      "Epoch: [1][400/558]\t\\Time 0.620 (0.551)\tData 0.510 (0.447)\tLoss 3.3699 (4.0554)\tPrec@1 18.750 (7.123)\tPrec@5 43.750 (25.436)\n",
      "Epoch: [1][500/558]\t\\Time 0.552 (0.550)\tData 0.442 (0.446)\tLoss 3.5039 (3.9781)\tPrec@1 18.750 (8.308)\tPrec@5 43.750 (27.844)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.560 (0.560)\n",
      "\n",
      "Loss 3.0909 (3.0909)\n",
      "\n",
      "Prec@1 31.250 (31.250)\n",
      "\n",
      "Prec@5 56.250 (56.250)\n",
      "\n",
      " * Prec@1 31.250 Prec@5 56.250\n",
      " * Prec@1 21.875 Prec@5 50.000\n",
      " * Prec@1 27.083 Prec@5 54.167\n",
      " * Prec@1 23.438 Prec@5 45.312\n",
      " * Prec@1 22.500 Prec@5 42.500\n",
      " * Prec@1 19.792 Prec@5 42.708\n",
      " * Prec@1 17.857 Prec@5 41.071\n",
      " * Prec@1 17.969 Prec@5 43.750\n",
      " * Prec@1 15.972 Prec@5 40.972\n",
      " * Prec@1 16.875 Prec@5 42.500\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.519 (0.553)\n",
      "\n",
      "Loss 3.2233 (3.4734)\n",
      "\n",
      "Prec@1 31.250 (18.182)\n",
      "\n",
      "Prec@5 50.000 (43.182)\n",
      "\n",
      " * Prec@1 18.182 Prec@5 43.182\n",
      " * Prec@1 17.708 Prec@5 42.708\n",
      " * Prec@1 17.788 Prec@5 43.269\n",
      " * Prec@1 16.964 Prec@5 42.857\n",
      " * Prec@1 17.083 Prec@5 43.750\n",
      " * Prec@1 17.969 Prec@5 44.531\n",
      " * Prec@1 18.015 Prec@5 44.118\n",
      " * Prec@1 17.361 Prec@5 44.444\n",
      " * Prec@1 16.447 Prec@5 44.408\n",
      " * Prec@1 16.875 Prec@5 44.062\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.539 (0.535)\n",
      "\n",
      "Loss 3.7789 (3.4748)\n",
      "\n",
      "Prec@1 0.000 (16.071)\n",
      "\n",
      "Prec@5 37.500 (43.750)\n",
      "\n",
      " * Prec@1 16.071 Prec@5 43.750\n",
      " * Prec@1 16.193 Prec@5 43.466\n",
      " * Prec@1 17.391 Prec@5 43.750\n",
      " * Prec@1 17.708 Prec@5 43.750\n",
      " * Prec@1 17.000 Prec@5 42.250\n",
      " * Prec@1 16.346 Prec@5 42.548\n",
      " * Prec@1 16.435 Prec@5 42.130\n",
      " * Prec@1 16.964 Prec@5 42.634\n",
      " * Prec@1 17.026 Prec@5 42.457\n",
      " * Prec@1 16.667 Prec@5 42.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.509 (0.538)\n",
      "\n",
      "Loss 3.4768 (3.5117)\n",
      "\n",
      "Prec@1 18.750 (16.734)\n",
      "\n",
      "Prec@5 31.250 (41.734)\n",
      "\n",
      " * Prec@1 16.734 Prec@5 41.734\n",
      " * Prec@1 16.797 Prec@5 41.602\n",
      " * Prec@1 16.477 Prec@5 41.098\n",
      " * Prec@1 16.544 Prec@5 40.993\n",
      " * Prec@1 16.786 Prec@5 41.250\n",
      " * Prec@1 16.840 Prec@5 40.799\n",
      " * Prec@1 16.892 Prec@5 40.709\n",
      " * Prec@1 16.776 Prec@5 40.296\n",
      " * Prec@1 16.346 Prec@5 39.904\n",
      " * Prec@1 16.250 Prec@5 39.844\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.460 (0.539)\n",
      "\n",
      "Loss 3.3373 (3.5558)\n",
      "\n",
      "Prec@1 18.750 (16.311)\n",
      "\n",
      "Prec@5 43.750 (39.939)\n",
      "\n",
      " * Prec@1 16.311 Prec@5 39.939\n",
      " * Prec@1 16.220 Prec@5 39.732\n",
      " * Prec@1 15.988 Prec@5 39.244\n",
      " * Prec@1 16.051 Prec@5 39.062\n",
      " * Prec@1 15.694 Prec@5 38.611\n",
      " * Prec@1 15.761 Prec@5 38.587\n",
      " * Prec@1 15.691 Prec@5 38.564\n",
      " * Prec@1 15.365 Prec@5 38.411\n",
      " * Prec@1 15.689 Prec@5 38.776\n",
      " * Prec@1 15.875 Prec@5 38.625\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.576 (0.539)\n",
      "\n",
      "Loss 3.3159 (3.5727)\n",
      "\n",
      "Prec@1 31.250 (16.176)\n",
      "\n",
      "Prec@5 50.000 (38.848)\n",
      "\n",
      " * Prec@1 16.176 Prec@5 38.848\n",
      " * Prec@1 16.346 Prec@5 38.942\n",
      " * Prec@1 16.509 Prec@5 39.269\n",
      " * Prec@1 16.435 Prec@5 39.120\n",
      " * Prec@1 16.136 Prec@5 38.636\n",
      " * Prec@1 15.960 Prec@5 38.504\n",
      " * Prec@1 15.789 Prec@5 38.268\n",
      " * Prec@1 15.625 Prec@5 38.039\n",
      " * Prec@1 15.572 Prec@5 38.136\n",
      " * Prec@1 15.625 Prec@5 38.021\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.521 (0.541)\n",
      "\n",
      "Loss 3.2960 (3.5966)\n",
      "\n",
      "Prec@1 25.000 (15.779)\n",
      "\n",
      "Prec@5 56.250 (38.320)\n",
      "\n",
      " * Prec@1 15.779 Prec@5 38.320\n",
      " * Prec@1 15.625 Prec@5 38.306\n",
      " * Prec@1 15.476 Prec@5 38.194\n",
      " * Prec@1 15.332 Prec@5 38.477\n",
      " * Prec@1 15.096 Prec@5 38.365\n",
      " * Prec@1 14.962 Prec@5 38.163\n",
      " * Prec@1 14.832 Prec@5 38.153\n",
      " * Prec@1 14.706 Prec@5 37.868\n",
      " * Prec@1 14.583 Prec@5 37.500\n",
      " * Prec@1 14.643 Prec@5 37.500\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.541 (0.539)\n",
      "\n",
      "Loss 3.4876 (3.6315)\n",
      "\n",
      "Prec@1 18.750 (14.701)\n",
      "\n",
      "Prec@5 31.250 (37.412)\n",
      "\n",
      " * Prec@1 14.701 Prec@5 37.412\n",
      " * Prec@1 14.670 Prec@5 37.240\n",
      " * Prec@1 14.726 Prec@5 37.414\n",
      " * Prec@1 14.611 Prec@5 37.753\n",
      " * Prec@1 14.583 Prec@5 37.583\n",
      " * Prec@1 14.474 Prec@5 37.336\n",
      " * Prec@1 14.448 Prec@5 37.256\n",
      " * Prec@1 14.503 Prec@5 37.580\n",
      " * Prec@1 14.478 Prec@5 37.263\n",
      " * Prec@1 14.375 Prec@5 37.344\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.529 (0.535)\n",
      "\n",
      "Loss 3.4678 (3.6439)\n",
      "\n",
      "Prec@1 6.250 (14.275)\n",
      "\n",
      "Prec@5 43.750 (37.423)\n",
      "\n",
      " * Prec@1 14.275 Prec@5 37.423\n",
      " * Prec@1 14.177 Prec@5 37.348\n",
      " * Prec@1 14.157 Prec@5 37.500\n",
      " * Prec@1 13.988 Prec@5 37.054\n",
      " * Prec@1 13.824 Prec@5 37.059\n",
      " * Prec@1 13.953 Prec@5 37.064\n",
      " * Prec@1 13.793 Prec@5 37.069\n",
      " * Prec@1 13.849 Prec@5 37.003\n",
      " * Prec@1 13.694 Prec@5 36.868\n",
      " * Prec@1 13.889 Prec@5 37.153\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.544 (0.533)\n",
      "\n",
      "Loss 3.4754 (3.6546)\n",
      "\n",
      "Prec@1 12.500 (13.874)\n",
      "\n",
      "Prec@5 31.250 (37.088)\n",
      "\n",
      " * Prec@1 13.874 Prec@5 37.088\n",
      " * Prec@1 13.859 Prec@5 37.228\n",
      " * Prec@1 13.911 Prec@5 37.433\n",
      " * Prec@1 13.763 Prec@5 37.367\n",
      " * Prec@1 13.618 Prec@5 37.500\n",
      " * Prec@1 13.607 Prec@5 37.500\n",
      " * Prec@1 13.531 Prec@5 37.564\n",
      " * Prec@1 13.520 Prec@5 37.372\n",
      " * Prec@1 13.447 Prec@5 37.374\n",
      " * Prec@1 13.312 Prec@5 37.312\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.545 (0.535)\n",
      "\n",
      "Loss 4.3465 (3.6657)\n",
      "\n",
      "Prec@1 12.500 (13.304)\n",
      "\n",
      "Prec@5 37.500 (37.314)\n",
      "\n",
      " * Prec@1 13.304 Prec@5 37.314\n",
      " * Prec@1 13.235 Prec@5 37.255\n",
      " * Prec@1 13.107 Prec@5 37.561\n",
      " * Prec@1 13.101 Prec@5 37.680\n",
      " * Prec@1 13.214 Prec@5 37.798\n",
      " * Prec@1 13.208 Prec@5 37.795\n",
      " * Prec@1 13.259 Prec@5 37.792\n",
      " * Prec@1 13.310 Prec@5 38.079\n",
      " * Prec@1 13.245 Prec@5 37.901\n",
      " * Prec@1 13.295 Prec@5 37.955\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.514 (0.535)\n",
      "\n",
      "Loss 3.7466 (3.6521)\n",
      "\n",
      "Prec@1 12.500 (13.288)\n",
      "\n",
      "Prec@5 37.500 (37.950)\n",
      "\n",
      " * Prec@1 13.288 Prec@5 37.950\n",
      " * Prec@1 13.225 Prec@5 37.946\n",
      " * Prec@1 13.219 Prec@5 37.942\n",
      " * Prec@1 13.158 Prec@5 38.158\n",
      " * Prec@1 13.261 Prec@5 38.098\n",
      " * Prec@1 13.308 Prec@5 37.985\n",
      " * Prec@1 13.194 Prec@5 38.194\n",
      " * Prec@1 13.136 Prec@5 38.083\n",
      " * Prec@1 13.078 Prec@5 37.973\n",
      " * Prec@1 12.969 Prec@5 38.021\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.524 (0.535)\n",
      "\n",
      "Loss 3.7357 (3.6595)\n",
      "\n",
      "Prec@1 12.500 (12.965)\n",
      "\n",
      "Prec@5 18.750 (37.862)\n",
      "\n",
      " * Prec@1 12.965 Prec@5 37.862\n",
      " * Prec@1 12.910 Prec@5 37.756\n",
      " * Prec@1 12.957 Prec@5 37.754\n",
      " * Prec@1 12.954 Prec@5 37.752\n",
      " * Prec@1 12.950 Prec@5 37.850\n",
      " * Prec@1 12.847 Prec@5 37.698\n",
      " * Prec@1 12.844 Prec@5 37.648\n",
      " * Prec@1 12.891 Prec@5 37.646\n",
      " * Prec@1 12.984 Prec@5 37.645\n",
      " * Prec@1 12.981 Prec@5 37.692\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.543 (0.536)\n",
      "\n",
      "Loss 4.2994 (3.6651)\n",
      "\n",
      "Prec@1 0.000 (12.882)\n",
      "\n",
      "Prec@5 18.750 (37.548)\n",
      "\n",
      " * Prec@1 12.882 Prec@5 37.548\n",
      " * Prec@1 12.831 Prec@5 37.500\n",
      " * Prec@1 12.735 Prec@5 37.547\n",
      " * Prec@1 12.920 Prec@5 37.733\n",
      " * Prec@1 12.870 Prec@5 37.731\n",
      " * Prec@1 12.914 Prec@5 37.730\n",
      " * Prec@1 12.956 Prec@5 37.865\n",
      " * Prec@1 12.953 Prec@5 37.908\n",
      " * Prec@1 12.905 Prec@5 37.725\n",
      " * Prec@1 12.858 Prec@5 37.724\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/558]\t\\Time 0.534 (0.534)\tData 0.425 (0.425)\tLoss 3.4438 (3.4438)\tPrec@1 25.000 (25.000)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [2][100/558]\t\\Time 0.567 (0.536)\tData 0.455 (0.433)\tLoss 3.6058 (3.4457)\tPrec@1 18.750 (16.151)\tPrec@5 37.500 (42.327)\n",
      "Epoch: [2][200/558]\t\\Time 0.524 (0.537)\tData 0.420 (0.435)\tLoss 3.3799 (3.3944)\tPrec@1 18.750 (17.475)\tPrec@5 43.750 (44.963)\n",
      "Epoch: [2][300/558]\t\\Time 0.540 (0.542)\tData 0.431 (0.439)\tLoss 3.0499 (3.3606)\tPrec@1 25.000 (17.587)\tPrec@5 50.000 (45.972)\n",
      "Epoch: [2][400/558]\t\\Time 0.553 (0.542)\tData 0.449 (0.438)\tLoss 3.2071 (3.3171)\tPrec@1 25.000 (18.469)\tPrec@5 50.000 (47.382)\n",
      "Epoch: [2][500/558]\t\\Time 0.540 (0.541)\tData 0.420 (0.437)\tLoss 2.9941 (3.2787)\tPrec@1 18.750 (19.174)\tPrec@5 56.250 (48.416)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.518 (0.518)\n",
      "\n",
      "Loss 2.9443 (2.9443)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 43.750 (43.750)\n",
      "\n",
      " * Prec@1 25.000 Prec@5 43.750\n",
      " * Prec@1 15.625 Prec@5 46.875\n",
      " * Prec@1 22.917 Prec@5 50.000\n",
      " * Prec@1 20.312 Prec@5 46.875\n",
      " * Prec@1 21.250 Prec@5 46.250\n",
      " * Prec@1 23.958 Prec@5 48.958\n",
      " * Prec@1 22.321 Prec@5 48.214\n",
      " * Prec@1 21.094 Prec@5 48.438\n",
      " * Prec@1 20.833 Prec@5 49.306\n",
      " * Prec@1 20.000 Prec@5 50.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.480 (0.526)\n",
      "\n",
      "Loss 2.4418 (3.0831)\n",
      "\n",
      "Prec@1 50.000 (22.727)\n",
      "\n",
      "Prec@5 68.750 (52.273)\n",
      "\n",
      " * Prec@1 22.727 Prec@5 52.273\n",
      " * Prec@1 21.354 Prec@5 51.562\n",
      " * Prec@1 22.115 Prec@5 53.846\n",
      " * Prec@1 23.661 Prec@5 54.018\n",
      " * Prec@1 25.417 Prec@5 55.417\n",
      " * Prec@1 25.391 Prec@5 57.422\n",
      " * Prec@1 25.000 Prec@5 57.721\n",
      " * Prec@1 25.694 Prec@5 57.639\n",
      " * Prec@1 26.645 Prec@5 58.553\n",
      " * Prec@1 26.562 Prec@5 58.750\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.562 (0.517)\n",
      "\n",
      "Loss 2.7414 (2.9398)\n",
      "\n",
      "Prec@1 37.500 (27.083)\n",
      "\n",
      "Prec@5 68.750 (59.226)\n",
      "\n",
      " * Prec@1 27.083 Prec@5 59.226\n",
      " * Prec@1 26.989 Prec@5 58.807\n",
      " * Prec@1 27.174 Prec@5 59.783\n",
      " * Prec@1 27.083 Prec@5 59.896\n",
      " * Prec@1 26.750 Prec@5 58.750\n",
      " * Prec@1 27.163 Prec@5 58.894\n",
      " * Prec@1 27.083 Prec@5 58.102\n",
      " * Prec@1 27.009 Prec@5 58.259\n",
      " * Prec@1 27.155 Prec@5 57.974\n",
      " * Prec@1 26.667 Prec@5 57.292\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.475 (0.516)\n",
      "\n",
      "Loss 3.1056 (3.0276)\n",
      "\n",
      "Prec@1 37.500 (27.016)\n",
      "\n",
      "Prec@5 56.250 (57.258)\n",
      "\n",
      " * Prec@1 27.016 Prec@5 57.258\n",
      " * Prec@1 26.562 Prec@5 57.227\n",
      " * Prec@1 26.326 Prec@5 57.008\n",
      " * Prec@1 26.654 Prec@5 57.353\n",
      " * Prec@1 26.786 Prec@5 58.036\n",
      " * Prec@1 26.562 Prec@5 57.812\n",
      " * Prec@1 26.351 Prec@5 57.939\n",
      " * Prec@1 26.316 Prec@5 57.401\n",
      " * Prec@1 25.801 Prec@5 57.051\n",
      " * Prec@1 25.781 Prec@5 57.188\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.462 (0.516)\n",
      "\n",
      "Loss 2.8105 (3.0356)\n",
      "\n",
      "Prec@1 25.000 (25.762)\n",
      "\n",
      "Prec@5 75.000 (57.622)\n",
      "\n",
      " * Prec@1 25.762 Prec@5 57.622\n",
      " * Prec@1 25.595 Prec@5 57.589\n",
      " * Prec@1 25.291 Prec@5 57.267\n",
      " * Prec@1 25.426 Prec@5 56.818\n",
      " * Prec@1 25.278 Prec@5 56.806\n",
      " * Prec@1 25.272 Prec@5 56.386\n",
      " * Prec@1 25.133 Prec@5 55.984\n",
      " * Prec@1 25.130 Prec@5 56.120\n",
      " * Prec@1 25.255 Prec@5 56.505\n",
      " * Prec@1 25.375 Prec@5 56.500\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.509 (0.515)\n",
      "\n",
      "Loss 2.9731 (3.0564)\n",
      "\n",
      "Prec@1 25.000 (25.368)\n",
      "\n",
      "Prec@5 56.250 (56.495)\n",
      "\n",
      " * Prec@1 25.368 Prec@5 56.495\n",
      " * Prec@1 25.240 Prec@5 56.250\n",
      " * Prec@1 25.472 Prec@5 56.368\n",
      " * Prec@1 25.347 Prec@5 56.481\n",
      " * Prec@1 25.000 Prec@5 55.795\n",
      " * Prec@1 24.777 Prec@5 55.580\n",
      " * Prec@1 24.781 Prec@5 55.154\n",
      " * Prec@1 24.892 Prec@5 54.849\n",
      " * Prec@1 25.106 Prec@5 54.661\n",
      " * Prec@1 25.521 Prec@5 54.688\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.500 (0.516)\n",
      "\n",
      "Loss 2.6316 (3.0808)\n",
      "\n",
      "Prec@1 37.500 (25.717)\n",
      "\n",
      "Prec@5 68.750 (54.918)\n",
      "\n",
      " * Prec@1 25.717 Prec@5 54.918\n",
      " * Prec@1 25.605 Prec@5 54.940\n",
      " * Prec@1 25.595 Prec@5 55.159\n",
      " * Prec@1 25.684 Prec@5 55.469\n",
      " * Prec@1 25.481 Prec@5 55.385\n",
      " * Prec@1 25.284 Prec@5 55.587\n",
      " * Prec@1 25.466 Prec@5 55.690\n",
      " * Prec@1 25.276 Prec@5 55.515\n",
      " * Prec@1 25.000 Prec@5 55.163\n",
      " * Prec@1 25.089 Prec@5 55.089\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.541 (0.516)\n",
      "\n",
      "Loss 2.8916 (3.0820)\n",
      "\n",
      "Prec@1 37.500 (25.264)\n",
      "\n",
      "Prec@5 50.000 (55.018)\n",
      "\n",
      " * Prec@1 25.264 Prec@5 55.018\n",
      " * Prec@1 25.260 Prec@5 54.774\n",
      " * Prec@1 25.342 Prec@5 55.308\n",
      " * Prec@1 25.084 Prec@5 55.152\n",
      " * Prec@1 24.917 Prec@5 54.833\n",
      " * Prec@1 24.836 Prec@5 54.770\n",
      " * Prec@1 24.594 Prec@5 54.627\n",
      " * Prec@1 24.599 Prec@5 54.728\n",
      " * Prec@1 24.604 Prec@5 54.668\n",
      " * Prec@1 24.453 Prec@5 54.453\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.550 (0.518)\n",
      "\n",
      "Loss 3.6828 (3.0956)\n",
      "\n",
      "Prec@1 12.500 (24.306)\n",
      "\n",
      "Prec@5 31.250 (54.167)\n",
      "\n",
      " * Prec@1 24.306 Prec@5 54.167\n",
      " * Prec@1 24.238 Prec@5 54.040\n",
      " * Prec@1 24.172 Prec@5 53.840\n",
      " * Prec@1 23.884 Prec@5 53.571\n",
      " * Prec@1 23.750 Prec@5 53.456\n",
      " * Prec@1 23.765 Prec@5 53.561\n",
      " * Prec@1 23.635 Prec@5 53.520\n",
      " * Prec@1 23.651 Prec@5 53.409\n",
      " * Prec@1 23.525 Prec@5 53.371\n",
      " * Prec@1 23.611 Prec@5 53.472\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.530 (0.518)\n",
      "\n",
      "Loss 2.7508 (3.1095)\n",
      "\n",
      "Prec@1 31.250 (23.695)\n",
      "\n",
      "Prec@5 56.250 (53.503)\n",
      "\n",
      " * Prec@1 23.695 Prec@5 53.503\n",
      " * Prec@1 23.777 Prec@5 53.465\n",
      " * Prec@1 23.925 Prec@5 53.427\n",
      " * Prec@1 23.803 Prec@5 53.590\n",
      " * Prec@1 23.750 Prec@5 53.553\n",
      " * Prec@1 23.568 Prec@5 53.516\n",
      " * Prec@1 23.518 Prec@5 53.415\n",
      " * Prec@1 23.406 Prec@5 53.253\n",
      " * Prec@1 23.422 Prec@5 53.346\n",
      " * Prec@1 23.312 Prec@5 53.250\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.511 (0.518)\n",
      "\n",
      "Loss 3.2409 (3.1163)\n",
      "\n",
      "Prec@1 31.250 (23.391)\n",
      "\n",
      "Prec@5 50.000 (53.218)\n",
      "\n",
      " * Prec@1 23.391 Prec@5 53.218\n",
      " * Prec@1 23.284 Prec@5 53.064\n",
      " * Prec@1 23.544 Prec@5 53.155\n",
      " * Prec@1 23.438 Prec@5 53.065\n",
      " * Prec@1 23.631 Prec@5 53.155\n",
      " * Prec@1 23.585 Prec@5 52.948\n",
      " * Prec@1 23.657 Prec@5 52.921\n",
      " * Prec@1 23.843 Prec@5 53.125\n",
      " * Prec@1 23.853 Prec@5 53.039\n",
      " * Prec@1 23.693 Prec@5 53.068\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.480 (0.518)\n",
      "\n",
      "Loss 3.6296 (3.1179)\n",
      "\n",
      "Prec@1 12.500 (23.592)\n",
      "\n",
      "Prec@5 25.000 (52.815)\n",
      "\n",
      " * Prec@1 23.592 Prec@5 52.815\n",
      " * Prec@1 23.605 Prec@5 52.846\n",
      " * Prec@1 23.451 Prec@5 52.821\n",
      " * Prec@1 23.520 Prec@5 52.961\n",
      " * Prec@1 23.587 Prec@5 52.935\n",
      " * Prec@1 23.491 Prec@5 53.071\n",
      " * Prec@1 23.397 Prec@5 53.098\n",
      " * Prec@1 23.358 Prec@5 52.966\n",
      " * Prec@1 23.319 Prec@5 52.994\n",
      " * Prec@1 23.385 Prec@5 52.917\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.523 (0.518)\n",
      "\n",
      "Loss 3.6373 (3.1204)\n",
      "\n",
      "Prec@1 18.750 (23.347)\n",
      "\n",
      "Prec@5 31.250 (52.738)\n",
      "\n",
      " * Prec@1 23.347 Prec@5 52.738\n",
      " * Prec@1 23.309 Prec@5 52.664\n",
      " * Prec@1 23.374 Prec@5 52.693\n",
      " * Prec@1 23.387 Prec@5 52.621\n",
      " * Prec@1 23.400 Prec@5 52.500\n",
      " * Prec@1 23.313 Prec@5 52.579\n",
      " * Prec@1 23.474 Prec@5 52.657\n",
      " * Prec@1 23.340 Prec@5 52.637\n",
      " * Prec@1 23.256 Prec@5 52.616\n",
      " * Prec@1 23.173 Prec@5 52.500\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.544 (0.518)\n",
      "\n",
      "Loss 4.1052 (3.1383)\n",
      "\n",
      "Prec@1 12.500 (23.092)\n",
      "\n",
      "Prec@5 31.250 (52.338)\n",
      "\n",
      " * Prec@1 23.092 Prec@5 52.338\n",
      " * Prec@1 23.153 Prec@5 52.320\n",
      " * Prec@1 23.167 Prec@5 52.303\n",
      " * Prec@1 23.274 Prec@5 52.379\n",
      " * Prec@1 23.241 Prec@5 52.407\n",
      " * Prec@1 23.300 Prec@5 52.390\n",
      " * Prec@1 23.449 Prec@5 52.509\n",
      " * Prec@1 23.324 Prec@5 52.446\n",
      " * Prec@1 23.246 Prec@5 52.338\n",
      " * Prec@1 23.163 Prec@5 52.330\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/558]\t\\Time 0.530 (0.530)\tData 0.417 (0.417)\tLoss 3.1351 (3.1351)\tPrec@1 6.250 (6.250)\tPrec@5 56.250 (56.250)\n",
      "Epoch: [3][100/558]\t\\Time 0.479 (0.512)\tData 0.369 (0.409)\tLoss 2.3702 (2.8817)\tPrec@1 31.250 (25.990)\tPrec@5 62.500 (58.045)\n",
      "Epoch: [3][200/558]\t\\Time 0.504 (0.513)\tData 0.400 (0.410)\tLoss 3.7970 (2.9156)\tPrec@1 12.500 (26.119)\tPrec@5 43.750 (57.307)\n",
      "Epoch: [3][300/558]\t\\Time 0.543 (0.513)\tData 0.441 (0.410)\tLoss 2.8895 (2.9286)\tPrec@1 18.750 (25.914)\tPrec@5 68.750 (56.748)\n",
      "Epoch: [3][400/558]\t\\Time 0.513 (0.514)\tData 0.406 (0.412)\tLoss 2.2350 (2.9076)\tPrec@1 50.000 (26.356)\tPrec@5 62.500 (57.793)\n",
      "Epoch: [3][500/558]\t\\Time 0.540 (0.516)\tData 0.434 (0.414)\tLoss 2.2638 (2.8819)\tPrec@1 37.500 (26.697)\tPrec@5 75.000 (58.520)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.509 (0.509)\n",
      "\n",
      "Loss 3.1152 (3.1152)\n",
      "\n",
      "Prec@1 37.500 (37.500)\n",
      "\n",
      "Prec@5 43.750 (43.750)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 43.750\n",
      " * Prec@1 37.500 Prec@5 46.875\n",
      " * Prec@1 37.500 Prec@5 54.167\n",
      " * Prec@1 34.375 Prec@5 53.125\n",
      " * Prec@1 32.500 Prec@5 52.500\n",
      " * Prec@1 32.292 Prec@5 52.083\n",
      " * Prec@1 29.464 Prec@5 50.893\n",
      " * Prec@1 29.688 Prec@5 50.781\n",
      " * Prec@1 27.778 Prec@5 52.083\n",
      " * Prec@1 28.125 Prec@5 52.500\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.519 (0.537)\n",
      "\n",
      "Loss 2.4368 (2.9403)\n",
      "\n",
      "Prec@1 37.500 (28.977)\n",
      "\n",
      "Prec@5 62.500 (53.409)\n",
      "\n",
      " * Prec@1 28.977 Prec@5 53.409\n",
      " * Prec@1 27.604 Prec@5 53.646\n",
      " * Prec@1 28.365 Prec@5 55.288\n",
      " * Prec@1 28.571 Prec@5 55.804\n",
      " * Prec@1 27.500 Prec@5 56.250\n",
      " * Prec@1 27.344 Prec@5 57.422\n",
      " * Prec@1 27.574 Prec@5 57.353\n",
      " * Prec@1 27.778 Prec@5 56.944\n",
      " * Prec@1 27.961 Prec@5 55.921\n",
      " * Prec@1 28.125 Prec@5 55.625\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.541 (0.524)\n",
      "\n",
      "Loss 3.1246 (2.8832)\n",
      "\n",
      "Prec@1 25.000 (27.976)\n",
      "\n",
      "Prec@5 43.750 (55.060)\n",
      "\n",
      " * Prec@1 27.976 Prec@5 55.060\n",
      " * Prec@1 28.125 Prec@5 55.398\n",
      " * Prec@1 28.261 Prec@5 55.435\n",
      " * Prec@1 28.385 Prec@5 55.729\n",
      " * Prec@1 27.750 Prec@5 55.250\n",
      " * Prec@1 27.644 Prec@5 55.769\n",
      " * Prec@1 27.546 Prec@5 55.324\n",
      " * Prec@1 27.455 Prec@5 55.804\n",
      " * Prec@1 27.586 Prec@5 56.034\n",
      " * Prec@1 27.292 Prec@5 55.625\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.488 (0.521)\n",
      "\n",
      "Loss 2.7667 (2.8917)\n",
      "\n",
      "Prec@1 18.750 (27.016)\n",
      "\n",
      "Prec@5 56.250 (55.645)\n",
      "\n",
      " * Prec@1 27.016 Prec@5 55.645\n",
      " * Prec@1 27.344 Prec@5 56.055\n",
      " * Prec@1 27.462 Prec@5 55.682\n",
      " * Prec@1 27.941 Prec@5 56.434\n",
      " * Prec@1 28.571 Prec@5 56.964\n",
      " * Prec@1 28.472 Prec@5 57.118\n",
      " * Prec@1 28.378 Prec@5 57.264\n",
      " * Prec@1 28.289 Prec@5 56.579\n",
      " * Prec@1 27.885 Prec@5 56.571\n",
      " * Prec@1 27.812 Prec@5 56.875\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.431 (0.522)\n",
      "\n",
      "Loss 2.6051 (2.8705)\n",
      "\n",
      "Prec@1 31.250 (27.896)\n",
      "\n",
      "Prec@5 75.000 (57.317)\n",
      "\n",
      " * Prec@1 27.896 Prec@5 57.317\n",
      " * Prec@1 27.827 Prec@5 57.143\n",
      " * Prec@1 27.326 Prec@5 56.831\n",
      " * Prec@1 27.131 Prec@5 56.960\n",
      " * Prec@1 26.944 Prec@5 56.667\n",
      " * Prec@1 26.766 Prec@5 56.386\n",
      " * Prec@1 26.862 Prec@5 56.383\n",
      " * Prec@1 27.083 Prec@5 56.771\n",
      " * Prec@1 26.913 Prec@5 56.888\n",
      " * Prec@1 27.000 Prec@5 57.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.538 (0.522)\n",
      "\n",
      "Loss 2.1905 (2.8851)\n",
      "\n",
      "Prec@1 50.000 (27.451)\n",
      "\n",
      "Prec@5 81.250 (57.721)\n",
      "\n",
      " * Prec@1 27.451 Prec@5 57.721\n",
      " * Prec@1 27.524 Prec@5 57.933\n",
      " * Prec@1 27.358 Prec@5 57.901\n",
      " * Prec@1 27.431 Prec@5 57.986\n",
      " * Prec@1 27.273 Prec@5 57.727\n",
      " * Prec@1 27.121 Prec@5 57.701\n",
      " * Prec@1 26.974 Prec@5 57.675\n",
      " * Prec@1 27.047 Prec@5 57.543\n",
      " * Prec@1 27.013 Prec@5 57.309\n",
      " * Prec@1 27.188 Prec@5 57.292\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.503 (0.523)\n",
      "\n",
      "Loss 2.4255 (2.8873)\n",
      "\n",
      "Prec@1 25.000 (27.152)\n",
      "\n",
      "Prec@5 75.000 (57.582)\n",
      "\n",
      " * Prec@1 27.152 Prec@5 57.582\n",
      " * Prec@1 27.016 Prec@5 57.560\n",
      " * Prec@1 27.083 Prec@5 57.440\n",
      " * Prec@1 27.637 Prec@5 57.910\n",
      " * Prec@1 27.500 Prec@5 57.885\n",
      " * Prec@1 27.462 Prec@5 57.765\n",
      " * Prec@1 27.425 Prec@5 58.022\n",
      " * Prec@1 27.114 Prec@5 57.629\n",
      " * Prec@1 26.812 Prec@5 57.337\n",
      " * Prec@1 26.786 Prec@5 57.321\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.582 (0.527)\n",
      "\n",
      "Loss 2.3869 (2.9035)\n",
      "\n",
      "Prec@1 37.500 (26.937)\n",
      "\n",
      "Prec@5 62.500 (57.394)\n",
      "\n",
      " * Prec@1 26.937 Prec@5 57.394\n",
      " * Prec@1 26.823 Prec@5 57.118\n",
      " * Prec@1 27.055 Prec@5 57.363\n",
      " * Prec@1 26.943 Prec@5 57.432\n",
      " * Prec@1 26.917 Prec@5 57.333\n",
      " * Prec@1 26.727 Prec@5 57.155\n",
      " * Prec@1 26.705 Prec@5 56.981\n",
      " * Prec@1 26.843 Prec@5 57.131\n",
      " * Prec@1 26.661 Prec@5 57.041\n",
      " * Prec@1 26.719 Prec@5 56.953\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.544 (0.529)\n",
      "\n",
      "Loss 3.4638 (2.9172)\n",
      "\n",
      "Prec@1 18.750 (26.620)\n",
      "\n",
      "Prec@5 50.000 (56.867)\n",
      "\n",
      " * Prec@1 26.620 Prec@5 56.867\n",
      " * Prec@1 26.601 Prec@5 56.860\n",
      " * Prec@1 26.506 Prec@5 56.852\n",
      " * Prec@1 26.339 Prec@5 56.771\n",
      " * Prec@1 26.250 Prec@5 56.691\n",
      " * Prec@1 26.235 Prec@5 56.686\n",
      " * Prec@1 26.293 Prec@5 56.753\n",
      " * Prec@1 26.349 Prec@5 56.676\n",
      " * Prec@1 26.194 Prec@5 56.320\n",
      " * Prec@1 26.458 Prec@5 56.528\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.592 (0.530)\n",
      "\n",
      "Loss 2.6281 (2.9215)\n",
      "\n",
      "Prec@1 18.750 (26.374)\n",
      "\n",
      "Prec@5 81.250 (56.799)\n",
      "\n",
      " * Prec@1 26.374 Prec@5 56.799\n",
      " * Prec@1 26.562 Prec@5 56.929\n",
      " * Prec@1 26.680 Prec@5 57.056\n",
      " * Prec@1 26.662 Prec@5 57.048\n",
      " * Prec@1 26.711 Prec@5 57.237\n",
      " * Prec@1 26.628 Prec@5 57.227\n",
      " * Prec@1 26.804 Prec@5 57.410\n",
      " * Prec@1 26.594 Prec@5 57.270\n",
      " * Prec@1 26.515 Prec@5 57.260\n",
      " * Prec@1 26.562 Prec@5 57.312\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.525 (0.531)\n",
      "\n",
      "Loss 3.7223 (2.9123)\n",
      "\n",
      "Prec@1 18.750 (26.485)\n",
      "\n",
      "Prec@5 43.750 (57.178)\n",
      "\n",
      " * Prec@1 26.485 Prec@5 57.178\n",
      " * Prec@1 26.409 Prec@5 57.169\n",
      " * Prec@1 26.456 Prec@5 57.160\n",
      " * Prec@1 26.322 Prec@5 57.212\n",
      " * Prec@1 26.548 Prec@5 57.381\n",
      " * Prec@1 26.356 Prec@5 57.429\n",
      " * Prec@1 26.460 Prec@5 57.593\n",
      " * Prec@1 26.562 Prec@5 57.755\n",
      " * Prec@1 26.663 Prec@5 57.626\n",
      " * Prec@1 26.648 Prec@5 57.557\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.487 (0.529)\n",
      "\n",
      "Loss 3.6184 (2.9142)\n",
      "\n",
      "Prec@1 6.250 (26.464)\n",
      "\n",
      "Prec@5 50.000 (57.489)\n",
      "\n",
      " * Prec@1 26.464 Prec@5 57.489\n",
      " * Prec@1 26.562 Prec@5 57.812\n",
      " * Prec@1 26.549 Prec@5 57.909\n",
      " * Prec@1 26.535 Prec@5 58.059\n",
      " * Prec@1 26.630 Prec@5 58.043\n",
      " * Prec@1 26.724 Prec@5 58.082\n",
      " * Prec@1 26.709 Prec@5 58.066\n",
      " * Prec@1 26.748 Prec@5 58.051\n",
      " * Prec@1 26.733 Prec@5 57.931\n",
      " * Prec@1 26.719 Prec@5 57.865\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.522 (0.528)\n",
      "\n",
      "Loss 3.7954 (2.9157)\n",
      "\n",
      "Prec@1 12.500 (26.601)\n",
      "\n",
      "Prec@5 37.500 (57.696)\n",
      "\n",
      " * Prec@1 26.601 Prec@5 57.696\n",
      " * Prec@1 26.588 Prec@5 57.428\n",
      " * Prec@1 26.626 Prec@5 57.419\n",
      " * Prec@1 26.512 Prec@5 57.359\n",
      " * Prec@1 26.550 Prec@5 57.300\n",
      " * Prec@1 26.488 Prec@5 57.292\n",
      " * Prec@1 26.624 Prec@5 57.431\n",
      " * Prec@1 26.611 Prec@5 57.471\n",
      " * Prec@1 26.599 Prec@5 57.510\n",
      " * Prec@1 26.538 Prec@5 57.500\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.501 (0.527)\n",
      "\n",
      "Loss 4.3701 (2.9302)\n",
      "\n",
      "Prec@1 6.250 (26.384)\n",
      "\n",
      "Prec@5 18.750 (57.204)\n",
      "\n",
      " * Prec@1 26.384 Prec@5 57.204\n",
      " * Prec@1 26.420 Prec@5 57.102\n",
      " * Prec@1 26.504 Prec@5 57.284\n",
      " * Prec@1 26.493 Prec@5 57.323\n",
      " * Prec@1 26.481 Prec@5 57.407\n",
      " * Prec@1 26.287 Prec@5 57.261\n",
      " * Prec@1 26.323 Prec@5 57.254\n",
      " * Prec@1 26.313 Prec@5 57.201\n",
      " * Prec@1 26.304 Prec@5 57.104\n",
      " * Prec@1 26.299 Prec@5 57.124\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/558]\t\\Time 0.518 (0.518)\tData 0.408 (0.408)\tLoss 2.2348 (2.2348)\tPrec@1 37.500 (37.500)\tPrec@5 68.750 (68.750)\n",
      "Epoch: [4][100/558]\t\\Time 0.520 (0.513)\tData 0.424 (0.413)\tLoss 2.3812 (2.5884)\tPrec@1 37.500 (32.364)\tPrec@5 75.000 (64.480)\n",
      "Epoch: [4][200/558]\t\\Time 0.584 (0.511)\tData 0.471 (0.411)\tLoss 2.5237 (2.5710)\tPrec@1 37.500 (33.427)\tPrec@5 81.250 (65.299)\n",
      "Epoch: [4][300/558]\t\\Time 0.579 (0.512)\tData 0.459 (0.411)\tLoss 2.6688 (2.5833)\tPrec@1 25.000 (33.555)\tPrec@5 68.750 (65.345)\n",
      "Epoch: [4][400/558]\t\\Time 0.481 (0.512)\tData 0.411 (0.411)\tLoss 2.8563 (2.5615)\tPrec@1 25.000 (34.320)\tPrec@5 50.000 (65.742)\n",
      "Epoch: [4][500/558]\t\\Time 0.455 (0.516)\tData 0.341 (0.414)\tLoss 2.5358 (2.5350)\tPrec@1 37.500 (34.843)\tPrec@5 75.000 (66.417)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.549 (0.549)\n",
      "\n",
      "Loss 3.0306 (3.0306)\n",
      "\n",
      "Prec@1 37.500 (37.500)\n",
      "\n",
      "Prec@5 43.750 (43.750)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 43.750\n",
      " * Prec@1 31.250 Prec@5 53.125\n",
      " * Prec@1 35.417 Prec@5 56.250\n",
      " * Prec@1 32.812 Prec@5 54.688\n",
      " * Prec@1 31.250 Prec@5 56.250\n",
      " * Prec@1 32.292 Prec@5 57.292\n",
      " * Prec@1 30.357 Prec@5 56.250\n",
      " * Prec@1 31.250 Prec@5 57.812\n",
      " * Prec@1 31.250 Prec@5 59.028\n",
      " * Prec@1 32.500 Prec@5 61.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.546 (0.533)\n",
      "\n",
      "Loss 2.0656 (2.6277)\n",
      "\n",
      "Prec@1 50.000 (34.091)\n",
      "\n",
      "Prec@5 68.750 (61.932)\n",
      "\n",
      " * Prec@1 34.091 Prec@5 61.932\n",
      " * Prec@1 32.812 Prec@5 61.458\n",
      " * Prec@1 33.654 Prec@5 62.981\n",
      " * Prec@1 34.375 Prec@5 64.286\n",
      " * Prec@1 34.583 Prec@5 65.000\n",
      " * Prec@1 36.328 Prec@5 66.797\n",
      " * Prec@1 36.397 Prec@5 66.176\n",
      " * Prec@1 36.458 Prec@5 65.972\n",
      " * Prec@1 36.513 Prec@5 66.776\n",
      " * Prec@1 35.938 Prec@5 66.562\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.532 (0.528)\n",
      "\n",
      "Loss 2.6885 (2.5611)\n",
      "\n",
      "Prec@1 25.000 (35.417)\n",
      "\n",
      "Prec@5 56.250 (66.071)\n",
      "\n",
      " * Prec@1 35.417 Prec@5 66.071\n",
      " * Prec@1 35.227 Prec@5 66.193\n",
      " * Prec@1 36.141 Prec@5 66.033\n",
      " * Prec@1 35.938 Prec@5 65.885\n",
      " * Prec@1 35.250 Prec@5 65.750\n",
      " * Prec@1 35.096 Prec@5 66.346\n",
      " * Prec@1 34.954 Prec@5 65.741\n",
      " * Prec@1 35.938 Prec@5 65.848\n",
      " * Prec@1 35.560 Prec@5 65.517\n",
      " * Prec@1 35.208 Prec@5 65.417\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.510 (0.531)\n",
      "\n",
      "Loss 2.2325 (2.5935)\n",
      "\n",
      "Prec@1 50.000 (35.685)\n",
      "\n",
      "Prec@5 75.000 (65.726)\n",
      "\n",
      " * Prec@1 35.685 Prec@5 65.726\n",
      " * Prec@1 35.938 Prec@5 65.625\n",
      " * Prec@1 35.985 Prec@5 65.530\n",
      " * Prec@1 36.397 Prec@5 65.625\n",
      " * Prec@1 36.429 Prec@5 65.536\n",
      " * Prec@1 36.458 Prec@5 65.799\n",
      " * Prec@1 36.149 Prec@5 65.709\n",
      " * Prec@1 35.691 Prec@5 65.296\n",
      " * Prec@1 35.737 Prec@5 65.224\n",
      " * Prec@1 35.938 Prec@5 65.000\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.487 (0.533)\n",
      "\n",
      "Loss 2.2164 (2.6045)\n",
      "\n",
      "Prec@1 37.500 (35.976)\n",
      "\n",
      "Prec@5 81.250 (65.396)\n",
      "\n",
      " * Prec@1 35.976 Prec@5 65.396\n",
      " * Prec@1 35.714 Prec@5 65.179\n",
      " * Prec@1 35.320 Prec@5 64.826\n",
      " * Prec@1 35.227 Prec@5 64.631\n",
      " * Prec@1 34.861 Prec@5 64.444\n",
      " * Prec@1 34.783 Prec@5 64.130\n",
      " * Prec@1 34.840 Prec@5 64.362\n",
      " * Prec@1 35.026 Prec@5 64.583\n",
      " * Prec@1 35.459 Prec@5 64.796\n",
      " * Prec@1 35.750 Prec@5 65.000\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.536 (0.532)\n",
      "\n",
      "Loss 2.3517 (2.6041)\n",
      "\n",
      "Prec@1 37.500 (35.784)\n",
      "\n",
      "Prec@5 68.750 (65.074)\n",
      "\n",
      " * Prec@1 35.784 Prec@5 65.074\n",
      " * Prec@1 35.817 Prec@5 65.024\n",
      " * Prec@1 36.085 Prec@5 65.094\n",
      " * Prec@1 36.227 Prec@5 65.278\n",
      " * Prec@1 35.909 Prec@5 65.227\n",
      " * Prec@1 36.049 Prec@5 65.067\n",
      " * Prec@1 36.184 Prec@5 64.803\n",
      " * Prec@1 35.991 Prec@5 64.763\n",
      " * Prec@1 36.017 Prec@5 64.513\n",
      " * Prec@1 36.042 Prec@5 64.479\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.513 (0.530)\n",
      "\n",
      "Loss 1.8695 (2.6028)\n",
      "\n",
      "Prec@1 50.000 (36.270)\n",
      "\n",
      "Prec@5 93.750 (64.959)\n",
      "\n",
      " * Prec@1 36.270 Prec@5 64.959\n",
      " * Prec@1 36.089 Prec@5 65.020\n",
      " * Prec@1 36.310 Prec@5 65.079\n",
      " * Prec@1 36.230 Prec@5 65.234\n",
      " * Prec@1 35.865 Prec@5 65.096\n",
      " * Prec@1 35.890 Prec@5 65.057\n",
      " * Prec@1 35.821 Prec@5 65.019\n",
      " * Prec@1 35.662 Prec@5 65.165\n",
      " * Prec@1 35.417 Prec@5 64.583\n",
      " * Prec@1 35.446 Prec@5 64.375\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.542 (0.530)\n",
      "\n",
      "Loss 1.9610 (2.6201)\n",
      "\n",
      "Prec@1 56.250 (35.739)\n",
      "\n",
      "Prec@5 68.750 (64.437)\n",
      "\n",
      " * Prec@1 35.739 Prec@5 64.437\n",
      " * Prec@1 35.590 Prec@5 64.323\n",
      " * Prec@1 35.616 Prec@5 64.555\n",
      " * Prec@1 35.642 Prec@5 64.443\n",
      " * Prec@1 35.667 Prec@5 64.333\n",
      " * Prec@1 35.526 Prec@5 64.145\n",
      " * Prec@1 35.390 Prec@5 64.042\n",
      " * Prec@1 35.577 Prec@5 64.103\n",
      " * Prec@1 35.680 Prec@5 64.082\n",
      " * Prec@1 35.547 Prec@5 64.141\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.509 (0.529)\n",
      "\n",
      "Loss 3.0482 (2.6326)\n",
      "\n",
      "Prec@1 25.000 (35.417)\n",
      "\n",
      "Prec@5 50.000 (63.966)\n",
      "\n",
      " * Prec@1 35.417 Prec@5 63.966\n",
      " * Prec@1 35.290 Prec@5 64.024\n",
      " * Prec@1 35.316 Prec@5 63.931\n",
      " * Prec@1 35.193 Prec@5 63.765\n",
      " * Prec@1 34.853 Prec@5 63.603\n",
      " * Prec@1 34.811 Prec@5 63.517\n",
      " * Prec@1 34.698 Prec@5 63.649\n",
      " * Prec@1 34.517 Prec@5 63.636\n",
      " * Prec@1 34.270 Prec@5 63.272\n",
      " * Prec@1 34.583 Prec@5 63.542\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.529 (0.527)\n",
      "\n",
      "Loss 2.2869 (2.6426)\n",
      "\n",
      "Prec@1 37.500 (34.615)\n",
      "\n",
      "Prec@5 75.000 (63.668)\n",
      "\n",
      " * Prec@1 34.615 Prec@5 63.668\n",
      " * Prec@1 34.715 Prec@5 63.723\n",
      " * Prec@1 34.745 Prec@5 63.642\n",
      " * Prec@1 34.774 Prec@5 63.630\n",
      " * Prec@1 34.803 Prec@5 63.553\n",
      " * Prec@1 34.701 Prec@5 63.672\n",
      " * Prec@1 34.858 Prec@5 63.789\n",
      " * Prec@1 34.694 Prec@5 63.712\n",
      " * Prec@1 34.596 Prec@5 63.699\n",
      " * Prec@1 34.625 Prec@5 63.875\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.514 (0.526)\n",
      "\n",
      "Loss 3.3245 (2.6395)\n",
      "\n",
      "Prec@1 31.250 (34.592)\n",
      "\n",
      "Prec@5 43.750 (63.676)\n",
      "\n",
      " * Prec@1 34.592 Prec@5 63.676\n",
      " * Prec@1 34.498 Prec@5 63.542\n",
      " * Prec@1 34.769 Prec@5 63.653\n",
      " * Prec@1 34.736 Prec@5 63.702\n",
      " * Prec@1 34.881 Prec@5 63.750\n",
      " * Prec@1 34.788 Prec@5 63.738\n",
      " * Prec@1 34.871 Prec@5 63.668\n",
      " * Prec@1 35.069 Prec@5 63.773\n",
      " * Prec@1 34.977 Prec@5 63.761\n",
      " * Prec@1 34.886 Prec@5 63.750\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.468 (0.526)\n",
      "\n",
      "Loss 3.0027 (2.6319)\n",
      "\n",
      "Prec@1 25.000 (34.797)\n",
      "\n",
      "Prec@5 56.250 (63.682)\n",
      "\n",
      " * Prec@1 34.797 Prec@5 63.682\n",
      " * Prec@1 34.877 Prec@5 63.839\n",
      " * Prec@1 34.790 Prec@5 63.883\n",
      " * Prec@1 34.759 Prec@5 63.980\n",
      " * Prec@1 34.728 Prec@5 63.967\n",
      " * Prec@1 34.752 Prec@5 63.955\n",
      " * Prec@1 34.669 Prec@5 63.942\n",
      " * Prec@1 34.534 Prec@5 63.983\n",
      " * Prec@1 34.454 Prec@5 64.023\n",
      " * Prec@1 34.479 Prec@5 64.010\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.505 (0.524)\n",
      "\n",
      "Loss 3.3198 (2.6398)\n",
      "\n",
      "Prec@1 25.000 (34.401)\n",
      "\n",
      "Prec@5 31.250 (63.740)\n",
      "\n",
      " * Prec@1 34.401 Prec@5 63.740\n",
      " * Prec@1 34.273 Prec@5 63.678\n",
      " * Prec@1 34.400 Prec@5 63.669\n",
      " * Prec@1 34.375 Prec@5 63.810\n",
      " * Prec@1 34.350 Prec@5 63.800\n",
      " * Prec@1 34.325 Prec@5 63.839\n",
      " * Prec@1 34.400 Prec@5 63.878\n",
      " * Prec@1 34.375 Prec@5 63.867\n",
      " * Prec@1 34.496 Prec@5 63.857\n",
      " * Prec@1 34.519 Prec@5 63.750\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.529 (0.523)\n",
      "\n",
      "Loss 3.6613 (2.6396)\n",
      "\n",
      "Prec@1 18.750 (34.399)\n",
      "\n",
      "Prec@5 31.250 (63.502)\n",
      "\n",
      " * Prec@1 34.399 Prec@5 63.502\n",
      " * Prec@1 34.375 Prec@5 63.494\n",
      " * Prec@1 34.398 Prec@5 63.534\n",
      " * Prec@1 34.468 Prec@5 63.619\n",
      " * Prec@1 34.398 Prec@5 63.657\n",
      " * Prec@1 34.375 Prec@5 63.649\n",
      " * Prec@1 34.352 Prec@5 63.732\n",
      " * Prec@1 34.330 Prec@5 63.678\n",
      " * Prec@1 34.263 Prec@5 63.624\n",
      " * Prec@1 34.185 Prec@5 63.530\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/558]\t\\Time 0.506 (0.506)\tData 0.406 (0.406)\tLoss 2.0771 (2.0771)\tPrec@1 50.000 (50.000)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [5][100/558]\t\\Time 0.527 (0.507)\tData 0.433 (0.408)\tLoss 1.5522 (2.1543)\tPrec@1 50.000 (43.564)\tPrec@5 75.000 (74.443)\n",
      "Epoch: [5][200/558]\t\\Time 0.460 (0.507)\tData 0.371 (0.409)\tLoss 2.5699 (2.1973)\tPrec@1 37.500 (41.791)\tPrec@5 68.750 (74.160)\n",
      "Epoch: [5][300/558]\t\\Time 0.483 (0.510)\tData 0.403 (0.410)\tLoss 2.3495 (2.2031)\tPrec@1 31.250 (41.923)\tPrec@5 75.000 (74.128)\n",
      "Epoch: [5][400/558]\t\\Time 0.604 (0.512)\tData 0.464 (0.411)\tLoss 2.4378 (2.2002)\tPrec@1 37.500 (42.207)\tPrec@5 75.000 (73.925)\n",
      "Epoch: [5][500/558]\t\\Time 0.520 (0.514)\tData 0.420 (0.413)\tLoss 1.7000 (2.2070)\tPrec@1 56.250 (42.166)\tPrec@5 75.000 (73.678)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.531 (0.531)\n",
      "\n",
      "Loss 2.5292 (2.5292)\n",
      "\n",
      "Prec@1 31.250 (31.250)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 31.250 Prec@5 68.750\n",
      " * Prec@1 31.250 Prec@5 71.875\n",
      " * Prec@1 39.583 Prec@5 75.000\n",
      " * Prec@1 35.938 Prec@5 71.875\n",
      " * Prec@1 36.250 Prec@5 67.500\n",
      " * Prec@1 36.458 Prec@5 68.750\n",
      " * Prec@1 33.929 Prec@5 69.643\n",
      " * Prec@1 34.375 Prec@5 69.531\n",
      " * Prec@1 35.417 Prec@5 71.528\n",
      " * Prec@1 35.000 Prec@5 71.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.521 (0.532)\n",
      "\n",
      "Loss 1.8867 (2.2612)\n",
      "\n",
      "Prec@1 50.000 (36.364)\n",
      "\n",
      "Prec@5 75.000 (71.591)\n",
      "\n",
      " * Prec@1 36.364 Prec@5 71.591\n",
      " * Prec@1 38.021 Prec@5 72.396\n",
      " * Prec@1 38.462 Prec@5 73.558\n",
      " * Prec@1 39.732 Prec@5 73.661\n",
      " * Prec@1 40.000 Prec@5 73.750\n",
      " * Prec@1 41.406 Prec@5 74.609\n",
      " * Prec@1 40.441 Prec@5 73.529\n",
      " * Prec@1 39.931 Prec@5 73.958\n",
      " * Prec@1 40.461 Prec@5 74.342\n",
      " * Prec@1 40.312 Prec@5 73.750\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.575 (0.532)\n",
      "\n",
      "Loss 2.7106 (2.2045)\n",
      "\n",
      "Prec@1 43.750 (40.476)\n",
      "\n",
      "Prec@5 56.250 (72.917)\n",
      "\n",
      " * Prec@1 40.476 Prec@5 72.917\n",
      " * Prec@1 40.341 Prec@5 72.727\n",
      " * Prec@1 40.761 Prec@5 73.370\n",
      " * Prec@1 41.146 Prec@5 72.917\n",
      " * Prec@1 40.500 Prec@5 72.000\n",
      " * Prec@1 41.106 Prec@5 72.596\n",
      " * Prec@1 40.509 Prec@5 72.222\n",
      " * Prec@1 40.848 Prec@5 72.098\n",
      " * Prec@1 40.517 Prec@5 71.552\n",
      " * Prec@1 40.000 Prec@5 71.250\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.539 (0.539)\n",
      "\n",
      "Loss 2.2309 (2.2736)\n",
      "\n",
      "Prec@1 31.250 (39.718)\n",
      "\n",
      "Prec@5 75.000 (71.371)\n",
      "\n",
      " * Prec@1 39.718 Prec@5 71.371\n",
      " * Prec@1 40.234 Prec@5 71.484\n",
      " * Prec@1 39.962 Prec@5 70.833\n",
      " * Prec@1 40.074 Prec@5 71.324\n",
      " * Prec@1 40.000 Prec@5 71.071\n",
      " * Prec@1 39.931 Prec@5 71.528\n",
      " * Prec@1 40.034 Prec@5 71.284\n",
      " * Prec@1 39.803 Prec@5 70.888\n",
      " * Prec@1 39.744 Prec@5 70.833\n",
      " * Prec@1 39.531 Prec@5 70.625\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.474 (0.539)\n",
      "\n",
      "Loss 1.6240 (2.2782)\n",
      "\n",
      "Prec@1 56.250 (39.939)\n",
      "\n",
      "Prec@5 93.750 (71.189)\n",
      "\n",
      " * Prec@1 39.939 Prec@5 71.189\n",
      " * Prec@1 39.881 Prec@5 70.982\n",
      " * Prec@1 39.826 Prec@5 71.221\n",
      " * Prec@1 40.057 Prec@5 71.449\n",
      " * Prec@1 39.722 Prec@5 71.111\n",
      " * Prec@1 39.674 Prec@5 70.924\n",
      " * Prec@1 39.894 Prec@5 71.144\n",
      " * Prec@1 39.974 Prec@5 71.354\n",
      " * Prec@1 40.306 Prec@5 71.684\n",
      " * Prec@1 40.250 Prec@5 71.875\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.594 (0.541)\n",
      "\n",
      "Loss 2.1697 (2.2918)\n",
      "\n",
      "Prec@1 50.000 (40.441)\n",
      "\n",
      "Prec@5 68.750 (71.814)\n",
      "\n",
      " * Prec@1 40.441 Prec@5 71.814\n",
      " * Prec@1 40.385 Prec@5 71.995\n",
      " * Prec@1 40.566 Prec@5 71.934\n",
      " * Prec@1 40.509 Prec@5 72.222\n",
      " * Prec@1 40.227 Prec@5 72.045\n",
      " * Prec@1 39.955 Prec@5 71.763\n",
      " * Prec@1 40.022 Prec@5 71.930\n",
      " * Prec@1 39.871 Prec@5 71.767\n",
      " * Prec@1 39.725 Prec@5 71.292\n",
      " * Prec@1 39.792 Prec@5 71.042\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.472 (0.538)\n",
      "\n",
      "Loss 1.8031 (2.3040)\n",
      "\n",
      "Prec@1 62.500 (40.164)\n",
      "\n",
      "Prec@5 75.000 (71.107)\n",
      "\n",
      " * Prec@1 40.164 Prec@5 71.107\n",
      " * Prec@1 40.524 Prec@5 71.270\n",
      " * Prec@1 40.575 Prec@5 71.329\n",
      " * Prec@1 41.016 Prec@5 71.582\n",
      " * Prec@1 40.769 Prec@5 71.731\n",
      " * Prec@1 40.814 Prec@5 71.686\n",
      " * Prec@1 40.951 Prec@5 71.828\n",
      " * Prec@1 40.901 Prec@5 71.783\n",
      " * Prec@1 40.399 Prec@5 71.649\n",
      " * Prec@1 40.446 Prec@5 71.696\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.520 (0.533)\n",
      "\n",
      "Loss 1.9389 (2.2924)\n",
      "\n",
      "Prec@1 50.000 (40.581)\n",
      "\n",
      "Prec@5 75.000 (71.743)\n",
      "\n",
      " * Prec@1 40.581 Prec@5 71.743\n",
      " * Prec@1 40.451 Prec@5 71.875\n",
      " * Prec@1 40.582 Prec@5 72.003\n",
      " * Prec@1 40.456 Prec@5 72.128\n",
      " * Prec@1 40.500 Prec@5 72.083\n",
      " * Prec@1 40.214 Prec@5 71.875\n",
      " * Prec@1 40.097 Prec@5 72.078\n",
      " * Prec@1 40.224 Prec@5 72.196\n",
      " * Prec@1 40.269 Prec@5 71.994\n",
      " * Prec@1 40.312 Prec@5 71.953\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.549 (0.533)\n",
      "\n",
      "Loss 3.1085 (2.3059)\n",
      "\n",
      "Prec@1 31.250 (40.201)\n",
      "\n",
      "Prec@5 56.250 (71.759)\n",
      "\n",
      " * Prec@1 40.201 Prec@5 71.759\n",
      " * Prec@1 40.320 Prec@5 71.723\n",
      " * Prec@1 40.361 Prec@5 71.762\n",
      " * Prec@1 40.104 Prec@5 71.429\n",
      " * Prec@1 39.853 Prec@5 71.324\n",
      " * Prec@1 39.971 Prec@5 71.366\n",
      " * Prec@1 40.086 Prec@5 71.480\n",
      " * Prec@1 40.270 Prec@5 71.520\n",
      " * Prec@1 40.098 Prec@5 71.067\n",
      " * Prec@1 40.278 Prec@5 71.319\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.520 (0.531)\n",
      "\n",
      "Loss 1.9523 (2.3209)\n",
      "\n",
      "Prec@1 43.750 (40.316)\n",
      "\n",
      "Prec@5 81.250 (71.429)\n",
      "\n",
      " * Prec@1 40.316 Prec@5 71.429\n",
      " * Prec@1 40.557 Prec@5 71.467\n",
      " * Prec@1 40.591 Prec@5 71.438\n",
      " * Prec@1 40.691 Prec@5 71.410\n",
      " * Prec@1 40.526 Prec@5 71.579\n",
      " * Prec@1 40.234 Prec@5 71.615\n",
      " * Prec@1 40.464 Prec@5 71.714\n",
      " * Prec@1 40.497 Prec@5 71.620\n",
      " * Prec@1 40.467 Prec@5 71.717\n",
      " * Prec@1 40.375 Prec@5 71.562\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.500 (0.530)\n",
      "\n",
      "Loss 2.5227 (2.3133)\n",
      "\n",
      "Prec@1 50.000 (40.470)\n",
      "\n",
      "Prec@5 68.750 (71.535)\n",
      "\n",
      " * Prec@1 40.470 Prec@5 71.535\n",
      " * Prec@1 40.257 Prec@5 71.446\n",
      " * Prec@1 40.352 Prec@5 71.420\n",
      " * Prec@1 40.264 Prec@5 71.274\n",
      " * Prec@1 40.417 Prec@5 71.310\n",
      " * Prec@1 40.507 Prec@5 71.285\n",
      " * Prec@1 40.537 Prec@5 71.320\n",
      " * Prec@1 40.683 Prec@5 71.296\n",
      " * Prec@1 40.711 Prec@5 71.330\n",
      " * Prec@1 40.625 Prec@5 71.193\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.451 (0.528)\n",
      "\n",
      "Loss 2.7137 (2.3173)\n",
      "\n",
      "Prec@1 25.000 (40.484)\n",
      "\n",
      "Prec@5 62.500 (71.115)\n",
      "\n",
      " * Prec@1 40.484 Prec@5 71.115\n",
      " * Prec@1 40.625 Prec@5 71.261\n",
      " * Prec@1 40.653 Prec@5 71.239\n",
      " * Prec@1 40.625 Prec@5 71.272\n",
      " * Prec@1 40.652 Prec@5 71.250\n",
      " * Prec@1 40.679 Prec@5 71.175\n",
      " * Prec@1 40.598 Prec@5 71.047\n",
      " * Prec@1 40.572 Prec@5 71.186\n",
      " * Prec@1 40.599 Prec@5 71.166\n",
      " * Prec@1 40.521 Prec@5 70.990\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.521 (0.527)\n",
      "\n",
      "Loss 2.7665 (2.3267)\n",
      "\n",
      "Prec@1 37.500 (40.496)\n",
      "\n",
      "Prec@5 37.500 (70.713)\n",
      "\n",
      " * Prec@1 40.496 Prec@5 70.713\n",
      " * Prec@1 40.420 Prec@5 70.492\n",
      " * Prec@1 40.498 Prec@5 70.528\n",
      " * Prec@1 40.575 Prec@5 70.565\n",
      " * Prec@1 40.500 Prec@5 70.600\n",
      " * Prec@1 40.575 Prec@5 70.685\n",
      " * Prec@1 40.650 Prec@5 70.719\n",
      " * Prec@1 40.625 Prec@5 70.752\n",
      " * Prec@1 40.746 Prec@5 70.736\n",
      " * Prec@1 40.673 Prec@5 70.673\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.550 (0.526)\n",
      "\n",
      "Loss 3.0419 (2.3350)\n",
      "\n",
      "Prec@1 12.500 (40.458)\n",
      "\n",
      "Prec@5 56.250 (70.563)\n",
      "\n",
      " * Prec@1 40.458 Prec@5 70.563\n",
      " * Prec@1 40.483 Prec@5 70.644\n",
      " * Prec@1 40.602 Prec@5 70.677\n",
      " * Prec@1 40.718 Prec@5 70.756\n",
      " * Prec@1 40.741 Prec@5 70.787\n",
      " * Prec@1 40.809 Prec@5 70.726\n",
      " * Prec@1 40.739 Prec@5 70.712\n",
      " * Prec@1 40.716 Prec@5 70.697\n",
      " * Prec@1 40.737 Prec@5 70.683\n",
      " * Prec@1 40.681 Prec@5 70.565\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/558]\t\\Time 0.508 (0.508)\tData 0.398 (0.398)\tLoss 2.0309 (2.0309)\tPrec@1 50.000 (50.000)\tPrec@5 81.250 (81.250)\n",
      "Epoch: [6][100/558]\t\\Time 0.486 (0.509)\tData 0.373 (0.409)\tLoss 1.1969 (1.8488)\tPrec@1 56.250 (50.186)\tPrec@5 87.500 (79.022)\n",
      "Epoch: [6][200/558]\t\\Time 0.515 (0.512)\tData 0.393 (0.411)\tLoss 1.5160 (1.8888)\tPrec@1 56.250 (48.881)\tPrec@5 75.000 (78.483)\n",
      "Epoch: [6][300/558]\t\\Time 0.541 (0.514)\tData 0.437 (0.413)\tLoss 1.2339 (1.9082)\tPrec@1 62.500 (48.713)\tPrec@5 87.500 (78.571)\n",
      "Epoch: [6][400/558]\t\\Time 0.544 (0.515)\tData 0.433 (0.413)\tLoss 1.9963 (1.9312)\tPrec@1 31.250 (48.208)\tPrec@5 87.500 (78.242)\n",
      "Epoch: [6][500/558]\t\\Time 0.516 (0.516)\tData 0.414 (0.415)\tLoss 2.0915 (1.9048)\tPrec@1 43.750 (48.802)\tPrec@5 68.750 (78.767)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.548 (0.548)\n",
      "\n",
      "Loss 2.4343 (2.4343)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 62.500 (62.500)\n",
      "\n",
      " * Prec@1 50.000 Prec@5 62.500\n",
      " * Prec@1 46.875 Prec@5 65.625\n",
      " * Prec@1 52.083 Prec@5 72.917\n",
      " * Prec@1 48.438 Prec@5 70.312\n",
      " * Prec@1 45.000 Prec@5 70.000\n",
      " * Prec@1 44.792 Prec@5 71.875\n",
      " * Prec@1 42.857 Prec@5 74.107\n",
      " * Prec@1 42.969 Prec@5 71.094\n",
      " * Prec@1 44.444 Prec@5 73.611\n",
      " * Prec@1 45.625 Prec@5 74.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.511 (0.555)\n",
      "\n",
      "Loss 1.9303 (2.0686)\n",
      "\n",
      "Prec@1 62.500 (47.159)\n",
      "\n",
      "Prec@5 75.000 (74.432)\n",
      "\n",
      " * Prec@1 47.159 Prec@5 74.432\n",
      " * Prec@1 47.917 Prec@5 75.000\n",
      " * Prec@1 49.038 Prec@5 76.442\n",
      " * Prec@1 49.554 Prec@5 76.786\n",
      " * Prec@1 51.250 Prec@5 77.083\n",
      " * Prec@1 51.172 Prec@5 78.125\n",
      " * Prec@1 50.000 Prec@5 77.941\n",
      " * Prec@1 48.264 Prec@5 78.125\n",
      " * Prec@1 48.684 Prec@5 78.618\n",
      " * Prec@1 49.375 Prec@5 79.062\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.527 (0.532)\n",
      "\n",
      "Loss 2.4865 (1.9428)\n",
      "\n",
      "Prec@1 31.250 (48.512)\n",
      "\n",
      "Prec@5 62.500 (78.274)\n",
      "\n",
      " * Prec@1 48.512 Prec@5 78.274\n",
      " * Prec@1 48.580 Prec@5 78.693\n",
      " * Prec@1 49.457 Prec@5 78.533\n",
      " * Prec@1 48.958 Prec@5 78.125\n",
      " * Prec@1 49.000 Prec@5 77.250\n",
      " * Prec@1 49.279 Prec@5 77.404\n",
      " * Prec@1 48.611 Prec@5 77.546\n",
      " * Prec@1 48.884 Prec@5 77.679\n",
      " * Prec@1 48.276 Prec@5 77.371\n",
      " * Prec@1 47.917 Prec@5 77.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.479 (0.525)\n",
      "\n",
      "Loss 1.3078 (2.0150)\n",
      "\n",
      "Prec@1 68.750 (48.589)\n",
      "\n",
      "Prec@5 87.500 (77.419)\n",
      "\n",
      " * Prec@1 48.589 Prec@5 77.419\n",
      " * Prec@1 48.633 Prec@5 76.953\n",
      " * Prec@1 47.917 Prec@5 76.515\n",
      " * Prec@1 48.162 Prec@5 77.022\n",
      " * Prec@1 47.857 Prec@5 76.786\n",
      " * Prec@1 47.743 Prec@5 76.736\n",
      " * Prec@1 47.635 Prec@5 76.520\n",
      " * Prec@1 47.368 Prec@5 75.987\n",
      " * Prec@1 47.756 Prec@5 75.962\n",
      " * Prec@1 47.656 Prec@5 75.781\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.463 (0.528)\n",
      "\n",
      "Loss 1.8086 (2.0702)\n",
      "\n",
      "Prec@1 37.500 (47.409)\n",
      "\n",
      "Prec@5 87.500 (76.067)\n",
      "\n",
      " * Prec@1 47.409 Prec@5 76.067\n",
      " * Prec@1 47.173 Prec@5 75.893\n",
      " * Prec@1 46.948 Prec@5 75.872\n",
      " * Prec@1 47.017 Prec@5 75.852\n",
      " * Prec@1 46.389 Prec@5 75.694\n",
      " * Prec@1 46.332 Prec@5 75.408\n",
      " * Prec@1 46.011 Prec@5 75.532\n",
      " * Prec@1 45.964 Prec@5 75.781\n",
      " * Prec@1 46.301 Prec@5 76.148\n",
      " * Prec@1 46.500 Prec@5 76.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.535 (0.526)\n",
      "\n",
      "Loss 1.8021 (2.1007)\n",
      "\n",
      "Prec@1 62.500 (46.814)\n",
      "\n",
      "Prec@5 75.000 (76.225)\n",
      "\n",
      " * Prec@1 46.814 Prec@5 76.225\n",
      " * Prec@1 46.875 Prec@5 76.442\n",
      " * Prec@1 46.934 Prec@5 76.415\n",
      " * Prec@1 46.644 Prec@5 76.736\n",
      " * Prec@1 46.705 Prec@5 76.705\n",
      " * Prec@1 46.205 Prec@5 76.562\n",
      " * Prec@1 46.162 Prec@5 76.425\n",
      " * Prec@1 46.121 Prec@5 76.509\n",
      " * Prec@1 45.869 Prec@5 75.847\n",
      " * Prec@1 46.042 Prec@5 75.625\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.507 (0.525)\n",
      "\n",
      "Loss 1.5943 (2.1204)\n",
      "\n",
      "Prec@1 56.250 (46.209)\n",
      "\n",
      "Prec@5 87.500 (75.820)\n",
      "\n",
      " * Prec@1 46.209 Prec@5 75.820\n",
      " * Prec@1 46.472 Prec@5 76.109\n",
      " * Prec@1 46.726 Prec@5 76.190\n",
      " * Prec@1 47.070 Prec@5 76.367\n",
      " * Prec@1 47.019 Prec@5 76.346\n",
      " * Prec@1 46.875 Prec@5 76.231\n",
      " * Prec@1 47.108 Prec@5 76.399\n",
      " * Prec@1 46.783 Prec@5 76.379\n",
      " * Prec@1 46.286 Prec@5 76.087\n",
      " * Prec@1 46.250 Prec@5 75.893\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.533 (0.524)\n",
      "\n",
      "Loss 1.6066 (2.1307)\n",
      "\n",
      "Prec@1 62.500 (46.479)\n",
      "\n",
      "Prec@5 75.000 (75.880)\n",
      "\n",
      " * Prec@1 46.479 Prec@5 75.880\n",
      " * Prec@1 46.354 Prec@5 75.868\n",
      " * Prec@1 46.404 Prec@5 75.942\n",
      " * Prec@1 46.368 Prec@5 75.760\n",
      " * Prec@1 46.500 Prec@5 75.583\n",
      " * Prec@1 46.053 Prec@5 75.329\n",
      " * Prec@1 46.185 Prec@5 75.568\n",
      " * Prec@1 46.474 Prec@5 75.721\n",
      " * Prec@1 46.598 Prec@5 75.554\n",
      " * Prec@1 46.562 Prec@5 75.469\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.550 (0.525)\n",
      "\n",
      "Loss 3.0222 (2.1519)\n",
      "\n",
      "Prec@1 18.750 (46.219)\n",
      "\n",
      "Prec@5 50.000 (75.154)\n",
      "\n",
      " * Prec@1 46.219 Prec@5 75.154\n",
      " * Prec@1 46.341 Prec@5 75.229\n",
      " * Prec@1 46.235 Prec@5 75.301\n",
      " * Prec@1 45.908 Prec@5 75.000\n",
      " * Prec@1 45.735 Prec@5 74.853\n",
      " * Prec@1 45.930 Prec@5 75.000\n",
      " * Prec@1 46.049 Prec@5 75.000\n",
      " * Prec@1 45.881 Prec@5 75.071\n",
      " * Prec@1 45.506 Prec@5 75.000\n",
      " * Prec@1 45.764 Prec@5 75.139\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.533 (0.524)\n",
      "\n",
      "Loss 1.6689 (2.1554)\n",
      "\n",
      "Prec@1 43.750 (45.742)\n",
      "\n",
      "Prec@5 93.750 (75.343)\n",
      "\n",
      " * Prec@1 45.742 Prec@5 75.343\n",
      " * Prec@1 45.856 Prec@5 75.272\n",
      " * Prec@1 45.968 Prec@5 75.269\n",
      " * Prec@1 45.745 Prec@5 75.266\n",
      " * Prec@1 45.526 Prec@5 75.263\n",
      " * Prec@1 45.443 Prec@5 75.391\n",
      " * Prec@1 45.619 Prec@5 75.515\n",
      " * Prec@1 45.536 Prec@5 75.446\n",
      " * Prec@1 45.581 Prec@5 75.568\n",
      " * Prec@1 45.562 Prec@5 75.625\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.511 (0.524)\n",
      "\n",
      "Loss 3.1429 (2.1486)\n",
      "\n",
      "Prec@1 37.500 (45.483)\n",
      "\n",
      "Prec@5 62.500 (75.495)\n",
      "\n",
      " * Prec@1 45.483 Prec@5 75.495\n",
      " * Prec@1 45.404 Prec@5 75.429\n",
      " * Prec@1 45.570 Prec@5 75.364\n",
      " * Prec@1 45.433 Prec@5 75.180\n",
      " * Prec@1 45.536 Prec@5 75.238\n",
      " * Prec@1 45.401 Prec@5 75.177\n",
      " * Prec@1 45.386 Prec@5 75.175\n",
      " * Prec@1 45.602 Prec@5 75.231\n",
      " * Prec@1 45.413 Prec@5 75.115\n",
      " * Prec@1 45.341 Prec@5 75.114\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.472 (0.523)\n",
      "\n",
      "Loss 2.6353 (2.1675)\n",
      "\n",
      "Prec@1 43.750 (45.327)\n",
      "\n",
      "Prec@5 62.500 (75.000)\n",
      "\n",
      " * Prec@1 45.327 Prec@5 75.000\n",
      " * Prec@1 45.480 Prec@5 75.167\n",
      " * Prec@1 45.465 Prec@5 75.221\n",
      " * Prec@1 45.340 Prec@5 75.219\n",
      " * Prec@1 45.326 Prec@5 75.109\n",
      " * Prec@1 45.312 Prec@5 75.108\n",
      " * Prec@1 45.139 Prec@5 75.000\n",
      " * Prec@1 45.074 Prec@5 75.053\n",
      " * Prec@1 45.011 Prec@5 75.000\n",
      " * Prec@1 45.104 Prec@5 75.052\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.532 (0.522)\n",
      "\n",
      "Loss 2.4282 (2.1714)\n",
      "\n",
      "Prec@1 37.500 (45.041)\n",
      "\n",
      "Prec@5 56.250 (74.897)\n",
      "\n",
      " * Prec@1 45.041 Prec@5 74.897\n",
      " * Prec@1 44.928 Prec@5 74.846\n",
      " * Prec@1 44.919 Prec@5 74.848\n",
      " * Prec@1 44.960 Prec@5 74.950\n",
      " * Prec@1 45.100 Prec@5 75.050\n",
      " * Prec@1 45.089 Prec@5 75.099\n",
      " * Prec@1 45.177 Prec@5 75.197\n",
      " * Prec@1 44.971 Prec@5 75.293\n",
      " * Prec@1 45.058 Prec@5 75.291\n",
      " * Prec@1 45.096 Prec@5 75.433\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.491 (0.521)\n",
      "\n",
      "Loss 2.6596 (2.1660)\n",
      "\n",
      "Prec@1 37.500 (45.038)\n",
      "\n",
      "Prec@5 62.500 (75.334)\n",
      "\n",
      " * Prec@1 45.038 Prec@5 75.334\n",
      " * Prec@1 45.028 Prec@5 75.379\n",
      " * Prec@1 45.019 Prec@5 75.376\n",
      " * Prec@1 45.103 Prec@5 75.420\n",
      " * Prec@1 45.185 Prec@5 75.463\n",
      " * Prec@1 45.083 Prec@5 75.322\n",
      " * Prec@1 45.164 Prec@5 75.365\n",
      " * Prec@1 45.199 Prec@5 75.317\n",
      " * Prec@1 45.144 Prec@5 75.315\n",
      " * Prec@1 45.116 Prec@5 75.269\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/558]\t\\Time 0.498 (0.498)\tData 0.387 (0.387)\tLoss 1.1619 (1.1619)\tPrec@1 75.000 (75.000)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [7][100/558]\t\\Time 0.531 (0.509)\tData 0.421 (0.407)\tLoss 1.5465 (1.4825)\tPrec@1 50.000 (59.963)\tPrec@5 93.750 (86.881)\n",
      "Epoch: [7][200/558]\t\\Time 0.486 (0.506)\tData 0.405 (0.406)\tLoss 1.4127 (1.5537)\tPrec@1 68.750 (57.432)\tPrec@5 87.500 (85.603)\n",
      "Epoch: [7][300/558]\t\\Time 0.551 (0.510)\tData 0.433 (0.409)\tLoss 2.1482 (1.5672)\tPrec@1 31.250 (56.914)\tPrec@5 81.250 (85.195)\n",
      "Epoch: [7][400/558]\t\\Time 0.460 (0.511)\tData 0.390 (0.410)\tLoss 1.0281 (1.5749)\tPrec@1 56.250 (56.593)\tPrec@5 93.750 (85.162)\n",
      "Epoch: [7][500/558]\t\\Time 0.464 (0.514)\tData 0.394 (0.413)\tLoss 1.4634 (1.6071)\tPrec@1 56.250 (56.113)\tPrec@5 93.750 (84.469)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.499 (0.499)\n",
      "\n",
      "Loss 3.0626 (3.0626)\n",
      "\n",
      "Prec@1 43.750 (43.750)\n",
      "\n",
      "Prec@5 56.250 (56.250)\n",
      "\n",
      " * Prec@1 43.750 Prec@5 56.250\n",
      " * Prec@1 46.875 Prec@5 68.750\n",
      " * Prec@1 50.000 Prec@5 75.000\n",
      " * Prec@1 50.000 Prec@5 75.000\n",
      " * Prec@1 51.250 Prec@5 73.750\n",
      " * Prec@1 52.083 Prec@5 75.000\n",
      " * Prec@1 52.679 Prec@5 75.893\n",
      " * Prec@1 50.781 Prec@5 75.000\n",
      " * Prec@1 50.694 Prec@5 76.389\n",
      " * Prec@1 50.625 Prec@5 76.875\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.541 (0.535)\n",
      "\n",
      "Loss 1.7006 (2.0634)\n",
      "\n",
      "Prec@1 56.250 (51.136)\n",
      "\n",
      "Prec@5 75.000 (76.705)\n",
      "\n",
      " * Prec@1 51.136 Prec@5 76.705\n",
      " * Prec@1 51.562 Prec@5 77.083\n",
      " * Prec@1 51.923 Prec@5 77.885\n",
      " * Prec@1 53.125 Prec@5 78.571\n",
      " * Prec@1 52.917 Prec@5 78.750\n",
      " * Prec@1 53.906 Prec@5 79.688\n",
      " * Prec@1 54.044 Prec@5 80.147\n",
      " * Prec@1 53.125 Prec@5 79.861\n",
      " * Prec@1 53.618 Prec@5 79.934\n",
      " * Prec@1 53.438 Prec@5 80.312\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.546 (0.533)\n",
      "\n",
      "Loss 2.2319 (1.9416)\n",
      "\n",
      "Prec@1 56.250 (53.571)\n",
      "\n",
      "Prec@5 75.000 (80.060)\n",
      "\n",
      " * Prec@1 53.571 Prec@5 80.060\n",
      " * Prec@1 53.977 Prec@5 79.830\n",
      " * Prec@1 53.261 Prec@5 79.891\n",
      " * Prec@1 52.604 Prec@5 79.427\n",
      " * Prec@1 52.250 Prec@5 79.750\n",
      " * Prec@1 52.885 Prec@5 80.048\n",
      " * Prec@1 52.083 Prec@5 79.398\n",
      " * Prec@1 52.009 Prec@5 79.464\n",
      " * Prec@1 52.155 Prec@5 79.095\n",
      " * Prec@1 52.083 Prec@5 78.958\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.503 (0.533)\n",
      "\n",
      "Loss 1.3768 (1.9799)\n",
      "\n",
      "Prec@1 62.500 (52.419)\n",
      "\n",
      "Prec@5 81.250 (79.032)\n",
      "\n",
      " * Prec@1 52.419 Prec@5 79.032\n",
      " * Prec@1 52.930 Prec@5 79.102\n",
      " * Prec@1 52.273 Prec@5 78.409\n",
      " * Prec@1 52.941 Prec@5 78.860\n",
      " * Prec@1 53.036 Prec@5 78.929\n",
      " * Prec@1 53.299 Prec@5 78.646\n",
      " * Prec@1 53.547 Prec@5 78.378\n",
      " * Prec@1 53.454 Prec@5 77.796\n",
      " * Prec@1 53.205 Prec@5 78.045\n",
      " * Prec@1 52.812 Prec@5 77.812\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.470 (0.536)\n",
      "\n",
      "Loss 1.1374 (1.9901)\n",
      "\n",
      "Prec@1 50.000 (52.744)\n",
      "\n",
      "Prec@5 100.000 (78.354)\n",
      "\n",
      " * Prec@1 52.744 Prec@5 78.354\n",
      " * Prec@1 52.530 Prec@5 78.125\n",
      " * Prec@1 52.471 Prec@5 77.762\n",
      " * Prec@1 52.273 Prec@5 77.557\n",
      " * Prec@1 51.944 Prec@5 77.361\n",
      " * Prec@1 52.038 Prec@5 77.310\n",
      " * Prec@1 51.862 Prec@5 77.128\n",
      " * Prec@1 52.344 Prec@5 77.344\n",
      " * Prec@1 52.551 Prec@5 77.679\n",
      " * Prec@1 52.875 Prec@5 77.875\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.548 (0.538)\n",
      "\n",
      "Loss 2.0939 (2.0105)\n",
      "\n",
      "Prec@1 50.000 (52.819)\n",
      "\n",
      "Prec@5 75.000 (77.819)\n",
      "\n",
      " * Prec@1 52.819 Prec@5 77.819\n",
      " * Prec@1 52.885 Prec@5 78.125\n",
      " * Prec@1 52.830 Prec@5 78.184\n",
      " * Prec@1 52.894 Prec@5 78.009\n",
      " * Prec@1 52.614 Prec@5 78.182\n",
      " * Prec@1 52.902 Prec@5 78.348\n",
      " * Prec@1 52.741 Prec@5 78.399\n",
      " * Prec@1 53.017 Prec@5 78.448\n",
      " * Prec@1 52.754 Prec@5 78.072\n",
      " * Prec@1 52.708 Prec@5 77.917\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.491 (0.534)\n",
      "\n",
      "Loss 1.6362 (2.0197)\n",
      "\n",
      "Prec@1 62.500 (52.869)\n",
      "\n",
      "Prec@5 81.250 (77.971)\n",
      "\n",
      " * Prec@1 52.869 Prec@5 77.971\n",
      " * Prec@1 52.923 Prec@5 78.024\n",
      " * Prec@1 52.976 Prec@5 78.075\n",
      " * Prec@1 53.223 Prec@5 78.320\n",
      " * Prec@1 52.788 Prec@5 78.077\n",
      " * Prec@1 52.652 Prec@5 77.936\n",
      " * Prec@1 52.985 Prec@5 78.078\n",
      " * Prec@1 52.757 Prec@5 78.033\n",
      " * Prec@1 52.355 Prec@5 77.989\n",
      " * Prec@1 52.143 Prec@5 77.768\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.552 (0.532)\n",
      "\n",
      "Loss 1.4050 (2.0184)\n",
      "\n",
      "Prec@1 56.250 (52.201)\n",
      "\n",
      "Prec@5 87.500 (77.905)\n",
      "\n",
      " * Prec@1 52.201 Prec@5 77.905\n",
      " * Prec@1 52.257 Prec@5 77.778\n",
      " * Prec@1 52.226 Prec@5 77.740\n",
      " * Prec@1 52.280 Prec@5 77.787\n",
      " * Prec@1 52.250 Prec@5 77.833\n",
      " * Prec@1 51.891 Prec@5 77.632\n",
      " * Prec@1 51.786 Prec@5 77.841\n",
      " * Prec@1 51.843 Prec@5 78.045\n",
      " * Prec@1 51.661 Prec@5 77.848\n",
      " * Prec@1 51.797 Prec@5 77.891\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.556 (0.534)\n",
      "\n",
      "Loss 2.8204 (2.0383)\n",
      "\n",
      "Prec@1 43.750 (51.698)\n",
      "\n",
      "Prec@5 50.000 (77.546)\n",
      "\n",
      " * Prec@1 51.698 Prec@5 77.546\n",
      " * Prec@1 51.601 Prec@5 77.439\n",
      " * Prec@1 51.657 Prec@5 77.410\n",
      " * Prec@1 51.414 Prec@5 77.083\n",
      " * Prec@1 51.103 Prec@5 76.838\n",
      " * Prec@1 51.235 Prec@5 76.817\n",
      " * Prec@1 51.365 Prec@5 76.940\n",
      " * Prec@1 51.349 Prec@5 76.989\n",
      " * Prec@1 50.983 Prec@5 76.615\n",
      " * Prec@1 51.250 Prec@5 76.806\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.492 (0.531)\n",
      "\n",
      "Loss 1.4994 (2.0652)\n",
      "\n",
      "Prec@1 62.500 (51.374)\n",
      "\n",
      "Prec@5 87.500 (76.923)\n",
      "\n",
      " * Prec@1 51.374 Prec@5 76.923\n",
      " * Prec@1 51.359 Prec@5 76.902\n",
      " * Prec@1 51.277 Prec@5 76.949\n",
      " * Prec@1 51.064 Prec@5 76.862\n",
      " * Prec@1 51.184 Prec@5 76.974\n",
      " * Prec@1 51.107 Prec@5 76.888\n",
      " * Prec@1 51.353 Prec@5 77.062\n",
      " * Prec@1 51.403 Prec@5 76.977\n",
      " * Prec@1 51.515 Prec@5 77.020\n",
      " * Prec@1 51.750 Prec@5 77.250\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.560 (0.531)\n",
      "\n",
      "Loss 2.5578 (2.0477)\n",
      "\n",
      "Prec@1 56.250 (51.795)\n",
      "\n",
      "Prec@5 81.250 (77.290)\n",
      "\n",
      " * Prec@1 51.795 Prec@5 77.290\n",
      " * Prec@1 51.716 Prec@5 77.206\n",
      " * Prec@1 51.760 Prec@5 77.184\n",
      " * Prec@1 51.623 Prec@5 77.103\n",
      " * Prec@1 51.786 Prec@5 77.202\n",
      " * Prec@1 51.651 Prec@5 77.005\n",
      " * Prec@1 51.694 Prec@5 76.986\n",
      " * Prec@1 51.678 Prec@5 76.968\n",
      " * Prec@1 51.548 Prec@5 76.950\n",
      " * Prec@1 51.534 Prec@5 76.932\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.472 (0.533)\n",
      "\n",
      "Loss 2.7191 (2.0720)\n",
      "\n",
      "Prec@1 43.750 (51.464)\n",
      "\n",
      "Prec@5 75.000 (76.914)\n",
      "\n",
      " * Prec@1 51.464 Prec@5 76.914\n",
      " * Prec@1 51.674 Prec@5 77.065\n",
      " * Prec@1 51.770 Prec@5 77.212\n",
      " * Prec@1 51.590 Prec@5 77.357\n",
      " * Prec@1 51.467 Prec@5 77.337\n",
      " * Prec@1 51.347 Prec@5 77.371\n",
      " * Prec@1 51.229 Prec@5 77.297\n",
      " * Prec@1 51.271 Prec@5 77.436\n",
      " * Prec@1 51.261 Prec@5 77.468\n",
      " * Prec@1 51.250 Prec@5 77.448\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.547 (0.531)\n",
      "\n",
      "Loss 2.7657 (2.0707)\n",
      "\n",
      "Prec@1 25.000 (51.033)\n",
      "\n",
      "Prec@5 62.500 (77.324)\n",
      "\n",
      " * Prec@1 51.033 Prec@5 77.324\n",
      " * Prec@1 51.178 Prec@5 77.305\n",
      " * Prec@1 51.270 Prec@5 77.337\n",
      " * Prec@1 51.310 Prec@5 77.369\n",
      " * Prec@1 51.200 Prec@5 77.350\n",
      " * Prec@1 51.290 Prec@5 77.282\n",
      " * Prec@1 51.427 Prec@5 77.362\n",
      " * Prec@1 51.416 Prec@5 77.344\n",
      " * Prec@1 51.550 Prec@5 77.471\n",
      " * Prec@1 51.587 Prec@5 77.500\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.501 (0.529)\n",
      "\n",
      "Loss 2.7256 (2.0537)\n",
      "\n",
      "Prec@1 37.500 (51.479)\n",
      "\n",
      "Prec@5 68.750 (77.433)\n",
      "\n",
      " * Prec@1 51.479 Prec@5 77.433\n",
      " * Prec@1 51.420 Prec@5 77.509\n",
      " * Prec@1 51.457 Prec@5 77.538\n",
      " * Prec@1 51.632 Prec@5 77.612\n",
      " * Prec@1 51.667 Prec@5 77.685\n",
      " * Prec@1 51.654 Prec@5 77.574\n",
      " * Prec@1 51.642 Prec@5 77.555\n",
      " * Prec@1 51.676 Prec@5 77.582\n",
      " * Prec@1 51.619 Prec@5 77.473\n",
      " * Prec@1 51.658 Prec@5 77.464\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/558]\t\\Time 0.599 (0.599)\tData 0.431 (0.431)\tLoss 1.0399 (1.0399)\tPrec@1 68.750 (68.750)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [8][100/558]\t\\Time 0.512 (0.515)\tData 0.372 (0.416)\tLoss 1.2026 (1.1941)\tPrec@1 75.000 (67.450)\tPrec@5 87.500 (89.975)\n",
      "Epoch: [8][200/558]\t\\Time 0.530 (0.513)\tData 0.420 (0.413)\tLoss 0.9968 (1.2606)\tPrec@1 75.000 (65.081)\tPrec@5 93.750 (88.930)\n",
      "Epoch: [8][300/558]\t\\Time 0.456 (0.513)\tData 0.376 (0.413)\tLoss 1.4337 (1.2751)\tPrec@1 56.250 (64.493)\tPrec@5 93.750 (88.995)\n",
      "Epoch: [8][400/558]\t\\Time 0.544 (0.513)\tData 0.433 (0.413)\tLoss 0.7961 (1.2945)\tPrec@1 75.000 (63.872)\tPrec@5 93.750 (88.887)\n",
      "Epoch: [8][500/558]\t\\Time 0.510 (0.513)\tData 0.401 (0.413)\tLoss 0.5968 (1.3073)\tPrec@1 93.750 (63.585)\tPrec@5 93.750 (88.648)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.547 (0.547)\n",
      "\n",
      "Loss 2.6789 (2.6789)\n",
      "\n",
      "Prec@1 56.250 (56.250)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 68.750\n",
      " * Prec@1 50.000 Prec@5 78.125\n",
      " * Prec@1 52.083 Prec@5 83.333\n",
      " * Prec@1 56.250 Prec@5 82.812\n",
      " * Prec@1 53.750 Prec@5 81.250\n",
      " * Prec@1 55.208 Prec@5 83.333\n",
      " * Prec@1 54.464 Prec@5 82.143\n",
      " * Prec@1 52.344 Prec@5 82.812\n",
      " * Prec@1 54.861 Prec@5 84.722\n",
      " * Prec@1 53.750 Prec@5 83.750\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.503 (0.542)\n",
      "\n",
      "Loss 1.4102 (1.7580)\n",
      "\n",
      "Prec@1 68.750 (55.114)\n",
      "\n",
      "Prec@5 75.000 (82.955)\n",
      "\n",
      " * Prec@1 55.114 Prec@5 82.955\n",
      " * Prec@1 55.208 Prec@5 83.333\n",
      " * Prec@1 54.808 Prec@5 84.135\n",
      " * Prec@1 55.804 Prec@5 84.821\n",
      " * Prec@1 56.667 Prec@5 85.000\n",
      " * Prec@1 57.422 Prec@5 85.547\n",
      " * Prec@1 57.721 Prec@5 85.294\n",
      " * Prec@1 57.986 Prec@5 85.069\n",
      " * Prec@1 57.237 Prec@5 85.855\n",
      " * Prec@1 57.188 Prec@5 85.625\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.552 (0.529)\n",
      "\n",
      "Loss 2.6453 (1.7387)\n",
      "\n",
      "Prec@1 43.750 (56.548)\n",
      "\n",
      "Prec@5 62.500 (84.524)\n",
      "\n",
      " * Prec@1 56.548 Prec@5 84.524\n",
      " * Prec@1 56.818 Prec@5 84.375\n",
      " * Prec@1 55.707 Prec@5 84.239\n",
      " * Prec@1 55.208 Prec@5 83.333\n",
      " * Prec@1 54.000 Prec@5 83.000\n",
      " * Prec@1 54.327 Prec@5 82.933\n",
      " * Prec@1 53.935 Prec@5 82.407\n",
      " * Prec@1 54.241 Prec@5 82.366\n",
      " * Prec@1 54.310 Prec@5 81.681\n",
      " * Prec@1 54.375 Prec@5 82.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.494 (0.532)\n",
      "\n",
      "Loss 1.3515 (1.8899)\n",
      "\n",
      "Prec@1 56.250 (54.435)\n",
      "\n",
      "Prec@5 81.250 (82.056)\n",
      "\n",
      " * Prec@1 54.435 Prec@5 82.056\n",
      " * Prec@1 54.297 Prec@5 82.031\n",
      " * Prec@1 53.977 Prec@5 81.250\n",
      " * Prec@1 54.963 Prec@5 81.434\n",
      " * Prec@1 55.357 Prec@5 81.429\n",
      " * Prec@1 55.729 Prec@5 81.597\n",
      " * Prec@1 55.574 Prec@5 81.419\n",
      " * Prec@1 55.263 Prec@5 80.757\n",
      " * Prec@1 55.128 Prec@5 80.929\n",
      " * Prec@1 55.000 Prec@5 81.094\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.519 (0.529)\n",
      "\n",
      "Loss 0.9711 (1.8899)\n",
      "\n",
      "Prec@1 68.750 (55.335)\n",
      "\n",
      "Prec@5 100.000 (81.555)\n",
      "\n",
      " * Prec@1 55.335 Prec@5 81.555\n",
      " * Prec@1 55.060 Prec@5 81.250\n",
      " * Prec@1 55.087 Prec@5 80.959\n",
      " * Prec@1 55.114 Prec@5 80.682\n",
      " * Prec@1 54.722 Prec@5 80.417\n",
      " * Prec@1 54.755 Prec@5 80.027\n",
      " * Prec@1 54.654 Prec@5 80.053\n",
      " * Prec@1 55.078 Prec@5 80.469\n",
      " * Prec@1 55.102 Prec@5 80.740\n",
      " * Prec@1 55.250 Prec@5 80.750\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.551 (0.533)\n",
      "\n",
      "Loss 2.0057 (1.9390)\n",
      "\n",
      "Prec@1 56.250 (55.270)\n",
      "\n",
      "Prec@5 87.500 (80.882)\n",
      "\n",
      " * Prec@1 55.270 Prec@5 80.882\n",
      " * Prec@1 55.409 Prec@5 81.010\n",
      " * Prec@1 55.071 Prec@5 80.778\n",
      " * Prec@1 55.208 Prec@5 80.903\n",
      " * Prec@1 55.114 Prec@5 80.568\n",
      " * Prec@1 54.911 Prec@5 80.469\n",
      " * Prec@1 55.044 Prec@5 80.482\n",
      " * Prec@1 55.280 Prec@5 80.496\n",
      " * Prec@1 54.873 Prec@5 79.979\n",
      " * Prec@1 55.104 Prec@5 80.104\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.492 (0.532)\n",
      "\n",
      "Loss 1.9721 (1.9568)\n",
      "\n",
      "Prec@1 37.500 (54.816)\n",
      "\n",
      "Prec@5 81.250 (80.123)\n",
      "\n",
      " * Prec@1 54.816 Prec@5 80.123\n",
      " * Prec@1 54.637 Prec@5 80.141\n",
      " * Prec@1 54.762 Prec@5 80.357\n",
      " * Prec@1 54.883 Prec@5 80.469\n",
      " * Prec@1 55.000 Prec@5 80.577\n",
      " * Prec@1 54.830 Prec@5 80.303\n",
      " * Prec@1 54.851 Prec@5 80.317\n",
      " * Prec@1 54.688 Prec@5 80.331\n",
      " * Prec@1 54.167 Prec@5 80.254\n",
      " * Prec@1 54.018 Prec@5 80.089\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.548 (0.529)\n",
      "\n",
      "Loss 1.5579 (1.9523)\n",
      "\n",
      "Prec@1 56.250 (54.049)\n",
      "\n",
      "Prec@5 81.250 (80.106)\n",
      "\n",
      " * Prec@1 54.049 Prec@5 80.106\n",
      " * Prec@1 54.080 Prec@5 80.035\n",
      " * Prec@1 54.024 Prec@5 80.051\n",
      " * Prec@1 53.885 Prec@5 80.152\n",
      " * Prec@1 53.750 Prec@5 80.000\n",
      " * Prec@1 53.536 Prec@5 79.688\n",
      " * Prec@1 53.490 Prec@5 79.708\n",
      " * Prec@1 53.606 Prec@5 79.808\n",
      " * Prec@1 53.481 Prec@5 79.747\n",
      " * Prec@1 53.672 Prec@5 79.844\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.569 (0.529)\n",
      "\n",
      "Loss 2.9723 (1.9715)\n",
      "\n",
      "Prec@1 31.250 (53.395)\n",
      "\n",
      "Prec@5 56.250 (79.552)\n",
      "\n",
      " * Prec@1 53.395 Prec@5 79.552\n",
      " * Prec@1 53.506 Prec@5 79.573\n",
      " * Prec@1 53.539 Prec@5 79.443\n",
      " * Prec@1 53.423 Prec@5 79.315\n",
      " * Prec@1 53.235 Prec@5 79.265\n",
      " * Prec@1 53.416 Prec@5 79.433\n",
      " * Prec@1 53.520 Prec@5 79.454\n",
      " * Prec@1 53.551 Prec@5 79.403\n",
      " * Prec@1 53.371 Prec@5 79.354\n",
      " * Prec@1 53.472 Prec@5 79.444\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.530 (0.530)\n",
      "\n",
      "Loss 1.7100 (1.9843)\n",
      "\n",
      "Prec@1 62.500 (53.571)\n",
      "\n",
      "Prec@5 81.250 (79.464)\n",
      "\n",
      " * Prec@1 53.571 Prec@5 79.464\n",
      " * Prec@1 53.736 Prec@5 79.416\n",
      " * Prec@1 53.831 Prec@5 79.503\n",
      " * Prec@1 53.590 Prec@5 79.455\n",
      " * Prec@1 53.618 Prec@5 79.539\n",
      " * Prec@1 53.516 Prec@5 79.557\n",
      " * Prec@1 53.608 Prec@5 79.768\n",
      " * Prec@1 53.571 Prec@5 79.783\n",
      " * Prec@1 53.725 Prec@5 79.798\n",
      " * Prec@1 53.938 Prec@5 79.938\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.502 (0.529)\n",
      "\n",
      "Loss 3.0179 (1.9638)\n",
      "\n",
      "Prec@1 43.750 (53.837)\n",
      "\n",
      "Prec@5 81.250 (79.950)\n",
      "\n",
      " * Prec@1 53.837 Prec@5 79.950\n",
      " * Prec@1 53.615 Prec@5 79.779\n",
      " * Prec@1 53.641 Prec@5 79.854\n",
      " * Prec@1 53.486 Prec@5 79.688\n",
      " * Prec@1 53.512 Prec@5 79.762\n",
      " * Prec@1 53.420 Prec@5 79.717\n",
      " * Prec@1 53.271 Prec@5 79.673\n",
      " * Prec@1 53.472 Prec@5 79.688\n",
      " * Prec@1 53.498 Prec@5 79.644\n",
      " * Prec@1 53.523 Prec@5 79.602\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.472 (0.528)\n",
      "\n",
      "Loss 2.3523 (1.9736)\n",
      "\n",
      "Prec@1 31.250 (53.322)\n",
      "\n",
      "Prec@5 62.500 (79.448)\n",
      "\n",
      " * Prec@1 53.322 Prec@5 79.448\n",
      " * Prec@1 53.516 Prec@5 79.576\n",
      " * Prec@1 53.650 Prec@5 79.646\n",
      " * Prec@1 53.618 Prec@5 79.605\n",
      " * Prec@1 53.533 Prec@5 79.565\n",
      " * Prec@1 53.610 Prec@5 79.634\n",
      " * Prec@1 53.419 Prec@5 79.647\n",
      " * Prec@1 53.496 Prec@5 79.714\n",
      " * Prec@1 53.519 Prec@5 79.727\n",
      " * Prec@1 53.490 Prec@5 79.688\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.492 (0.527)\n",
      "\n",
      "Loss 2.6494 (1.9661)\n",
      "\n",
      "Prec@1 43.750 (53.409)\n",
      "\n",
      "Prec@5 62.500 (79.545)\n",
      "\n",
      " * Prec@1 53.409 Prec@5 79.545\n",
      " * Prec@1 53.279 Prec@5 79.406\n",
      " * Prec@1 53.303 Prec@5 79.421\n",
      " * Prec@1 53.327 Prec@5 79.385\n",
      " * Prec@1 53.300 Prec@5 79.350\n",
      " * Prec@1 53.423 Prec@5 79.415\n",
      " * Prec@1 53.346 Prec@5 79.478\n",
      " * Prec@1 53.223 Prec@5 79.443\n",
      " * Prec@1 53.198 Prec@5 79.457\n",
      " * Prec@1 53.221 Prec@5 79.567\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.531 (0.524)\n",
      "\n",
      "Loss 2.1860 (1.9623)\n",
      "\n",
      "Prec@1 56.250 (53.244)\n",
      "\n",
      "Prec@5 75.000 (79.532)\n",
      "\n",
      " * Prec@1 53.244 Prec@5 79.532\n",
      " * Prec@1 53.220 Prec@5 79.688\n",
      " * Prec@1 53.242 Prec@5 79.699\n",
      " * Prec@1 53.451 Prec@5 79.757\n",
      " * Prec@1 53.472 Prec@5 79.769\n",
      " * Prec@1 53.401 Prec@5 79.642\n",
      " * Prec@1 53.422 Prec@5 79.699\n",
      " * Prec@1 53.533 Prec@5 79.710\n",
      " * Prec@1 53.552 Prec@5 79.676\n",
      " * Prec@1 53.539 Prec@5 79.659\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/558]\t\\Time 0.541 (0.541)\tData 0.431 (0.431)\tLoss 0.4276 (0.4276)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/558]\t\\Time 0.551 (0.511)\tData 0.461 (0.412)\tLoss 1.0023 (0.8852)\tPrec@1 62.500 (74.567)\tPrec@5 100.000 (93.874)\n",
      "Epoch: [9][200/558]\t\\Time 0.482 (0.513)\tData 0.395 (0.412)\tLoss 0.7755 (0.9701)\tPrec@1 87.500 (72.046)\tPrec@5 87.500 (92.910)\n",
      "Epoch: [9][300/558]\t\\Time 0.501 (0.515)\tData 0.428 (0.414)\tLoss 0.9046 (0.9866)\tPrec@1 75.000 (71.865)\tPrec@5 93.750 (92.608)\n",
      "Epoch: [9][400/558]\t\\Time 0.541 (0.519)\tData 0.436 (0.417)\tLoss 1.8801 (1.0163)\tPrec@1 50.000 (71.322)\tPrec@5 81.250 (92.472)\n",
      "Epoch: [9][500/558]\t\\Time 0.529 (0.525)\tData 0.419 (0.422)\tLoss 0.8526 (1.0312)\tPrec@1 68.750 (70.758)\tPrec@5 93.750 (92.353)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.525 (0.525)\n",
      "\n",
      "Loss 1.8031 (1.8031)\n",
      "\n",
      "Prec@1 56.250 (56.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 81.250\n",
      " * Prec@1 59.375 Prec@5 81.250\n",
      " * Prec@1 64.583 Prec@5 87.500\n",
      " * Prec@1 62.500 Prec@5 84.375\n",
      " * Prec@1 61.250 Prec@5 85.000\n",
      " * Prec@1 62.500 Prec@5 86.458\n",
      " * Prec@1 61.607 Prec@5 86.607\n",
      " * Prec@1 60.156 Prec@5 86.719\n",
      " * Prec@1 62.500 Prec@5 87.500\n",
      " * Prec@1 60.625 Prec@5 87.500\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.532 (0.524)\n",
      "\n",
      "Loss 1.9687 (1.5922)\n",
      "\n",
      "Prec@1 62.500 (60.795)\n",
      "\n",
      "Prec@5 75.000 (86.364)\n",
      "\n",
      " * Prec@1 60.795 Prec@5 86.364\n",
      " * Prec@1 60.938 Prec@5 86.458\n",
      " * Prec@1 60.577 Prec@5 87.019\n",
      " * Prec@1 60.714 Prec@5 87.054\n",
      " * Prec@1 61.667 Prec@5 87.500\n",
      " * Prec@1 63.281 Prec@5 87.891\n",
      " * Prec@1 62.132 Prec@5 87.868\n",
      " * Prec@1 63.194 Prec@5 87.500\n",
      " * Prec@1 63.158 Prec@5 87.829\n",
      " * Prec@1 63.125 Prec@5 87.188\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.525 (0.519)\n",
      "\n",
      "Loss 2.7916 (1.6317)\n",
      "\n",
      "Prec@1 56.250 (62.798)\n",
      "\n",
      "Prec@5 81.250 (86.905)\n",
      "\n",
      " * Prec@1 62.798 Prec@5 86.905\n",
      " * Prec@1 63.352 Prec@5 86.932\n",
      " * Prec@1 63.315 Prec@5 86.413\n",
      " * Prec@1 62.760 Prec@5 85.677\n",
      " * Prec@1 62.500 Prec@5 85.500\n",
      " * Prec@1 62.500 Prec@5 85.577\n",
      " * Prec@1 62.269 Prec@5 85.185\n",
      " * Prec@1 62.277 Prec@5 85.268\n",
      " * Prec@1 61.638 Prec@5 84.914\n",
      " * Prec@1 61.458 Prec@5 84.792\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.528 (0.526)\n",
      "\n",
      "Loss 1.3918 (1.7143)\n",
      "\n",
      "Prec@1 56.250 (61.290)\n",
      "\n",
      "Prec@5 87.500 (84.879)\n",
      "\n",
      " * Prec@1 61.290 Prec@5 84.879\n",
      " * Prec@1 61.719 Prec@5 85.156\n",
      " * Prec@1 60.985 Prec@5 84.659\n",
      " * Prec@1 61.213 Prec@5 84.926\n",
      " * Prec@1 60.893 Prec@5 84.643\n",
      " * Prec@1 60.938 Prec@5 84.549\n",
      " * Prec@1 60.642 Prec@5 84.291\n",
      " * Prec@1 60.033 Prec@5 83.717\n",
      " * Prec@1 59.936 Prec@5 83.654\n",
      " * Prec@1 59.688 Prec@5 83.594\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.445 (0.524)\n",
      "\n",
      "Loss 1.2779 (1.7590)\n",
      "\n",
      "Prec@1 75.000 (60.061)\n",
      "\n",
      "Prec@5 93.750 (83.841)\n",
      "\n",
      " * Prec@1 60.061 Prec@5 83.841\n",
      " * Prec@1 60.268 Prec@5 83.929\n",
      " * Prec@1 59.738 Prec@5 83.576\n",
      " * Prec@1 59.517 Prec@5 83.381\n",
      " * Prec@1 59.167 Prec@5 82.917\n",
      " * Prec@1 58.967 Prec@5 82.745\n",
      " * Prec@1 58.910 Prec@5 82.846\n",
      " * Prec@1 59.375 Prec@5 83.203\n",
      " * Prec@1 59.056 Prec@5 83.291\n",
      " * Prec@1 59.125 Prec@5 83.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.521 (0.522)\n",
      "\n",
      "Loss 1.7792 (1.7930)\n",
      "\n",
      "Prec@1 56.250 (59.069)\n",
      "\n",
      "Prec@5 87.500 (83.456)\n",
      "\n",
      " * Prec@1 59.069 Prec@5 83.456\n",
      " * Prec@1 59.014 Prec@5 83.534\n",
      " * Prec@1 58.962 Prec@5 83.608\n",
      " * Prec@1 59.259 Prec@5 83.796\n",
      " * Prec@1 58.977 Prec@5 83.636\n",
      " * Prec@1 59.040 Prec@5 83.594\n",
      " * Prec@1 58.772 Prec@5 83.662\n",
      " * Prec@1 58.944 Prec@5 83.728\n",
      " * Prec@1 58.581 Prec@5 83.369\n",
      " * Prec@1 58.542 Prec@5 83.333\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.488 (0.523)\n",
      "\n",
      "Loss 1.4818 (1.8070)\n",
      "\n",
      "Prec@1 68.750 (58.709)\n",
      "\n",
      "Prec@5 81.250 (83.299)\n",
      "\n",
      " * Prec@1 58.709 Prec@5 83.299\n",
      " * Prec@1 59.073 Prec@5 83.468\n",
      " * Prec@1 59.127 Prec@5 83.631\n",
      " * Prec@1 59.375 Prec@5 83.887\n",
      " * Prec@1 59.135 Prec@5 84.038\n",
      " * Prec@1 58.996 Prec@5 83.902\n",
      " * Prec@1 59.049 Prec@5 83.862\n",
      " * Prec@1 59.007 Prec@5 83.732\n",
      " * Prec@1 58.877 Prec@5 83.605\n",
      " * Prec@1 58.839 Prec@5 83.482\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.532 (0.521)\n",
      "\n",
      "Loss 1.4667 (1.7982)\n",
      "\n",
      "Prec@1 62.500 (58.891)\n",
      "\n",
      "Prec@5 87.500 (83.539)\n",
      "\n",
      " * Prec@1 58.891 Prec@5 83.539\n",
      " * Prec@1 58.681 Prec@5 83.420\n",
      " * Prec@1 58.562 Prec@5 83.390\n",
      " * Prec@1 58.699 Prec@5 83.530\n",
      " * Prec@1 58.667 Prec@5 83.333\n",
      " * Prec@1 58.470 Prec@5 83.306\n",
      " * Prec@1 58.604 Prec@5 83.442\n",
      " * Prec@1 58.894 Prec@5 83.574\n",
      " * Prec@1 58.940 Prec@5 83.386\n",
      " * Prec@1 58.828 Prec@5 83.359\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.518 (0.520)\n",
      "\n",
      "Loss 3.4334 (1.8476)\n",
      "\n",
      "Prec@1 31.250 (58.488)\n",
      "\n",
      "Prec@5 56.250 (83.025)\n",
      "\n",
      " * Prec@1 58.488 Prec@5 83.025\n",
      " * Prec@1 58.384 Prec@5 83.003\n",
      " * Prec@1 58.283 Prec@5 82.907\n",
      " * Prec@1 58.110 Prec@5 82.812\n",
      " * Prec@1 57.941 Prec@5 82.647\n",
      " * Prec@1 58.067 Prec@5 82.776\n",
      " * Prec@1 58.046 Prec@5 82.759\n",
      " * Prec@1 58.026 Prec@5 82.812\n",
      " * Prec@1 57.654 Prec@5 82.584\n",
      " * Prec@1 57.917 Prec@5 82.569\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.574 (0.522)\n",
      "\n",
      "Loss 1.0978 (1.8630)\n",
      "\n",
      "Prec@1 62.500 (57.967)\n",
      "\n",
      "Prec@5 87.500 (82.624)\n",
      "\n",
      " * Prec@1 57.967 Prec@5 82.624\n",
      " * Prec@1 57.948 Prec@5 82.677\n",
      " * Prec@1 58.199 Prec@5 82.796\n",
      " * Prec@1 58.178 Prec@5 82.779\n",
      " * Prec@1 58.158 Prec@5 82.829\n",
      " * Prec@1 58.203 Prec@5 82.878\n",
      " * Prec@1 58.312 Prec@5 82.990\n",
      " * Prec@1 58.355 Prec@5 82.972\n",
      " * Prec@1 58.333 Prec@5 83.018\n",
      " * Prec@1 58.438 Prec@5 83.125\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.511 (0.521)\n",
      "\n",
      "Loss 2.2927 (1.8450)\n",
      "\n",
      "Prec@1 50.000 (58.354)\n",
      "\n",
      "Prec@5 75.000 (83.045)\n",
      "\n",
      " * Prec@1 58.354 Prec@5 83.045\n",
      " * Prec@1 58.211 Prec@5 82.843\n",
      " * Prec@1 58.252 Prec@5 82.828\n",
      " * Prec@1 58.173 Prec@5 82.692\n",
      " * Prec@1 58.214 Prec@5 82.798\n",
      " * Prec@1 58.137 Prec@5 82.606\n",
      " * Prec@1 58.178 Prec@5 82.652\n",
      " * Prec@1 58.275 Prec@5 82.755\n",
      " * Prec@1 58.314 Prec@5 82.798\n",
      " * Prec@1 58.295 Prec@5 82.784\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.475 (0.521)\n",
      "\n",
      "Loss 3.5957 (1.8732)\n",
      "\n",
      "Prec@1 37.500 (58.108)\n",
      "\n",
      "Prec@5 81.250 (82.770)\n",
      "\n",
      " * Prec@1 58.108 Prec@5 82.770\n",
      " * Prec@1 58.203 Prec@5 82.868\n",
      " * Prec@1 58.131 Prec@5 82.799\n",
      " * Prec@1 58.279 Prec@5 82.785\n",
      " * Prec@1 58.261 Prec@5 82.717\n",
      " * Prec@1 58.244 Prec@5 82.705\n",
      " * Prec@1 58.173 Prec@5 82.639\n",
      " * Prec@1 58.263 Prec@5 82.733\n",
      " * Prec@1 58.141 Prec@5 82.721\n",
      " * Prec@1 58.229 Prec@5 82.708\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.624 (0.521)\n",
      "\n",
      "Loss 2.2500 (1.8738)\n",
      "\n",
      "Prec@1 43.750 (58.110)\n",
      "\n",
      "Prec@5 56.250 (82.490)\n",
      "\n",
      " * Prec@1 58.110 Prec@5 82.490\n",
      " * Prec@1 58.094 Prec@5 82.377\n",
      " * Prec@1 58.283 Prec@5 82.368\n",
      " * Prec@1 58.367 Prec@5 82.460\n",
      " * Prec@1 58.350 Prec@5 82.450\n",
      " * Prec@1 58.383 Prec@5 82.490\n",
      " * Prec@1 58.465 Prec@5 82.579\n",
      " * Prec@1 58.496 Prec@5 82.617\n",
      " * Prec@1 58.624 Prec@5 82.655\n",
      " * Prec@1 58.654 Prec@5 82.692\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.536 (0.520)\n",
      "\n",
      "Loss 2.8647 (1.8593)\n",
      "\n",
      "Prec@1 37.500 (58.492)\n",
      "\n",
      "Prec@5 62.500 (82.538)\n",
      "\n",
      " * Prec@1 58.492 Prec@5 82.538\n",
      " * Prec@1 58.523 Prec@5 82.623\n",
      " * Prec@1 58.553 Prec@5 82.613\n",
      " * Prec@1 58.629 Prec@5 82.696\n",
      " * Prec@1 58.796 Prec@5 82.731\n",
      " * Prec@1 58.686 Prec@5 82.583\n",
      " * Prec@1 58.850 Prec@5 82.664\n",
      " * Prec@1 58.832 Prec@5 82.654\n",
      " * Prec@1 58.813 Prec@5 82.599\n",
      " * Prec@1 58.781 Prec@5 82.572\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [10][0/558]\t\\Time 0.600 (0.600)\tData 0.460 (0.460)\tLoss 0.4190 (0.4190)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/558]\t\\Time 0.527 (0.522)\tData 0.407 (0.419)\tLoss 0.3970 (0.6727)\tPrec@1 93.750 (80.384)\tPrec@5 93.750 (96.349)\n",
      "Epoch: [10][200/558]\t\\Time 0.500 (0.523)\tData 0.430 (0.420)\tLoss 1.1466 (0.7105)\tPrec@1 62.500 (79.415)\tPrec@5 93.750 (96.300)\n",
      "Epoch: [10][300/558]\t\\Time 0.522 (0.524)\tData 0.412 (0.421)\tLoss 0.6457 (0.7698)\tPrec@1 81.250 (77.907)\tPrec@5 100.000 (95.640)\n",
      "Epoch: [10][400/558]\t\\Time 0.512 (0.525)\tData 0.402 (0.423)\tLoss 0.5218 (0.8172)\tPrec@1 75.000 (76.356)\tPrec@5 100.000 (95.075)\n",
      "Epoch: [10][500/558]\t\\Time 0.510 (0.527)\tData 0.450 (0.424)\tLoss 1.3980 (0.8367)\tPrec@1 62.500 (75.886)\tPrec@5 81.250 (94.873)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.489 (0.489)\n",
      "\n",
      "Loss 2.4383 (2.4383)\n",
      "\n",
      "Prec@1 56.250 (56.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 81.250\n",
      " * Prec@1 53.125 Prec@5 78.125\n",
      " * Prec@1 62.500 Prec@5 83.333\n",
      " * Prec@1 60.938 Prec@5 84.375\n",
      " * Prec@1 60.000 Prec@5 82.500\n",
      " * Prec@1 63.542 Prec@5 84.375\n",
      " * Prec@1 64.286 Prec@5 85.714\n",
      " * Prec@1 64.844 Prec@5 85.938\n",
      " * Prec@1 66.667 Prec@5 87.500\n",
      " * Prec@1 66.875 Prec@5 86.875\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.520 (0.524)\n",
      "\n",
      "Loss 1.8256 (1.5477)\n",
      "\n",
      "Prec@1 62.500 (66.477)\n",
      "\n",
      "Prec@5 81.250 (86.364)\n",
      "\n",
      " * Prec@1 66.477 Prec@5 86.364\n",
      " * Prec@1 66.667 Prec@5 85.938\n",
      " * Prec@1 66.827 Prec@5 87.019\n",
      " * Prec@1 66.964 Prec@5 87.054\n",
      " * Prec@1 66.667 Prec@5 87.083\n",
      " * Prec@1 67.969 Prec@5 87.500\n",
      " * Prec@1 67.647 Prec@5 87.500\n",
      " * Prec@1 67.708 Prec@5 87.153\n",
      " * Prec@1 67.763 Prec@5 87.500\n",
      " * Prec@1 68.125 Prec@5 87.188\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.562 (0.523)\n",
      "\n",
      "Loss 2.9028 (1.5319)\n",
      "\n",
      "Prec@1 62.500 (67.857)\n",
      "\n",
      "Prec@5 81.250 (86.905)\n",
      "\n",
      " * Prec@1 67.857 Prec@5 86.905\n",
      " * Prec@1 68.466 Prec@5 86.648\n",
      " * Prec@1 68.750 Prec@5 86.957\n",
      " * Prec@1 68.490 Prec@5 85.938\n",
      " * Prec@1 68.000 Prec@5 86.000\n",
      " * Prec@1 68.029 Prec@5 85.577\n",
      " * Prec@1 66.667 Prec@5 85.185\n",
      " * Prec@1 66.964 Prec@5 85.268\n",
      " * Prec@1 66.595 Prec@5 84.698\n",
      " * Prec@1 66.250 Prec@5 84.792\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.508 (0.534)\n",
      "\n",
      "Loss 1.4920 (1.6699)\n",
      "\n",
      "Prec@1 62.500 (66.129)\n",
      "\n",
      "Prec@5 87.500 (84.879)\n",
      "\n",
      " * Prec@1 66.129 Prec@5 84.879\n",
      " * Prec@1 66.406 Prec@5 85.156\n",
      " * Prec@1 65.720 Prec@5 85.038\n",
      " * Prec@1 65.993 Prec@5 85.294\n",
      " * Prec@1 66.071 Prec@5 85.179\n",
      " * Prec@1 65.972 Prec@5 85.417\n",
      " * Prec@1 65.878 Prec@5 85.304\n",
      " * Prec@1 65.625 Prec@5 85.033\n",
      " * Prec@1 65.705 Prec@5 84.936\n",
      " * Prec@1 65.625 Prec@5 84.531\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.464 (0.533)\n",
      "\n",
      "Loss 1.2116 (1.6770)\n",
      "\n",
      "Prec@1 50.000 (65.244)\n",
      "\n",
      "Prec@5 87.500 (84.604)\n",
      "\n",
      " * Prec@1 65.244 Prec@5 84.604\n",
      " * Prec@1 64.732 Prec@5 84.375\n",
      " * Prec@1 64.244 Prec@5 83.866\n",
      " * Prec@1 64.062 Prec@5 83.807\n",
      " * Prec@1 64.028 Prec@5 83.472\n",
      " * Prec@1 64.266 Prec@5 83.288\n",
      " * Prec@1 64.362 Prec@5 83.378\n",
      " * Prec@1 64.453 Prec@5 83.724\n",
      " * Prec@1 64.413 Prec@5 83.801\n",
      " * Prec@1 64.625 Prec@5 84.000\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.562 (0.536)\n",
      "\n",
      "Loss 2.9682 (1.7714)\n",
      "\n",
      "Prec@1 37.500 (64.093)\n",
      "\n",
      "Prec@5 68.750 (83.701)\n",
      "\n",
      " * Prec@1 64.093 Prec@5 83.701\n",
      " * Prec@1 63.942 Prec@5 84.014\n",
      " * Prec@1 63.915 Prec@5 83.726\n",
      " * Prec@1 63.657 Prec@5 83.912\n",
      " * Prec@1 63.636 Prec@5 83.636\n",
      " * Prec@1 63.504 Prec@5 83.594\n",
      " * Prec@1 63.596 Prec@5 83.662\n",
      " * Prec@1 63.685 Prec@5 83.728\n",
      " * Prec@1 63.242 Prec@5 83.475\n",
      " * Prec@1 63.229 Prec@5 83.438\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.483 (0.536)\n",
      "\n",
      "Loss 1.5861 (1.7921)\n",
      "\n",
      "Prec@1 68.750 (63.320)\n",
      "\n",
      "Prec@5 81.250 (83.402)\n",
      "\n",
      " * Prec@1 63.320 Prec@5 83.402\n",
      " * Prec@1 63.407 Prec@5 83.569\n",
      " * Prec@1 63.492 Prec@5 83.730\n",
      " * Prec@1 63.867 Prec@5 83.789\n",
      " * Prec@1 63.654 Prec@5 83.846\n",
      " * Prec@1 63.352 Prec@5 83.712\n",
      " * Prec@1 63.619 Prec@5 83.769\n",
      " * Prec@1 63.511 Prec@5 83.732\n",
      " * Prec@1 63.043 Prec@5 83.696\n",
      " * Prec@1 62.768 Prec@5 83.482\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.540 (0.531)\n",
      "\n",
      "Loss 1.8977 (1.8036)\n",
      "\n",
      "Prec@1 56.250 (62.676)\n",
      "\n",
      "Prec@5 81.250 (83.451)\n",
      "\n",
      " * Prec@1 62.676 Prec@5 83.451\n",
      " * Prec@1 62.587 Prec@5 83.333\n",
      " * Prec@1 62.329 Prec@5 83.305\n",
      " * Prec@1 62.416 Prec@5 83.446\n",
      " * Prec@1 62.250 Prec@5 83.250\n",
      " * Prec@1 61.842 Prec@5 83.141\n",
      " * Prec@1 61.851 Prec@5 83.198\n",
      " * Prec@1 61.939 Prec@5 83.253\n",
      " * Prec@1 61.946 Prec@5 83.228\n",
      " * Prec@1 62.109 Prec@5 83.281\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.515 (0.531)\n",
      "\n",
      "Loss 2.7921 (1.8159)\n",
      "\n",
      "Prec@1 43.750 (61.883)\n",
      "\n",
      "Prec@5 62.500 (83.025)\n",
      "\n",
      " * Prec@1 61.883 Prec@5 83.025\n",
      " * Prec@1 61.890 Prec@5 83.079\n",
      " * Prec@1 61.973 Prec@5 82.982\n",
      " * Prec@1 61.756 Prec@5 82.887\n",
      " * Prec@1 61.691 Prec@5 82.794\n",
      " * Prec@1 61.773 Prec@5 82.922\n",
      " * Prec@1 61.853 Prec@5 82.974\n",
      " * Prec@1 61.932 Prec@5 82.955\n",
      " * Prec@1 61.657 Prec@5 82.514\n",
      " * Prec@1 61.736 Prec@5 82.569\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.530 (0.529)\n",
      "\n",
      "Loss 1.2102 (1.8320)\n",
      "\n",
      "Prec@1 68.750 (61.813)\n",
      "\n",
      "Prec@5 93.750 (82.692)\n",
      "\n",
      " * Prec@1 61.813 Prec@5 82.692\n",
      " * Prec@1 62.024 Prec@5 82.745\n",
      " * Prec@1 62.030 Prec@5 82.728\n",
      " * Prec@1 61.902 Prec@5 82.646\n",
      " * Prec@1 61.776 Prec@5 82.697\n",
      " * Prec@1 61.849 Prec@5 82.878\n",
      " * Prec@1 62.049 Prec@5 82.990\n",
      " * Prec@1 62.117 Prec@5 82.972\n",
      " * Prec@1 62.058 Prec@5 82.955\n",
      " * Prec@1 62.188 Prec@5 83.125\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.510 (0.528)\n",
      "\n",
      "Loss 2.2022 (1.8080)\n",
      "\n",
      "Prec@1 62.500 (62.191)\n",
      "\n",
      "Prec@5 75.000 (83.045)\n",
      "\n",
      " * Prec@1 62.191 Prec@5 83.045\n",
      " * Prec@1 62.010 Prec@5 82.966\n",
      " * Prec@1 62.015 Prec@5 83.010\n",
      " * Prec@1 61.719 Prec@5 82.752\n",
      " * Prec@1 61.845 Prec@5 82.857\n",
      " * Prec@1 61.675 Prec@5 82.783\n",
      " * Prec@1 61.565 Prec@5 82.769\n",
      " * Prec@1 61.690 Prec@5 82.812\n",
      " * Prec@1 61.583 Prec@5 82.741\n",
      " * Prec@1 61.705 Prec@5 82.784\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.480 (0.527)\n",
      "\n",
      "Loss 2.4373 (1.8213)\n",
      "\n",
      "Prec@1 50.000 (61.599)\n",
      "\n",
      "Prec@5 81.250 (82.770)\n",
      "\n",
      " * Prec@1 61.599 Prec@5 82.770\n",
      " * Prec@1 61.775 Prec@5 82.812\n",
      " * Prec@1 61.836 Prec@5 82.854\n",
      " * Prec@1 61.842 Prec@5 82.950\n",
      " * Prec@1 61.848 Prec@5 82.935\n",
      " * Prec@1 61.907 Prec@5 82.974\n",
      " * Prec@1 61.859 Prec@5 82.799\n",
      " * Prec@1 61.917 Prec@5 82.839\n",
      " * Prec@1 61.975 Prec@5 82.826\n",
      " * Prec@1 61.875 Prec@5 82.760\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.546 (0.527)\n",
      "\n",
      "Loss 2.2920 (1.8157)\n",
      "\n",
      "Prec@1 31.250 (61.622)\n",
      "\n",
      "Prec@5 81.250 (82.748)\n",
      "\n",
      " * Prec@1 61.622 Prec@5 82.748\n",
      " * Prec@1 61.578 Prec@5 82.582\n",
      " * Prec@1 61.687 Prec@5 82.571\n",
      " * Prec@1 61.794 Prec@5 82.661\n",
      " * Prec@1 61.850 Prec@5 82.600\n",
      " * Prec@1 61.954 Prec@5 82.688\n",
      " * Prec@1 61.860 Prec@5 82.677\n",
      " * Prec@1 61.768 Prec@5 82.617\n",
      " * Prec@1 61.725 Prec@5 82.655\n",
      " * Prec@1 61.779 Prec@5 82.692\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.530 (0.525)\n",
      "\n",
      "Loss 2.3071 (1.8202)\n",
      "\n",
      "Prec@1 56.250 (61.737)\n",
      "\n",
      "Prec@5 75.000 (82.634)\n",
      "\n",
      " * Prec@1 61.737 Prec@5 82.634\n",
      " * Prec@1 61.837 Prec@5 82.765\n",
      " * Prec@1 61.795 Prec@5 82.754\n",
      " * Prec@1 61.940 Prec@5 82.836\n",
      " * Prec@1 61.991 Prec@5 82.963\n",
      " * Prec@1 61.857 Prec@5 82.858\n",
      " * Prec@1 61.953 Prec@5 82.892\n",
      " * Prec@1 62.047 Prec@5 82.835\n",
      " * Prec@1 62.005 Prec@5 82.824\n",
      " * Prec@1 61.962 Prec@5 82.751\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [11][0/558]\t\\Time 0.610 (0.610)\tData 0.450 (0.450)\tLoss 0.6535 (0.6535)\tPrec@1 81.250 (81.250)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [11][100/558]\t\\Time 0.541 (0.532)\tData 0.431 (0.427)\tLoss 0.7072 (0.5230)\tPrec@1 81.250 (83.911)\tPrec@5 100.000 (98.391)\n",
      "Epoch: [11][200/558]\t\\Time 0.572 (0.541)\tData 0.462 (0.436)\tLoss 0.4069 (0.5386)\tPrec@1 81.250 (83.364)\tPrec@5 100.000 (97.823)\n",
      "Epoch: [11][300/558]\t\\Time 0.546 (0.538)\tData 0.445 (0.434)\tLoss 0.8614 (0.5694)\tPrec@1 68.750 (82.434)\tPrec@5 93.750 (97.674)\n",
      "Epoch: [11][400/558]\t\\Time 0.541 (0.537)\tData 0.431 (0.433)\tLoss 0.9243 (0.5995)\tPrec@1 68.750 (81.671)\tPrec@5 93.750 (97.226)\n",
      "Epoch: [11][500/558]\t\\Time 0.547 (0.536)\tData 0.437 (0.432)\tLoss 1.4511 (0.6110)\tPrec@1 68.750 (81.425)\tPrec@5 93.750 (97.156)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.502 (0.502)\n",
      "\n",
      "Loss 1.9696 (1.9696)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 81.250\n",
      " * Prec@1 62.500 Prec@5 84.375\n",
      " * Prec@1 68.750 Prec@5 89.583\n",
      " * Prec@1 70.312 Prec@5 89.062\n",
      " * Prec@1 70.000 Prec@5 86.250\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 71.429 Prec@5 88.393\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 88.889\n",
      " * Prec@1 68.125 Prec@5 88.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.571 (0.549)\n",
      "\n",
      "Loss 1.1007 (1.3756)\n",
      "\n",
      "Prec@1 75.000 (68.750)\n",
      "\n",
      "Prec@5 93.750 (88.636)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 88.636\n",
      " * Prec@1 69.271 Prec@5 88.542\n",
      " * Prec@1 69.231 Prec@5 88.942\n",
      " * Prec@1 69.643 Prec@5 89.286\n",
      " * Prec@1 69.167 Prec@5 88.750\n",
      " * Prec@1 69.531 Prec@5 89.062\n",
      " * Prec@1 69.485 Prec@5 89.338\n",
      " * Prec@1 68.750 Prec@5 88.542\n",
      " * Prec@1 68.750 Prec@5 88.487\n",
      " * Prec@1 68.125 Prec@5 87.812\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.542 (0.550)\n",
      "\n",
      "Loss 2.1802 (1.4197)\n",
      "\n",
      "Prec@1 50.000 (67.262)\n",
      "\n",
      "Prec@5 87.500 (87.798)\n",
      "\n",
      " * Prec@1 67.262 Prec@5 87.798\n",
      " * Prec@1 67.898 Prec@5 87.784\n",
      " * Prec@1 66.848 Prec@5 86.957\n",
      " * Prec@1 65.885 Prec@5 86.198\n",
      " * Prec@1 65.250 Prec@5 85.750\n",
      " * Prec@1 64.904 Prec@5 85.337\n",
      " * Prec@1 64.352 Prec@5 84.722\n",
      " * Prec@1 65.179 Prec@5 84.821\n",
      " * Prec@1 64.871 Prec@5 84.052\n",
      " * Prec@1 64.792 Prec@5 84.167\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.533 (0.544)\n",
      "\n",
      "Loss 1.0823 (1.6533)\n",
      "\n",
      "Prec@1 56.250 (64.516)\n",
      "\n",
      "Prec@5 100.000 (84.677)\n",
      "\n",
      " * Prec@1 64.516 Prec@5 84.677\n",
      " * Prec@1 64.844 Prec@5 84.961\n",
      " * Prec@1 64.583 Prec@5 84.848\n",
      " * Prec@1 65.074 Prec@5 85.110\n",
      " * Prec@1 64.464 Prec@5 84.643\n",
      " * Prec@1 64.583 Prec@5 84.722\n",
      " * Prec@1 64.358 Prec@5 84.628\n",
      " * Prec@1 64.309 Prec@5 84.539\n",
      " * Prec@1 64.103 Prec@5 84.615\n",
      " * Prec@1 64.375 Prec@5 84.688\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.460 (0.544)\n",
      "\n",
      "Loss 1.0728 (1.6486)\n",
      "\n",
      "Prec@1 62.500 (64.329)\n",
      "\n",
      "Prec@5 93.750 (84.909)\n",
      "\n",
      " * Prec@1 64.329 Prec@5 84.909\n",
      " * Prec@1 64.286 Prec@5 84.524\n",
      " * Prec@1 63.808 Prec@5 84.157\n",
      " * Prec@1 63.494 Prec@5 83.807\n",
      " * Prec@1 63.194 Prec@5 83.611\n",
      " * Prec@1 63.315 Prec@5 83.424\n",
      " * Prec@1 63.697 Prec@5 83.378\n",
      " * Prec@1 63.932 Prec@5 83.594\n",
      " * Prec@1 64.031 Prec@5 83.801\n",
      " * Prec@1 64.250 Prec@5 83.875\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.530 (0.541)\n",
      "\n",
      "Loss 1.7817 (1.7117)\n",
      "\n",
      "Prec@1 56.250 (64.093)\n",
      "\n",
      "Prec@5 75.000 (83.701)\n",
      "\n",
      " * Prec@1 64.093 Prec@5 83.701\n",
      " * Prec@1 64.303 Prec@5 83.894\n",
      " * Prec@1 64.033 Prec@5 83.726\n",
      " * Prec@1 64.236 Prec@5 83.912\n",
      " * Prec@1 63.977 Prec@5 83.864\n",
      " * Prec@1 63.839 Prec@5 83.817\n",
      " * Prec@1 63.925 Prec@5 83.882\n",
      " * Prec@1 64.009 Prec@5 83.944\n",
      " * Prec@1 63.665 Prec@5 83.898\n",
      " * Prec@1 63.958 Prec@5 83.854\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.533 (0.538)\n",
      "\n",
      "Loss 0.6488 (1.6990)\n",
      "\n",
      "Prec@1 87.500 (64.344)\n",
      "\n",
      "Prec@5 87.500 (83.914)\n",
      "\n",
      " * Prec@1 64.344 Prec@5 83.914\n",
      " * Prec@1 64.315 Prec@5 84.173\n",
      " * Prec@1 64.484 Prec@5 84.226\n",
      " * Prec@1 64.844 Prec@5 84.375\n",
      " * Prec@1 65.192 Prec@5 84.519\n",
      " * Prec@1 64.962 Prec@5 84.375\n",
      " * Prec@1 65.019 Prec@5 84.328\n",
      " * Prec@1 64.890 Prec@5 84.283\n",
      " * Prec@1 64.583 Prec@5 83.877\n",
      " * Prec@1 64.464 Prec@5 83.750\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.553 (0.535)\n",
      "\n",
      "Loss 2.3947 (1.7176)\n",
      "\n",
      "Prec@1 56.250 (64.349)\n",
      "\n",
      "Prec@5 68.750 (83.539)\n",
      "\n",
      " * Prec@1 64.349 Prec@5 83.539\n",
      " * Prec@1 64.149 Prec@5 83.594\n",
      " * Prec@1 64.041 Prec@5 83.562\n",
      " * Prec@1 64.105 Prec@5 83.699\n",
      " * Prec@1 64.167 Prec@5 83.583\n",
      " * Prec@1 64.062 Prec@5 83.388\n",
      " * Prec@1 64.123 Prec@5 83.442\n",
      " * Prec@1 64.183 Prec@5 83.574\n",
      " * Prec@1 64.161 Prec@5 83.544\n",
      " * Prec@1 63.984 Prec@5 83.516\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.526 (0.535)\n",
      "\n",
      "Loss 3.3192 (1.7537)\n",
      "\n",
      "Prec@1 43.750 (63.735)\n",
      "\n",
      "Prec@5 75.000 (83.410)\n",
      "\n",
      " * Prec@1 63.735 Prec@5 83.410\n",
      " * Prec@1 63.796 Prec@5 83.384\n",
      " * Prec@1 63.855 Prec@5 83.358\n",
      " * Prec@1 63.765 Prec@5 83.036\n",
      " * Prec@1 63.676 Prec@5 83.015\n",
      " * Prec@1 63.735 Prec@5 83.140\n",
      " * Prec@1 63.865 Prec@5 83.261\n",
      " * Prec@1 63.849 Prec@5 83.097\n",
      " * Prec@1 63.553 Prec@5 82.795\n",
      " * Prec@1 63.611 Prec@5 82.917\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.541 (0.534)\n",
      "\n",
      "Loss 0.8781 (1.7712)\n",
      "\n",
      "Prec@1 81.250 (63.805)\n",
      "\n",
      "Prec@5 93.750 (83.036)\n",
      "\n",
      " * Prec@1 63.805 Prec@5 83.036\n",
      " * Prec@1 63.723 Prec@5 82.948\n",
      " * Prec@1 63.844 Prec@5 82.997\n",
      " * Prec@1 63.630 Prec@5 82.912\n",
      " * Prec@1 63.816 Prec@5 83.026\n",
      " * Prec@1 63.932 Prec@5 83.203\n",
      " * Prec@1 64.240 Prec@5 83.376\n",
      " * Prec@1 64.222 Prec@5 83.355\n",
      " * Prec@1 64.205 Prec@5 83.396\n",
      " * Prec@1 64.375 Prec@5 83.562\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.565 (0.533)\n",
      "\n",
      "Loss 2.3617 (1.7535)\n",
      "\n",
      "Prec@1 50.000 (64.233)\n",
      "\n",
      "Prec@5 68.750 (83.416)\n",
      "\n",
      " * Prec@1 64.233 Prec@5 83.416\n",
      " * Prec@1 64.032 Prec@5 83.272\n",
      " * Prec@1 64.078 Prec@5 83.252\n",
      " * Prec@1 63.942 Prec@5 83.053\n",
      " * Prec@1 63.929 Prec@5 83.155\n",
      " * Prec@1 63.856 Prec@5 82.960\n",
      " * Prec@1 63.843 Prec@5 83.061\n",
      " * Prec@1 63.657 Prec@5 83.102\n",
      " * Prec@1 63.589 Prec@5 83.085\n",
      " * Prec@1 63.466 Prec@5 83.068\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.462 (0.532)\n",
      "\n",
      "Loss 3.1156 (1.7926)\n",
      "\n",
      "Prec@1 50.000 (63.345)\n",
      "\n",
      "Prec@5 81.250 (83.052)\n",
      "\n",
      " * Prec@1 63.345 Prec@5 83.052\n",
      " * Prec@1 63.560 Prec@5 83.092\n",
      " * Prec@1 63.772 Prec@5 83.131\n",
      " * Prec@1 63.816 Prec@5 83.169\n",
      " * Prec@1 63.913 Prec@5 83.261\n",
      " * Prec@1 64.062 Prec@5 83.351\n",
      " * Prec@1 63.889 Prec@5 83.226\n",
      " * Prec@1 63.983 Prec@5 83.263\n",
      " * Prec@1 63.971 Prec@5 83.193\n",
      " * Prec@1 63.958 Prec@5 83.125\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.510 (0.531)\n",
      "\n",
      "Loss 2.0770 (1.7711)\n",
      "\n",
      "Prec@1 56.250 (63.895)\n",
      "\n",
      "Prec@5 81.250 (83.110)\n",
      "\n",
      " * Prec@1 63.895 Prec@5 83.110\n",
      " * Prec@1 63.883 Prec@5 83.043\n",
      " * Prec@1 63.974 Prec@5 83.079\n",
      " * Prec@1 64.012 Prec@5 83.115\n",
      " * Prec@1 63.950 Prec@5 83.100\n",
      " * Prec@1 63.938 Prec@5 83.185\n",
      " * Prec@1 63.878 Prec@5 83.169\n",
      " * Prec@1 63.867 Prec@5 83.154\n",
      " * Prec@1 63.905 Prec@5 83.236\n",
      " * Prec@1 63.990 Prec@5 83.269\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.514 (0.529)\n",
      "\n",
      "Loss 2.6790 (1.7793)\n",
      "\n",
      "Prec@1 43.750 (63.836)\n",
      "\n",
      "Prec@5 68.750 (83.158)\n",
      "\n",
      " * Prec@1 63.836 Prec@5 83.158\n",
      " * Prec@1 63.920 Prec@5 83.239\n",
      " * Prec@1 63.910 Prec@5 83.224\n",
      " * Prec@1 63.993 Prec@5 83.209\n",
      " * Prec@1 64.074 Prec@5 83.241\n",
      " * Prec@1 63.925 Prec@5 83.088\n",
      " * Prec@1 63.869 Prec@5 83.120\n",
      " * Prec@1 63.904 Prec@5 83.152\n",
      " * Prec@1 63.714 Prec@5 83.004\n",
      " * Prec@1 63.710 Prec@5 82.975\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [12][0/558]\t\\Time 0.584 (0.584)\tData 0.454 (0.454)\tLoss 0.5452 (0.5452)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/558]\t\\Time 0.532 (0.524)\tData 0.462 (0.422)\tLoss 0.8417 (0.4347)\tPrec@1 75.000 (86.819)\tPrec@5 100.000 (99.010)\n",
      "Epoch: [12][200/558]\t\\Time 0.522 (0.523)\tData 0.422 (0.421)\tLoss 0.5038 (0.4172)\tPrec@1 93.750 (86.878)\tPrec@5 100.000 (99.005)\n",
      "Epoch: [12][300/558]\t\\Time 0.490 (0.522)\tData 0.420 (0.421)\tLoss 0.2925 (0.4223)\tPrec@1 93.750 (86.919)\tPrec@5 100.000 (98.858)\n",
      "Epoch: [12][400/558]\t\\Time 0.570 (0.525)\tData 0.460 (0.423)\tLoss 0.7307 (0.4329)\tPrec@1 75.000 (86.705)\tPrec@5 100.000 (98.550)\n",
      "Epoch: [12][500/558]\t\\Time 0.538 (0.529)\tData 0.433 (0.426)\tLoss 0.4417 (0.4515)\tPrec@1 87.500 (86.178)\tPrec@5 100.000 (98.366)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.513 (0.513)\n",
      "\n",
      "Loss 2.4852 (2.4852)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 81.250\n",
      " * Prec@1 59.375 Prec@5 81.250\n",
      " * Prec@1 66.667 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 85.938\n",
      " * Prec@1 67.500 Prec@5 85.000\n",
      " * Prec@1 68.750 Prec@5 86.458\n",
      " * Prec@1 69.643 Prec@5 87.500\n",
      " * Prec@1 67.969 Prec@5 85.938\n",
      " * Prec@1 68.056 Prec@5 87.500\n",
      " * Prec@1 69.375 Prec@5 87.500\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.520 (0.530)\n",
      "\n",
      "Loss 1.8326 (1.4875)\n",
      "\n",
      "Prec@1 62.500 (68.750)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 69.271 Prec@5 87.500\n",
      " * Prec@1 70.673 Prec@5 87.981\n",
      " * Prec@1 71.429 Prec@5 87.946\n",
      " * Prec@1 70.833 Prec@5 88.333\n",
      " * Prec@1 71.094 Prec@5 89.062\n",
      " * Prec@1 70.956 Prec@5 89.338\n",
      " * Prec@1 70.486 Prec@5 88.889\n",
      " * Prec@1 70.395 Prec@5 89.145\n",
      " * Prec@1 70.625 Prec@5 88.438\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.532 (0.529)\n",
      "\n",
      "Loss 2.1421 (1.4904)\n",
      "\n",
      "Prec@1 68.750 (70.536)\n",
      "\n",
      "Prec@5 87.500 (88.393)\n",
      "\n",
      " * Prec@1 70.536 Prec@5 88.393\n",
      " * Prec@1 70.455 Prec@5 88.352\n",
      " * Prec@1 69.837 Prec@5 88.043\n",
      " * Prec@1 69.792 Prec@5 87.760\n",
      " * Prec@1 69.500 Prec@5 87.750\n",
      " * Prec@1 68.990 Prec@5 87.500\n",
      " * Prec@1 68.287 Prec@5 86.574\n",
      " * Prec@1 68.527 Prec@5 86.607\n",
      " * Prec@1 68.319 Prec@5 85.991\n",
      " * Prec@1 67.708 Prec@5 85.625\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.513 (0.533)\n",
      "\n",
      "Loss 1.5143 (1.7276)\n",
      "\n",
      "Prec@1 75.000 (67.944)\n",
      "\n",
      "Prec@5 93.750 (85.887)\n",
      "\n",
      " * Prec@1 67.944 Prec@5 85.887\n",
      " * Prec@1 68.359 Prec@5 86.133\n",
      " * Prec@1 67.992 Prec@5 85.795\n",
      " * Prec@1 68.382 Prec@5 85.846\n",
      " * Prec@1 68.036 Prec@5 85.893\n",
      " * Prec@1 68.229 Prec@5 85.938\n",
      " * Prec@1 67.568 Prec@5 85.980\n",
      " * Prec@1 67.599 Prec@5 85.855\n",
      " * Prec@1 67.147 Prec@5 85.577\n",
      " * Prec@1 66.562 Prec@5 85.469\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.454 (0.535)\n",
      "\n",
      "Loss 1.2861 (1.7346)\n",
      "\n",
      "Prec@1 75.000 (66.768)\n",
      "\n",
      "Prec@5 100.000 (85.823)\n",
      "\n",
      " * Prec@1 66.768 Prec@5 85.823\n",
      " * Prec@1 66.667 Prec@5 85.565\n",
      " * Prec@1 66.279 Prec@5 84.884\n",
      " * Prec@1 65.909 Prec@5 84.659\n",
      " * Prec@1 65.833 Prec@5 84.306\n",
      " * Prec@1 65.489 Prec@5 84.239\n",
      " * Prec@1 65.293 Prec@5 84.309\n",
      " * Prec@1 65.625 Prec@5 84.505\n",
      " * Prec@1 65.689 Prec@5 84.439\n",
      " * Prec@1 66.125 Prec@5 84.625\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.529 (0.534)\n",
      "\n",
      "Loss 1.9120 (1.8285)\n",
      "\n",
      "Prec@1 62.500 (66.054)\n",
      "\n",
      "Prec@5 75.000 (84.436)\n",
      "\n",
      " * Prec@1 66.054 Prec@5 84.436\n",
      " * Prec@1 66.106 Prec@5 84.495\n",
      " * Prec@1 66.038 Prec@5 84.552\n",
      " * Prec@1 65.972 Prec@5 84.606\n",
      " * Prec@1 65.795 Prec@5 84.318\n",
      " * Prec@1 65.737 Prec@5 84.152\n",
      " * Prec@1 65.570 Prec@5 84.211\n",
      " * Prec@1 65.841 Prec@5 84.267\n",
      " * Prec@1 65.678 Prec@5 84.216\n",
      " * Prec@1 65.729 Prec@5 84.271\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.501 (0.532)\n",
      "\n",
      "Loss 1.3715 (1.8067)\n",
      "\n",
      "Prec@1 62.500 (65.676)\n",
      "\n",
      "Prec@5 93.750 (84.426)\n",
      "\n",
      " * Prec@1 65.676 Prec@5 84.426\n",
      " * Prec@1 65.827 Prec@5 84.577\n",
      " * Prec@1 65.675 Prec@5 84.722\n",
      " * Prec@1 65.820 Prec@5 84.863\n",
      " * Prec@1 65.769 Prec@5 84.904\n",
      " * Prec@1 65.530 Prec@5 84.470\n",
      " * Prec@1 65.672 Prec@5 84.515\n",
      " * Prec@1 65.625 Prec@5 84.559\n",
      " * Prec@1 65.308 Prec@5 84.330\n",
      " * Prec@1 65.179 Prec@5 84.107\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.540 (0.529)\n",
      "\n",
      "Loss 1.0901 (1.8109)\n",
      "\n",
      "Prec@1 68.750 (65.229)\n",
      "\n",
      "Prec@5 93.750 (84.243)\n",
      "\n",
      " * Prec@1 65.229 Prec@5 84.243\n",
      " * Prec@1 64.931 Prec@5 83.941\n",
      " * Prec@1 65.068 Prec@5 83.990\n",
      " * Prec@1 65.372 Prec@5 84.122\n",
      " * Prec@1 65.250 Prec@5 84.083\n",
      " * Prec@1 64.803 Prec@5 83.964\n",
      " * Prec@1 64.692 Prec@5 84.010\n",
      " * Prec@1 64.744 Prec@5 84.135\n",
      " * Prec@1 64.794 Prec@5 83.940\n",
      " * Prec@1 64.844 Prec@5 84.062\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.482 (0.528)\n",
      "\n",
      "Loss 3.8946 (1.8531)\n",
      "\n",
      "Prec@1 25.000 (64.352)\n",
      "\n",
      "Prec@5 75.000 (83.951)\n",
      "\n",
      " * Prec@1 64.352 Prec@5 83.951\n",
      " * Prec@1 64.405 Prec@5 83.918\n",
      " * Prec@1 64.608 Prec@5 83.886\n",
      " * Prec@1 64.435 Prec@5 83.705\n",
      " * Prec@1 64.191 Prec@5 83.603\n",
      " * Prec@1 64.244 Prec@5 83.576\n",
      " * Prec@1 64.440 Prec@5 83.693\n",
      " * Prec@1 64.418 Prec@5 83.665\n",
      " * Prec@1 64.045 Prec@5 83.287\n",
      " * Prec@1 64.236 Prec@5 83.403\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.512 (0.528)\n",
      "\n",
      "Loss 1.2243 (1.9031)\n",
      "\n",
      "Prec@1 62.500 (64.217)\n",
      "\n",
      "Prec@5 87.500 (83.448)\n",
      "\n",
      " * Prec@1 64.217 Prec@5 83.448\n",
      " * Prec@1 64.266 Prec@5 83.356\n",
      " * Prec@1 64.180 Prec@5 83.266\n",
      " * Prec@1 64.096 Prec@5 83.245\n",
      " * Prec@1 64.145 Prec@5 83.289\n",
      " * Prec@1 64.258 Prec@5 83.398\n",
      " * Prec@1 64.497 Prec@5 83.441\n",
      " * Prec@1 64.477 Prec@5 83.291\n",
      " * Prec@1 64.457 Prec@5 83.270\n",
      " * Prec@1 64.500 Prec@5 83.375\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.562 (0.528)\n",
      "\n",
      "Loss 3.2452 (1.9016)\n",
      "\n",
      "Prec@1 56.250 (64.418)\n",
      "\n",
      "Prec@5 62.500 (83.168)\n",
      "\n",
      " * Prec@1 64.418 Prec@5 83.168\n",
      " * Prec@1 64.338 Prec@5 83.027\n",
      " * Prec@1 64.260 Prec@5 83.010\n",
      " * Prec@1 64.123 Prec@5 82.873\n",
      " * Prec@1 64.286 Prec@5 82.976\n",
      " * Prec@1 64.328 Prec@5 82.901\n",
      " * Prec@1 64.311 Prec@5 82.944\n",
      " * Prec@1 64.468 Prec@5 82.986\n",
      " * Prec@1 64.507 Prec@5 83.085\n",
      " * Prec@1 64.545 Prec@5 83.182\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.461 (0.529)\n",
      "\n",
      "Loss 2.5075 (1.9024)\n",
      "\n",
      "Prec@1 62.500 (64.527)\n",
      "\n",
      "Prec@5 75.000 (83.108)\n",
      "\n",
      " * Prec@1 64.527 Prec@5 83.108\n",
      " * Prec@1 64.676 Prec@5 83.203\n",
      " * Prec@1 64.878 Prec@5 83.296\n",
      " * Prec@1 64.748 Prec@5 83.169\n",
      " * Prec@1 64.728 Prec@5 83.261\n",
      " * Prec@1 64.817 Prec@5 83.351\n",
      " * Prec@1 64.744 Prec@5 83.280\n",
      " * Prec@1 64.725 Prec@5 83.369\n",
      " * Prec@1 64.758 Prec@5 83.456\n",
      " * Prec@1 64.740 Prec@5 83.438\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.520 (0.528)\n",
      "\n",
      "Loss 2.9527 (1.8851)\n",
      "\n",
      "Prec@1 43.750 (64.566)\n",
      "\n",
      "Prec@5 62.500 (83.264)\n",
      "\n",
      " * Prec@1 64.566 Prec@5 83.264\n",
      " * Prec@1 64.549 Prec@5 83.145\n",
      " * Prec@1 64.634 Prec@5 83.130\n",
      " * Prec@1 64.718 Prec@5 83.165\n",
      " * Prec@1 64.750 Prec@5 83.250\n",
      " * Prec@1 64.732 Prec@5 83.234\n",
      " * Prec@1 64.813 Prec@5 83.219\n",
      " * Prec@1 64.795 Prec@5 83.203\n",
      " * Prec@1 64.777 Prec@5 83.236\n",
      " * Prec@1 64.760 Prec@5 83.221\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.532 (0.525)\n",
      "\n",
      "Loss 2.5333 (1.8863)\n",
      "\n",
      "Prec@1 56.250 (64.695)\n",
      "\n",
      "Prec@5 68.750 (83.111)\n",
      "\n",
      " * Prec@1 64.695 Prec@5 83.111\n",
      " * Prec@1 64.725 Prec@5 83.144\n",
      " * Prec@1 64.756 Prec@5 83.130\n",
      " * Prec@1 64.879 Prec@5 83.209\n",
      " * Prec@1 64.954 Prec@5 83.287\n",
      " * Prec@1 64.890 Prec@5 83.134\n",
      " * Prec@1 64.918 Prec@5 83.212\n",
      " * Prec@1 64.991 Prec@5 83.288\n",
      " * Prec@1 64.928 Prec@5 83.273\n",
      " * Prec@1 64.919 Prec@5 83.289\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [13][0/558]\t\\Time 0.587 (0.587)\tData 0.425 (0.425)\tLoss 0.6864 (0.6864)\tPrec@1 81.250 (81.250)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/558]\t\\Time 0.550 (0.531)\tData 0.429 (0.428)\tLoss 0.5508 (0.3419)\tPrec@1 81.250 (89.604)\tPrec@5 100.000 (99.010)\n",
      "Epoch: [13][200/558]\t\\Time 0.521 (0.529)\tData 0.411 (0.425)\tLoss 0.2325 (0.3243)\tPrec@1 87.500 (90.485)\tPrec@5 100.000 (98.974)\n",
      "Epoch: [13][300/558]\t\\Time 0.574 (0.526)\tData 0.453 (0.422)\tLoss 0.3890 (0.3442)\tPrec@1 93.750 (89.701)\tPrec@5 100.000 (99.003)\n",
      "Epoch: [13][400/558]\t\\Time 0.461 (0.526)\tData 0.391 (0.423)\tLoss 0.4705 (0.3510)\tPrec@1 81.250 (89.448)\tPrec@5 100.000 (99.034)\n",
      "Epoch: [13][500/558]\t\\Time 0.604 (0.528)\tData 0.494 (0.425)\tLoss 0.2515 (0.3570)\tPrec@1 93.750 (89.097)\tPrec@5 100.000 (99.052)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.535 (0.535)\n",
      "\n",
      "Loss 1.5823 (1.5823)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 65.625 Prec@5 84.375\n",
      " * Prec@1 68.750 Prec@5 89.583\n",
      " * Prec@1 70.312 Prec@5 87.500\n",
      " * Prec@1 71.250 Prec@5 87.500\n",
      " * Prec@1 72.917 Prec@5 88.542\n",
      " * Prec@1 74.107 Prec@5 88.393\n",
      " * Prec@1 71.875 Prec@5 86.719\n",
      " * Prec@1 72.917 Prec@5 88.194\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.594 (0.562)\n",
      "\n",
      "Loss 1.1313 (1.3834)\n",
      "\n",
      "Prec@1 75.000 (72.159)\n",
      "\n",
      "Prec@5 100.000 (88.636)\n",
      "\n",
      " * Prec@1 72.159 Prec@5 88.636\n",
      " * Prec@1 72.917 Prec@5 88.542\n",
      " * Prec@1 73.558 Prec@5 88.942\n",
      " * Prec@1 74.107 Prec@5 88.839\n",
      " * Prec@1 74.167 Prec@5 88.750\n",
      " * Prec@1 74.219 Prec@5 89.062\n",
      " * Prec@1 74.632 Prec@5 88.971\n",
      " * Prec@1 74.653 Prec@5 88.542\n",
      " * Prec@1 75.329 Prec@5 88.816\n",
      " * Prec@1 75.000 Prec@5 88.125\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.530 (0.546)\n",
      "\n",
      "Loss 2.6132 (1.4744)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (88.095)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 88.095\n",
      " * Prec@1 75.000 Prec@5 87.784\n",
      " * Prec@1 74.185 Prec@5 87.228\n",
      " * Prec@1 73.177 Prec@5 86.198\n",
      " * Prec@1 73.250 Prec@5 86.000\n",
      " * Prec@1 73.077 Prec@5 85.817\n",
      " * Prec@1 72.222 Prec@5 85.185\n",
      " * Prec@1 72.098 Prec@5 85.268\n",
      " * Prec@1 71.767 Prec@5 84.698\n",
      " * Prec@1 71.250 Prec@5 84.375\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.518 (0.540)\n",
      "\n",
      "Loss 0.8989 (1.7154)\n",
      "\n",
      "Prec@1 81.250 (71.573)\n",
      "\n",
      "Prec@5 87.500 (84.476)\n",
      "\n",
      " * Prec@1 71.573 Prec@5 84.476\n",
      " * Prec@1 71.680 Prec@5 84.766\n",
      " * Prec@1 71.212 Prec@5 84.470\n",
      " * Prec@1 71.324 Prec@5 84.743\n",
      " * Prec@1 71.429 Prec@5 84.821\n",
      " * Prec@1 71.528 Prec@5 84.896\n",
      " * Prec@1 71.115 Prec@5 84.797\n",
      " * Prec@1 70.888 Prec@5 84.539\n",
      " * Prec@1 70.673 Prec@5 84.295\n",
      " * Prec@1 70.781 Prec@5 84.219\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.504 (0.539)\n",
      "\n",
      "Loss 0.7198 (1.6779)\n",
      "\n",
      "Prec@1 75.000 (70.884)\n",
      "\n",
      "Prec@5 100.000 (84.604)\n",
      "\n",
      " * Prec@1 70.884 Prec@5 84.604\n",
      " * Prec@1 70.536 Prec@5 84.524\n",
      " * Prec@1 70.203 Prec@5 84.157\n",
      " * Prec@1 69.744 Prec@5 84.091\n",
      " * Prec@1 69.583 Prec@5 83.750\n",
      " * Prec@1 69.429 Prec@5 83.560\n",
      " * Prec@1 69.681 Prec@5 83.644\n",
      " * Prec@1 69.661 Prec@5 83.854\n",
      " * Prec@1 69.770 Prec@5 83.929\n",
      " * Prec@1 70.125 Prec@5 84.125\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.544 (0.535)\n",
      "\n",
      "Loss 1.9360 (1.7428)\n",
      "\n",
      "Prec@1 62.500 (69.975)\n",
      "\n",
      "Prec@5 81.250 (84.069)\n",
      "\n",
      " * Prec@1 69.975 Prec@5 84.069\n",
      " * Prec@1 70.192 Prec@5 84.255\n",
      " * Prec@1 70.165 Prec@5 84.316\n",
      " * Prec@1 70.370 Prec@5 84.491\n",
      " * Prec@1 70.341 Prec@5 84.432\n",
      " * Prec@1 70.201 Prec@5 84.375\n",
      " * Prec@1 70.285 Prec@5 84.430\n",
      " * Prec@1 70.366 Prec@5 84.483\n",
      " * Prec@1 70.021 Prec@5 84.322\n",
      " * Prec@1 70.208 Prec@5 84.271\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.481 (0.531)\n",
      "\n",
      "Loss 1.1295 (1.7267)\n",
      "\n",
      "Prec@1 75.000 (70.287)\n",
      "\n",
      "Prec@5 100.000 (84.529)\n",
      "\n",
      " * Prec@1 70.287 Prec@5 84.529\n",
      " * Prec@1 70.363 Prec@5 84.677\n",
      " * Prec@1 70.437 Prec@5 84.821\n",
      " * Prec@1 70.703 Prec@5 84.961\n",
      " * Prec@1 70.769 Prec@5 85.000\n",
      " * Prec@1 70.549 Prec@5 84.848\n",
      " * Prec@1 70.709 Prec@5 84.888\n",
      " * Prec@1 70.588 Prec@5 84.835\n",
      " * Prec@1 70.380 Prec@5 84.692\n",
      " * Prec@1 70.089 Prec@5 84.554\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.552 (0.532)\n",
      "\n",
      "Loss 2.0580 (1.7224)\n",
      "\n",
      "Prec@1 62.500 (69.982)\n",
      "\n",
      "Prec@5 81.250 (84.507)\n",
      "\n",
      " * Prec@1 69.982 Prec@5 84.507\n",
      " * Prec@1 69.965 Prec@5 84.375\n",
      " * Prec@1 69.777 Prec@5 84.332\n",
      " * Prec@1 69.595 Prec@5 84.459\n",
      " * Prec@1 69.500 Prec@5 84.417\n",
      " * Prec@1 69.243 Prec@5 84.211\n",
      " * Prec@1 69.399 Prec@5 84.253\n",
      " * Prec@1 69.551 Prec@5 84.375\n",
      " * Prec@1 69.620 Prec@5 84.415\n",
      " * Prec@1 69.531 Prec@5 84.531\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.519 (0.531)\n",
      "\n",
      "Loss 2.7016 (1.7520)\n",
      "\n",
      "Prec@1 50.000 (69.290)\n",
      "\n",
      "Prec@5 81.250 (84.491)\n",
      "\n",
      " * Prec@1 69.290 Prec@5 84.491\n",
      " * Prec@1 69.284 Prec@5 84.527\n",
      " * Prec@1 69.352 Prec@5 84.488\n",
      " * Prec@1 69.196 Prec@5 84.152\n",
      " * Prec@1 69.191 Prec@5 84.044\n",
      " * Prec@1 69.331 Prec@5 84.084\n",
      " * Prec@1 69.397 Prec@5 84.124\n",
      " * Prec@1 69.460 Prec@5 84.162\n",
      " * Prec@1 69.171 Prec@5 83.778\n",
      " * Prec@1 69.444 Prec@5 83.958\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.524 (0.528)\n",
      "\n",
      "Loss 1.3066 (1.7584)\n",
      "\n",
      "Prec@1 75.000 (69.505)\n",
      "\n",
      "Prec@5 87.500 (83.997)\n",
      "\n",
      " * Prec@1 69.505 Prec@5 83.997\n",
      " * Prec@1 69.565 Prec@5 83.899\n",
      " * Prec@1 69.691 Prec@5 83.938\n",
      " * Prec@1 69.681 Prec@5 83.910\n",
      " * Prec@1 69.671 Prec@5 84.079\n",
      " * Prec@1 69.857 Prec@5 84.245\n",
      " * Prec@1 69.974 Prec@5 84.278\n",
      " * Prec@1 69.962 Prec@5 84.311\n",
      " * Prec@1 70.013 Prec@5 84.407\n",
      " * Prec@1 70.188 Prec@5 84.562\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.557 (0.528)\n",
      "\n",
      "Loss 3.0887 (1.7329)\n",
      "\n",
      "Prec@1 62.500 (70.111)\n",
      "\n",
      "Prec@5 68.750 (84.406)\n",
      "\n",
      " * Prec@1 70.111 Prec@5 84.406\n",
      " * Prec@1 69.853 Prec@5 84.436\n",
      " * Prec@1 69.903 Prec@5 84.466\n",
      " * Prec@1 69.651 Prec@5 84.315\n",
      " * Prec@1 69.821 Prec@5 84.345\n",
      " * Prec@1 69.693 Prec@5 84.316\n",
      " * Prec@1 69.568 Prec@5 84.346\n",
      " * Prec@1 69.734 Prec@5 84.375\n",
      " * Prec@1 69.725 Prec@5 84.404\n",
      " * Prec@1 69.773 Prec@5 84.489\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.478 (0.527)\n",
      "\n",
      "Loss 2.1904 (1.7401)\n",
      "\n",
      "Prec@1 50.000 (69.595)\n",
      "\n",
      "Prec@5 87.500 (84.516)\n",
      "\n",
      " * Prec@1 69.595 Prec@5 84.516\n",
      " * Prec@1 69.587 Prec@5 84.598\n",
      " * Prec@1 69.746 Prec@5 84.624\n",
      " * Prec@1 69.737 Prec@5 84.704\n",
      " * Prec@1 69.837 Prec@5 84.783\n",
      " * Prec@1 69.935 Prec@5 84.860\n",
      " * Prec@1 69.925 Prec@5 84.776\n",
      " * Prec@1 69.968 Prec@5 84.852\n",
      " * Prec@1 69.905 Prec@5 84.821\n",
      " * Prec@1 69.896 Prec@5 84.896\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.553 (0.527)\n",
      "\n",
      "Loss 1.9166 (1.7228)\n",
      "\n",
      "Prec@1 56.250 (69.783)\n",
      "\n",
      "Prec@5 68.750 (84.762)\n",
      "\n",
      " * Prec@1 69.783 Prec@5 84.762\n",
      " * Prec@1 69.775 Prec@5 84.631\n",
      " * Prec@1 69.817 Prec@5 84.654\n",
      " * Prec@1 69.859 Prec@5 84.627\n",
      " * Prec@1 69.850 Prec@5 84.600\n",
      " * Prec@1 69.792 Prec@5 84.673\n",
      " * Prec@1 69.734 Prec@5 84.646\n",
      " * Prec@1 69.629 Prec@5 84.668\n",
      " * Prec@1 69.671 Prec@5 84.738\n",
      " * Prec@1 69.808 Prec@5 84.808\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.529 (0.527)\n",
      "\n",
      "Loss 3.5942 (1.7311)\n",
      "\n",
      "Prec@1 50.000 (69.656)\n",
      "\n",
      "Prec@5 56.250 (84.590)\n",
      "\n",
      " * Prec@1 69.656 Prec@5 84.590\n",
      " * Prec@1 69.650 Prec@5 84.659\n",
      " * Prec@1 69.690 Prec@5 84.680\n",
      " * Prec@1 69.683 Prec@5 84.701\n",
      " * Prec@1 69.722 Prec@5 84.815\n",
      " * Prec@1 69.623 Prec@5 84.697\n",
      " * Prec@1 69.617 Prec@5 84.672\n",
      " * Prec@1 69.656 Prec@5 84.692\n",
      " * Prec@1 69.649 Prec@5 84.622\n",
      " * Prec@1 69.534 Prec@5 84.633\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [14][0/558]\t\\Time 0.562 (0.562)\tData 0.458 (0.458)\tLoss 0.0699 (0.0699)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/558]\t\\Time 0.532 (0.517)\tData 0.433 (0.417)\tLoss 0.1004 (0.1768)\tPrec@1 100.000 (94.183)\tPrec@5 100.000 (99.814)\n",
      "Epoch: [14][200/558]\t\\Time 0.540 (0.529)\tData 0.430 (0.426)\tLoss 0.0827 (0.1758)\tPrec@1 100.000 (94.403)\tPrec@5 100.000 (99.876)\n",
      "Epoch: [14][300/558]\t\\Time 0.511 (0.537)\tData 0.400 (0.434)\tLoss 0.0980 (0.1893)\tPrec@1 100.000 (94.145)\tPrec@5 100.000 (99.792)\n",
      "Epoch: [14][400/558]\t\\Time 0.570 (0.539)\tData 0.461 (0.437)\tLoss 0.1660 (0.2079)\tPrec@1 93.750 (93.625)\tPrec@5 100.000 (99.719)\n",
      "Epoch: [14][500/558]\t\\Time 0.504 (0.536)\tData 0.424 (0.434)\tLoss 0.2235 (0.2262)\tPrec@1 87.500 (93.164)\tPrec@5 100.000 (99.576)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.486 (0.486)\n",
      "\n",
      "Loss 2.2756 (2.2756)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 81.250\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 72.917 Prec@5 91.667\n",
      " * Prec@1 71.875 Prec@5 90.625\n",
      " * Prec@1 70.000 Prec@5 88.750\n",
      " * Prec@1 72.917 Prec@5 89.583\n",
      " * Prec@1 75.000 Prec@5 90.179\n",
      " * Prec@1 71.875 Prec@5 88.281\n",
      " * Prec@1 72.917 Prec@5 88.889\n",
      " * Prec@1 73.750 Prec@5 88.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.505 (0.524)\n",
      "\n",
      "Loss 1.2293 (1.4406)\n",
      "\n",
      "Prec@1 81.250 (74.432)\n",
      "\n",
      "Prec@5 87.500 (88.068)\n",
      "\n",
      " * Prec@1 74.432 Prec@5 88.068\n",
      " * Prec@1 75.000 Prec@5 88.021\n",
      " * Prec@1 75.962 Prec@5 88.942\n",
      " * Prec@1 76.339 Prec@5 88.839\n",
      " * Prec@1 75.417 Prec@5 89.167\n",
      " * Prec@1 75.781 Prec@5 89.062\n",
      " * Prec@1 74.632 Prec@5 88.971\n",
      " * Prec@1 74.653 Prec@5 88.542\n",
      " * Prec@1 75.329 Prec@5 88.816\n",
      " * Prec@1 75.000 Prec@5 88.438\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.537 (0.520)\n",
      "\n",
      "Loss 2.5964 (1.4701)\n",
      "\n",
      "Prec@1 62.500 (74.405)\n",
      "\n",
      "Prec@5 81.250 (88.095)\n",
      "\n",
      " * Prec@1 74.405 Prec@5 88.095\n",
      " * Prec@1 74.148 Prec@5 87.784\n",
      " * Prec@1 74.185 Prec@5 88.043\n",
      " * Prec@1 73.438 Prec@5 87.240\n",
      " * Prec@1 73.500 Prec@5 87.000\n",
      " * Prec@1 73.077 Prec@5 87.260\n",
      " * Prec@1 72.222 Prec@5 86.806\n",
      " * Prec@1 72.321 Prec@5 86.607\n",
      " * Prec@1 71.552 Prec@5 85.776\n",
      " * Prec@1 71.250 Prec@5 85.625\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.503 (0.529)\n",
      "\n",
      "Loss 0.8865 (1.7051)\n",
      "\n",
      "Prec@1 81.250 (71.573)\n",
      "\n",
      "Prec@5 93.750 (85.887)\n",
      "\n",
      " * Prec@1 71.573 Prec@5 85.887\n",
      " * Prec@1 71.680 Prec@5 85.938\n",
      " * Prec@1 71.970 Prec@5 85.795\n",
      " * Prec@1 72.243 Prec@5 86.029\n",
      " * Prec@1 71.964 Prec@5 85.893\n",
      " * Prec@1 72.049 Prec@5 85.938\n",
      " * Prec@1 71.453 Prec@5 85.642\n",
      " * Prec@1 71.546 Prec@5 85.362\n",
      " * Prec@1 71.795 Prec@5 85.417\n",
      " * Prec@1 71.719 Prec@5 85.469\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.469 (0.529)\n",
      "\n",
      "Loss 0.4504 (1.6755)\n",
      "\n",
      "Prec@1 87.500 (72.104)\n",
      "\n",
      "Prec@5 100.000 (85.823)\n",
      "\n",
      " * Prec@1 72.104 Prec@5 85.823\n",
      " * Prec@1 72.024 Prec@5 85.863\n",
      " * Prec@1 71.512 Prec@5 85.465\n",
      " * Prec@1 71.165 Prec@5 85.369\n",
      " * Prec@1 70.972 Prec@5 85.139\n",
      " * Prec@1 70.788 Prec@5 84.783\n",
      " * Prec@1 70.612 Prec@5 84.973\n",
      " * Prec@1 70.573 Prec@5 85.156\n",
      " * Prec@1 70.536 Prec@5 85.204\n",
      " * Prec@1 70.875 Prec@5 85.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.558 (0.527)\n",
      "\n",
      "Loss 2.2946 (1.7429)\n",
      "\n",
      "Prec@1 56.250 (70.588)\n",
      "\n",
      "Prec@5 81.250 (85.294)\n",
      "\n",
      " * Prec@1 70.588 Prec@5 85.294\n",
      " * Prec@1 70.673 Prec@5 85.457\n",
      " * Prec@1 70.755 Prec@5 85.377\n",
      " * Prec@1 70.833 Prec@5 85.417\n",
      " * Prec@1 70.795 Prec@5 85.455\n",
      " * Prec@1 70.647 Prec@5 85.491\n",
      " * Prec@1 70.614 Prec@5 85.307\n",
      " * Prec@1 70.690 Prec@5 85.453\n",
      " * Prec@1 70.445 Prec@5 85.275\n",
      " * Prec@1 70.521 Prec@5 85.208\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.540 (0.528)\n",
      "\n",
      "Loss 0.7979 (1.7286)\n",
      "\n",
      "Prec@1 81.250 (70.697)\n",
      "\n",
      "Prec@5 93.750 (85.348)\n",
      "\n",
      " * Prec@1 70.697 Prec@5 85.348\n",
      " * Prec@1 70.766 Prec@5 85.484\n",
      " * Prec@1 70.833 Prec@5 85.516\n",
      " * Prec@1 71.191 Prec@5 85.742\n",
      " * Prec@1 71.250 Prec@5 85.769\n",
      " * Prec@1 70.833 Prec@5 85.511\n",
      " * Prec@1 71.082 Prec@5 85.541\n",
      " * Prec@1 70.956 Prec@5 85.570\n",
      " * Prec@1 70.743 Prec@5 85.236\n",
      " * Prec@1 70.446 Prec@5 85.000\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.542 (0.527)\n",
      "\n",
      "Loss 1.9763 (1.7497)\n",
      "\n",
      "Prec@1 62.500 (70.335)\n",
      "\n",
      "Prec@5 75.000 (84.859)\n",
      "\n",
      " * Prec@1 70.335 Prec@5 84.859\n",
      " * Prec@1 70.139 Prec@5 84.809\n",
      " * Prec@1 69.949 Prec@5 84.589\n",
      " * Prec@1 69.932 Prec@5 84.713\n",
      " * Prec@1 70.000 Prec@5 84.667\n",
      " * Prec@1 69.490 Prec@5 84.375\n",
      " * Prec@1 69.481 Prec@5 84.334\n",
      " * Prec@1 69.712 Prec@5 84.455\n",
      " * Prec@1 69.699 Prec@5 84.415\n",
      " * Prec@1 69.844 Prec@5 84.531\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.512 (0.526)\n",
      "\n",
      "Loss 2.9554 (1.7837)\n",
      "\n",
      "Prec@1 56.250 (69.676)\n",
      "\n",
      "Prec@5 75.000 (84.414)\n",
      "\n",
      " * Prec@1 69.676 Prec@5 84.414\n",
      " * Prec@1 69.741 Prec@5 84.451\n",
      " * Prec@1 69.880 Prec@5 84.413\n",
      " * Prec@1 69.717 Prec@5 84.152\n",
      " * Prec@1 69.559 Prec@5 84.044\n",
      " * Prec@1 69.622 Prec@5 84.012\n",
      " * Prec@1 69.756 Prec@5 83.980\n",
      " * Prec@1 69.815 Prec@5 84.091\n",
      " * Prec@1 69.312 Prec@5 83.848\n",
      " * Prec@1 69.514 Prec@5 83.958\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.558 (0.526)\n",
      "\n",
      "Loss 1.0645 (1.7901)\n",
      "\n",
      "Prec@1 81.250 (69.643)\n",
      "\n",
      "Prec@5 93.750 (84.066)\n",
      "\n",
      " * Prec@1 69.643 Prec@5 84.066\n",
      " * Prec@1 69.769 Prec@5 84.035\n",
      " * Prec@1 69.825 Prec@5 83.938\n",
      " * Prec@1 69.747 Prec@5 83.843\n",
      " * Prec@1 69.737 Prec@5 83.750\n",
      " * Prec@1 69.792 Prec@5 83.919\n",
      " * Prec@1 69.974 Prec@5 84.021\n",
      " * Prec@1 69.962 Prec@5 83.992\n",
      " * Prec@1 69.823 Prec@5 84.028\n",
      " * Prec@1 70.000 Prec@5 84.188\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.528 (0.525)\n",
      "\n",
      "Loss 2.5841 (1.7753)\n",
      "\n",
      "Prec@1 62.500 (69.926)\n",
      "\n",
      "Prec@5 75.000 (84.097)\n",
      "\n",
      " * Prec@1 69.926 Prec@5 84.097\n",
      " * Prec@1 69.792 Prec@5 83.946\n",
      " * Prec@1 69.842 Prec@5 83.981\n",
      " * Prec@1 69.651 Prec@5 83.714\n",
      " * Prec@1 69.583 Prec@5 83.750\n",
      " * Prec@1 69.458 Prec@5 83.667\n",
      " * Prec@1 69.393 Prec@5 83.703\n",
      " * Prec@1 69.329 Prec@5 83.738\n",
      " * Prec@1 69.381 Prec@5 83.716\n",
      " * Prec@1 69.432 Prec@5 83.750\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.487 (0.525)\n",
      "\n",
      "Loss 2.2201 (1.8064)\n",
      "\n",
      "Prec@1 62.500 (69.369)\n",
      "\n",
      "Prec@5 81.250 (83.727)\n",
      "\n",
      " * Prec@1 69.369 Prec@5 83.727\n",
      " * Prec@1 69.475 Prec@5 83.817\n",
      " * Prec@1 69.524 Prec@5 83.850\n",
      " * Prec@1 69.463 Prec@5 83.772\n",
      " * Prec@1 69.620 Prec@5 83.859\n",
      " * Prec@1 69.612 Prec@5 83.944\n",
      " * Prec@1 69.498 Prec@5 83.814\n",
      " * Prec@1 69.544 Prec@5 83.898\n",
      " * Prec@1 69.590 Prec@5 83.824\n",
      " * Prec@1 69.635 Prec@5 83.958\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.561 (0.527)\n",
      "\n",
      "Loss 2.6562 (1.7985)\n",
      "\n",
      "Prec@1 56.250 (69.525)\n",
      "\n",
      "Prec@5 75.000 (83.884)\n",
      "\n",
      " * Prec@1 69.525 Prec@5 83.884\n",
      " * Prec@1 69.570 Prec@5 83.811\n",
      " * Prec@1 69.665 Prec@5 83.791\n",
      " * Prec@1 69.708 Prec@5 83.821\n",
      " * Prec@1 69.700 Prec@5 83.800\n",
      " * Prec@1 69.643 Prec@5 83.879\n",
      " * Prec@1 69.488 Prec@5 83.907\n",
      " * Prec@1 69.336 Prec@5 83.887\n",
      " * Prec@1 69.428 Prec@5 83.915\n",
      " * Prec@1 69.615 Prec@5 83.990\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.520 (0.527)\n",
      "\n",
      "Loss 3.2399 (1.8186)\n",
      "\n",
      "Prec@1 50.000 (69.466)\n",
      "\n",
      "Prec@5 62.500 (83.826)\n",
      "\n",
      " * Prec@1 69.466 Prec@5 83.826\n",
      " * Prec@1 69.508 Prec@5 83.902\n",
      " * Prec@1 69.502 Prec@5 83.929\n",
      " * Prec@1 69.590 Prec@5 83.955\n",
      " * Prec@1 69.676 Prec@5 84.074\n",
      " * Prec@1 69.531 Prec@5 83.869\n",
      " * Prec@1 69.571 Prec@5 83.896\n",
      " * Prec@1 69.701 Prec@5 83.967\n",
      " * Prec@1 69.559 Prec@5 83.813\n",
      " * Prec@1 69.444 Prec@5 83.781\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [15][0/558]\t\\Time 0.520 (0.520)\tData 0.410 (0.410)\tLoss 0.3749 (0.3749)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/558]\t\\Time 0.543 (0.516)\tData 0.432 (0.413)\tLoss 0.1972 (0.1988)\tPrec@1 100.000 (93.750)\tPrec@5 100.000 (99.443)\n",
      "Epoch: [15][200/558]\t\\Time 0.502 (0.518)\tData 0.395 (0.415)\tLoss 0.1586 (0.1773)\tPrec@1 93.750 (94.558)\tPrec@5 100.000 (99.658)\n",
      "Epoch: [15][300/558]\t\\Time 0.521 (0.518)\tData 0.412 (0.416)\tLoss 0.8848 (0.1723)\tPrec@1 75.000 (94.560)\tPrec@5 100.000 (99.751)\n",
      "Epoch: [15][400/558]\t\\Time 0.517 (0.518)\tData 0.407 (0.416)\tLoss 0.1882 (0.1751)\tPrec@1 93.750 (94.623)\tPrec@5 100.000 (99.766)\n",
      "Epoch: [15][500/558]\t\\Time 0.558 (0.519)\tData 0.420 (0.417)\tLoss 0.2549 (0.1715)\tPrec@1 87.500 (94.698)\tPrec@5 100.000 (99.775)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.480 (0.480)\n",
      "\n",
      "Loss 2.3739 (2.3739)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 81.250\n",
      " * Prec@1 65.625 Prec@5 81.250\n",
      " * Prec@1 75.000 Prec@5 85.417\n",
      " * Prec@1 78.125 Prec@5 85.938\n",
      " * Prec@1 77.500 Prec@5 85.000\n",
      " * Prec@1 79.167 Prec@5 86.458\n",
      " * Prec@1 77.679 Prec@5 88.393\n",
      " * Prec@1 73.438 Prec@5 89.062\n",
      " * Prec@1 75.000 Prec@5 90.278\n",
      " * Prec@1 74.375 Prec@5 89.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.523 (0.528)\n",
      "\n",
      "Loss 1.9469 (1.4725)\n",
      "\n",
      "Prec@1 68.750 (73.864)\n",
      "\n",
      "Prec@5 75.000 (88.068)\n",
      "\n",
      " * Prec@1 73.864 Prec@5 88.068\n",
      " * Prec@1 73.958 Prec@5 86.979\n",
      " * Prec@1 74.038 Prec@5 87.981\n",
      " * Prec@1 75.000 Prec@5 87.946\n",
      " * Prec@1 74.583 Prec@5 88.333\n",
      " * Prec@1 75.391 Prec@5 88.672\n",
      " * Prec@1 75.368 Prec@5 88.971\n",
      " * Prec@1 75.000 Prec@5 88.542\n",
      " * Prec@1 75.987 Prec@5 88.816\n",
      " * Prec@1 75.312 Prec@5 89.062\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.511 (0.516)\n",
      "\n",
      "Loss 2.6360 (1.4931)\n",
      "\n",
      "Prec@1 62.500 (74.702)\n",
      "\n",
      "Prec@5 81.250 (88.690)\n",
      "\n",
      " * Prec@1 74.702 Prec@5 88.690\n",
      " * Prec@1 74.716 Prec@5 88.636\n",
      " * Prec@1 74.728 Prec@5 88.859\n",
      " * Prec@1 73.698 Prec@5 88.542\n",
      " * Prec@1 73.750 Prec@5 88.250\n",
      " * Prec@1 73.558 Prec@5 87.981\n",
      " * Prec@1 73.148 Prec@5 87.037\n",
      " * Prec@1 73.214 Prec@5 86.607\n",
      " * Prec@1 72.629 Prec@5 86.207\n",
      " * Prec@1 72.083 Prec@5 85.625\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.485 (0.515)\n",
      "\n",
      "Loss 0.3717 (1.7624)\n",
      "\n",
      "Prec@1 87.500 (72.581)\n",
      "\n",
      "Prec@5 93.750 (85.887)\n",
      "\n",
      " * Prec@1 72.581 Prec@5 85.887\n",
      " * Prec@1 73.047 Prec@5 86.328\n",
      " * Prec@1 72.917 Prec@5 86.364\n",
      " * Prec@1 73.346 Prec@5 86.581\n",
      " * Prec@1 73.571 Prec@5 86.607\n",
      " * Prec@1 73.785 Prec@5 86.806\n",
      " * Prec@1 73.480 Prec@5 86.486\n",
      " * Prec@1 73.520 Prec@5 86.349\n",
      " * Prec@1 73.558 Prec@5 86.378\n",
      " * Prec@1 73.594 Prec@5 86.250\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.442 (0.514)\n",
      "\n",
      "Loss 0.9797 (1.7010)\n",
      "\n",
      "Prec@1 81.250 (73.780)\n",
      "\n",
      "Prec@5 93.750 (86.433)\n",
      "\n",
      " * Prec@1 73.780 Prec@5 86.433\n",
      " * Prec@1 73.810 Prec@5 86.458\n",
      " * Prec@1 73.110 Prec@5 85.901\n",
      " * Prec@1 72.727 Prec@5 85.795\n",
      " * Prec@1 72.222 Prec@5 85.417\n",
      " * Prec@1 71.875 Prec@5 85.190\n",
      " * Prec@1 72.074 Prec@5 85.239\n",
      " * Prec@1 72.396 Prec@5 85.417\n",
      " * Prec@1 72.321 Prec@5 85.332\n",
      " * Prec@1 72.625 Prec@5 85.500\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.495 (0.512)\n",
      "\n",
      "Loss 1.2606 (1.7924)\n",
      "\n",
      "Prec@1 75.000 (72.672)\n",
      "\n",
      "Prec@5 87.500 (85.539)\n",
      "\n",
      " * Prec@1 72.672 Prec@5 85.539\n",
      " * Prec@1 72.837 Prec@5 85.577\n",
      " * Prec@1 72.524 Prec@5 85.613\n",
      " * Prec@1 72.569 Prec@5 85.880\n",
      " * Prec@1 72.500 Prec@5 85.682\n",
      " * Prec@1 72.433 Prec@5 85.603\n",
      " * Prec@1 72.368 Prec@5 85.636\n",
      " * Prec@1 72.522 Prec@5 85.668\n",
      " * Prec@1 72.352 Prec@5 85.487\n",
      " * Prec@1 72.500 Prec@5 85.417\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.496 (0.512)\n",
      "\n",
      "Loss 1.2941 (1.7959)\n",
      "\n",
      "Prec@1 75.000 (72.541)\n",
      "\n",
      "Prec@5 87.500 (85.451)\n",
      "\n",
      " * Prec@1 72.541 Prec@5 85.451\n",
      " * Prec@1 72.883 Prec@5 85.685\n",
      " * Prec@1 72.817 Prec@5 85.714\n",
      " * Prec@1 72.949 Prec@5 85.938\n",
      " * Prec@1 72.885 Prec@5 85.962\n",
      " * Prec@1 72.538 Prec@5 85.701\n",
      " * Prec@1 72.575 Prec@5 85.821\n",
      " * Prec@1 72.335 Prec@5 85.754\n",
      " * Prec@1 72.101 Prec@5 85.688\n",
      " * Prec@1 71.696 Prec@5 85.446\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.553 (0.511)\n",
      "\n",
      "Loss 2.3008 (1.8399)\n",
      "\n",
      "Prec@1 56.250 (71.479)\n",
      "\n",
      "Prec@5 75.000 (85.299)\n",
      "\n",
      " * Prec@1 71.479 Prec@5 85.299\n",
      " * Prec@1 71.528 Prec@5 85.330\n",
      " * Prec@1 71.490 Prec@5 85.188\n",
      " * Prec@1 71.453 Prec@5 85.304\n",
      " * Prec@1 71.500 Prec@5 85.167\n",
      " * Prec@1 71.135 Prec@5 84.951\n",
      " * Prec@1 71.266 Prec@5 85.065\n",
      " * Prec@1 71.474 Prec@5 85.176\n",
      " * Prec@1 71.598 Prec@5 85.206\n",
      " * Prec@1 71.641 Prec@5 85.312\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.530 (0.511)\n",
      "\n",
      "Loss 4.1897 (1.8466)\n",
      "\n",
      "Prec@1 50.000 (71.373)\n",
      "\n",
      "Prec@5 68.750 (85.108)\n",
      "\n",
      " * Prec@1 71.373 Prec@5 85.108\n",
      " * Prec@1 71.341 Prec@5 85.213\n",
      " * Prec@1 71.386 Prec@5 85.166\n",
      " * Prec@1 71.205 Prec@5 85.045\n",
      " * Prec@1 71.103 Prec@5 84.926\n",
      " * Prec@1 71.221 Prec@5 85.029\n",
      " * Prec@1 71.264 Prec@5 85.057\n",
      " * Prec@1 71.307 Prec@5 85.085\n",
      " * Prec@1 70.997 Prec@5 84.691\n",
      " * Prec@1 70.972 Prec@5 84.792\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.510 (0.508)\n",
      "\n",
      "Loss 0.7074 (1.8841)\n",
      "\n",
      "Prec@1 81.250 (71.085)\n",
      "\n",
      "Prec@5 93.750 (84.890)\n",
      "\n",
      " * Prec@1 71.085 Prec@5 84.890\n",
      " * Prec@1 71.196 Prec@5 84.851\n",
      " * Prec@1 71.304 Prec@5 84.812\n",
      " * Prec@1 71.144 Prec@5 84.774\n",
      " * Prec@1 70.987 Prec@5 84.803\n",
      " * Prec@1 71.159 Prec@5 84.961\n",
      " * Prec@1 71.392 Prec@5 85.052\n",
      " * Prec@1 71.365 Prec@5 85.013\n",
      " * Prec@1 71.402 Prec@5 85.101\n",
      " * Prec@1 71.500 Prec@5 85.250\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.519 (0.510)\n",
      "\n",
      "Loss 3.2851 (1.8649)\n",
      "\n",
      "Prec@1 62.500 (71.411)\n",
      "\n",
      "Prec@5 68.750 (85.087)\n",
      "\n",
      " * Prec@1 71.411 Prec@5 85.087\n",
      " * Prec@1 71.385 Prec@5 85.049\n",
      " * Prec@1 71.420 Prec@5 85.012\n",
      " * Prec@1 71.214 Prec@5 84.736\n",
      " * Prec@1 71.369 Prec@5 84.821\n",
      " * Prec@1 71.226 Prec@5 84.729\n",
      " * Prec@1 71.320 Prec@5 84.813\n",
      " * Prec@1 71.354 Prec@5 84.838\n",
      " * Prec@1 71.330 Prec@5 84.805\n",
      " * Prec@1 71.193 Prec@5 84.886\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.470 (0.509)\n",
      "\n",
      "Loss 2.3708 (1.8806)\n",
      "\n",
      "Prec@1 56.250 (71.059)\n",
      "\n",
      "Prec@5 87.500 (84.910)\n",
      "\n",
      " * Prec@1 71.059 Prec@5 84.910\n",
      " * Prec@1 71.205 Prec@5 84.933\n",
      " * Prec@1 71.405 Prec@5 85.011\n",
      " * Prec@1 71.327 Prec@5 84.923\n",
      " * Prec@1 71.413 Prec@5 84.946\n",
      " * Prec@1 71.552 Prec@5 85.022\n",
      " * Prec@1 71.421 Prec@5 84.989\n",
      " * Prec@1 71.451 Prec@5 85.064\n",
      " * Prec@1 71.429 Prec@5 84.926\n",
      " * Prec@1 71.562 Prec@5 85.000\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.515 (0.509)\n",
      "\n",
      "Loss 2.1566 (1.8687)\n",
      "\n",
      "Prec@1 50.000 (71.384)\n",
      "\n",
      "Prec@5 75.000 (84.917)\n",
      "\n",
      " * Prec@1 71.384 Prec@5 84.917\n",
      " * Prec@1 71.260 Prec@5 84.887\n",
      " * Prec@1 71.341 Prec@5 84.858\n",
      " * Prec@1 71.371 Prec@5 84.879\n",
      " * Prec@1 71.300 Prec@5 84.800\n",
      " * Prec@1 71.379 Prec@5 84.821\n",
      " * Prec@1 71.309 Prec@5 84.793\n",
      " * Prec@1 71.289 Prec@5 84.717\n",
      " * Prec@1 71.269 Prec@5 84.690\n",
      " * Prec@1 71.346 Prec@5 84.712\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.549 (0.509)\n",
      "\n",
      "Loss 2.9636 (1.8664)\n",
      "\n",
      "Prec@1 56.250 (71.231)\n",
      "\n",
      "Prec@5 75.000 (84.637)\n",
      "\n",
      " * Prec@1 71.231 Prec@5 84.637\n",
      " * Prec@1 71.259 Prec@5 84.754\n",
      " * Prec@1 71.288 Prec@5 84.727\n",
      " * Prec@1 71.409 Prec@5 84.748\n",
      " * Prec@1 71.481 Prec@5 84.815\n",
      " * Prec@1 71.369 Prec@5 84.651\n",
      " * Prec@1 71.350 Prec@5 84.717\n",
      " * Prec@1 71.377 Prec@5 84.783\n",
      " * Prec@1 71.268 Prec@5 84.712\n",
      " * Prec@1 71.192 Prec@5 84.722\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [16][0/558]\t\\Time 0.544 (0.544)\tData 0.423 (0.423)\tLoss 0.0803 (0.0803)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/558]\t\\Time 0.562 (0.519)\tData 0.455 (0.415)\tLoss 0.1308 (0.1369)\tPrec@1 93.750 (95.978)\tPrec@5 100.000 (99.814)\n",
      "Epoch: [16][200/558]\t\\Time 0.554 (0.525)\tData 0.451 (0.421)\tLoss 0.2260 (0.1243)\tPrec@1 87.500 (96.269)\tPrec@5 100.000 (99.876)\n",
      "Epoch: [16][300/558]\t\\Time 0.492 (0.524)\tData 0.392 (0.421)\tLoss 0.0318 (0.1077)\tPrec@1 100.000 (96.823)\tPrec@5 100.000 (99.896)\n",
      "Epoch: [16][400/558]\t\\Time 0.513 (0.526)\tData 0.405 (0.423)\tLoss 0.0657 (0.1156)\tPrec@1 100.000 (96.540)\tPrec@5 100.000 (99.891)\n",
      "Epoch: [16][500/558]\t\\Time 0.492 (0.532)\tData 0.422 (0.429)\tLoss 0.0177 (0.1161)\tPrec@1 100.000 (96.544)\tPrec@5 100.000 (99.900)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.576 (0.576)\n",
      "\n",
      "Loss 2.2702 (2.2702)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 81.250\n",
      " * Prec@1 65.625 Prec@5 84.375\n",
      " * Prec@1 72.917 Prec@5 89.583\n",
      " * Prec@1 76.562 Prec@5 89.062\n",
      " * Prec@1 76.250 Prec@5 87.500\n",
      " * Prec@1 79.167 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 90.179\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 79.861 Prec@5 90.278\n",
      " * Prec@1 80.000 Prec@5 89.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.528 (0.555)\n",
      "\n",
      "Loss 2.2180 (1.3747)\n",
      "\n",
      "Prec@1 75.000 (79.545)\n",
      "\n",
      "Prec@5 81.250 (88.636)\n",
      "\n",
      " * Prec@1 79.545 Prec@5 88.636\n",
      " * Prec@1 79.688 Prec@5 88.021\n",
      " * Prec@1 80.288 Prec@5 88.462\n",
      " * Prec@1 80.357 Prec@5 88.393\n",
      " * Prec@1 79.583 Prec@5 88.333\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 78.309 Prec@5 88.971\n",
      " * Prec@1 78.472 Prec@5 88.542\n",
      " * Prec@1 78.947 Prec@5 88.816\n",
      " * Prec@1 78.750 Prec@5 88.438\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.550 (0.539)\n",
      "\n",
      "Loss 2.8762 (1.5030)\n",
      "\n",
      "Prec@1 68.750 (78.274)\n",
      "\n",
      "Prec@5 75.000 (87.798)\n",
      "\n",
      " * Prec@1 78.274 Prec@5 87.798\n",
      " * Prec@1 78.125 Prec@5 87.216\n",
      " * Prec@1 78.261 Prec@5 87.500\n",
      " * Prec@1 77.604 Prec@5 86.458\n",
      " * Prec@1 77.750 Prec@5 86.250\n",
      " * Prec@1 77.644 Prec@5 86.298\n",
      " * Prec@1 77.546 Prec@5 85.880\n",
      " * Prec@1 77.679 Prec@5 85.938\n",
      " * Prec@1 76.940 Prec@5 85.345\n",
      " * Prec@1 76.458 Prec@5 85.417\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.522 (0.538)\n",
      "\n",
      "Loss 1.0318 (1.6950)\n",
      "\n",
      "Prec@1 81.250 (76.613)\n",
      "\n",
      "Prec@5 93.750 (85.685)\n",
      "\n",
      " * Prec@1 76.613 Prec@5 85.685\n",
      " * Prec@1 77.148 Prec@5 85.938\n",
      " * Prec@1 77.273 Prec@5 85.795\n",
      " * Prec@1 77.390 Prec@5 85.846\n",
      " * Prec@1 77.321 Prec@5 86.071\n",
      " * Prec@1 77.257 Prec@5 86.285\n",
      " * Prec@1 77.027 Prec@5 86.149\n",
      " * Prec@1 76.974 Prec@5 85.855\n",
      " * Prec@1 76.763 Prec@5 85.897\n",
      " * Prec@1 76.562 Prec@5 85.781\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.446 (0.544)\n",
      "\n",
      "Loss 0.6768 (1.6171)\n",
      "\n",
      "Prec@1 87.500 (76.829)\n",
      "\n",
      "Prec@5 100.000 (86.128)\n",
      "\n",
      " * Prec@1 76.829 Prec@5 86.128\n",
      " * Prec@1 76.786 Prec@5 86.012\n",
      " * Prec@1 76.308 Prec@5 85.465\n",
      " * Prec@1 75.994 Prec@5 85.227\n",
      " * Prec@1 75.556 Prec@5 84.861\n",
      " * Prec@1 75.543 Prec@5 84.783\n",
      " * Prec@1 75.399 Prec@5 84.840\n",
      " * Prec@1 75.521 Prec@5 85.156\n",
      " * Prec@1 75.638 Prec@5 85.204\n",
      " * Prec@1 75.875 Prec@5 85.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.541 (0.542)\n",
      "\n",
      "Loss 1.7909 (1.7078)\n",
      "\n",
      "Prec@1 68.750 (75.735)\n",
      "\n",
      "Prec@5 81.250 (85.294)\n",
      "\n",
      " * Prec@1 75.735 Prec@5 85.294\n",
      " * Prec@1 75.962 Prec@5 85.457\n",
      " * Prec@1 75.590 Prec@5 85.377\n",
      " * Prec@1 75.579 Prec@5 85.532\n",
      " * Prec@1 75.341 Prec@5 85.227\n",
      " * Prec@1 75.446 Prec@5 85.156\n",
      " * Prec@1 75.439 Prec@5 85.197\n",
      " * Prec@1 75.539 Prec@5 85.237\n",
      " * Prec@1 75.318 Prec@5 85.064\n",
      " * Prec@1 75.417 Prec@5 85.000\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.503 (0.539)\n",
      "\n",
      "Loss 0.9893 (1.6989)\n",
      "\n",
      "Prec@1 75.000 (75.410)\n",
      "\n",
      "Prec@5 93.750 (85.143)\n",
      "\n",
      " * Prec@1 75.410 Prec@5 85.143\n",
      " * Prec@1 75.504 Prec@5 85.282\n",
      " * Prec@1 75.595 Prec@5 85.417\n",
      " * Prec@1 75.781 Prec@5 85.547\n",
      " * Prec@1 75.769 Prec@5 85.577\n",
      " * Prec@1 75.379 Prec@5 85.322\n",
      " * Prec@1 75.373 Prec@5 85.261\n",
      " * Prec@1 75.092 Prec@5 85.202\n",
      " * Prec@1 74.909 Prec@5 85.145\n",
      " * Prec@1 74.821 Prec@5 84.911\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.590 (0.537)\n",
      "\n",
      "Loss 2.3921 (1.6957)\n",
      "\n",
      "Prec@1 62.500 (74.648)\n",
      "\n",
      "Prec@5 75.000 (84.771)\n",
      "\n",
      " * Prec@1 74.648 Prec@5 84.771\n",
      " * Prec@1 74.566 Prec@5 84.635\n",
      " * Prec@1 74.486 Prec@5 84.589\n",
      " * Prec@1 74.578 Prec@5 84.713\n",
      " * Prec@1 74.583 Prec@5 84.583\n",
      " * Prec@1 74.178 Prec@5 84.457\n",
      " * Prec@1 74.351 Prec@5 84.578\n",
      " * Prec@1 74.519 Prec@5 84.696\n",
      " * Prec@1 74.604 Prec@5 84.652\n",
      " * Prec@1 74.609 Prec@5 84.766\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.571 (0.538)\n",
      "\n",
      "Loss 4.2861 (1.7429)\n",
      "\n",
      "Prec@1 50.000 (74.306)\n",
      "\n",
      "Prec@5 62.500 (84.491)\n",
      "\n",
      " * Prec@1 74.306 Prec@5 84.491\n",
      " * Prec@1 74.314 Prec@5 84.527\n",
      " * Prec@1 74.322 Prec@5 84.488\n",
      " * Prec@1 74.107 Prec@5 84.226\n",
      " * Prec@1 73.750 Prec@5 84.118\n",
      " * Prec@1 73.837 Prec@5 84.230\n",
      " * Prec@1 73.922 Prec@5 84.267\n",
      " * Prec@1 73.935 Prec@5 84.233\n",
      " * Prec@1 73.525 Prec@5 83.778\n",
      " * Prec@1 73.611 Prec@5 83.819\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.552 (0.537)\n",
      "\n",
      "Loss 1.4334 (1.7969)\n",
      "\n",
      "Prec@1 81.250 (73.695)\n",
      "\n",
      "Prec@5 87.500 (83.860)\n",
      "\n",
      " * Prec@1 73.695 Prec@5 83.860\n",
      " * Prec@1 73.709 Prec@5 83.764\n",
      " * Prec@1 73.790 Prec@5 83.737\n",
      " * Prec@1 73.604 Prec@5 83.644\n",
      " * Prec@1 73.553 Prec@5 83.618\n",
      " * Prec@1 73.763 Prec@5 83.724\n",
      " * Prec@1 73.905 Prec@5 83.763\n",
      " * Prec@1 74.043 Prec@5 83.801\n",
      " * Prec@1 74.116 Prec@5 83.775\n",
      " * Prec@1 74.250 Prec@5 83.938\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.546 (0.537)\n",
      "\n",
      "Loss 2.8933 (1.7920)\n",
      "\n",
      "Prec@1 75.000 (74.257)\n",
      "\n",
      "Prec@5 75.000 (83.849)\n",
      "\n",
      " * Prec@1 74.257 Prec@5 83.849\n",
      " * Prec@1 74.142 Prec@5 83.762\n",
      " * Prec@1 74.211 Prec@5 83.799\n",
      " * Prec@1 73.978 Prec@5 83.654\n",
      " * Prec@1 74.107 Prec@5 83.750\n",
      " * Prec@1 73.998 Prec@5 83.667\n",
      " * Prec@1 74.007 Prec@5 83.762\n",
      " * Prec@1 73.958 Prec@5 83.796\n",
      " * Prec@1 73.911 Prec@5 83.830\n",
      " * Prec@1 73.807 Prec@5 83.807\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.483 (0.535)\n",
      "\n",
      "Loss 1.7488 (1.8002)\n",
      "\n",
      "Prec@1 75.000 (73.818)\n",
      "\n",
      "Prec@5 81.250 (83.784)\n",
      "\n",
      " * Prec@1 73.818 Prec@5 83.784\n",
      " * Prec@1 73.828 Prec@5 83.873\n",
      " * Prec@1 73.949 Prec@5 83.905\n",
      " * Prec@1 73.904 Prec@5 83.882\n",
      " * Prec@1 73.967 Prec@5 83.967\n",
      " * Prec@1 74.084 Prec@5 84.052\n",
      " * Prec@1 74.038 Prec@5 84.028\n",
      " * Prec@1 74.153 Prec@5 84.057\n",
      " * Prec@1 74.160 Prec@5 84.086\n",
      " * Prec@1 74.219 Prec@5 84.167\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.545 (0.534)\n",
      "\n",
      "Loss 2.4280 (1.7812)\n",
      "\n",
      "Prec@1 62.500 (74.122)\n",
      "\n",
      "Prec@5 68.750 (84.039)\n",
      "\n",
      " * Prec@1 74.122 Prec@5 84.039\n",
      " * Prec@1 74.027 Prec@5 83.914\n",
      " * Prec@1 74.085 Prec@5 83.892\n",
      " * Prec@1 74.143 Prec@5 83.921\n",
      " * Prec@1 74.100 Prec@5 83.800\n",
      " * Prec@1 74.058 Prec@5 83.929\n",
      " * Prec@1 73.967 Prec@5 83.907\n",
      " * Prec@1 73.975 Prec@5 83.887\n",
      " * Prec@1 73.983 Prec@5 83.915\n",
      " * Prec@1 74.135 Prec@5 83.990\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.539 (0.534)\n",
      "\n",
      "Loss 1.9737 (1.7892)\n",
      "\n",
      "Prec@1 75.000 (74.141)\n",
      "\n",
      "Prec@5 81.250 (83.969)\n",
      "\n",
      " * Prec@1 74.141 Prec@5 83.969\n",
      " * Prec@1 74.242 Prec@5 84.091\n",
      " * Prec@1 74.248 Prec@5 84.070\n",
      " * Prec@1 74.347 Prec@5 84.095\n",
      " * Prec@1 74.398 Prec@5 84.120\n",
      " * Prec@1 74.265 Prec@5 83.961\n",
      " * Prec@1 74.270 Prec@5 84.033\n",
      " * Prec@1 74.321 Prec@5 84.103\n",
      " * Prec@1 74.281 Prec@5 84.038\n",
      " * Prec@1 74.238 Prec@5 84.005\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [17][0/558]\t\\Time 0.541 (0.541)\tData 0.381 (0.381)\tLoss 0.0433 (0.0433)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/558]\t\\Time 0.503 (0.516)\tData 0.403 (0.416)\tLoss 0.0059 (0.0749)\tPrec@1 100.000 (98.267)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [17][200/558]\t\\Time 0.577 (0.520)\tData 0.466 (0.419)\tLoss 0.0234 (0.0604)\tPrec@1 100.000 (98.725)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [17][300/558]\t\\Time 0.510 (0.520)\tData 0.410 (0.419)\tLoss 0.1559 (0.0537)\tPrec@1 93.750 (98.879)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [17][400/558]\t\\Time 0.579 (0.521)\tData 0.470 (0.421)\tLoss 0.0066 (0.0485)\tPrec@1 100.000 (98.956)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [17][500/558]\t\\Time 0.494 (0.525)\tData 0.404 (0.424)\tLoss 0.0138 (0.0483)\tPrec@1 100.000 (98.927)\tPrec@5 100.000 (99.988)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.544 (0.544)\n",
      "\n",
      "Loss 2.1311 (2.1311)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 90.625\n",
      " * Prec@1 75.000 Prec@5 91.667\n",
      " * Prec@1 78.125 Prec@5 90.625\n",
      " * Prec@1 80.000 Prec@5 90.000\n",
      " * Prec@1 81.250 Prec@5 91.667\n",
      " * Prec@1 82.143 Prec@5 91.964\n",
      " * Prec@1 80.469 Prec@5 91.406\n",
      " * Prec@1 81.944 Prec@5 92.361\n",
      " * Prec@1 81.875 Prec@5 91.875\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.544 (0.555)\n",
      "\n",
      "Loss 1.5945 (1.1706)\n",
      "\n",
      "Prec@1 75.000 (81.250)\n",
      "\n",
      "Prec@5 93.750 (92.045)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 92.045\n",
      " * Prec@1 81.250 Prec@5 91.667\n",
      " * Prec@1 81.250 Prec@5 92.308\n",
      " * Prec@1 81.696 Prec@5 92.411\n",
      " * Prec@1 81.667 Prec@5 92.083\n",
      " * Prec@1 81.641 Prec@5 92.578\n",
      " * Prec@1 81.250 Prec@5 92.279\n",
      " * Prec@1 81.250 Prec@5 91.667\n",
      " * Prec@1 81.908 Prec@5 91.776\n",
      " * Prec@1 80.938 Prec@5 91.250\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.551 (0.541)\n",
      "\n",
      "Loss 2.7897 (1.3214)\n",
      "\n",
      "Prec@1 62.500 (80.060)\n",
      "\n",
      "Prec@5 81.250 (90.774)\n",
      "\n",
      " * Prec@1 80.060 Prec@5 90.774\n",
      " * Prec@1 79.830 Prec@5 90.625\n",
      " * Prec@1 79.620 Prec@5 91.033\n",
      " * Prec@1 78.646 Prec@5 90.625\n",
      " * Prec@1 78.750 Prec@5 90.250\n",
      " * Prec@1 78.606 Prec@5 89.904\n",
      " * Prec@1 78.009 Prec@5 89.120\n",
      " * Prec@1 78.125 Prec@5 89.062\n",
      " * Prec@1 77.371 Prec@5 88.578\n",
      " * Prec@1 77.083 Prec@5 88.125\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.555 (0.539)\n",
      "\n",
      "Loss 0.6427 (1.5525)\n",
      "\n",
      "Prec@1 81.250 (77.218)\n",
      "\n",
      "Prec@5 93.750 (88.306)\n",
      "\n",
      " * Prec@1 77.218 Prec@5 88.306\n",
      " * Prec@1 77.344 Prec@5 88.477\n",
      " * Prec@1 77.462 Prec@5 88.258\n",
      " * Prec@1 77.757 Prec@5 88.419\n",
      " * Prec@1 78.036 Prec@5 88.393\n",
      " * Prec@1 78.125 Prec@5 88.368\n",
      " * Prec@1 77.703 Prec@5 88.176\n",
      " * Prec@1 77.632 Prec@5 87.829\n",
      " * Prec@1 77.564 Prec@5 87.821\n",
      " * Prec@1 77.344 Prec@5 87.812\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.431 (0.537)\n",
      "\n",
      "Loss 0.9498 (1.5174)\n",
      "\n",
      "Prec@1 81.250 (77.439)\n",
      "\n",
      "Prec@5 93.750 (87.957)\n",
      "\n",
      " * Prec@1 77.439 Prec@5 87.957\n",
      " * Prec@1 77.381 Prec@5 87.798\n",
      " * Prec@1 76.744 Prec@5 87.209\n",
      " * Prec@1 76.278 Prec@5 87.216\n",
      " * Prec@1 75.972 Prec@5 86.806\n",
      " * Prec@1 75.815 Prec@5 86.685\n",
      " * Prec@1 75.931 Prec@5 86.835\n",
      " * Prec@1 75.781 Prec@5 87.109\n",
      " * Prec@1 75.765 Prec@5 87.117\n",
      " * Prec@1 76.000 Prec@5 87.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.531 (0.533)\n",
      "\n",
      "Loss 1.6039 (1.5973)\n",
      "\n",
      "Prec@1 68.750 (75.858)\n",
      "\n",
      "Prec@5 81.250 (87.132)\n",
      "\n",
      " * Prec@1 75.858 Prec@5 87.132\n",
      " * Prec@1 75.962 Prec@5 87.139\n",
      " * Prec@1 75.943 Prec@5 87.028\n",
      " * Prec@1 75.926 Prec@5 87.153\n",
      " * Prec@1 75.795 Prec@5 87.159\n",
      " * Prec@1 75.781 Prec@5 87.054\n",
      " * Prec@1 75.768 Prec@5 86.952\n",
      " * Prec@1 75.970 Prec@5 86.961\n",
      " * Prec@1 75.742 Prec@5 86.864\n",
      " * Prec@1 75.833 Prec@5 86.771\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.497 (0.531)\n",
      "\n",
      "Loss 0.5439 (1.5872)\n",
      "\n",
      "Prec@1 75.000 (75.820)\n",
      "\n",
      "Prec@5 100.000 (86.988)\n",
      "\n",
      " * Prec@1 75.820 Prec@5 86.988\n",
      " * Prec@1 75.907 Prec@5 87.198\n",
      " * Prec@1 76.091 Prec@5 87.302\n",
      " * Prec@1 76.367 Prec@5 87.500\n",
      " * Prec@1 76.442 Prec@5 87.596\n",
      " * Prec@1 76.042 Prec@5 87.500\n",
      " * Prec@1 76.119 Prec@5 87.593\n",
      " * Prec@1 76.011 Prec@5 87.500\n",
      " * Prec@1 75.815 Prec@5 87.409\n",
      " * Prec@1 75.625 Prec@5 87.232\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.542 (0.531)\n",
      "\n",
      "Loss 1.7969 (1.5863)\n",
      "\n",
      "Prec@1 62.500 (75.440)\n",
      "\n",
      "Prec@5 75.000 (87.060)\n",
      "\n",
      " * Prec@1 75.440 Prec@5 87.060\n",
      " * Prec@1 75.347 Prec@5 86.979\n",
      " * Prec@1 75.171 Prec@5 86.815\n",
      " * Prec@1 75.338 Prec@5 86.824\n",
      " * Prec@1 75.333 Prec@5 86.750\n",
      " * Prec@1 75.000 Prec@5 86.595\n",
      " * Prec@1 75.000 Prec@5 86.688\n",
      " * Prec@1 75.080 Prec@5 86.779\n",
      " * Prec@1 75.158 Prec@5 86.709\n",
      " * Prec@1 75.156 Prec@5 86.875\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.524 (0.530)\n",
      "\n",
      "Loss 3.4051 (1.6347)\n",
      "\n",
      "Prec@1 56.250 (74.923)\n",
      "\n",
      "Prec@5 68.750 (86.651)\n",
      "\n",
      " * Prec@1 74.923 Prec@5 86.651\n",
      " * Prec@1 74.924 Prec@5 86.662\n",
      " * Prec@1 75.000 Prec@5 86.596\n",
      " * Prec@1 74.777 Prec@5 86.310\n",
      " * Prec@1 74.559 Prec@5 86.176\n",
      " * Prec@1 74.637 Prec@5 86.265\n",
      " * Prec@1 74.713 Prec@5 86.207\n",
      " * Prec@1 74.645 Prec@5 86.151\n",
      " * Prec@1 74.228 Prec@5 85.885\n",
      " * Prec@1 74.306 Prec@5 85.972\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.537 (0.528)\n",
      "\n",
      "Loss 0.7173 (1.6677)\n",
      "\n",
      "Prec@1 81.250 (74.382)\n",
      "\n",
      "Prec@5 100.000 (86.126)\n",
      "\n",
      " * Prec@1 74.382 Prec@5 86.126\n",
      " * Prec@1 74.389 Prec@5 86.005\n",
      " * Prec@1 74.462 Prec@5 85.954\n",
      " * Prec@1 74.335 Prec@5 85.838\n",
      " * Prec@1 74.211 Prec@5 85.855\n",
      " * Prec@1 74.414 Prec@5 86.003\n",
      " * Prec@1 74.613 Prec@5 86.082\n",
      " * Prec@1 74.617 Prec@5 86.224\n",
      " * Prec@1 74.621 Prec@5 86.237\n",
      " * Prec@1 74.750 Prec@5 86.375\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.563 (0.530)\n",
      "\n",
      "Loss 2.8611 (1.6561)\n",
      "\n",
      "Prec@1 75.000 (74.752)\n",
      "\n",
      "Prec@5 81.250 (86.324)\n",
      "\n",
      " * Prec@1 74.752 Prec@5 86.324\n",
      " * Prec@1 74.694 Prec@5 86.213\n",
      " * Prec@1 74.757 Prec@5 86.226\n",
      " * Prec@1 74.519 Prec@5 86.058\n",
      " * Prec@1 74.643 Prec@5 86.131\n",
      " * Prec@1 74.528 Prec@5 86.085\n",
      " * Prec@1 74.533 Prec@5 86.098\n",
      " * Prec@1 74.595 Prec@5 86.111\n",
      " * Prec@1 74.656 Prec@5 86.124\n",
      " * Prec@1 74.602 Prec@5 86.136\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.478 (0.529)\n",
      "\n",
      "Loss 2.1519 (1.6744)\n",
      "\n",
      "Prec@1 62.500 (74.493)\n",
      "\n",
      "Prec@5 87.500 (86.149)\n",
      "\n",
      " * Prec@1 74.493 Prec@5 86.149\n",
      " * Prec@1 74.609 Prec@5 86.161\n",
      " * Prec@1 74.723 Prec@5 86.228\n",
      " * Prec@1 74.671 Prec@5 86.129\n",
      " * Prec@1 74.783 Prec@5 86.250\n",
      " * Prec@1 74.892 Prec@5 86.315\n",
      " * Prec@1 74.733 Prec@5 86.325\n",
      " * Prec@1 74.788 Prec@5 86.335\n",
      " * Prec@1 74.790 Prec@5 86.292\n",
      " * Prec@1 74.844 Prec@5 86.354\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.501 (0.528)\n",
      "\n",
      "Loss 1.8512 (1.6652)\n",
      "\n",
      "Prec@1 62.500 (74.742)\n",
      "\n",
      "Prec@5 75.000 (86.260)\n",
      "\n",
      " * Prec@1 74.742 Prec@5 86.260\n",
      " * Prec@1 74.693 Prec@5 86.219\n",
      " * Prec@1 74.746 Prec@5 86.179\n",
      " * Prec@1 74.748 Prec@5 86.190\n",
      " * Prec@1 74.750 Prec@5 86.100\n",
      " * Prec@1 74.802 Prec@5 86.161\n",
      " * Prec@1 74.754 Prec@5 86.073\n",
      " * Prec@1 74.707 Prec@5 86.035\n",
      " * Prec@1 74.758 Prec@5 86.047\n",
      " * Prec@1 74.856 Prec@5 86.058\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.538 (0.527)\n",
      "\n",
      "Loss 1.9451 (1.6715)\n",
      "\n",
      "Prec@1 81.250 (74.905)\n",
      "\n",
      "Prec@5 81.250 (86.021)\n",
      "\n",
      " * Prec@1 74.905 Prec@5 86.021\n",
      " * Prec@1 74.905 Prec@5 86.127\n",
      " * Prec@1 74.906 Prec@5 86.090\n",
      " * Prec@1 75.000 Prec@5 86.101\n",
      " * Prec@1 75.093 Prec@5 86.204\n",
      " * Prec@1 74.954 Prec@5 86.029\n",
      " * Prec@1 74.954 Prec@5 86.040\n",
      " * Prec@1 75.000 Prec@5 86.096\n",
      " * Prec@1 74.955 Prec@5 86.061\n",
      " * Prec@1 74.866 Prec@5 86.066\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [18][0/558]\t\\Time 0.552 (0.552)\tData 0.432 (0.432)\tLoss 0.0245 (0.0245)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/558]\t\\Time 0.491 (0.527)\tData 0.381 (0.424)\tLoss 0.0037 (0.0141)\tPrec@1 100.000 (99.876)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][200/558]\t\\Time 0.522 (0.526)\tData 0.412 (0.424)\tLoss 0.0055 (0.0184)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][300/558]\t\\Time 0.530 (0.524)\tData 0.421 (0.422)\tLoss 0.0081 (0.0214)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][400/558]\t\\Time 0.591 (0.526)\tData 0.481 (0.423)\tLoss 0.0036 (0.0196)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][500/558]\t\\Time 0.531 (0.531)\tData 0.428 (0.428)\tLoss 0.0377 (0.0215)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.522 (0.522)\n",
      "\n",
      "Loss 1.9866 (1.9866)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 81.250\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 91.667\n",
      " * Prec@1 78.125 Prec@5 90.625\n",
      " * Prec@1 77.500 Prec@5 90.000\n",
      " * Prec@1 79.167 Prec@5 91.667\n",
      " * Prec@1 80.357 Prec@5 91.964\n",
      " * Prec@1 77.344 Prec@5 91.406\n",
      " * Prec@1 78.472 Prec@5 92.361\n",
      " * Prec@1 78.125 Prec@5 91.875\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.540 (0.533)\n",
      "\n",
      "Loss 1.5081 (1.1829)\n",
      "\n",
      "Prec@1 75.000 (77.841)\n",
      "\n",
      "Prec@5 81.250 (90.909)\n",
      "\n",
      " * Prec@1 77.841 Prec@5 90.909\n",
      " * Prec@1 78.125 Prec@5 90.625\n",
      " * Prec@1 78.846 Prec@5 91.346\n",
      " * Prec@1 79.464 Prec@5 91.071\n",
      " * Prec@1 79.167 Prec@5 90.833\n",
      " * Prec@1 78.906 Prec@5 91.406\n",
      " * Prec@1 78.309 Prec@5 91.544\n",
      " * Prec@1 78.472 Prec@5 90.972\n",
      " * Prec@1 79.276 Prec@5 91.118\n",
      " * Prec@1 78.750 Prec@5 90.938\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.572 (0.533)\n",
      "\n",
      "Loss 2.4584 (1.3160)\n",
      "\n",
      "Prec@1 68.750 (78.274)\n",
      "\n",
      "Prec@5 81.250 (90.476)\n",
      "\n",
      " * Prec@1 78.274 Prec@5 90.476\n",
      " * Prec@1 78.125 Prec@5 90.341\n",
      " * Prec@1 78.261 Prec@5 90.217\n",
      " * Prec@1 77.344 Prec@5 89.844\n",
      " * Prec@1 77.500 Prec@5 89.500\n",
      " * Prec@1 77.404 Prec@5 89.183\n",
      " * Prec@1 76.852 Prec@5 88.657\n",
      " * Prec@1 77.009 Prec@5 88.616\n",
      " * Prec@1 76.509 Prec@5 88.147\n",
      " * Prec@1 76.458 Prec@5 87.917\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.525 (0.537)\n",
      "\n",
      "Loss 0.5895 (1.5221)\n",
      "\n",
      "Prec@1 81.250 (76.613)\n",
      "\n",
      "Prec@5 93.750 (88.105)\n",
      "\n",
      " * Prec@1 76.613 Prec@5 88.105\n",
      " * Prec@1 76.758 Prec@5 88.086\n",
      " * Prec@1 76.894 Prec@5 87.879\n",
      " * Prec@1 77.206 Prec@5 88.051\n",
      " * Prec@1 77.321 Prec@5 88.036\n",
      " * Prec@1 77.431 Prec@5 87.847\n",
      " * Prec@1 77.196 Prec@5 87.838\n",
      " * Prec@1 77.138 Prec@5 87.500\n",
      " * Prec@1 76.763 Prec@5 87.500\n",
      " * Prec@1 76.719 Prec@5 87.344\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.473 (0.535)\n",
      "\n",
      "Loss 0.7431 (1.4843)\n",
      "\n",
      "Prec@1 87.500 (76.982)\n",
      "\n",
      "Prec@5 100.000 (87.652)\n",
      "\n",
      " * Prec@1 76.982 Prec@5 87.652\n",
      " * Prec@1 76.786 Prec@5 87.649\n",
      " * Prec@1 76.163 Prec@5 87.355\n",
      " * Prec@1 75.568 Prec@5 87.358\n",
      " * Prec@1 75.278 Prec@5 86.944\n",
      " * Prec@1 75.136 Prec@5 86.685\n",
      " * Prec@1 75.266 Prec@5 86.835\n",
      " * Prec@1 75.260 Prec@5 87.109\n",
      " * Prec@1 75.255 Prec@5 87.117\n",
      " * Prec@1 75.500 Prec@5 87.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.533 (0.533)\n",
      "\n",
      "Loss 1.8705 (1.5634)\n",
      "\n",
      "Prec@1 75.000 (75.490)\n",
      "\n",
      "Prec@5 81.250 (87.132)\n",
      "\n",
      " * Prec@1 75.490 Prec@5 87.132\n",
      " * Prec@1 75.601 Prec@5 87.260\n",
      " * Prec@1 75.472 Prec@5 87.264\n",
      " * Prec@1 75.579 Prec@5 87.384\n",
      " * Prec@1 75.455 Prec@5 87.273\n",
      " * Prec@1 75.335 Prec@5 87.165\n",
      " * Prec@1 75.329 Prec@5 87.171\n",
      " * Prec@1 75.539 Prec@5 87.177\n",
      " * Prec@1 75.318 Prec@5 87.182\n",
      " * Prec@1 75.417 Prec@5 87.083\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.511 (0.533)\n",
      "\n",
      "Loss 0.6442 (1.5545)\n",
      "\n",
      "Prec@1 75.000 (75.410)\n",
      "\n",
      "Prec@5 100.000 (87.295)\n",
      "\n",
      " * Prec@1 75.410 Prec@5 87.295\n",
      " * Prec@1 75.504 Prec@5 87.399\n",
      " * Prec@1 75.595 Prec@5 87.500\n",
      " * Prec@1 75.879 Prec@5 87.695\n",
      " * Prec@1 76.058 Prec@5 87.692\n",
      " * Prec@1 75.663 Prec@5 87.500\n",
      " * Prec@1 75.746 Prec@5 87.500\n",
      " * Prec@1 75.551 Prec@5 87.408\n",
      " * Prec@1 75.362 Prec@5 87.228\n",
      " * Prec@1 75.179 Prec@5 86.964\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.561 (0.532)\n",
      "\n",
      "Loss 2.0540 (1.5636)\n",
      "\n",
      "Prec@1 62.500 (75.000)\n",
      "\n",
      "Prec@5 81.250 (86.884)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.884\n",
      " * Prec@1 74.913 Prec@5 86.806\n",
      " * Prec@1 74.743 Prec@5 86.729\n",
      " * Prec@1 74.831 Prec@5 86.824\n",
      " * Prec@1 74.833 Prec@5 86.750\n",
      " * Prec@1 74.507 Prec@5 86.678\n",
      " * Prec@1 74.675 Prec@5 86.769\n",
      " * Prec@1 74.840 Prec@5 86.859\n",
      " * Prec@1 74.921 Prec@5 86.788\n",
      " * Prec@1 74.922 Prec@5 86.875\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.557 (0.531)\n",
      "\n",
      "Loss 3.4696 (1.6063)\n",
      "\n",
      "Prec@1 50.000 (74.614)\n",
      "\n",
      "Prec@5 75.000 (86.728)\n",
      "\n",
      " * Prec@1 74.614 Prec@5 86.728\n",
      " * Prec@1 74.619 Prec@5 86.662\n",
      " * Prec@1 74.699 Prec@5 86.596\n",
      " * Prec@1 74.479 Prec@5 86.310\n",
      " * Prec@1 74.338 Prec@5 86.176\n",
      " * Prec@1 74.419 Prec@5 86.265\n",
      " * Prec@1 74.497 Prec@5 86.279\n",
      " * Prec@1 74.432 Prec@5 86.222\n",
      " * Prec@1 74.017 Prec@5 86.025\n",
      " * Prec@1 74.236 Prec@5 86.111\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.541 (0.530)\n",
      "\n",
      "Loss 0.7358 (1.6323)\n",
      "\n",
      "Prec@1 81.250 (74.313)\n",
      "\n",
      "Prec@5 100.000 (86.264)\n",
      "\n",
      " * Prec@1 74.313 Prec@5 86.264\n",
      " * Prec@1 74.321 Prec@5 86.209\n",
      " * Prec@1 74.395 Prec@5 86.223\n",
      " * Prec@1 74.202 Prec@5 86.104\n",
      " * Prec@1 74.013 Prec@5 86.053\n",
      " * Prec@1 74.219 Prec@5 86.198\n",
      " * Prec@1 74.420 Prec@5 86.276\n",
      " * Prec@1 74.426 Prec@5 86.288\n",
      " * Prec@1 74.432 Prec@5 86.301\n",
      " * Prec@1 74.562 Prec@5 86.438\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.521 (0.530)\n",
      "\n",
      "Loss 2.5165 (1.6262)\n",
      "\n",
      "Prec@1 75.000 (74.567)\n",
      "\n",
      "Prec@5 81.250 (86.386)\n",
      "\n",
      " * Prec@1 74.567 Prec@5 86.386\n",
      " * Prec@1 74.571 Prec@5 86.275\n",
      " * Prec@1 74.636 Prec@5 86.286\n",
      " * Prec@1 74.459 Prec@5 86.118\n",
      " * Prec@1 74.524 Prec@5 86.190\n",
      " * Prec@1 74.410 Prec@5 86.085\n",
      " * Prec@1 74.416 Prec@5 86.215\n",
      " * Prec@1 74.479 Prec@5 86.227\n",
      " * Prec@1 74.427 Prec@5 86.239\n",
      " * Prec@1 74.432 Prec@5 86.250\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.472 (0.530)\n",
      "\n",
      "Loss 1.9716 (1.6504)\n",
      "\n",
      "Prec@1 75.000 (74.437)\n",
      "\n",
      "Prec@5 81.250 (86.205)\n",
      "\n",
      " * Prec@1 74.437 Prec@5 86.205\n",
      " * Prec@1 74.498 Prec@5 86.217\n",
      " * Prec@1 74.613 Prec@5 86.283\n",
      " * Prec@1 74.561 Prec@5 86.294\n",
      " * Prec@1 74.674 Prec@5 86.359\n",
      " * Prec@1 74.784 Prec@5 86.422\n",
      " * Prec@1 74.626 Prec@5 86.432\n",
      " * Prec@1 74.735 Prec@5 86.494\n",
      " * Prec@1 74.632 Prec@5 86.502\n",
      " * Prec@1 74.740 Prec@5 86.562\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.542 (0.531)\n",
      "\n",
      "Loss 2.0401 (1.6382)\n",
      "\n",
      "Prec@1 68.750 (74.690)\n",
      "\n",
      "Prec@5 75.000 (86.467)\n",
      "\n",
      " * Prec@1 74.690 Prec@5 86.467\n",
      " * Prec@1 74.641 Prec@5 86.424\n",
      " * Prec@1 74.695 Prec@5 86.382\n",
      " * Prec@1 74.698 Prec@5 86.391\n",
      " * Prec@1 74.650 Prec@5 86.300\n",
      " * Prec@1 74.702 Prec@5 86.359\n",
      " * Prec@1 74.656 Prec@5 86.417\n",
      " * Prec@1 74.658 Prec@5 86.377\n",
      " * Prec@1 74.661 Prec@5 86.434\n",
      " * Prec@1 74.760 Prec@5 86.442\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.516 (0.529)\n",
      "\n",
      "Loss 2.1820 (1.6485)\n",
      "\n",
      "Prec@1 68.750 (74.714)\n",
      "\n",
      "Prec@5 81.250 (86.403)\n",
      "\n",
      " * Prec@1 74.714 Prec@5 86.403\n",
      " * Prec@1 74.811 Prec@5 86.506\n",
      " * Prec@1 74.812 Prec@5 86.419\n",
      " * Prec@1 74.907 Prec@5 86.427\n",
      " * Prec@1 75.000 Prec@5 86.481\n",
      " * Prec@1 74.862 Prec@5 86.305\n",
      " * Prec@1 74.909 Prec@5 86.314\n",
      " * Prec@1 75.000 Prec@5 86.368\n",
      " * Prec@1 74.955 Prec@5 86.331\n",
      " * Prec@1 74.910 Prec@5 86.335\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [19][0/558]\t\\Time 0.552 (0.552)\tData 0.435 (0.435)\tLoss 0.0111 (0.0111)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][100/558]\t\\Time 0.544 (0.536)\tData 0.435 (0.433)\tLoss 0.0011 (0.0112)\tPrec@1 100.000 (99.876)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][200/558]\t\\Time 0.432 (0.528)\tData 0.362 (0.427)\tLoss 0.0013 (0.0138)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][300/558]\t\\Time 0.500 (0.530)\tData 0.430 (0.428)\tLoss 0.0014 (0.0134)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][400/558]\t\\Time 0.544 (0.534)\tData 0.435 (0.431)\tLoss 0.0039 (0.0177)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [19][500/558]\t\\Time 0.530 (0.535)\tData 0.429 (0.433)\tLoss 0.0005 (0.0158)\tPrec@1 100.000 (99.726)\tPrec@5 100.000 (99.988)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.505 (0.505)\n",
      "\n",
      "Loss 1.8780 (1.8780)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 79.167 Prec@5 91.667\n",
      " * Prec@1 79.688 Prec@5 90.625\n",
      " * Prec@1 78.750 Prec@5 88.750\n",
      " * Prec@1 80.208 Prec@5 90.625\n",
      " * Prec@1 81.250 Prec@5 91.071\n",
      " * Prec@1 78.125 Prec@5 90.625\n",
      " * Prec@1 79.167 Prec@5 91.667\n",
      " * Prec@1 79.375 Prec@5 91.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.535 (0.531)\n",
      "\n",
      "Loss 1.4338 (1.1438)\n",
      "\n",
      "Prec@1 81.250 (79.545)\n",
      "\n",
      "Prec@5 93.750 (91.477)\n",
      "\n",
      " * Prec@1 79.545 Prec@5 91.477\n",
      " * Prec@1 79.688 Prec@5 91.146\n",
      " * Prec@1 80.769 Prec@5 91.827\n",
      " * Prec@1 81.250 Prec@5 91.518\n",
      " * Prec@1 81.250 Prec@5 91.250\n",
      " * Prec@1 80.859 Prec@5 91.406\n",
      " * Prec@1 80.147 Prec@5 91.544\n",
      " * Prec@1 80.208 Prec@5 90.972\n",
      " * Prec@1 80.921 Prec@5 91.118\n",
      " * Prec@1 80.312 Prec@5 90.625\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.540 (0.534)\n",
      "\n",
      "Loss 2.3356 (1.2985)\n",
      "\n",
      "Prec@1 62.500 (79.464)\n",
      "\n",
      "Prec@5 81.250 (90.179)\n",
      "\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 78.693 Prec@5 89.773\n",
      " * Prec@1 78.261 Prec@5 89.946\n",
      " * Prec@1 77.344 Prec@5 89.583\n",
      " * Prec@1 77.500 Prec@5 89.250\n",
      " * Prec@1 77.163 Prec@5 88.942\n",
      " * Prec@1 76.620 Prec@5 88.426\n",
      " * Prec@1 76.786 Prec@5 88.393\n",
      " * Prec@1 76.293 Prec@5 87.931\n",
      " * Prec@1 76.250 Prec@5 87.500\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.503 (0.532)\n",
      "\n",
      "Loss 0.6789 (1.5419)\n",
      "\n",
      "Prec@1 75.000 (76.210)\n",
      "\n",
      "Prec@5 93.750 (87.702)\n",
      "\n",
      " * Prec@1 76.210 Prec@5 87.702\n",
      " * Prec@1 76.562 Prec@5 87.891\n",
      " * Prec@1 76.515 Prec@5 87.689\n",
      " * Prec@1 76.838 Prec@5 87.868\n",
      " * Prec@1 76.964 Prec@5 87.857\n",
      " * Prec@1 77.083 Prec@5 88.021\n",
      " * Prec@1 77.027 Prec@5 88.007\n",
      " * Prec@1 76.974 Prec@5 87.664\n",
      " * Prec@1 76.763 Prec@5 87.500\n",
      " * Prec@1 76.562 Prec@5 87.500\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.453 (0.530)\n",
      "\n",
      "Loss 0.7373 (1.4952)\n",
      "\n",
      "Prec@1 87.500 (76.829)\n",
      "\n",
      "Prec@5 93.750 (87.652)\n",
      "\n",
      " * Prec@1 76.829 Prec@5 87.652\n",
      " * Prec@1 76.935 Prec@5 87.500\n",
      " * Prec@1 76.453 Prec@5 87.355\n",
      " * Prec@1 75.852 Prec@5 87.216\n",
      " * Prec@1 75.556 Prec@5 86.806\n",
      " * Prec@1 75.408 Prec@5 86.685\n",
      " * Prec@1 75.532 Prec@5 86.835\n",
      " * Prec@1 75.391 Prec@5 87.109\n",
      " * Prec@1 75.383 Prec@5 87.117\n",
      " * Prec@1 75.625 Prec@5 87.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.548 (0.533)\n",
      "\n",
      "Loss 1.9715 (1.5720)\n",
      "\n",
      "Prec@1 75.000 (75.613)\n",
      "\n",
      "Prec@5 81.250 (87.132)\n",
      "\n",
      " * Prec@1 75.613 Prec@5 87.132\n",
      " * Prec@1 75.841 Prec@5 87.260\n",
      " * Prec@1 75.708 Prec@5 87.264\n",
      " * Prec@1 75.694 Prec@5 87.384\n",
      " * Prec@1 75.568 Prec@5 87.273\n",
      " * Prec@1 75.558 Prec@5 87.165\n",
      " * Prec@1 75.548 Prec@5 87.171\n",
      " * Prec@1 75.754 Prec@5 87.177\n",
      " * Prec@1 75.530 Prec@5 87.182\n",
      " * Prec@1 75.625 Prec@5 87.083\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.503 (0.530)\n",
      "\n",
      "Loss 0.4838 (1.5511)\n",
      "\n",
      "Prec@1 81.250 (75.717)\n",
      "\n",
      "Prec@5 100.000 (87.295)\n",
      "\n",
      " * Prec@1 75.717 Prec@5 87.295\n",
      " * Prec@1 75.907 Prec@5 87.500\n",
      " * Prec@1 76.091 Prec@5 87.599\n",
      " * Prec@1 76.367 Prec@5 87.793\n",
      " * Prec@1 76.346 Prec@5 87.788\n",
      " * Prec@1 76.042 Prec@5 87.595\n",
      " * Prec@1 76.119 Prec@5 87.593\n",
      " * Prec@1 76.103 Prec@5 87.500\n",
      " * Prec@1 75.906 Prec@5 87.409\n",
      " * Prec@1 75.714 Prec@5 87.054\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.537 (0.528)\n",
      "\n",
      "Loss 1.8111 (1.5530)\n",
      "\n",
      "Prec@1 62.500 (75.528)\n",
      "\n",
      "Prec@5 87.500 (87.060)\n",
      "\n",
      " * Prec@1 75.528 Prec@5 87.060\n",
      " * Prec@1 75.434 Prec@5 86.979\n",
      " * Prec@1 75.171 Prec@5 86.986\n",
      " * Prec@1 75.253 Prec@5 86.993\n",
      " * Prec@1 75.250 Prec@5 86.917\n",
      " * Prec@1 74.918 Prec@5 86.760\n",
      " * Prec@1 75.081 Prec@5 86.851\n",
      " * Prec@1 75.240 Prec@5 86.939\n",
      " * Prec@1 75.316 Prec@5 86.867\n",
      " * Prec@1 75.312 Prec@5 86.953\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.527 (0.529)\n",
      "\n",
      "Loss 3.6631 (1.6017)\n",
      "\n",
      "Prec@1 50.000 (75.000)\n",
      "\n",
      "Prec@5 68.750 (86.728)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.728\n",
      " * Prec@1 75.000 Prec@5 86.814\n",
      " * Prec@1 75.075 Prec@5 86.747\n",
      " * Prec@1 74.851 Prec@5 86.533\n",
      " * Prec@1 74.632 Prec@5 86.397\n",
      " * Prec@1 74.709 Prec@5 86.410\n",
      " * Prec@1 74.784 Prec@5 86.422\n",
      " * Prec@1 74.716 Prec@5 86.364\n",
      " * Prec@1 74.298 Prec@5 86.166\n",
      " * Prec@1 74.375 Prec@5 86.250\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.567 (0.527)\n",
      "\n",
      "Loss 0.5625 (1.6280)\n",
      "\n",
      "Prec@1 81.250 (74.451)\n",
      "\n",
      "Prec@5 100.000 (86.401)\n",
      "\n",
      " * Prec@1 74.451 Prec@5 86.401\n",
      " * Prec@1 74.457 Prec@5 86.345\n",
      " * Prec@1 74.530 Prec@5 86.358\n",
      " * Prec@1 74.335 Prec@5 86.237\n",
      " * Prec@1 74.276 Prec@5 86.250\n",
      " * Prec@1 74.414 Prec@5 86.393\n",
      " * Prec@1 74.613 Prec@5 86.469\n",
      " * Prec@1 74.681 Prec@5 86.543\n",
      " * Prec@1 74.747 Prec@5 86.553\n",
      " * Prec@1 74.875 Prec@5 86.688\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.522 (0.526)\n",
      "\n",
      "Loss 2.4268 (1.6140)\n",
      "\n",
      "Prec@1 75.000 (74.876)\n",
      "\n",
      "Prec@5 81.250 (86.634)\n",
      "\n",
      " * Prec@1 74.876 Prec@5 86.634\n",
      " * Prec@1 74.816 Prec@5 86.458\n",
      " * Prec@1 74.879 Prec@5 86.468\n",
      " * Prec@1 74.639 Prec@5 86.238\n",
      " * Prec@1 74.702 Prec@5 86.310\n",
      " * Prec@1 74.705 Prec@5 86.262\n",
      " * Prec@1 74.708 Prec@5 86.273\n",
      " * Prec@1 74.769 Prec@5 86.285\n",
      " * Prec@1 74.713 Prec@5 86.296\n",
      " * Prec@1 74.716 Prec@5 86.307\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.491 (0.526)\n",
      "\n",
      "Loss 1.9551 (1.6352)\n",
      "\n",
      "Prec@1 75.000 (74.718)\n",
      "\n",
      "Prec@5 81.250 (86.261)\n",
      "\n",
      " * Prec@1 74.718 Prec@5 86.261\n",
      " * Prec@1 74.777 Prec@5 86.328\n",
      " * Prec@1 74.889 Prec@5 86.338\n",
      " * Prec@1 74.836 Prec@5 86.404\n",
      " * Prec@1 74.946 Prec@5 86.522\n",
      " * Prec@1 75.054 Prec@5 86.584\n",
      " * Prec@1 74.893 Prec@5 86.538\n",
      " * Prec@1 75.000 Prec@5 86.600\n",
      " * Prec@1 75.000 Prec@5 86.607\n",
      " * Prec@1 75.052 Prec@5 86.667\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.521 (0.525)\n",
      "\n",
      "Loss 1.8128 (1.6131)\n",
      "\n",
      "Prec@1 62.500 (74.948)\n",
      "\n",
      "Prec@5 87.500 (86.674)\n",
      "\n",
      " * Prec@1 74.948 Prec@5 86.674\n",
      " * Prec@1 74.898 Prec@5 86.578\n",
      " * Prec@1 74.949 Prec@5 86.535\n",
      " * Prec@1 74.950 Prec@5 86.542\n",
      " * Prec@1 74.950 Prec@5 86.450\n",
      " * Prec@1 75.000 Prec@5 86.508\n",
      " * Prec@1 74.951 Prec@5 86.565\n",
      " * Prec@1 74.902 Prec@5 86.523\n",
      " * Prec@1 74.952 Prec@5 86.579\n",
      " * Prec@1 75.048 Prec@5 86.587\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.520 (0.525)\n",
      "\n",
      "Loss 2.1959 (1.6212)\n",
      "\n",
      "Prec@1 68.750 (75.000)\n",
      "\n",
      "Prec@5 81.250 (86.546)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.546\n",
      " * Prec@1 75.095 Prec@5 86.600\n",
      " * Prec@1 75.094 Prec@5 86.607\n",
      " * Prec@1 75.187 Prec@5 86.614\n",
      " * Prec@1 75.278 Prec@5 86.713\n",
      " * Prec@1 75.138 Prec@5 86.535\n",
      " * Prec@1 75.228 Prec@5 86.542\n",
      " * Prec@1 75.317 Prec@5 86.594\n",
      " * Prec@1 75.270 Prec@5 86.556\n",
      " * Prec@1 75.179 Prec@5 86.514\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [20][0/558]\t\\Time 0.531 (0.531)\tData 0.381 (0.381)\tLoss 0.0008 (0.0008)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [20][100/558]\t\\Time 0.541 (0.527)\tData 0.441 (0.424)\tLoss 0.2533 (0.0152)\tPrec@1 93.750 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [20][200/558]\t\\Time 0.500 (0.527)\tData 0.394 (0.425)\tLoss 0.0025 (0.0125)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [20][300/558]\t\\Time 0.581 (0.525)\tData 0.461 (0.423)\tLoss 0.0034 (0.0107)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [20][400/558]\t\\Time 0.510 (0.525)\tData 0.440 (0.424)\tLoss 0.0015 (0.0118)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [20][500/558]\t\\Time 0.511 (0.529)\tData 0.391 (0.427)\tLoss 0.0946 (0.0129)\tPrec@1 93.750 (99.713)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.521 (0.521)\n",
      "\n",
      "Loss 1.9638 (1.9638)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 84.375\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 78.750 Prec@5 87.500\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 80.357 Prec@5 90.179\n",
      " * Prec@1 77.344 Prec@5 89.062\n",
      " * Prec@1 79.167 Prec@5 90.278\n",
      " * Prec@1 78.750 Prec@5 90.000\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.535 (0.535)\n",
      "\n",
      "Loss 1.6993 (1.2561)\n",
      "\n",
      "Prec@1 68.750 (77.841)\n",
      "\n",
      "Prec@5 81.250 (89.205)\n",
      "\n",
      " * Prec@1 77.841 Prec@5 89.205\n",
      " * Prec@1 78.125 Prec@5 88.542\n",
      " * Prec@1 78.846 Prec@5 89.423\n",
      " * Prec@1 79.464 Prec@5 89.286\n",
      " * Prec@1 79.583 Prec@5 89.167\n",
      " * Prec@1 80.078 Prec@5 89.453\n",
      " * Prec@1 79.412 Prec@5 89.338\n",
      " * Prec@1 79.514 Prec@5 88.889\n",
      " * Prec@1 80.263 Prec@5 89.145\n",
      " * Prec@1 79.688 Prec@5 88.750\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.542 (0.530)\n",
      "\n",
      "Loss 2.5019 (1.3501)\n",
      "\n",
      "Prec@1 62.500 (78.869)\n",
      "\n",
      "Prec@5 87.500 (88.690)\n",
      "\n",
      " * Prec@1 78.869 Prec@5 88.690\n",
      " * Prec@1 78.125 Prec@5 88.352\n",
      " * Prec@1 77.717 Prec@5 88.587\n",
      " * Prec@1 76.562 Prec@5 88.281\n",
      " * Prec@1 76.750 Prec@5 88.000\n",
      " * Prec@1 76.683 Prec@5 87.740\n",
      " * Prec@1 76.157 Prec@5 87.037\n",
      " * Prec@1 76.339 Prec@5 87.054\n",
      " * Prec@1 75.862 Prec@5 86.638\n",
      " * Prec@1 75.833 Prec@5 86.458\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.506 (0.528)\n",
      "\n",
      "Loss 0.5415 (1.5528)\n",
      "\n",
      "Prec@1 75.000 (75.806)\n",
      "\n",
      "Prec@5 93.750 (86.694)\n",
      "\n",
      " * Prec@1 75.806 Prec@5 86.694\n",
      " * Prec@1 75.977 Prec@5 86.719\n",
      " * Prec@1 75.947 Prec@5 86.553\n",
      " * Prec@1 76.287 Prec@5 86.581\n",
      " * Prec@1 76.429 Prec@5 86.607\n",
      " * Prec@1 76.562 Prec@5 86.806\n",
      " * Prec@1 76.351 Prec@5 86.655\n",
      " * Prec@1 76.316 Prec@5 86.513\n",
      " * Prec@1 76.282 Prec@5 86.538\n",
      " * Prec@1 76.094 Prec@5 86.406\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.460 (0.529)\n",
      "\n",
      "Loss 0.8561 (1.5210)\n",
      "\n",
      "Prec@1 87.500 (76.372)\n",
      "\n",
      "Prec@5 100.000 (86.738)\n",
      "\n",
      " * Prec@1 76.372 Prec@5 86.738\n",
      " * Prec@1 76.339 Prec@5 86.607\n",
      " * Prec@1 75.727 Prec@5 86.047\n",
      " * Prec@1 75.284 Prec@5 86.080\n",
      " * Prec@1 74.861 Prec@5 85.694\n",
      " * Prec@1 74.728 Prec@5 85.598\n",
      " * Prec@1 74.867 Prec@5 85.771\n",
      " * Prec@1 74.870 Prec@5 86.068\n",
      " * Prec@1 74.872 Prec@5 86.097\n",
      " * Prec@1 75.125 Prec@5 86.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.541 (0.532)\n",
      "\n",
      "Loss 1.8699 (1.5886)\n",
      "\n",
      "Prec@1 75.000 (75.123)\n",
      "\n",
      "Prec@5 81.250 (86.152)\n",
      "\n",
      " * Prec@1 75.123 Prec@5 86.152\n",
      " * Prec@1 75.361 Prec@5 86.298\n",
      " * Prec@1 75.354 Prec@5 86.321\n",
      " * Prec@1 75.347 Prec@5 86.458\n",
      " * Prec@1 75.227 Prec@5 86.250\n",
      " * Prec@1 75.223 Prec@5 86.161\n",
      " * Prec@1 75.439 Prec@5 86.184\n",
      " * Prec@1 75.647 Prec@5 86.207\n",
      " * Prec@1 75.424 Prec@5 86.229\n",
      " * Prec@1 75.521 Prec@5 86.146\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.503 (0.531)\n",
      "\n",
      "Loss 0.4795 (1.5673)\n",
      "\n",
      "Prec@1 81.250 (75.615)\n",
      "\n",
      "Prec@5 100.000 (86.373)\n",
      "\n",
      " * Prec@1 75.615 Prec@5 86.373\n",
      " * Prec@1 75.907 Prec@5 86.593\n",
      " * Prec@1 76.091 Prec@5 86.706\n",
      " * Prec@1 76.367 Prec@5 86.914\n",
      " * Prec@1 76.538 Prec@5 86.923\n",
      " * Prec@1 76.136 Prec@5 86.742\n",
      " * Prec@1 76.213 Prec@5 86.754\n",
      " * Prec@1 76.195 Prec@5 86.673\n",
      " * Prec@1 75.996 Prec@5 86.504\n",
      " * Prec@1 75.804 Prec@5 86.250\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.551 (0.530)\n",
      "\n",
      "Loss 1.4859 (1.5745)\n",
      "\n",
      "Prec@1 62.500 (75.616)\n",
      "\n",
      "Prec@5 87.500 (86.268)\n",
      "\n",
      " * Prec@1 75.616 Prec@5 86.268\n",
      " * Prec@1 75.521 Prec@5 86.198\n",
      " * Prec@1 75.428 Prec@5 86.216\n",
      " * Prec@1 75.507 Prec@5 86.233\n",
      " * Prec@1 75.500 Prec@5 86.167\n",
      " * Prec@1 75.082 Prec@5 86.020\n",
      " * Prec@1 75.244 Prec@5 86.120\n",
      " * Prec@1 75.481 Prec@5 86.218\n",
      " * Prec@1 75.554 Prec@5 86.155\n",
      " * Prec@1 75.547 Prec@5 86.250\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.532 (0.530)\n",
      "\n",
      "Loss 3.4858 (1.6082)\n",
      "\n",
      "Prec@1 50.000 (75.231)\n",
      "\n",
      "Prec@5 75.000 (86.111)\n",
      "\n",
      " * Prec@1 75.231 Prec@5 86.111\n",
      " * Prec@1 75.229 Prec@5 86.128\n",
      " * Prec@1 75.301 Prec@5 86.069\n",
      " * Prec@1 75.074 Prec@5 85.863\n",
      " * Prec@1 74.853 Prec@5 85.735\n",
      " * Prec@1 74.927 Prec@5 85.756\n",
      " * Prec@1 75.000 Prec@5 85.704\n",
      " * Prec@1 74.929 Prec@5 85.724\n",
      " * Prec@1 74.508 Prec@5 85.534\n",
      " * Prec@1 74.583 Prec@5 85.625\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.522 (0.528)\n",
      "\n",
      "Loss 0.5836 (1.6358)\n",
      "\n",
      "Prec@1 81.250 (74.657)\n",
      "\n",
      "Prec@5 100.000 (85.783)\n",
      "\n",
      " * Prec@1 74.657 Prec@5 85.783\n",
      " * Prec@1 74.660 Prec@5 85.734\n",
      " * Prec@1 74.731 Prec@5 85.685\n",
      " * Prec@1 74.601 Prec@5 85.572\n",
      " * Prec@1 74.539 Prec@5 85.592\n",
      " * Prec@1 74.674 Prec@5 85.742\n",
      " * Prec@1 74.871 Prec@5 85.825\n",
      " * Prec@1 74.936 Prec@5 85.842\n",
      " * Prec@1 74.937 Prec@5 85.795\n",
      " * Prec@1 75.062 Prec@5 85.938\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.553 (0.529)\n",
      "\n",
      "Loss 2.5235 (1.6260)\n",
      "\n",
      "Prec@1 75.000 (75.062)\n",
      "\n",
      "Prec@5 75.000 (85.829)\n",
      "\n",
      " * Prec@1 75.062 Prec@5 85.829\n",
      " * Prec@1 74.939 Prec@5 85.723\n",
      " * Prec@1 75.000 Prec@5 85.740\n",
      " * Prec@1 74.760 Prec@5 85.517\n",
      " * Prec@1 74.881 Prec@5 85.595\n",
      " * Prec@1 74.823 Prec@5 85.495\n",
      " * Prec@1 74.825 Prec@5 85.514\n",
      " * Prec@1 74.884 Prec@5 85.532\n",
      " * Prec@1 74.828 Prec@5 85.550\n",
      " * Prec@1 74.830 Prec@5 85.568\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.483 (0.528)\n",
      "\n",
      "Loss 1.9515 (1.6459)\n",
      "\n",
      "Prec@1 68.750 (74.775)\n",
      "\n",
      "Prec@5 81.250 (85.529)\n",
      "\n",
      " * Prec@1 74.775 Prec@5 85.529\n",
      " * Prec@1 74.833 Prec@5 85.603\n",
      " * Prec@1 74.945 Prec@5 85.619\n",
      " * Prec@1 74.890 Prec@5 85.691\n",
      " * Prec@1 75.000 Prec@5 85.761\n",
      " * Prec@1 75.108 Prec@5 85.830\n",
      " * Prec@1 74.947 Prec@5 85.791\n",
      " * Prec@1 75.053 Prec@5 85.858\n",
      " * Prec@1 75.000 Prec@5 85.819\n",
      " * Prec@1 75.052 Prec@5 85.885\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.502 (0.527)\n",
      "\n",
      "Loss 1.8068 (1.6256)\n",
      "\n",
      "Prec@1 62.500 (74.948)\n",
      "\n",
      "Prec@5 81.250 (85.847)\n",
      "\n",
      " * Prec@1 74.948 Prec@5 85.847\n",
      " * Prec@1 74.898 Prec@5 85.758\n",
      " * Prec@1 74.949 Prec@5 85.722\n",
      " * Prec@1 74.950 Prec@5 85.685\n",
      " * Prec@1 74.950 Prec@5 85.600\n",
      " * Prec@1 75.000 Prec@5 85.665\n",
      " * Prec@1 75.000 Prec@5 85.728\n",
      " * Prec@1 75.000 Prec@5 85.693\n",
      " * Prec@1 75.048 Prec@5 85.707\n",
      " * Prec@1 75.144 Prec@5 85.721\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.541 (0.525)\n",
      "\n",
      "Loss 2.0421 (1.6288)\n",
      "\n",
      "Prec@1 75.000 (75.143)\n",
      "\n",
      "Prec@5 81.250 (85.687)\n",
      "\n",
      " * Prec@1 75.143 Prec@5 85.687\n",
      " * Prec@1 75.237 Prec@5 85.748\n",
      " * Prec@1 75.235 Prec@5 85.714\n",
      " * Prec@1 75.326 Prec@5 85.728\n",
      " * Prec@1 75.417 Prec@5 85.833\n",
      " * Prec@1 75.276 Prec@5 85.662\n",
      " * Prec@1 75.319 Prec@5 85.675\n",
      " * Prec@1 75.408 Prec@5 85.734\n",
      " * Prec@1 75.360 Prec@5 85.701\n",
      " * Prec@1 75.269 Prec@5 85.663\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [21][0/558]\t\\Time 0.541 (0.541)\tData 0.444 (0.444)\tLoss 0.0021 (0.0021)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [21][100/558]\t\\Time 0.492 (0.526)\tData 0.376 (0.423)\tLoss 0.0011 (0.0088)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [21][200/558]\t\\Time 0.521 (0.525)\tData 0.411 (0.422)\tLoss 0.0016 (0.0119)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [21][300/558]\t\\Time 0.561 (0.528)\tData 0.441 (0.426)\tLoss 0.0017 (0.0112)\tPrec@1 100.000 (99.730)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [21][400/558]\t\\Time 0.571 (0.530)\tData 0.461 (0.426)\tLoss 0.0010 (0.0124)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [21][500/558]\t\\Time 0.590 (0.532)\tData 0.480 (0.429)\tLoss 0.0020 (0.0126)\tPrec@1 100.000 (99.651)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.551 (0.551)\n",
      "\n",
      "Loss 1.8128 (1.8128)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 84.375\n",
      " * Prec@1 77.083 Prec@5 87.500\n",
      " * Prec@1 78.125 Prec@5 87.500\n",
      " * Prec@1 77.500 Prec@5 86.250\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 80.357 Prec@5 89.286\n",
      " * Prec@1 78.125 Prec@5 89.844\n",
      " * Prec@1 79.167 Prec@5 90.972\n",
      " * Prec@1 78.750 Prec@5 90.000\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.533 (0.565)\n",
      "\n",
      "Loss 1.3345 (1.1743)\n",
      "\n",
      "Prec@1 68.750 (77.841)\n",
      "\n",
      "Prec@5 87.500 (89.773)\n",
      "\n",
      " * Prec@1 77.841 Prec@5 89.773\n",
      " * Prec@1 78.125 Prec@5 89.583\n",
      " * Prec@1 78.846 Prec@5 90.385\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 79.583 Prec@5 90.000\n",
      " * Prec@1 80.078 Prec@5 90.625\n",
      " * Prec@1 79.412 Prec@5 90.441\n",
      " * Prec@1 79.167 Prec@5 89.931\n",
      " * Prec@1 79.934 Prec@5 90.132\n",
      " * Prec@1 79.375 Prec@5 89.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.551 (0.542)\n",
      "\n",
      "Loss 2.3850 (1.2799)\n",
      "\n",
      "Prec@1 62.500 (78.571)\n",
      "\n",
      "Prec@5 81.250 (89.286)\n",
      "\n",
      " * Prec@1 78.571 Prec@5 89.286\n",
      " * Prec@1 78.409 Prec@5 88.920\n",
      " * Prec@1 78.261 Prec@5 89.402\n",
      " * Prec@1 77.083 Prec@5 88.802\n",
      " * Prec@1 77.250 Prec@5 88.500\n",
      " * Prec@1 77.163 Prec@5 88.221\n",
      " * Prec@1 76.620 Prec@5 87.731\n",
      " * Prec@1 76.786 Prec@5 87.723\n",
      " * Prec@1 76.293 Prec@5 87.284\n",
      " * Prec@1 76.250 Prec@5 87.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.512 (0.541)\n",
      "\n",
      "Loss 0.6597 (1.5080)\n",
      "\n",
      "Prec@1 81.250 (76.411)\n",
      "\n",
      "Prec@5 93.750 (87.298)\n",
      "\n",
      " * Prec@1 76.411 Prec@5 87.298\n",
      " * Prec@1 76.758 Prec@5 87.305\n",
      " * Prec@1 76.705 Prec@5 87.121\n",
      " * Prec@1 77.022 Prec@5 87.316\n",
      " * Prec@1 77.143 Prec@5 87.321\n",
      " * Prec@1 77.257 Prec@5 87.500\n",
      " * Prec@1 77.196 Prec@5 87.331\n",
      " * Prec@1 77.138 Prec@5 87.007\n",
      " * Prec@1 77.244 Prec@5 87.019\n",
      " * Prec@1 77.188 Prec@5 86.875\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.466 (0.539)\n",
      "\n",
      "Loss 0.6947 (1.4726)\n",
      "\n",
      "Prec@1 87.500 (77.439)\n",
      "\n",
      "Prec@5 100.000 (87.195)\n",
      "\n",
      " * Prec@1 77.439 Prec@5 87.195\n",
      " * Prec@1 77.232 Prec@5 87.054\n",
      " * Prec@1 76.744 Prec@5 86.773\n",
      " * Prec@1 76.136 Prec@5 86.790\n",
      " * Prec@1 75.694 Prec@5 86.389\n",
      " * Prec@1 75.543 Prec@5 86.277\n",
      " * Prec@1 75.665 Prec@5 86.436\n",
      " * Prec@1 75.651 Prec@5 86.719\n",
      " * Prec@1 75.638 Prec@5 86.735\n",
      " * Prec@1 75.875 Prec@5 86.875\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.532 (0.535)\n",
      "\n",
      "Loss 2.0146 (1.5554)\n",
      "\n",
      "Prec@1 75.000 (75.858)\n",
      "\n",
      "Prec@5 81.250 (86.765)\n",
      "\n",
      " * Prec@1 75.858 Prec@5 86.765\n",
      " * Prec@1 76.082 Prec@5 86.899\n",
      " * Prec@1 76.061 Prec@5 86.910\n",
      " * Prec@1 76.157 Prec@5 87.153\n",
      " * Prec@1 76.023 Prec@5 87.045\n",
      " * Prec@1 76.004 Prec@5 86.942\n",
      " * Prec@1 75.987 Prec@5 86.952\n",
      " * Prec@1 76.185 Prec@5 86.961\n",
      " * Prec@1 75.953 Prec@5 86.970\n",
      " * Prec@1 76.042 Prec@5 86.875\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.490 (0.533)\n",
      "\n",
      "Loss 0.5099 (1.5360)\n",
      "\n",
      "Prec@1 81.250 (76.127)\n",
      "\n",
      "Prec@5 100.000 (87.090)\n",
      "\n",
      " * Prec@1 76.127 Prec@5 87.090\n",
      " * Prec@1 76.109 Prec@5 87.298\n",
      " * Prec@1 76.290 Prec@5 87.401\n",
      " * Prec@1 76.562 Prec@5 87.598\n",
      " * Prec@1 76.635 Prec@5 87.596\n",
      " * Prec@1 76.136 Prec@5 87.405\n",
      " * Prec@1 76.213 Prec@5 87.407\n",
      " * Prec@1 76.011 Prec@5 87.316\n",
      " * Prec@1 75.815 Prec@5 87.228\n",
      " * Prec@1 75.536 Prec@5 86.875\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.581 (0.533)\n",
      "\n",
      "Loss 1.7951 (1.5505)\n",
      "\n",
      "Prec@1 62.500 (75.352)\n",
      "\n",
      "Prec@5 81.250 (86.796)\n",
      "\n",
      " * Prec@1 75.352 Prec@5 86.796\n",
      " * Prec@1 75.260 Prec@5 86.719\n",
      " * Prec@1 75.171 Prec@5 86.729\n",
      " * Prec@1 75.253 Prec@5 86.824\n",
      " * Prec@1 75.250 Prec@5 86.750\n",
      " * Prec@1 74.918 Prec@5 86.595\n",
      " * Prec@1 75.081 Prec@5 86.688\n",
      " * Prec@1 75.240 Prec@5 86.779\n",
      " * Prec@1 75.316 Prec@5 86.709\n",
      " * Prec@1 75.312 Prec@5 86.797\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.521 (0.531)\n",
      "\n",
      "Loss 3.7779 (1.5926)\n",
      "\n",
      "Prec@1 50.000 (75.000)\n",
      "\n",
      "Prec@5 68.750 (86.574)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.574\n",
      " * Prec@1 75.000 Prec@5 86.509\n",
      " * Prec@1 75.075 Prec@5 86.446\n",
      " * Prec@1 74.851 Prec@5 86.161\n",
      " * Prec@1 74.706 Prec@5 86.029\n",
      " * Prec@1 74.782 Prec@5 86.119\n",
      " * Prec@1 74.856 Prec@5 86.135\n",
      " * Prec@1 74.787 Prec@5 86.080\n",
      " * Prec@1 74.368 Prec@5 85.815\n",
      " * Prec@1 74.444 Prec@5 85.903\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.561 (0.529)\n",
      "\n",
      "Loss 0.5836 (1.6186)\n",
      "\n",
      "Prec@1 81.250 (74.519)\n",
      "\n",
      "Prec@5 100.000 (86.058)\n",
      "\n",
      " * Prec@1 74.519 Prec@5 86.058\n",
      " * Prec@1 74.524 Prec@5 86.005\n",
      " * Prec@1 74.597 Prec@5 85.954\n",
      " * Prec@1 74.468 Prec@5 85.838\n",
      " * Prec@1 74.342 Prec@5 85.855\n",
      " * Prec@1 74.479 Prec@5 86.003\n",
      " * Prec@1 74.678 Prec@5 86.082\n",
      " * Prec@1 74.681 Prec@5 86.161\n",
      " * Prec@1 74.684 Prec@5 86.174\n",
      " * Prec@1 74.812 Prec@5 86.312\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.550 (0.529)\n",
      "\n",
      "Loss 2.4767 (1.6072)\n",
      "\n",
      "Prec@1 75.000 (74.814)\n",
      "\n",
      "Prec@5 75.000 (86.200)\n",
      "\n",
      " * Prec@1 74.814 Prec@5 86.200\n",
      " * Prec@1 74.755 Prec@5 86.029\n",
      " * Prec@1 74.818 Prec@5 86.044\n",
      " * Prec@1 74.579 Prec@5 85.877\n",
      " * Prec@1 74.702 Prec@5 85.952\n",
      " * Prec@1 74.646 Prec@5 85.908\n",
      " * Prec@1 74.650 Prec@5 85.923\n",
      " * Prec@1 74.711 Prec@5 85.938\n",
      " * Prec@1 74.656 Prec@5 85.952\n",
      " * Prec@1 74.659 Prec@5 85.966\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.481 (0.528)\n",
      "\n",
      "Loss 1.7844 (1.6272)\n",
      "\n",
      "Prec@1 68.750 (74.606)\n",
      "\n",
      "Prec@5 81.250 (85.923)\n",
      "\n",
      " * Prec@1 74.606 Prec@5 85.923\n",
      " * Prec@1 74.665 Prec@5 85.938\n",
      " * Prec@1 74.779 Prec@5 85.951\n",
      " * Prec@1 74.671 Prec@5 86.020\n",
      " * Prec@1 74.783 Prec@5 86.087\n",
      " * Prec@1 74.892 Prec@5 86.153\n",
      " * Prec@1 74.733 Prec@5 86.111\n",
      " * Prec@1 74.841 Prec@5 86.176\n",
      " * Prec@1 74.737 Prec@5 86.187\n",
      " * Prec@1 74.844 Prec@5 86.250\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.540 (0.527)\n",
      "\n",
      "Loss 1.8273 (1.6116)\n",
      "\n",
      "Prec@1 62.500 (74.742)\n",
      "\n",
      "Prec@5 75.000 (86.157)\n",
      "\n",
      " * Prec@1 74.742 Prec@5 86.157\n",
      " * Prec@1 74.693 Prec@5 86.066\n",
      " * Prec@1 74.746 Prec@5 86.026\n",
      " * Prec@1 74.748 Prec@5 85.988\n",
      " * Prec@1 74.750 Prec@5 85.900\n",
      " * Prec@1 74.851 Prec@5 85.962\n",
      " * Prec@1 74.803 Prec@5 85.974\n",
      " * Prec@1 74.805 Prec@5 85.938\n",
      " * Prec@1 74.806 Prec@5 85.998\n",
      " * Prec@1 74.904 Prec@5 86.010\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.566 (0.527)\n",
      "\n",
      "Loss 2.0638 (1.6166)\n",
      "\n",
      "Prec@1 62.500 (74.809)\n",
      "\n",
      "Prec@5 81.250 (85.973)\n",
      "\n",
      " * Prec@1 74.809 Prec@5 85.973\n",
      " * Prec@1 74.953 Prec@5 86.080\n",
      " * Prec@1 74.953 Prec@5 86.090\n",
      " * Prec@1 75.047 Prec@5 86.101\n",
      " * Prec@1 75.139 Prec@5 86.204\n",
      " * Prec@1 75.000 Prec@5 86.029\n",
      " * Prec@1 75.046 Prec@5 86.040\n",
      " * Prec@1 75.136 Prec@5 86.096\n",
      " * Prec@1 75.045 Prec@5 86.061\n",
      " * Prec@1 75.000 Prec@5 86.022\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [22][0/558]\t\\Time 0.532 (0.532)\tData 0.423 (0.423)\tLoss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [22][100/558]\t\\Time 0.513 (0.503)\tData 0.423 (0.401)\tLoss 0.0019 (0.0038)\tPrec@1 100.000 (99.876)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [22][200/558]\t\\Time 0.470 (0.506)\tData 0.369 (0.404)\tLoss 0.0025 (0.0098)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [22][300/558]\t\\Time 0.491 (0.507)\tData 0.410 (0.405)\tLoss 0.0018 (0.0097)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [22][400/558]\t\\Time 0.542 (0.507)\tData 0.431 (0.406)\tLoss 0.0011 (0.0103)\tPrec@1 100.000 (99.719)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [22][500/558]\t\\Time 0.501 (0.506)\tData 0.401 (0.405)\tLoss 0.0013 (0.0109)\tPrec@1 100.000 (99.713)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.512 (0.512)\n",
      "\n",
      "Loss 1.8503 (1.8503)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 78.750 Prec@5 87.500\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 82.143 Prec@5 90.179\n",
      " * Prec@1 78.906 Prec@5 89.844\n",
      " * Prec@1 79.861 Prec@5 90.972\n",
      " * Prec@1 79.375 Prec@5 90.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.510 (0.520)\n",
      "\n",
      "Loss 1.2011 (1.1377)\n",
      "\n",
      "Prec@1 68.750 (78.409)\n",
      "\n",
      "Prec@5 87.500 (90.341)\n",
      "\n",
      " * Prec@1 78.409 Prec@5 90.341\n",
      " * Prec@1 78.646 Prec@5 90.104\n",
      " * Prec@1 79.327 Prec@5 90.865\n",
      " * Prec@1 79.911 Prec@5 90.625\n",
      " * Prec@1 80.000 Prec@5 90.417\n",
      " * Prec@1 80.469 Prec@5 90.625\n",
      " * Prec@1 79.779 Prec@5 90.441\n",
      " * Prec@1 79.861 Prec@5 89.931\n",
      " * Prec@1 80.592 Prec@5 90.132\n",
      " * Prec@1 80.000 Prec@5 89.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.502 (0.512)\n",
      "\n",
      "Loss 2.4291 (1.2804)\n",
      "\n",
      "Prec@1 62.500 (79.167)\n",
      "\n",
      "Prec@5 81.250 (89.286)\n",
      "\n",
      " * Prec@1 79.167 Prec@5 89.286\n",
      " * Prec@1 78.693 Prec@5 88.920\n",
      " * Prec@1 78.261 Prec@5 89.130\n",
      " * Prec@1 77.083 Prec@5 88.542\n",
      " * Prec@1 77.250 Prec@5 88.500\n",
      " * Prec@1 76.923 Prec@5 88.221\n",
      " * Prec@1 76.389 Prec@5 87.731\n",
      " * Prec@1 76.562 Prec@5 87.723\n",
      " * Prec@1 76.078 Prec@5 87.284\n",
      " * Prec@1 76.042 Prec@5 86.875\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.542 (0.520)\n",
      "\n",
      "Loss 0.6303 (1.5045)\n",
      "\n",
      "Prec@1 75.000 (76.008)\n",
      "\n",
      "Prec@5 93.750 (87.097)\n",
      "\n",
      " * Prec@1 76.008 Prec@5 87.097\n",
      " * Prec@1 76.172 Prec@5 87.109\n",
      " * Prec@1 76.326 Prec@5 86.932\n",
      " * Prec@1 76.654 Prec@5 87.132\n",
      " * Prec@1 76.786 Prec@5 87.143\n",
      " * Prec@1 76.910 Prec@5 87.326\n",
      " * Prec@1 76.858 Prec@5 87.162\n",
      " * Prec@1 76.809 Prec@5 86.842\n",
      " * Prec@1 76.763 Prec@5 86.699\n",
      " * Prec@1 76.562 Prec@5 86.562\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.442 (0.517)\n",
      "\n",
      "Loss 0.7336 (1.4686)\n",
      "\n",
      "Prec@1 87.500 (76.829)\n",
      "\n",
      "Prec@5 93.750 (86.738)\n",
      "\n",
      " * Prec@1 76.829 Prec@5 86.738\n",
      " * Prec@1 76.637 Prec@5 86.756\n",
      " * Prec@1 76.163 Prec@5 86.628\n",
      " * Prec@1 75.710 Prec@5 86.506\n",
      " * Prec@1 75.278 Prec@5 86.111\n",
      " * Prec@1 75.136 Prec@5 86.005\n",
      " * Prec@1 75.266 Prec@5 86.170\n",
      " * Prec@1 75.130 Prec@5 86.458\n",
      " * Prec@1 75.128 Prec@5 86.480\n",
      " * Prec@1 75.500 Prec@5 86.625\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.531 (0.515)\n",
      "\n",
      "Loss 1.9487 (1.5427)\n",
      "\n",
      "Prec@1 75.000 (75.490)\n",
      "\n",
      "Prec@5 81.250 (86.520)\n",
      "\n",
      " * Prec@1 75.490 Prec@5 86.520\n",
      " * Prec@1 75.721 Prec@5 86.659\n",
      " * Prec@1 75.708 Prec@5 86.675\n",
      " * Prec@1 75.579 Prec@5 86.806\n",
      " * Prec@1 75.455 Prec@5 86.705\n",
      " * Prec@1 75.446 Prec@5 86.607\n",
      " * Prec@1 75.439 Prec@5 86.623\n",
      " * Prec@1 75.647 Prec@5 86.638\n",
      " * Prec@1 75.424 Prec@5 86.441\n",
      " * Prec@1 75.521 Prec@5 86.354\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.540 (0.514)\n",
      "\n",
      "Loss 0.5050 (1.5271)\n",
      "\n",
      "Prec@1 81.250 (75.615)\n",
      "\n",
      "Prec@5 100.000 (86.578)\n",
      "\n",
      " * Prec@1 75.615 Prec@5 86.578\n",
      " * Prec@1 75.806 Prec@5 86.794\n",
      " * Prec@1 75.992 Prec@5 86.905\n",
      " * Prec@1 76.270 Prec@5 87.109\n",
      " * Prec@1 76.346 Prec@5 87.115\n",
      " * Prec@1 75.852 Prec@5 86.932\n",
      " * Prec@1 75.933 Prec@5 86.940\n",
      " * Prec@1 75.827 Prec@5 86.857\n",
      " * Prec@1 75.634 Prec@5 86.775\n",
      " * Prec@1 75.446 Prec@5 86.429\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.510 (0.512)\n",
      "\n",
      "Loss 1.9080 (1.5388)\n",
      "\n",
      "Prec@1 62.500 (75.264)\n",
      "\n",
      "Prec@5 87.500 (86.444)\n",
      "\n",
      " * Prec@1 75.264 Prec@5 86.444\n",
      " * Prec@1 75.174 Prec@5 86.372\n",
      " * Prec@1 75.000 Prec@5 86.387\n",
      " * Prec@1 75.084 Prec@5 86.402\n",
      " * Prec@1 75.083 Prec@5 86.333\n",
      " * Prec@1 74.753 Prec@5 86.266\n",
      " * Prec@1 74.919 Prec@5 86.364\n",
      " * Prec@1 75.080 Prec@5 86.458\n",
      " * Prec@1 75.158 Prec@5 86.392\n",
      " * Prec@1 75.156 Prec@5 86.484\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.545 (0.512)\n",
      "\n",
      "Loss 3.5017 (1.5799)\n",
      "\n",
      "Prec@1 50.000 (74.846)\n",
      "\n",
      "Prec@5 68.750 (86.265)\n",
      "\n",
      " * Prec@1 74.846 Prec@5 86.265\n",
      " * Prec@1 74.848 Prec@5 86.280\n",
      " * Prec@1 74.925 Prec@5 86.220\n",
      " * Prec@1 74.702 Prec@5 86.012\n",
      " * Prec@1 74.559 Prec@5 85.882\n",
      " * Prec@1 74.637 Prec@5 85.974\n",
      " * Prec@1 74.713 Prec@5 85.991\n",
      " * Prec@1 74.645 Prec@5 85.938\n",
      " * Prec@1 74.228 Prec@5 85.604\n",
      " * Prec@1 74.306 Prec@5 85.694\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.521 (0.510)\n",
      "\n",
      "Loss 0.4546 (1.6066)\n",
      "\n",
      "Prec@1 81.250 (74.382)\n",
      "\n",
      "Prec@5 100.000 (85.852)\n",
      "\n",
      " * Prec@1 74.382 Prec@5 85.852\n",
      " * Prec@1 74.389 Prec@5 85.802\n",
      " * Prec@1 74.462 Prec@5 85.753\n",
      " * Prec@1 74.335 Prec@5 85.638\n",
      " * Prec@1 74.145 Prec@5 85.658\n",
      " * Prec@1 74.284 Prec@5 85.807\n",
      " * Prec@1 74.485 Prec@5 85.889\n",
      " * Prec@1 74.490 Prec@5 85.906\n",
      " * Prec@1 74.495 Prec@5 85.922\n",
      " * Prec@1 74.625 Prec@5 86.062\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.506 (0.510)\n",
      "\n",
      "Loss 2.4173 (1.5977)\n",
      "\n",
      "Prec@1 75.000 (74.629)\n",
      "\n",
      "Prec@5 75.000 (85.953)\n",
      "\n",
      " * Prec@1 74.629 Prec@5 85.953\n",
      " * Prec@1 74.571 Prec@5 85.846\n",
      " * Prec@1 74.636 Prec@5 85.862\n",
      " * Prec@1 74.399 Prec@5 85.637\n",
      " * Prec@1 74.524 Prec@5 85.714\n",
      " * Prec@1 74.469 Prec@5 85.672\n",
      " * Prec@1 74.533 Prec@5 85.689\n",
      " * Prec@1 74.595 Prec@5 85.706\n",
      " * Prec@1 74.541 Prec@5 85.722\n",
      " * Prec@1 74.545 Prec@5 85.739\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.481 (0.510)\n",
      "\n",
      "Loss 1.7801 (1.6160)\n",
      "\n",
      "Prec@1 68.750 (74.493)\n",
      "\n",
      "Prec@5 87.500 (85.755)\n",
      "\n",
      " * Prec@1 74.493 Prec@5 85.755\n",
      " * Prec@1 74.554 Prec@5 85.770\n",
      " * Prec@1 74.668 Prec@5 85.785\n",
      " * Prec@1 74.616 Prec@5 85.855\n",
      " * Prec@1 74.728 Prec@5 85.924\n",
      " * Prec@1 74.838 Prec@5 85.991\n",
      " * Prec@1 74.679 Prec@5 85.951\n",
      " * Prec@1 74.788 Prec@5 86.017\n",
      " * Prec@1 74.790 Prec@5 85.977\n",
      " * Prec@1 74.896 Prec@5 86.042\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.517 (0.510)\n",
      "\n",
      "Loss 1.7516 (1.5950)\n",
      "\n",
      "Prec@1 62.500 (74.793)\n",
      "\n",
      "Prec@5 75.000 (85.950)\n",
      "\n",
      " * Prec@1 74.793 Prec@5 85.950\n",
      " * Prec@1 74.744 Prec@5 85.861\n",
      " * Prec@1 74.797 Prec@5 85.823\n",
      " * Prec@1 74.798 Prec@5 85.786\n",
      " * Prec@1 74.800 Prec@5 85.700\n",
      " * Prec@1 74.802 Prec@5 85.764\n",
      " * Prec@1 74.754 Prec@5 85.778\n",
      " * Prec@1 74.756 Prec@5 85.742\n",
      " * Prec@1 74.806 Prec@5 85.804\n",
      " * Prec@1 74.904 Prec@5 85.817\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.511 (0.510)\n",
      "\n",
      "Loss 2.0236 (1.6038)\n",
      "\n",
      "Prec@1 75.000 (74.905)\n",
      "\n",
      "Prec@5 81.250 (85.782)\n",
      "\n",
      " * Prec@1 74.905 Prec@5 85.782\n",
      " * Prec@1 75.000 Prec@5 85.890\n",
      " * Prec@1 75.000 Prec@5 85.902\n",
      " * Prec@1 75.093 Prec@5 85.961\n",
      " * Prec@1 75.185 Prec@5 86.065\n",
      " * Prec@1 75.046 Prec@5 85.846\n",
      " * Prec@1 75.137 Prec@5 85.858\n",
      " * Prec@1 75.226 Prec@5 85.915\n",
      " * Prec@1 75.225 Prec@5 85.836\n",
      " * Prec@1 75.134 Prec@5 85.797\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [23][0/558]\t\\Time 0.580 (0.580)\tData 0.439 (0.439)\tLoss 0.0018 (0.0018)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [23][100/558]\t\\Time 0.490 (0.501)\tData 0.400 (0.399)\tLoss 0.0013 (0.0100)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [23][200/558]\t\\Time 0.460 (0.503)\tData 0.390 (0.402)\tLoss 0.0011 (0.0086)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [23][300/558]\t\\Time 0.541 (0.504)\tData 0.440 (0.403)\tLoss 0.0019 (0.0075)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [23][400/558]\t\\Time 0.490 (0.503)\tData 0.390 (0.403)\tLoss 0.0015 (0.0083)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [23][500/558]\t\\Time 0.520 (0.505)\tData 0.410 (0.404)\tLoss 0.0010 (0.0087)\tPrec@1 100.000 (99.726)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.490 (0.490)\n",
      "\n",
      "Loss 1.8711 (1.8711)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 79.167 Prec@5 91.667\n",
      " * Prec@1 79.688 Prec@5 90.625\n",
      " * Prec@1 78.750 Prec@5 88.750\n",
      " * Prec@1 80.208 Prec@5 90.625\n",
      " * Prec@1 82.143 Prec@5 91.071\n",
      " * Prec@1 78.906 Prec@5 90.625\n",
      " * Prec@1 79.861 Prec@5 91.667\n",
      " * Prec@1 79.375 Prec@5 91.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.510 (0.519)\n",
      "\n",
      "Loss 1.4438 (1.1560)\n",
      "\n",
      "Prec@1 68.750 (78.409)\n",
      "\n",
      "Prec@5 87.500 (90.909)\n",
      "\n",
      " * Prec@1 78.409 Prec@5 90.909\n",
      " * Prec@1 78.646 Prec@5 90.625\n",
      " * Prec@1 79.327 Prec@5 91.346\n",
      " * Prec@1 79.911 Prec@5 91.071\n",
      " * Prec@1 80.000 Prec@5 90.833\n",
      " * Prec@1 80.469 Prec@5 91.406\n",
      " * Prec@1 79.779 Prec@5 91.176\n",
      " * Prec@1 79.861 Prec@5 90.625\n",
      " * Prec@1 80.592 Prec@5 90.789\n",
      " * Prec@1 80.000 Prec@5 90.312\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.541 (0.512)\n",
      "\n",
      "Loss 2.4045 (1.3004)\n",
      "\n",
      "Prec@1 62.500 (79.167)\n",
      "\n",
      "Prec@5 81.250 (89.881)\n",
      "\n",
      " * Prec@1 79.167 Prec@5 89.881\n",
      " * Prec@1 78.409 Prec@5 89.489\n",
      " * Prec@1 78.261 Prec@5 89.946\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 77.250 Prec@5 89.250\n",
      " * Prec@1 76.923 Prec@5 88.942\n",
      " * Prec@1 76.389 Prec@5 88.426\n",
      " * Prec@1 76.562 Prec@5 88.393\n",
      " * Prec@1 76.078 Prec@5 87.931\n",
      " * Prec@1 76.042 Prec@5 87.708\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.480 (0.516)\n",
      "\n",
      "Loss 0.6994 (1.5134)\n",
      "\n",
      "Prec@1 81.250 (76.210)\n",
      "\n",
      "Prec@5 93.750 (87.903)\n",
      "\n",
      " * Prec@1 76.210 Prec@5 87.903\n",
      " * Prec@1 76.562 Prec@5 87.891\n",
      " * Prec@1 76.515 Prec@5 87.689\n",
      " * Prec@1 76.838 Prec@5 87.868\n",
      " * Prec@1 76.964 Prec@5 87.857\n",
      " * Prec@1 77.083 Prec@5 88.021\n",
      " * Prec@1 76.858 Prec@5 87.838\n",
      " * Prec@1 76.809 Prec@5 87.500\n",
      " * Prec@1 76.763 Prec@5 87.340\n",
      " * Prec@1 76.562 Prec@5 87.188\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.450 (0.514)\n",
      "\n",
      "Loss 0.8576 (1.4853)\n",
      "\n",
      "Prec@1 87.500 (76.829)\n",
      "\n",
      "Prec@5 100.000 (87.500)\n",
      "\n",
      " * Prec@1 76.829 Prec@5 87.500\n",
      " * Prec@1 76.935 Prec@5 87.351\n",
      " * Prec@1 76.308 Prec@5 87.209\n",
      " * Prec@1 75.710 Prec@5 87.216\n",
      " * Prec@1 75.278 Prec@5 86.806\n",
      " * Prec@1 75.136 Prec@5 86.685\n",
      " * Prec@1 75.266 Prec@5 86.835\n",
      " * Prec@1 75.130 Prec@5 87.109\n",
      " * Prec@1 75.128 Prec@5 87.117\n",
      " * Prec@1 75.500 Prec@5 87.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.510 (0.514)\n",
      "\n",
      "Loss 1.9278 (1.5517)\n",
      "\n",
      "Prec@1 75.000 (75.490)\n",
      "\n",
      "Prec@5 81.250 (87.132)\n",
      "\n",
      " * Prec@1 75.490 Prec@5 87.132\n",
      " * Prec@1 75.721 Prec@5 87.260\n",
      " * Prec@1 75.590 Prec@5 87.146\n",
      " * Prec@1 75.463 Prec@5 87.269\n",
      " * Prec@1 75.341 Prec@5 87.159\n",
      " * Prec@1 75.335 Prec@5 87.054\n",
      " * Prec@1 75.439 Prec@5 87.061\n",
      " * Prec@1 75.647 Prec@5 87.069\n",
      " * Prec@1 75.424 Prec@5 87.076\n",
      " * Prec@1 75.521 Prec@5 86.979\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.510 (0.514)\n",
      "\n",
      "Loss 0.5153 (1.5342)\n",
      "\n",
      "Prec@1 81.250 (75.615)\n",
      "\n",
      "Prec@5 100.000 (87.193)\n",
      "\n",
      " * Prec@1 75.615 Prec@5 87.193\n",
      " * Prec@1 75.907 Prec@5 87.399\n",
      " * Prec@1 76.091 Prec@5 87.500\n",
      " * Prec@1 76.367 Prec@5 87.598\n",
      " * Prec@1 76.538 Prec@5 87.596\n",
      " * Prec@1 76.136 Prec@5 87.405\n",
      " * Prec@1 76.213 Prec@5 87.313\n",
      " * Prec@1 76.195 Prec@5 87.224\n",
      " * Prec@1 75.996 Prec@5 87.138\n",
      " * Prec@1 75.804 Prec@5 86.786\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.530 (0.513)\n",
      "\n",
      "Loss 1.6848 (1.5354)\n",
      "\n",
      "Prec@1 62.500 (75.616)\n",
      "\n",
      "Prec@5 87.500 (86.796)\n",
      "\n",
      " * Prec@1 75.616 Prec@5 86.796\n",
      " * Prec@1 75.521 Prec@5 86.719\n",
      " * Prec@1 75.342 Prec@5 86.729\n",
      " * Prec@1 75.422 Prec@5 86.824\n",
      " * Prec@1 75.417 Prec@5 86.750\n",
      " * Prec@1 75.082 Prec@5 86.678\n",
      " * Prec@1 75.244 Prec@5 86.769\n",
      " * Prec@1 75.401 Prec@5 86.859\n",
      " * Prec@1 75.475 Prec@5 86.788\n",
      " * Prec@1 75.469 Prec@5 86.875\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.559 (0.512)\n",
      "\n",
      "Loss 3.4976 (1.5744)\n",
      "\n",
      "Prec@1 50.000 (75.154)\n",
      "\n",
      "Prec@5 75.000 (86.728)\n",
      "\n",
      " * Prec@1 75.154 Prec@5 86.728\n",
      " * Prec@1 75.152 Prec@5 86.738\n",
      " * Prec@1 75.226 Prec@5 86.672\n",
      " * Prec@1 75.000 Prec@5 86.458\n",
      " * Prec@1 74.853 Prec@5 86.324\n",
      " * Prec@1 74.927 Prec@5 86.410\n",
      " * Prec@1 75.000 Prec@5 86.494\n",
      " * Prec@1 74.929 Prec@5 86.435\n",
      " * Prec@1 74.508 Prec@5 86.236\n",
      " * Prec@1 74.583 Prec@5 86.319\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.540 (0.512)\n",
      "\n",
      "Loss 0.4382 (1.5990)\n",
      "\n",
      "Prec@1 81.250 (74.657)\n",
      "\n",
      "Prec@5 100.000 (86.470)\n",
      "\n",
      " * Prec@1 74.657 Prec@5 86.470\n",
      " * Prec@1 74.660 Prec@5 86.413\n",
      " * Prec@1 74.731 Prec@5 86.358\n",
      " * Prec@1 74.535 Prec@5 86.237\n",
      " * Prec@1 74.474 Prec@5 86.118\n",
      " * Prec@1 74.609 Prec@5 86.198\n",
      " * Prec@1 74.807 Prec@5 86.276\n",
      " * Prec@1 74.872 Prec@5 86.288\n",
      " * Prec@1 74.874 Prec@5 86.237\n",
      " * Prec@1 75.000 Prec@5 86.375\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.520 (0.512)\n",
      "\n",
      "Loss 2.5443 (1.5902)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 75.000 (86.262)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.262\n",
      " * Prec@1 74.939 Prec@5 86.152\n",
      " * Prec@1 75.000 Prec@5 86.165\n",
      " * Prec@1 74.760 Prec@5 85.998\n",
      " * Prec@1 74.881 Prec@5 86.071\n",
      " * Prec@1 74.823 Prec@5 85.967\n",
      " * Prec@1 74.883 Prec@5 85.981\n",
      " * Prec@1 74.942 Prec@5 85.995\n",
      " * Prec@1 74.943 Prec@5 86.009\n",
      " * Prec@1 74.943 Prec@5 86.023\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.491 (0.511)\n",
      "\n",
      "Loss 1.9555 (1.6058)\n",
      "\n",
      "Prec@1 68.750 (74.887)\n",
      "\n",
      "Prec@5 81.250 (85.980)\n",
      "\n",
      " * Prec@1 74.887 Prec@5 85.980\n",
      " * Prec@1 74.944 Prec@5 86.049\n",
      " * Prec@1 75.055 Prec@5 86.062\n",
      " * Prec@1 75.000 Prec@5 86.129\n",
      " * Prec@1 75.109 Prec@5 86.196\n",
      " * Prec@1 75.216 Prec@5 86.261\n",
      " * Prec@1 75.053 Prec@5 86.218\n",
      " * Prec@1 75.159 Prec@5 86.282\n",
      " * Prec@1 75.158 Prec@5 86.292\n",
      " * Prec@1 75.260 Prec@5 86.354\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.532 (0.511)\n",
      "\n",
      "Loss 1.7368 (1.5879)\n",
      "\n",
      "Prec@1 62.500 (75.155)\n",
      "\n",
      "Prec@5 81.250 (86.312)\n",
      "\n",
      " * Prec@1 75.155 Prec@5 86.312\n",
      " * Prec@1 75.102 Prec@5 86.219\n",
      " * Prec@1 75.152 Prec@5 86.179\n",
      " * Prec@1 75.151 Prec@5 86.139\n",
      " * Prec@1 75.150 Prec@5 86.050\n",
      " * Prec@1 75.248 Prec@5 86.111\n",
      " * Prec@1 75.197 Prec@5 86.171\n",
      " * Prec@1 75.146 Prec@5 86.133\n",
      " * Prec@1 75.194 Prec@5 86.143\n",
      " * Prec@1 75.288 Prec@5 86.154\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.521 (0.510)\n",
      "\n",
      "Loss 1.9981 (1.5953)\n",
      "\n",
      "Prec@1 68.750 (75.239)\n",
      "\n",
      "Prec@5 81.250 (86.116)\n",
      "\n",
      " * Prec@1 75.239 Prec@5 86.116\n",
      " * Prec@1 75.331 Prec@5 86.174\n",
      " * Prec@1 75.329 Prec@5 86.184\n",
      " * Prec@1 75.420 Prec@5 86.194\n",
      " * Prec@1 75.509 Prec@5 86.296\n",
      " * Prec@1 75.368 Prec@5 86.075\n",
      " * Prec@1 75.456 Prec@5 86.086\n",
      " * Prec@1 75.543 Prec@5 86.141\n",
      " * Prec@1 75.495 Prec@5 86.106\n",
      " * Prec@1 75.403 Prec@5 86.066\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [24][0/558]\t\\Time 0.571 (0.571)\tData 0.461 (0.461)\tLoss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [24][100/558]\t\\Time 0.561 (0.526)\tData 0.458 (0.424)\tLoss 0.0013 (0.0119)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [24][200/558]\t\\Time 0.531 (0.525)\tData 0.412 (0.422)\tLoss 0.0014 (0.0120)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [24][300/558]\t\\Time 0.522 (0.529)\tData 0.408 (0.425)\tLoss 0.0010 (0.0092)\tPrec@1 100.000 (99.689)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [24][400/558]\t\\Time 0.456 (0.530)\tData 0.381 (0.427)\tLoss 0.0401 (0.0085)\tPrec@1 100.000 (99.735)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [24][500/558]\t\\Time 0.486 (0.530)\tData 0.415 (0.428)\tLoss 0.0012 (0.0087)\tPrec@1 100.000 (99.726)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.553 (0.553)\n",
      "\n",
      "Loss 1.7342 (1.7342)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 91.667\n",
      " * Prec@1 78.125 Prec@5 90.625\n",
      " * Prec@1 77.500 Prec@5 88.750\n",
      " * Prec@1 79.167 Prec@5 90.625\n",
      " * Prec@1 80.357 Prec@5 91.071\n",
      " * Prec@1 77.344 Prec@5 90.625\n",
      " * Prec@1 78.472 Prec@5 91.667\n",
      " * Prec@1 78.125 Prec@5 91.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.531 (0.563)\n",
      "\n",
      "Loss 1.3435 (1.1315)\n",
      "\n",
      "Prec@1 75.000 (77.841)\n",
      "\n",
      "Prec@5 93.750 (91.477)\n",
      "\n",
      " * Prec@1 77.841 Prec@5 91.477\n",
      " * Prec@1 78.125 Prec@5 91.146\n",
      " * Prec@1 79.327 Prec@5 91.827\n",
      " * Prec@1 79.911 Prec@5 91.518\n",
      " * Prec@1 80.000 Prec@5 91.250\n",
      " * Prec@1 80.078 Prec@5 91.406\n",
      " * Prec@1 79.412 Prec@5 91.544\n",
      " * Prec@1 79.514 Prec@5 90.972\n",
      " * Prec@1 80.263 Prec@5 91.118\n",
      " * Prec@1 79.688 Prec@5 90.625\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.558 (0.556)\n",
      "\n",
      "Loss 2.3787 (1.2727)\n",
      "\n",
      "Prec@1 62.500 (78.869)\n",
      "\n",
      "Prec@5 81.250 (90.179)\n",
      "\n",
      " * Prec@1 78.869 Prec@5 90.179\n",
      " * Prec@1 78.693 Prec@5 89.773\n",
      " * Prec@1 78.261 Prec@5 89.674\n",
      " * Prec@1 77.344 Prec@5 89.323\n",
      " * Prec@1 77.500 Prec@5 89.000\n",
      " * Prec@1 77.404 Prec@5 88.702\n",
      " * Prec@1 76.852 Prec@5 88.194\n",
      " * Prec@1 77.009 Prec@5 88.170\n",
      " * Prec@1 76.509 Prec@5 87.716\n",
      " * Prec@1 76.458 Prec@5 87.500\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.516 (0.551)\n",
      "\n",
      "Loss 0.6924 (1.4941)\n",
      "\n",
      "Prec@1 75.000 (76.411)\n",
      "\n",
      "Prec@5 93.750 (87.702)\n",
      "\n",
      " * Prec@1 76.411 Prec@5 87.702\n",
      " * Prec@1 76.562 Prec@5 87.695\n",
      " * Prec@1 76.705 Prec@5 87.500\n",
      " * Prec@1 77.022 Prec@5 87.684\n",
      " * Prec@1 77.143 Prec@5 87.679\n",
      " * Prec@1 77.257 Prec@5 87.674\n",
      " * Prec@1 77.196 Prec@5 87.500\n",
      " * Prec@1 77.138 Prec@5 87.171\n",
      " * Prec@1 77.083 Prec@5 87.179\n",
      " * Prec@1 76.875 Prec@5 87.031\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.440 (0.546)\n",
      "\n",
      "Loss 0.8914 (1.4645)\n",
      "\n",
      "Prec@1 87.500 (77.134)\n",
      "\n",
      "Prec@5 100.000 (87.348)\n",
      "\n",
      " * Prec@1 77.134 Prec@5 87.348\n",
      " * Prec@1 77.083 Prec@5 87.202\n",
      " * Prec@1 76.453 Prec@5 86.919\n",
      " * Prec@1 75.852 Prec@5 86.932\n",
      " * Prec@1 75.556 Prec@5 86.528\n",
      " * Prec@1 75.408 Prec@5 86.413\n",
      " * Prec@1 75.532 Prec@5 86.569\n",
      " * Prec@1 75.391 Prec@5 86.849\n",
      " * Prec@1 75.383 Prec@5 86.862\n",
      " * Prec@1 75.625 Prec@5 87.000\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.593 (0.545)\n",
      "\n",
      "Loss 1.9609 (1.5378)\n",
      "\n",
      "Prec@1 75.000 (75.613)\n",
      "\n",
      "Prec@5 81.250 (86.887)\n",
      "\n",
      " * Prec@1 75.613 Prec@5 86.887\n",
      " * Prec@1 75.841 Prec@5 87.019\n",
      " * Prec@1 75.708 Prec@5 87.028\n",
      " * Prec@1 75.579 Prec@5 87.153\n",
      " * Prec@1 75.455 Prec@5 87.045\n",
      " * Prec@1 75.446 Prec@5 86.942\n",
      " * Prec@1 75.439 Prec@5 86.952\n",
      " * Prec@1 75.647 Prec@5 86.961\n",
      " * Prec@1 75.424 Prec@5 86.970\n",
      " * Prec@1 75.521 Prec@5 86.875\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.485 (0.542)\n",
      "\n",
      "Loss 0.5220 (1.5190)\n",
      "\n",
      "Prec@1 81.250 (75.615)\n",
      "\n",
      "Prec@5 100.000 (87.090)\n",
      "\n",
      " * Prec@1 75.615 Prec@5 87.090\n",
      " * Prec@1 75.706 Prec@5 87.298\n",
      " * Prec@1 75.893 Prec@5 87.401\n",
      " * Prec@1 76.172 Prec@5 87.598\n",
      " * Prec@1 76.250 Prec@5 87.596\n",
      " * Prec@1 75.758 Prec@5 87.405\n",
      " * Prec@1 75.840 Prec@5 87.407\n",
      " * Prec@1 75.643 Prec@5 87.316\n",
      " * Prec@1 75.453 Prec@5 87.228\n",
      " * Prec@1 75.268 Prec@5 86.875\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.543 (0.539)\n",
      "\n",
      "Loss 1.7265 (1.5208)\n",
      "\n",
      "Prec@1 62.500 (75.088)\n",
      "\n",
      "Prec@5 81.250 (86.796)\n",
      "\n",
      " * Prec@1 75.088 Prec@5 86.796\n",
      " * Prec@1 75.000 Prec@5 86.719\n",
      " * Prec@1 74.829 Prec@5 86.729\n",
      " * Prec@1 74.916 Prec@5 86.824\n",
      " * Prec@1 74.917 Prec@5 86.750\n",
      " * Prec@1 74.589 Prec@5 86.595\n",
      " * Prec@1 74.756 Prec@5 86.688\n",
      " * Prec@1 74.840 Prec@5 86.779\n",
      " * Prec@1 74.921 Prec@5 86.709\n",
      " * Prec@1 74.922 Prec@5 86.875\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.542 (0.538)\n",
      "\n",
      "Loss 3.6398 (1.5656)\n",
      "\n",
      "Prec@1 50.000 (74.614)\n",
      "\n",
      "Prec@5 75.000 (86.728)\n",
      "\n",
      " * Prec@1 74.614 Prec@5 86.728\n",
      " * Prec@1 74.619 Prec@5 86.662\n",
      " * Prec@1 74.699 Prec@5 86.596\n",
      " * Prec@1 74.479 Prec@5 86.384\n",
      " * Prec@1 74.338 Prec@5 86.250\n",
      " * Prec@1 74.419 Prec@5 86.265\n",
      " * Prec@1 74.497 Prec@5 86.279\n",
      " * Prec@1 74.432 Prec@5 86.222\n",
      " * Prec@1 74.017 Prec@5 86.025\n",
      " * Prec@1 74.097 Prec@5 86.111\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.540 (0.536)\n",
      "\n",
      "Loss 0.5248 (1.5915)\n",
      "\n",
      "Prec@1 81.250 (74.176)\n",
      "\n",
      "Prec@5 100.000 (86.264)\n",
      "\n",
      " * Prec@1 74.176 Prec@5 86.264\n",
      " * Prec@1 74.185 Prec@5 86.209\n",
      " * Prec@1 74.261 Prec@5 86.223\n",
      " * Prec@1 74.069 Prec@5 86.104\n",
      " * Prec@1 74.079 Prec@5 86.118\n",
      " * Prec@1 74.284 Prec@5 86.198\n",
      " * Prec@1 74.485 Prec@5 86.276\n",
      " * Prec@1 74.490 Prec@5 86.352\n",
      " * Prec@1 74.495 Prec@5 86.364\n",
      " * Prec@1 74.625 Prec@5 86.500\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.573 (0.538)\n",
      "\n",
      "Loss 2.4983 (1.5792)\n",
      "\n",
      "Prec@1 68.750 (74.567)\n",
      "\n",
      "Prec@5 75.000 (86.386)\n",
      "\n",
      " * Prec@1 74.567 Prec@5 86.386\n",
      " * Prec@1 74.510 Prec@5 86.275\n",
      " * Prec@1 74.575 Prec@5 86.286\n",
      " * Prec@1 74.339 Prec@5 86.058\n",
      " * Prec@1 74.464 Prec@5 86.131\n",
      " * Prec@1 74.351 Prec@5 86.085\n",
      " * Prec@1 74.357 Prec@5 86.098\n",
      " * Prec@1 74.421 Prec@5 86.111\n",
      " * Prec@1 74.369 Prec@5 86.124\n",
      " * Prec@1 74.375 Prec@5 86.136\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.536 (0.541)\n",
      "\n",
      "Loss 1.8323 (1.5967)\n",
      "\n",
      "Prec@1 68.750 (74.324)\n",
      "\n",
      "Prec@5 87.500 (86.149)\n",
      "\n",
      " * Prec@1 74.324 Prec@5 86.149\n",
      " * Prec@1 74.386 Prec@5 86.217\n",
      " * Prec@1 74.502 Prec@5 86.228\n",
      " * Prec@1 74.452 Prec@5 86.294\n",
      " * Prec@1 74.565 Prec@5 86.359\n",
      " * Prec@1 74.677 Prec@5 86.422\n",
      " * Prec@1 74.519 Prec@5 86.378\n",
      " * Prec@1 74.629 Prec@5 86.441\n",
      " * Prec@1 74.580 Prec@5 86.450\n",
      " * Prec@1 74.688 Prec@5 86.510\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.551 (0.542)\n",
      "\n",
      "Loss 1.8086 (1.5790)\n",
      "\n",
      "Prec@1 62.500 (74.587)\n",
      "\n",
      "Prec@5 75.000 (86.415)\n",
      "\n",
      " * Prec@1 74.587 Prec@5 86.415\n",
      " * Prec@1 74.539 Prec@5 86.322\n",
      " * Prec@1 74.593 Prec@5 86.280\n",
      " * Prec@1 74.597 Prec@5 86.290\n",
      " * Prec@1 74.550 Prec@5 86.200\n",
      " * Prec@1 74.653 Prec@5 86.260\n",
      " * Prec@1 74.606 Prec@5 86.270\n",
      " * Prec@1 74.561 Prec@5 86.230\n",
      " * Prec@1 74.612 Prec@5 86.289\n",
      " * Prec@1 74.712 Prec@5 86.298\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.523 (0.540)\n",
      "\n",
      "Loss 1.8890 (1.5850)\n",
      "\n",
      "Prec@1 75.000 (74.714)\n",
      "\n",
      "Prec@5 81.250 (86.260)\n",
      "\n",
      " * Prec@1 74.714 Prec@5 86.260\n",
      " * Prec@1 74.763 Prec@5 86.316\n",
      " * Prec@1 74.765 Prec@5 86.325\n",
      " * Prec@1 74.860 Prec@5 86.334\n",
      " * Prec@1 74.954 Prec@5 86.435\n",
      " * Prec@1 74.816 Prec@5 86.259\n",
      " * Prec@1 74.909 Prec@5 86.268\n",
      " * Prec@1 75.000 Prec@5 86.322\n",
      " * Prec@1 74.955 Prec@5 86.241\n",
      " * Prec@1 74.910 Prec@5 86.201\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [25][0/558]\t\\Time 0.567 (0.567)\tData 0.451 (0.451)\tLoss 0.0016 (0.0016)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [25][100/558]\t\\Time 0.533 (0.511)\tData 0.431 (0.409)\tLoss 0.0014 (0.0083)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [25][200/558]\t\\Time 0.529 (0.511)\tData 0.419 (0.408)\tLoss 0.0062 (0.0089)\tPrec@1 100.000 (99.658)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [25][300/558]\t\\Time 0.500 (0.509)\tData 0.403 (0.407)\tLoss 0.0021 (0.0099)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [25][400/558]\t\\Time 0.561 (0.509)\tData 0.434 (0.407)\tLoss 0.0012 (0.0102)\tPrec@1 100.000 (99.642)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [25][500/558]\t\\Time 0.521 (0.509)\tData 0.411 (0.407)\tLoss 0.0006 (0.0096)\tPrec@1 100.000 (99.676)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.500 (0.500)\n",
      "\n",
      "Loss 1.8544 (1.8544)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 78.750 Prec@5 87.500\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 90.179\n",
      " * Prec@1 78.125 Prec@5 89.844\n",
      " * Prec@1 79.861 Prec@5 90.972\n",
      " * Prec@1 80.000 Prec@5 90.000\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.551 (0.527)\n",
      "\n",
      "Loss 1.0764 (1.1013)\n",
      "\n",
      "Prec@1 81.250 (80.114)\n",
      "\n",
      "Prec@5 93.750 (90.341)\n",
      "\n",
      " * Prec@1 80.114 Prec@5 90.341\n",
      " * Prec@1 80.208 Prec@5 90.104\n",
      " * Prec@1 80.769 Prec@5 90.865\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      " * Prec@1 81.250 Prec@5 90.417\n",
      " * Prec@1 81.250 Prec@5 91.016\n",
      " * Prec@1 80.515 Prec@5 90.809\n",
      " * Prec@1 80.556 Prec@5 90.278\n",
      " * Prec@1 81.250 Prec@5 90.461\n",
      " * Prec@1 80.625 Prec@5 90.000\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.551 (0.519)\n",
      "\n",
      "Loss 2.3497 (1.2465)\n",
      "\n",
      "Prec@1 62.500 (79.762)\n",
      "\n",
      "Prec@5 81.250 (89.583)\n",
      "\n",
      " * Prec@1 79.762 Prec@5 89.583\n",
      " * Prec@1 79.545 Prec@5 89.205\n",
      " * Prec@1 79.348 Prec@5 89.402\n",
      " * Prec@1 78.385 Prec@5 88.542\n",
      " * Prec@1 78.500 Prec@5 88.250\n",
      " * Prec@1 78.365 Prec@5 87.981\n",
      " * Prec@1 77.778 Prec@5 87.500\n",
      " * Prec@1 77.902 Prec@5 87.500\n",
      " * Prec@1 77.371 Prec@5 87.069\n",
      " * Prec@1 77.292 Prec@5 86.875\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.471 (0.517)\n",
      "\n",
      "Loss 0.6126 (1.4853)\n",
      "\n",
      "Prec@1 81.250 (77.419)\n",
      "\n",
      "Prec@5 87.500 (86.895)\n",
      "\n",
      " * Prec@1 77.419 Prec@5 86.895\n",
      " * Prec@1 77.539 Prec@5 86.914\n",
      " * Prec@1 77.652 Prec@5 86.742\n",
      " * Prec@1 77.941 Prec@5 86.949\n",
      " * Prec@1 78.036 Prec@5 86.964\n",
      " * Prec@1 78.125 Prec@5 86.979\n",
      " * Prec@1 77.872 Prec@5 86.824\n",
      " * Prec@1 77.796 Prec@5 86.513\n",
      " * Prec@1 77.724 Prec@5 86.538\n",
      " * Prec@1 77.500 Prec@5 86.406\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.454 (0.515)\n",
      "\n",
      "Loss 0.7260 (1.4492)\n",
      "\n",
      "Prec@1 87.500 (77.744)\n",
      "\n",
      "Prec@5 100.000 (86.738)\n",
      "\n",
      " * Prec@1 77.744 Prec@5 86.738\n",
      " * Prec@1 77.530 Prec@5 86.756\n",
      " * Prec@1 77.035 Prec@5 86.628\n",
      " * Prec@1 76.420 Prec@5 86.648\n",
      " * Prec@1 75.972 Prec@5 86.250\n",
      " * Prec@1 75.815 Prec@5 86.141\n",
      " * Prec@1 75.931 Prec@5 86.303\n",
      " * Prec@1 75.781 Prec@5 86.589\n",
      " * Prec@1 75.765 Prec@5 86.607\n",
      " * Prec@1 76.000 Prec@5 86.750\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.522 (0.513)\n",
      "\n",
      "Loss 1.9111 (1.5195)\n",
      "\n",
      "Prec@1 75.000 (75.980)\n",
      "\n",
      "Prec@5 81.250 (86.642)\n",
      "\n",
      " * Prec@1 75.980 Prec@5 86.642\n",
      " * Prec@1 76.202 Prec@5 86.779\n",
      " * Prec@1 76.061 Prec@5 86.792\n",
      " * Prec@1 75.926 Prec@5 86.921\n",
      " * Prec@1 75.795 Prec@5 86.818\n",
      " * Prec@1 75.781 Prec@5 86.719\n",
      " * Prec@1 75.768 Prec@5 86.732\n",
      " * Prec@1 75.970 Prec@5 86.746\n",
      " * Prec@1 75.742 Prec@5 86.547\n",
      " * Prec@1 75.833 Prec@5 86.458\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.481 (0.512)\n",
      "\n",
      "Loss 0.5226 (1.5023)\n",
      "\n",
      "Prec@1 81.250 (75.922)\n",
      "\n",
      "Prec@5 100.000 (86.680)\n",
      "\n",
      " * Prec@1 75.922 Prec@5 86.680\n",
      " * Prec@1 76.008 Prec@5 86.895\n",
      " * Prec@1 76.190 Prec@5 87.004\n",
      " * Prec@1 76.465 Prec@5 87.207\n",
      " * Prec@1 76.538 Prec@5 87.212\n",
      " * Prec@1 76.042 Prec@5 87.027\n",
      " * Prec@1 76.119 Prec@5 87.127\n",
      " * Prec@1 75.919 Prec@5 87.040\n",
      " * Prec@1 75.725 Prec@5 86.957\n",
      " * Prec@1 75.536 Prec@5 86.607\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.520 (0.511)\n",
      "\n",
      "Loss 1.9225 (1.5114)\n",
      "\n",
      "Prec@1 62.500 (75.352)\n",
      "\n",
      "Prec@5 81.250 (86.532)\n",
      "\n",
      " * Prec@1 75.352 Prec@5 86.532\n",
      " * Prec@1 75.260 Prec@5 86.458\n",
      " * Prec@1 75.086 Prec@5 86.473\n",
      " * Prec@1 75.169 Prec@5 86.571\n",
      " * Prec@1 75.167 Prec@5 86.500\n",
      " * Prec@1 74.753 Prec@5 86.349\n",
      " * Prec@1 74.919 Prec@5 86.445\n",
      " * Prec@1 75.000 Prec@5 86.538\n",
      " * Prec@1 75.079 Prec@5 86.472\n",
      " * Prec@1 75.078 Prec@5 86.641\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.545 (0.513)\n",
      "\n",
      "Loss 3.2947 (1.5566)\n",
      "\n",
      "Prec@1 50.000 (74.769)\n",
      "\n",
      "Prec@5 75.000 (86.497)\n",
      "\n",
      " * Prec@1 74.769 Prec@5 86.497\n",
      " * Prec@1 74.771 Prec@5 86.433\n",
      " * Prec@1 74.849 Prec@5 86.370\n",
      " * Prec@1 74.628 Prec@5 86.086\n",
      " * Prec@1 74.485 Prec@5 85.956\n",
      " * Prec@1 74.564 Prec@5 85.974\n",
      " * Prec@1 74.641 Prec@5 85.991\n",
      " * Prec@1 74.574 Prec@5 85.938\n",
      " * Prec@1 74.157 Prec@5 85.674\n",
      " * Prec@1 74.236 Prec@5 85.764\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.526 (0.512)\n",
      "\n",
      "Loss 0.5362 (1.5851)\n",
      "\n",
      "Prec@1 81.250 (74.313)\n",
      "\n",
      "Prec@5 100.000 (85.920)\n",
      "\n",
      " * Prec@1 74.313 Prec@5 85.920\n",
      " * Prec@1 74.321 Prec@5 85.870\n",
      " * Prec@1 74.395 Prec@5 85.820\n",
      " * Prec@1 74.202 Prec@5 85.705\n",
      " * Prec@1 74.013 Prec@5 85.724\n",
      " * Prec@1 74.219 Prec@5 85.807\n",
      " * Prec@1 74.420 Prec@5 85.889\n",
      " * Prec@1 74.490 Prec@5 85.969\n",
      " * Prec@1 74.495 Prec@5 85.985\n",
      " * Prec@1 74.625 Prec@5 86.125\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.521 (0.511)\n",
      "\n",
      "Loss 2.4252 (1.5742)\n",
      "\n",
      "Prec@1 68.750 (74.567)\n",
      "\n",
      "Prec@5 81.250 (86.077)\n",
      "\n",
      " * Prec@1 74.567 Prec@5 86.077\n",
      " * Prec@1 74.510 Prec@5 85.968\n",
      " * Prec@1 74.575 Prec@5 85.983\n",
      " * Prec@1 74.339 Prec@5 85.817\n",
      " * Prec@1 74.464 Prec@5 85.893\n",
      " * Prec@1 74.410 Prec@5 85.849\n",
      " * Prec@1 74.416 Prec@5 85.923\n",
      " * Prec@1 74.479 Prec@5 85.938\n",
      " * Prec@1 74.427 Prec@5 85.952\n",
      " * Prec@1 74.432 Prec@5 85.966\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.510 (0.512)\n",
      "\n",
      "Loss 1.6926 (1.5913)\n",
      "\n",
      "Prec@1 68.750 (74.381)\n",
      "\n",
      "Prec@5 87.500 (85.980)\n",
      "\n",
      " * Prec@1 74.381 Prec@5 85.980\n",
      " * Prec@1 74.442 Prec@5 86.049\n",
      " * Prec@1 74.558 Prec@5 86.062\n",
      " * Prec@1 74.452 Prec@5 86.129\n",
      " * Prec@1 74.565 Prec@5 86.250\n",
      " * Prec@1 74.623 Prec@5 86.315\n",
      " * Prec@1 74.466 Prec@5 86.271\n",
      " * Prec@1 74.576 Prec@5 86.335\n",
      " * Prec@1 74.527 Prec@5 86.345\n",
      " * Prec@1 74.635 Prec@5 86.406\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.501 (0.512)\n",
      "\n",
      "Loss 1.8310 (1.5720)\n",
      "\n",
      "Prec@1 62.500 (74.535)\n",
      "\n",
      "Prec@5 81.250 (86.364)\n",
      "\n",
      " * Prec@1 74.535 Prec@5 86.364\n",
      " * Prec@1 74.488 Prec@5 86.270\n",
      " * Prec@1 74.543 Prec@5 86.230\n",
      " * Prec@1 74.546 Prec@5 86.240\n",
      " * Prec@1 74.500 Prec@5 86.150\n",
      " * Prec@1 74.554 Prec@5 86.210\n",
      " * Prec@1 74.508 Prec@5 86.171\n",
      " * Prec@1 74.512 Prec@5 86.133\n",
      " * Prec@1 74.564 Prec@5 86.192\n",
      " * Prec@1 74.663 Prec@5 86.250\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.502 (0.510)\n",
      "\n",
      "Loss 1.8495 (1.5788)\n",
      "\n",
      "Prec@1 75.000 (74.666)\n",
      "\n",
      "Prec@5 81.250 (86.212)\n",
      "\n",
      " * Prec@1 74.666 Prec@5 86.212\n",
      " * Prec@1 74.763 Prec@5 86.269\n",
      " * Prec@1 74.765 Prec@5 86.278\n",
      " * Prec@1 74.860 Prec@5 86.287\n",
      " * Prec@1 74.954 Prec@5 86.389\n",
      " * Prec@1 74.816 Prec@5 86.167\n",
      " * Prec@1 74.909 Prec@5 86.177\n",
      " * Prec@1 75.000 Prec@5 86.232\n",
      " * Prec@1 74.955 Prec@5 86.151\n",
      " * Prec@1 74.910 Prec@5 86.111\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [26][0/558]\t\\Time 0.514 (0.514)\tData 0.397 (0.397)\tLoss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [26][100/558]\t\\Time 0.537 (0.507)\tData 0.427 (0.405)\tLoss 0.0016 (0.0073)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [26][200/558]\t\\Time 0.559 (0.506)\tData 0.448 (0.404)\tLoss 0.0008 (0.0097)\tPrec@1 100.000 (99.689)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [26][300/558]\t\\Time 0.470 (0.504)\tData 0.360 (0.403)\tLoss 0.0015 (0.0079)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [26][400/558]\t\\Time 0.496 (0.506)\tData 0.426 (0.404)\tLoss 0.0005 (0.0077)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [26][500/558]\t\\Time 0.588 (0.506)\tData 0.482 (0.405)\tLoss 0.1245 (0.0083)\tPrec@1 93.750 (99.726)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.521 (0.521)\n",
      "\n",
      "Loss 1.6170 (1.6170)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 75.000 Prec@5 89.583\n",
      " * Prec@1 76.562 Prec@5 89.062\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 78.571 Prec@5 90.179\n",
      " * Prec@1 75.781 Prec@5 89.844\n",
      " * Prec@1 77.778 Prec@5 90.972\n",
      " * Prec@1 77.500 Prec@5 90.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.499 (0.528)\n",
      "\n",
      "Loss 1.4292 (1.1061)\n",
      "\n",
      "Prec@1 75.000 (77.273)\n",
      "\n",
      "Prec@5 81.250 (89.773)\n",
      "\n",
      " * Prec@1 77.273 Prec@5 89.773\n",
      " * Prec@1 77.604 Prec@5 89.583\n",
      " * Prec@1 78.365 Prec@5 90.385\n",
      " * Prec@1 79.018 Prec@5 90.179\n",
      " * Prec@1 79.167 Prec@5 90.000\n",
      " * Prec@1 79.688 Prec@5 90.625\n",
      " * Prec@1 79.044 Prec@5 90.441\n",
      " * Prec@1 79.167 Prec@5 89.931\n",
      " * Prec@1 79.934 Prec@5 90.132\n",
      " * Prec@1 79.375 Prec@5 89.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.524 (0.516)\n",
      "\n",
      "Loss 2.4579 (1.2427)\n",
      "\n",
      "Prec@1 68.750 (78.869)\n",
      "\n",
      "Prec@5 75.000 (88.988)\n",
      "\n",
      " * Prec@1 78.869 Prec@5 88.988\n",
      " * Prec@1 78.409 Prec@5 88.636\n",
      " * Prec@1 78.261 Prec@5 89.130\n",
      " * Prec@1 77.083 Prec@5 88.542\n",
      " * Prec@1 77.250 Prec@5 88.500\n",
      " * Prec@1 77.163 Prec@5 88.221\n",
      " * Prec@1 76.620 Prec@5 87.731\n",
      " * Prec@1 76.786 Prec@5 87.723\n",
      " * Prec@1 76.293 Prec@5 87.284\n",
      " * Prec@1 76.250 Prec@5 87.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.501 (0.518)\n",
      "\n",
      "Loss 0.6781 (1.4717)\n",
      "\n",
      "Prec@1 81.250 (76.411)\n",
      "\n",
      "Prec@5 93.750 (87.298)\n",
      "\n",
      " * Prec@1 76.411 Prec@5 87.298\n",
      " * Prec@1 76.562 Prec@5 87.305\n",
      " * Prec@1 76.326 Prec@5 87.121\n",
      " * Prec@1 76.654 Prec@5 87.316\n",
      " * Prec@1 76.786 Prec@5 87.321\n",
      " * Prec@1 76.910 Prec@5 87.500\n",
      " * Prec@1 76.858 Prec@5 87.500\n",
      " * Prec@1 76.809 Prec@5 87.171\n",
      " * Prec@1 76.763 Prec@5 87.179\n",
      " * Prec@1 76.719 Prec@5 87.031\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.457 (0.519)\n",
      "\n",
      "Loss 0.7634 (1.4462)\n",
      "\n",
      "Prec@1 81.250 (76.829)\n",
      "\n",
      "Prec@5 100.000 (87.348)\n",
      "\n",
      " * Prec@1 76.829 Prec@5 87.348\n",
      " * Prec@1 76.786 Prec@5 87.202\n",
      " * Prec@1 76.163 Prec@5 86.628\n",
      " * Prec@1 75.710 Prec@5 86.506\n",
      " * Prec@1 75.278 Prec@5 86.111\n",
      " * Prec@1 75.136 Prec@5 86.005\n",
      " * Prec@1 75.266 Prec@5 86.170\n",
      " * Prec@1 75.260 Prec@5 86.458\n",
      " * Prec@1 75.383 Prec@5 86.480\n",
      " * Prec@1 75.750 Prec@5 86.625\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.524 (0.517)\n",
      "\n",
      "Loss 1.6843 (1.5061)\n",
      "\n",
      "Prec@1 75.000 (75.735)\n",
      "\n",
      "Prec@5 81.250 (86.520)\n",
      "\n",
      " * Prec@1 75.735 Prec@5 86.520\n",
      " * Prec@1 75.962 Prec@5 86.659\n",
      " * Prec@1 75.825 Prec@5 86.557\n",
      " * Prec@1 75.810 Prec@5 86.690\n",
      " * Prec@1 75.682 Prec@5 86.477\n",
      " * Prec@1 75.670 Prec@5 86.384\n",
      " * Prec@1 75.768 Prec@5 86.404\n",
      " * Prec@1 75.970 Prec@5 86.422\n",
      " * Prec@1 75.742 Prec@5 86.335\n",
      " * Prec@1 75.833 Prec@5 86.250\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.483 (0.517)\n",
      "\n",
      "Loss 0.4947 (1.4922)\n",
      "\n",
      "Prec@1 81.250 (75.922)\n",
      "\n",
      "Prec@5 100.000 (86.475)\n",
      "\n",
      " * Prec@1 75.922 Prec@5 86.475\n",
      " * Prec@1 76.210 Prec@5 86.694\n",
      " * Prec@1 76.290 Prec@5 86.806\n",
      " * Prec@1 76.562 Prec@5 87.012\n",
      " * Prec@1 76.635 Prec@5 87.019\n",
      " * Prec@1 76.231 Prec@5 86.837\n",
      " * Prec@1 76.306 Prec@5 86.847\n",
      " * Prec@1 76.103 Prec@5 86.765\n",
      " * Prec@1 75.906 Prec@5 86.685\n",
      " * Prec@1 75.714 Prec@5 86.339\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.510 (0.515)\n",
      "\n",
      "Loss 1.4652 (1.4989)\n",
      "\n",
      "Prec@1 62.500 (75.528)\n",
      "\n",
      "Prec@5 81.250 (86.268)\n",
      "\n",
      " * Prec@1 75.528 Prec@5 86.268\n",
      " * Prec@1 75.434 Prec@5 86.198\n",
      " * Prec@1 75.257 Prec@5 86.216\n",
      " * Prec@1 75.338 Prec@5 86.233\n",
      " * Prec@1 75.333 Prec@5 86.167\n",
      " * Prec@1 75.000 Prec@5 86.020\n",
      " * Prec@1 75.081 Prec@5 86.039\n",
      " * Prec@1 75.240 Prec@5 86.138\n",
      " * Prec@1 75.316 Prec@5 86.076\n",
      " * Prec@1 75.312 Prec@5 86.172\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.503 (0.514)\n",
      "\n",
      "Loss 3.6650 (1.5436)\n",
      "\n",
      "Prec@1 50.000 (75.000)\n",
      "\n",
      "Prec@5 75.000 (86.034)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.034\n",
      " * Prec@1 75.000 Prec@5 86.052\n",
      " * Prec@1 75.075 Prec@5 85.994\n",
      " * Prec@1 74.851 Prec@5 85.789\n",
      " * Prec@1 74.706 Prec@5 85.662\n",
      " * Prec@1 74.782 Prec@5 85.683\n",
      " * Prec@1 74.856 Prec@5 85.776\n",
      " * Prec@1 74.787 Prec@5 85.724\n",
      " * Prec@1 74.368 Prec@5 85.534\n",
      " * Prec@1 74.444 Prec@5 85.625\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.526 (0.513)\n",
      "\n",
      "Loss 0.4205 (1.5706)\n",
      "\n",
      "Prec@1 81.250 (74.519)\n",
      "\n",
      "Prec@5 100.000 (85.783)\n",
      "\n",
      " * Prec@1 74.519 Prec@5 85.783\n",
      " * Prec@1 74.524 Prec@5 85.734\n",
      " * Prec@1 74.597 Prec@5 85.685\n",
      " * Prec@1 74.468 Prec@5 85.572\n",
      " * Prec@1 74.474 Prec@5 85.592\n",
      " * Prec@1 74.609 Prec@5 85.742\n",
      " * Prec@1 74.807 Prec@5 85.825\n",
      " * Prec@1 74.809 Prec@5 85.842\n",
      " * Prec@1 74.811 Prec@5 85.859\n",
      " * Prec@1 74.938 Prec@5 86.000\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.547 (0.513)\n",
      "\n",
      "Loss 2.4057 (1.5568)\n",
      "\n",
      "Prec@1 75.000 (74.938)\n",
      "\n",
      "Prec@5 75.000 (85.891)\n",
      "\n",
      " * Prec@1 74.938 Prec@5 85.891\n",
      " * Prec@1 74.877 Prec@5 85.784\n",
      " * Prec@1 74.939 Prec@5 85.801\n",
      " * Prec@1 74.700 Prec@5 85.637\n",
      " * Prec@1 74.821 Prec@5 85.714\n",
      " * Prec@1 74.705 Prec@5 85.613\n",
      " * Prec@1 74.766 Prec@5 85.631\n",
      " * Prec@1 74.826 Prec@5 85.648\n",
      " * Prec@1 74.828 Prec@5 85.665\n",
      " * Prec@1 74.773 Prec@5 85.682\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.473 (0.512)\n",
      "\n",
      "Loss 1.7687 (1.5718)\n",
      "\n",
      "Prec@1 68.750 (74.718)\n",
      "\n",
      "Prec@5 87.500 (85.698)\n",
      "\n",
      " * Prec@1 74.718 Prec@5 85.698\n",
      " * Prec@1 74.721 Prec@5 85.770\n",
      " * Prec@1 74.834 Prec@5 85.785\n",
      " * Prec@1 74.726 Prec@5 85.800\n",
      " * Prec@1 74.837 Prec@5 85.870\n",
      " * Prec@1 74.946 Prec@5 85.938\n",
      " * Prec@1 74.786 Prec@5 85.897\n",
      " * Prec@1 74.894 Prec@5 85.964\n",
      " * Prec@1 74.842 Prec@5 85.977\n",
      " * Prec@1 74.948 Prec@5 86.042\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.488 (0.511)\n",
      "\n",
      "Loss 1.8723 (1.5577)\n",
      "\n",
      "Prec@1 62.500 (74.845)\n",
      "\n",
      "Prec@5 81.250 (86.002)\n",
      "\n",
      " * Prec@1 74.845 Prec@5 86.002\n",
      " * Prec@1 74.795 Prec@5 85.912\n",
      " * Prec@1 74.848 Prec@5 85.874\n",
      " * Prec@1 74.899 Prec@5 85.887\n",
      " * Prec@1 74.850 Prec@5 85.800\n",
      " * Prec@1 74.950 Prec@5 85.863\n",
      " * Prec@1 74.902 Prec@5 85.876\n",
      " * Prec@1 74.854 Prec@5 85.889\n",
      " * Prec@1 74.903 Prec@5 85.901\n",
      " * Prec@1 75.000 Prec@5 85.913\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.532 (0.511)\n",
      "\n",
      "Loss 1.7936 (1.5617)\n",
      "\n",
      "Prec@1 68.750 (74.952)\n",
      "\n",
      "Prec@5 81.250 (85.878)\n",
      "\n",
      " * Prec@1 74.952 Prec@5 85.878\n",
      " * Prec@1 75.000 Prec@5 85.938\n",
      " * Prec@1 75.000 Prec@5 85.949\n",
      " * Prec@1 75.093 Prec@5 85.961\n",
      " * Prec@1 75.185 Prec@5 86.065\n",
      " * Prec@1 75.046 Prec@5 85.846\n",
      " * Prec@1 75.137 Prec@5 85.858\n",
      " * Prec@1 75.226 Prec@5 85.915\n",
      " * Prec@1 75.180 Prec@5 85.881\n",
      " * Prec@1 75.134 Prec@5 85.842\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [27][0/558]\t\\Time 0.540 (0.540)\tData 0.420 (0.420)\tLoss 0.0008 (0.0008)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [27][100/558]\t\\Time 0.481 (0.507)\tData 0.371 (0.406)\tLoss 0.0005 (0.0025)\tPrec@1 100.000 (99.938)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [27][200/558]\t\\Time 0.513 (0.507)\tData 0.430 (0.406)\tLoss 0.0005 (0.0051)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [27][300/558]\t\\Time 0.490 (0.506)\tData 0.380 (0.405)\tLoss 0.0018 (0.0059)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [27][400/558]\t\\Time 0.511 (0.506)\tData 0.400 (0.405)\tLoss 0.0008 (0.0062)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [27][500/558]\t\\Time 0.431 (0.506)\tData 0.360 (0.405)\tLoss 0.0008 (0.0065)\tPrec@1 100.000 (99.800)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.521 (0.521)\n",
      "\n",
      "Loss 1.7139 (1.7139)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 78.750 Prec@5 87.500\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 90.179\n",
      " * Prec@1 78.125 Prec@5 89.844\n",
      " * Prec@1 79.861 Prec@5 90.972\n",
      " * Prec@1 79.375 Prec@5 90.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.530 (0.531)\n",
      "\n",
      "Loss 1.4577 (1.1216)\n",
      "\n",
      "Prec@1 75.000 (78.977)\n",
      "\n",
      "Prec@5 87.500 (90.341)\n",
      "\n",
      " * Prec@1 78.977 Prec@5 90.341\n",
      " * Prec@1 79.167 Prec@5 90.104\n",
      " * Prec@1 80.288 Prec@5 90.865\n",
      " * Prec@1 80.804 Prec@5 90.625\n",
      " * Prec@1 80.833 Prec@5 90.417\n",
      " * Prec@1 80.859 Prec@5 91.016\n",
      " * Prec@1 80.147 Prec@5 91.176\n",
      " * Prec@1 80.208 Prec@5 90.625\n",
      " * Prec@1 80.921 Prec@5 90.789\n",
      " * Prec@1 80.312 Prec@5 90.312\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.510 (0.520)\n",
      "\n",
      "Loss 2.4316 (1.2742)\n",
      "\n",
      "Prec@1 62.500 (79.464)\n",
      "\n",
      "Prec@5 87.500 (90.179)\n",
      "\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 79.261 Prec@5 89.773\n",
      " * Prec@1 79.076 Prec@5 90.217\n",
      " * Prec@1 78.125 Prec@5 89.844\n",
      " * Prec@1 78.250 Prec@5 89.500\n",
      " * Prec@1 78.125 Prec@5 89.423\n",
      " * Prec@1 77.546 Prec@5 88.889\n",
      " * Prec@1 77.679 Prec@5 88.839\n",
      " * Prec@1 77.155 Prec@5 88.362\n",
      " * Prec@1 77.083 Prec@5 88.125\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.490 (0.520)\n",
      "\n",
      "Loss 0.8517 (1.4836)\n",
      "\n",
      "Prec@1 75.000 (77.016)\n",
      "\n",
      "Prec@5 87.500 (88.105)\n",
      "\n",
      " * Prec@1 77.016 Prec@5 88.105\n",
      " * Prec@1 77.148 Prec@5 88.281\n",
      " * Prec@1 77.273 Prec@5 88.068\n",
      " * Prec@1 77.574 Prec@5 88.235\n",
      " * Prec@1 77.679 Prec@5 88.214\n",
      " * Prec@1 77.778 Prec@5 88.368\n",
      " * Prec@1 77.703 Prec@5 88.345\n",
      " * Prec@1 77.632 Prec@5 87.993\n",
      " * Prec@1 77.564 Prec@5 87.981\n",
      " * Prec@1 77.500 Prec@5 87.812\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.450 (0.521)\n",
      "\n",
      "Loss 0.8264 (1.4528)\n",
      "\n",
      "Prec@1 87.500 (77.744)\n",
      "\n",
      "Prec@5 100.000 (88.110)\n",
      "\n",
      " * Prec@1 77.744 Prec@5 88.110\n",
      " * Prec@1 77.827 Prec@5 87.946\n",
      " * Prec@1 77.180 Prec@5 87.355\n",
      " * Prec@1 76.562 Prec@5 87.216\n",
      " * Prec@1 76.250 Prec@5 86.806\n",
      " * Prec@1 76.087 Prec@5 86.549\n",
      " * Prec@1 76.064 Prec@5 86.702\n",
      " * Prec@1 76.042 Prec@5 86.979\n",
      " * Prec@1 76.020 Prec@5 86.990\n",
      " * Prec@1 76.375 Prec@5 87.125\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.560 (0.519)\n",
      "\n",
      "Loss 1.7733 (1.5184)\n",
      "\n",
      "Prec@1 75.000 (76.348)\n",
      "\n",
      "Prec@5 81.250 (87.010)\n",
      "\n",
      " * Prec@1 76.348 Prec@5 87.010\n",
      " * Prec@1 76.442 Prec@5 87.139\n",
      " * Prec@1 76.297 Prec@5 87.146\n",
      " * Prec@1 76.157 Prec@5 87.269\n",
      " * Prec@1 76.023 Prec@5 87.159\n",
      " * Prec@1 76.004 Prec@5 87.054\n",
      " * Prec@1 76.096 Prec@5 87.061\n",
      " * Prec@1 76.293 Prec@5 87.069\n",
      " * Prec@1 76.059 Prec@5 87.076\n",
      " * Prec@1 76.146 Prec@5 86.979\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.500 (0.518)\n",
      "\n",
      "Loss 0.5270 (1.5041)\n",
      "\n",
      "Prec@1 81.250 (76.230)\n",
      "\n",
      "Prec@5 100.000 (87.193)\n",
      "\n",
      " * Prec@1 76.230 Prec@5 87.193\n",
      " * Prec@1 76.411 Prec@5 87.399\n",
      " * Prec@1 76.587 Prec@5 87.500\n",
      " * Prec@1 76.855 Prec@5 87.695\n",
      " * Prec@1 76.923 Prec@5 87.692\n",
      " * Prec@1 76.515 Prec@5 87.500\n",
      " * Prec@1 76.586 Prec@5 87.500\n",
      " * Prec@1 76.471 Prec@5 87.408\n",
      " * Prec@1 76.268 Prec@5 87.319\n",
      " * Prec@1 76.071 Prec@5 87.054\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.530 (0.517)\n",
      "\n",
      "Loss 1.5578 (1.5065)\n",
      "\n",
      "Prec@1 68.750 (75.968)\n",
      "\n",
      "Prec@5 81.250 (86.972)\n",
      "\n",
      " * Prec@1 75.968 Prec@5 86.972\n",
      " * Prec@1 75.868 Prec@5 86.892\n",
      " * Prec@1 75.685 Prec@5 86.901\n",
      " * Prec@1 75.760 Prec@5 86.993\n",
      " * Prec@1 75.750 Prec@5 86.917\n",
      " * Prec@1 75.411 Prec@5 86.760\n",
      " * Prec@1 75.568 Prec@5 86.769\n",
      " * Prec@1 75.721 Prec@5 86.859\n",
      " * Prec@1 75.791 Prec@5 86.788\n",
      " * Prec@1 75.781 Prec@5 86.875\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.500 (0.515)\n",
      "\n",
      "Loss 3.5502 (1.5475)\n",
      "\n",
      "Prec@1 50.000 (75.463)\n",
      "\n",
      "Prec@5 68.750 (86.651)\n",
      "\n",
      " * Prec@1 75.463 Prec@5 86.651\n",
      " * Prec@1 75.457 Prec@5 86.585\n",
      " * Prec@1 75.527 Prec@5 86.521\n",
      " * Prec@1 75.298 Prec@5 86.310\n",
      " * Prec@1 75.147 Prec@5 86.176\n",
      " * Prec@1 75.218 Prec@5 86.192\n",
      " * Prec@1 75.287 Prec@5 86.207\n",
      " * Prec@1 75.213 Prec@5 86.222\n",
      " * Prec@1 74.789 Prec@5 86.025\n",
      " * Prec@1 74.792 Prec@5 86.111\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.502 (0.514)\n",
      "\n",
      "Loss 0.4307 (1.5720)\n",
      "\n",
      "Prec@1 81.250 (74.863)\n",
      "\n",
      "Prec@5 100.000 (86.264)\n",
      "\n",
      " * Prec@1 74.863 Prec@5 86.264\n",
      " * Prec@1 74.864 Prec@5 86.209\n",
      " * Prec@1 74.933 Prec@5 86.223\n",
      " * Prec@1 74.734 Prec@5 86.104\n",
      " * Prec@1 74.737 Prec@5 86.118\n",
      " * Prec@1 74.935 Prec@5 86.263\n",
      " * Prec@1 75.129 Prec@5 86.340\n",
      " * Prec@1 75.128 Prec@5 86.352\n",
      " * Prec@1 75.126 Prec@5 86.301\n",
      " * Prec@1 75.250 Prec@5 86.438\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.500 (0.514)\n",
      "\n",
      "Loss 2.5254 (1.5612)\n",
      "\n",
      "Prec@1 75.000 (75.248)\n",
      "\n",
      "Prec@5 75.000 (86.324)\n",
      "\n",
      " * Prec@1 75.248 Prec@5 86.324\n",
      " * Prec@1 75.123 Prec@5 86.213\n",
      " * Prec@1 75.182 Prec@5 86.226\n",
      " * Prec@1 74.940 Prec@5 86.118\n",
      " * Prec@1 75.060 Prec@5 86.190\n",
      " * Prec@1 75.000 Prec@5 86.085\n",
      " * Prec@1 75.058 Prec@5 86.098\n",
      " * Prec@1 75.116 Prec@5 86.111\n",
      " * Prec@1 75.057 Prec@5 86.124\n",
      " * Prec@1 75.057 Prec@5 86.136\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.466 (0.513)\n",
      "\n",
      "Loss 1.9262 (1.5780)\n",
      "\n",
      "Prec@1 68.750 (75.000)\n",
      "\n",
      "Prec@5 87.500 (86.149)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 86.149\n",
      " * Prec@1 75.056 Prec@5 86.217\n",
      " * Prec@1 75.166 Prec@5 86.228\n",
      " * Prec@1 75.110 Prec@5 86.294\n",
      " * Prec@1 75.217 Prec@5 86.359\n",
      " * Prec@1 75.323 Prec@5 86.422\n",
      " * Prec@1 75.160 Prec@5 86.378\n",
      " * Prec@1 75.265 Prec@5 86.441\n",
      " * Prec@1 75.210 Prec@5 86.450\n",
      " * Prec@1 75.312 Prec@5 86.510\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.491 (0.513)\n",
      "\n",
      "Loss 1.9252 (1.5616)\n",
      "\n",
      "Prec@1 62.500 (75.207)\n",
      "\n",
      "Prec@5 81.250 (86.467)\n",
      "\n",
      " * Prec@1 75.207 Prec@5 86.467\n",
      " * Prec@1 75.154 Prec@5 86.373\n",
      " * Prec@1 75.203 Prec@5 86.331\n",
      " * Prec@1 75.202 Prec@5 86.341\n",
      " * Prec@1 75.200 Prec@5 86.250\n",
      " * Prec@1 75.298 Prec@5 86.310\n",
      " * Prec@1 75.246 Prec@5 86.368\n",
      " * Prec@1 75.195 Prec@5 86.328\n",
      " * Prec@1 75.242 Prec@5 86.386\n",
      " * Prec@1 75.337 Prec@5 86.394\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.521 (0.512)\n",
      "\n",
      "Loss 1.9125 (1.5672)\n",
      "\n",
      "Prec@1 75.000 (75.334)\n",
      "\n",
      "Prec@5 81.250 (86.355)\n",
      "\n",
      " * Prec@1 75.334 Prec@5 86.355\n",
      " * Prec@1 75.331 Prec@5 86.411\n",
      " * Prec@1 75.329 Prec@5 86.419\n",
      " * Prec@1 75.420 Prec@5 86.427\n",
      " * Prec@1 75.509 Prec@5 86.528\n",
      " * Prec@1 75.368 Prec@5 86.351\n",
      " * Prec@1 75.456 Prec@5 86.359\n",
      " * Prec@1 75.543 Prec@5 86.413\n",
      " * Prec@1 75.495 Prec@5 86.376\n",
      " * Prec@1 75.448 Prec@5 86.335\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [28][0/558]\t\\Time 0.567 (0.567)\tData 0.457 (0.457)\tLoss 0.0022 (0.0022)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [28][100/558]\t\\Time 0.531 (0.521)\tData 0.425 (0.419)\tLoss 0.0021 (0.0086)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [28][200/558]\t\\Time 0.482 (0.519)\tData 0.412 (0.418)\tLoss 0.0008 (0.0095)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [28][300/558]\t\\Time 0.499 (0.521)\tData 0.416 (0.420)\tLoss 0.0009 (0.0095)\tPrec@1 100.000 (99.730)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [28][400/558]\t\\Time 0.490 (0.524)\tData 0.419 (0.423)\tLoss 0.0012 (0.0097)\tPrec@1 100.000 (99.704)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [28][500/558]\t\\Time 0.596 (0.527)\tData 0.520 (0.425)\tLoss 0.0013 (0.0082)\tPrec@1 100.000 (99.763)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.556 (0.556)\n",
      "\n",
      "Loss 1.6811 (1.6811)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 84.375\n",
      " * Prec@1 77.083 Prec@5 87.500\n",
      " * Prec@1 78.125 Prec@5 87.500\n",
      " * Prec@1 77.500 Prec@5 86.250\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 81.250 Prec@5 89.286\n",
      " * Prec@1 78.125 Prec@5 89.062\n",
      " * Prec@1 79.167 Prec@5 90.278\n",
      " * Prec@1 78.750 Prec@5 90.000\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.557 (0.558)\n",
      "\n",
      "Loss 1.3446 (1.1248)\n",
      "\n",
      "Prec@1 68.750 (77.841)\n",
      "\n",
      "Prec@5 87.500 (89.773)\n",
      "\n",
      " * Prec@1 77.841 Prec@5 89.773\n",
      " * Prec@1 78.125 Prec@5 89.583\n",
      " * Prec@1 78.846 Prec@5 90.385\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 79.583 Prec@5 90.000\n",
      " * Prec@1 80.078 Prec@5 90.625\n",
      " * Prec@1 79.412 Prec@5 90.441\n",
      " * Prec@1 79.514 Prec@5 89.931\n",
      " * Prec@1 80.263 Prec@5 90.132\n",
      " * Prec@1 79.688 Prec@5 89.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.542 (0.539)\n",
      "\n",
      "Loss 2.4501 (1.2608)\n",
      "\n",
      "Prec@1 62.500 (78.869)\n",
      "\n",
      "Prec@5 81.250 (89.286)\n",
      "\n",
      " * Prec@1 78.869 Prec@5 89.286\n",
      " * Prec@1 78.409 Prec@5 88.920\n",
      " * Prec@1 77.989 Prec@5 89.130\n",
      " * Prec@1 77.083 Prec@5 88.542\n",
      " * Prec@1 77.250 Prec@5 88.500\n",
      " * Prec@1 77.163 Prec@5 88.221\n",
      " * Prec@1 76.620 Prec@5 87.731\n",
      " * Prec@1 76.786 Prec@5 87.723\n",
      " * Prec@1 76.293 Prec@5 87.284\n",
      " * Prec@1 76.250 Prec@5 87.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.503 (0.536)\n",
      "\n",
      "Loss 0.7248 (1.4701)\n",
      "\n",
      "Prec@1 75.000 (76.210)\n",
      "\n",
      "Prec@5 87.500 (87.097)\n",
      "\n",
      " * Prec@1 76.210 Prec@5 87.097\n",
      " * Prec@1 76.367 Prec@5 87.109\n",
      " * Prec@1 76.326 Prec@5 86.932\n",
      " * Prec@1 76.654 Prec@5 87.132\n",
      " * Prec@1 76.786 Prec@5 87.143\n",
      " * Prec@1 76.910 Prec@5 87.326\n",
      " * Prec@1 76.858 Prec@5 87.162\n",
      " * Prec@1 76.809 Prec@5 86.842\n",
      " * Prec@1 76.763 Prec@5 86.699\n",
      " * Prec@1 76.719 Prec@5 86.719\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.448 (0.536)\n",
      "\n",
      "Loss 0.7522 (1.4339)\n",
      "\n",
      "Prec@1 87.500 (76.982)\n",
      "\n",
      "Prec@5 100.000 (87.043)\n",
      "\n",
      " * Prec@1 76.982 Prec@5 87.043\n",
      " * Prec@1 76.935 Prec@5 86.905\n",
      " * Prec@1 76.453 Prec@5 86.483\n",
      " * Prec@1 75.994 Prec@5 86.506\n",
      " * Prec@1 75.556 Prec@5 86.111\n",
      " * Prec@1 75.408 Prec@5 86.005\n",
      " * Prec@1 75.532 Prec@5 86.170\n",
      " * Prec@1 75.521 Prec@5 86.458\n",
      " * Prec@1 75.510 Prec@5 86.480\n",
      " * Prec@1 75.875 Prec@5 86.625\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.547 (0.533)\n",
      "\n",
      "Loss 1.8327 (1.5006)\n",
      "\n",
      "Prec@1 75.000 (75.858)\n",
      "\n",
      "Prec@5 81.250 (86.520)\n",
      "\n",
      " * Prec@1 75.858 Prec@5 86.520\n",
      " * Prec@1 76.082 Prec@5 86.659\n",
      " * Prec@1 76.061 Prec@5 86.675\n",
      " * Prec@1 75.926 Prec@5 86.921\n",
      " * Prec@1 75.795 Prec@5 86.818\n",
      " * Prec@1 75.781 Prec@5 86.719\n",
      " * Prec@1 75.768 Prec@5 86.732\n",
      " * Prec@1 75.970 Prec@5 86.746\n",
      " * Prec@1 75.742 Prec@5 86.653\n",
      " * Prec@1 75.833 Prec@5 86.562\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.519 (0.533)\n",
      "\n",
      "Loss 0.5300 (1.4896)\n",
      "\n",
      "Prec@1 81.250 (75.922)\n",
      "\n",
      "Prec@5 100.000 (86.783)\n",
      "\n",
      " * Prec@1 75.922 Prec@5 86.783\n",
      " * Prec@1 76.109 Prec@5 86.996\n",
      " * Prec@1 76.290 Prec@5 87.103\n",
      " * Prec@1 76.562 Prec@5 87.305\n",
      " * Prec@1 76.731 Prec@5 87.308\n",
      " * Prec@1 76.326 Prec@5 87.121\n",
      " * Prec@1 76.399 Prec@5 87.127\n",
      " * Prec@1 76.379 Prec@5 87.040\n",
      " * Prec@1 76.178 Prec@5 86.957\n",
      " * Prec@1 75.982 Prec@5 86.607\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.533 (0.532)\n",
      "\n",
      "Loss 1.7117 (1.4973)\n",
      "\n",
      "Prec@1 62.500 (75.792)\n",
      "\n",
      "Prec@5 87.500 (86.620)\n",
      "\n",
      " * Prec@1 75.792 Prec@5 86.620\n",
      " * Prec@1 75.694 Prec@5 86.545\n",
      " * Prec@1 75.514 Prec@5 86.558\n",
      " * Prec@1 75.591 Prec@5 86.571\n",
      " * Prec@1 75.583 Prec@5 86.500\n",
      " * Prec@1 75.247 Prec@5 86.349\n",
      " * Prec@1 75.244 Prec@5 86.445\n",
      " * Prec@1 75.401 Prec@5 86.538\n",
      " * Prec@1 75.475 Prec@5 86.472\n",
      " * Prec@1 75.469 Prec@5 86.562\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.501 (0.530)\n",
      "\n",
      "Loss 3.3402 (1.5392)\n",
      "\n",
      "Prec@1 50.000 (75.154)\n",
      "\n",
      "Prec@5 75.000 (86.420)\n",
      "\n",
      " * Prec@1 75.154 Prec@5 86.420\n",
      " * Prec@1 75.152 Prec@5 86.357\n",
      " * Prec@1 75.226 Prec@5 86.295\n",
      " * Prec@1 75.000 Prec@5 86.086\n",
      " * Prec@1 74.853 Prec@5 85.956\n",
      " * Prec@1 74.927 Prec@5 85.974\n",
      " * Prec@1 75.000 Prec@5 86.063\n",
      " * Prec@1 74.929 Prec@5 86.009\n",
      " * Prec@1 74.508 Prec@5 85.744\n",
      " * Prec@1 74.583 Prec@5 85.833\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.584 (0.529)\n",
      "\n",
      "Loss 0.4710 (1.5637)\n",
      "\n",
      "Prec@1 81.250 (74.657)\n",
      "\n",
      "Prec@5 100.000 (85.989)\n",
      "\n",
      " * Prec@1 74.657 Prec@5 85.989\n",
      " * Prec@1 74.660 Prec@5 85.938\n",
      " * Prec@1 74.731 Prec@5 85.954\n",
      " * Prec@1 74.668 Prec@5 85.838\n",
      " * Prec@1 74.474 Prec@5 85.789\n",
      " * Prec@1 74.609 Prec@5 85.872\n",
      " * Prec@1 74.807 Prec@5 85.954\n",
      " * Prec@1 74.809 Prec@5 85.969\n",
      " * Prec@1 74.811 Prec@5 85.922\n",
      " * Prec@1 74.938 Prec@5 86.062\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.527 (0.530)\n",
      "\n",
      "Loss 2.3853 (1.5533)\n",
      "\n",
      "Prec@1 75.000 (74.938)\n",
      "\n",
      "Prec@5 75.000 (85.953)\n",
      "\n",
      " * Prec@1 74.938 Prec@5 85.953\n",
      " * Prec@1 74.877 Prec@5 85.784\n",
      " * Prec@1 74.939 Prec@5 85.801\n",
      " * Prec@1 74.700 Prec@5 85.637\n",
      " * Prec@1 74.821 Prec@5 85.714\n",
      " * Prec@1 74.764 Prec@5 85.613\n",
      " * Prec@1 74.825 Prec@5 85.631\n",
      " * Prec@1 74.884 Prec@5 85.648\n",
      " * Prec@1 74.828 Prec@5 85.665\n",
      " * Prec@1 74.830 Prec@5 85.682\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.490 (0.529)\n",
      "\n",
      "Loss 1.8626 (1.5707)\n",
      "\n",
      "Prec@1 68.750 (74.775)\n",
      "\n",
      "Prec@5 87.500 (85.698)\n",
      "\n",
      " * Prec@1 74.775 Prec@5 85.698\n",
      " * Prec@1 74.833 Prec@5 85.714\n",
      " * Prec@1 74.945 Prec@5 85.730\n",
      " * Prec@1 74.890 Prec@5 85.800\n",
      " * Prec@1 75.000 Prec@5 85.870\n",
      " * Prec@1 75.108 Prec@5 85.938\n",
      " * Prec@1 74.947 Prec@5 85.897\n",
      " * Prec@1 75.053 Prec@5 85.964\n",
      " * Prec@1 75.053 Prec@5 85.977\n",
      " * Prec@1 75.156 Prec@5 86.042\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.538 (0.528)\n",
      "\n",
      "Loss 1.7602 (1.5529)\n",
      "\n",
      "Prec@1 62.500 (75.052)\n",
      "\n",
      "Prec@5 75.000 (85.950)\n",
      "\n",
      " * Prec@1 75.052 Prec@5 85.950\n",
      " * Prec@1 75.000 Prec@5 85.861\n",
      " * Prec@1 75.051 Prec@5 85.823\n",
      " * Prec@1 75.050 Prec@5 85.786\n",
      " * Prec@1 75.050 Prec@5 85.700\n",
      " * Prec@1 75.099 Prec@5 85.764\n",
      " * Prec@1 75.049 Prec@5 85.778\n",
      " * Prec@1 75.000 Prec@5 85.791\n",
      " * Prec@1 75.048 Prec@5 85.853\n",
      " * Prec@1 75.144 Prec@5 85.865\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.550 (0.527)\n",
      "\n",
      "Loss 1.8347 (1.5620)\n",
      "\n",
      "Prec@1 68.750 (75.095)\n",
      "\n",
      "Prec@5 81.250 (85.830)\n",
      "\n",
      " * Prec@1 75.095 Prec@5 85.830\n",
      " * Prec@1 75.189 Prec@5 85.890\n",
      " * Prec@1 75.188 Prec@5 85.902\n",
      " * Prec@1 75.280 Prec@5 85.961\n",
      " * Prec@1 75.370 Prec@5 86.065\n",
      " * Prec@1 75.230 Prec@5 85.846\n",
      " * Prec@1 75.319 Prec@5 85.858\n",
      " * Prec@1 75.408 Prec@5 85.915\n",
      " * Prec@1 75.360 Prec@5 85.881\n",
      " * Prec@1 75.269 Prec@5 85.842\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [29][0/558]\t\\Time 0.542 (0.542)\tData 0.448 (0.448)\tLoss 0.0007 (0.0007)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [29][100/558]\t\\Time 0.512 (0.518)\tData 0.391 (0.417)\tLoss 0.1726 (0.0077)\tPrec@1 93.750 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [29][200/558]\t\\Time 0.517 (0.517)\tData 0.441 (0.415)\tLoss 0.0015 (0.0067)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [29][300/558]\t\\Time 0.515 (0.516)\tData 0.415 (0.414)\tLoss 0.0022 (0.0070)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [29][400/558]\t\\Time 0.540 (0.514)\tData 0.412 (0.412)\tLoss 0.0019 (0.0068)\tPrec@1 100.000 (99.782)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [29][500/558]\t\\Time 0.511 (0.514)\tData 0.401 (0.411)\tLoss 0.0020 (0.0071)\tPrec@1 100.000 (99.763)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.470 (0.470)\n",
      "\n",
      "Loss 1.5968 (1.5968)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 75.000 Prec@5 89.583\n",
      " * Prec@1 76.562 Prec@5 89.062\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 76.562 Prec@5 89.844\n",
      " * Prec@1 77.778 Prec@5 90.972\n",
      " * Prec@1 77.500 Prec@5 90.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.508 (0.513)\n",
      "\n",
      "Loss 1.4129 (1.1115)\n",
      "\n",
      "Prec@1 68.750 (76.705)\n",
      "\n",
      "Prec@5 81.250 (89.773)\n",
      "\n",
      " * Prec@1 76.705 Prec@5 89.773\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 77.885 Prec@5 90.385\n",
      " * Prec@1 78.571 Prec@5 90.179\n",
      " * Prec@1 78.750 Prec@5 90.000\n",
      " * Prec@1 78.906 Prec@5 90.625\n",
      " * Prec@1 78.309 Prec@5 90.441\n",
      " * Prec@1 78.472 Prec@5 89.931\n",
      " * Prec@1 79.276 Prec@5 90.132\n",
      " * Prec@1 78.750 Prec@5 89.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.510 (0.517)\n",
      "\n",
      "Loss 2.3346 (1.2389)\n",
      "\n",
      "Prec@1 62.500 (77.976)\n",
      "\n",
      "Prec@5 87.500 (89.583)\n",
      "\n",
      " * Prec@1 77.976 Prec@5 89.583\n",
      " * Prec@1 77.841 Prec@5 89.205\n",
      " * Prec@1 77.717 Prec@5 89.674\n",
      " * Prec@1 76.823 Prec@5 89.062\n",
      " * Prec@1 77.000 Prec@5 89.000\n",
      " * Prec@1 76.923 Prec@5 88.702\n",
      " * Prec@1 76.389 Prec@5 88.194\n",
      " * Prec@1 76.562 Prec@5 88.170\n",
      " * Prec@1 76.078 Prec@5 87.716\n",
      " * Prec@1 76.042 Prec@5 87.500\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.519 (0.520)\n",
      "\n",
      "Loss 0.7268 (1.4605)\n",
      "\n",
      "Prec@1 81.250 (76.210)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 76.210 Prec@5 87.500\n",
      " * Prec@1 76.367 Prec@5 87.500\n",
      " * Prec@1 76.326 Prec@5 87.311\n",
      " * Prec@1 76.654 Prec@5 87.500\n",
      " * Prec@1 76.786 Prec@5 87.500\n",
      " * Prec@1 76.910 Prec@5 87.674\n",
      " * Prec@1 76.858 Prec@5 87.669\n",
      " * Prec@1 76.809 Prec@5 87.336\n",
      " * Prec@1 76.603 Prec@5 87.179\n",
      " * Prec@1 76.562 Prec@5 87.031\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.421 (0.517)\n",
      "\n",
      "Loss 0.8120 (1.4265)\n",
      "\n",
      "Prec@1 87.500 (76.829)\n",
      "\n",
      "Prec@5 100.000 (87.348)\n",
      "\n",
      " * Prec@1 76.829 Prec@5 87.348\n",
      " * Prec@1 76.786 Prec@5 87.202\n",
      " * Prec@1 76.163 Prec@5 86.919\n",
      " * Prec@1 75.710 Prec@5 86.932\n",
      " * Prec@1 75.278 Prec@5 86.528\n",
      " * Prec@1 75.136 Prec@5 86.413\n",
      " * Prec@1 75.266 Prec@5 86.569\n",
      " * Prec@1 75.260 Prec@5 86.849\n",
      " * Prec@1 75.255 Prec@5 86.862\n",
      " * Prec@1 75.500 Prec@5 87.000\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.520 (0.516)\n",
      "\n",
      "Loss 1.7719 (1.4924)\n",
      "\n",
      "Prec@1 75.000 (75.490)\n",
      "\n",
      "Prec@5 81.250 (86.887)\n",
      "\n",
      " * Prec@1 75.490 Prec@5 86.887\n",
      " * Prec@1 75.721 Prec@5 87.019\n",
      " * Prec@1 75.472 Prec@5 87.028\n",
      " * Prec@1 75.347 Prec@5 87.269\n",
      " * Prec@1 75.227 Prec@5 87.045\n",
      " * Prec@1 75.223 Prec@5 86.942\n",
      " * Prec@1 75.329 Prec@5 86.952\n",
      " * Prec@1 75.539 Prec@5 86.961\n",
      " * Prec@1 75.318 Prec@5 86.864\n",
      " * Prec@1 75.417 Prec@5 86.771\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.461 (0.515)\n",
      "\n",
      "Loss 0.5468 (1.4834)\n",
      "\n",
      "Prec@1 81.250 (75.512)\n",
      "\n",
      "Prec@5 100.000 (86.988)\n",
      "\n",
      " * Prec@1 75.512 Prec@5 86.988\n",
      " * Prec@1 75.706 Prec@5 87.198\n",
      " * Prec@1 75.794 Prec@5 87.302\n",
      " * Prec@1 76.074 Prec@5 87.500\n",
      " * Prec@1 76.250 Prec@5 87.500\n",
      " * Prec@1 75.852 Prec@5 87.311\n",
      " * Prec@1 75.933 Prec@5 87.313\n",
      " * Prec@1 75.827 Prec@5 87.224\n",
      " * Prec@1 75.634 Prec@5 87.138\n",
      " * Prec@1 75.446 Prec@5 86.875\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.511 (0.513)\n",
      "\n",
      "Loss 1.6035 (1.4878)\n",
      "\n",
      "Prec@1 62.500 (75.264)\n",
      "\n",
      "Prec@5 81.250 (86.796)\n",
      "\n",
      " * Prec@1 75.264 Prec@5 86.796\n",
      " * Prec@1 75.174 Prec@5 86.719\n",
      " * Prec@1 75.000 Prec@5 86.729\n",
      " * Prec@1 75.084 Prec@5 86.824\n",
      " * Prec@1 75.083 Prec@5 86.750\n",
      " * Prec@1 74.753 Prec@5 86.678\n",
      " * Prec@1 74.756 Prec@5 86.769\n",
      " * Prec@1 74.840 Prec@5 86.859\n",
      " * Prec@1 74.921 Prec@5 86.788\n",
      " * Prec@1 74.922 Prec@5 86.875\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.522 (0.513)\n",
      "\n",
      "Loss 3.5328 (1.5296)\n",
      "\n",
      "Prec@1 50.000 (74.614)\n",
      "\n",
      "Prec@5 75.000 (86.728)\n",
      "\n",
      " * Prec@1 74.614 Prec@5 86.728\n",
      " * Prec@1 74.619 Prec@5 86.662\n",
      " * Prec@1 74.699 Prec@5 86.596\n",
      " * Prec@1 74.479 Prec@5 86.384\n",
      " * Prec@1 74.338 Prec@5 86.250\n",
      " * Prec@1 74.419 Prec@5 86.337\n",
      " * Prec@1 74.497 Prec@5 86.351\n",
      " * Prec@1 74.432 Prec@5 86.364\n",
      " * Prec@1 74.017 Prec@5 86.166\n",
      " * Prec@1 74.097 Prec@5 86.250\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.520 (0.512)\n",
      "\n",
      "Loss 0.5460 (1.5558)\n",
      "\n",
      "Prec@1 81.250 (74.176)\n",
      "\n",
      "Prec@5 100.000 (86.401)\n",
      "\n",
      " * Prec@1 74.176 Prec@5 86.401\n",
      " * Prec@1 74.185 Prec@5 86.345\n",
      " * Prec@1 74.261 Prec@5 86.358\n",
      " * Prec@1 74.069 Prec@5 86.237\n",
      " * Prec@1 73.947 Prec@5 86.316\n",
      " * Prec@1 74.154 Prec@5 86.393\n",
      " * Prec@1 74.356 Prec@5 86.469\n",
      " * Prec@1 74.362 Prec@5 86.480\n",
      " * Prec@1 74.369 Prec@5 86.490\n",
      " * Prec@1 74.500 Prec@5 86.625\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.526 (0.512)\n",
      "\n",
      "Loss 2.4365 (1.5445)\n",
      "\n",
      "Prec@1 75.000 (74.505)\n",
      "\n",
      "Prec@5 75.000 (86.510)\n",
      "\n",
      " * Prec@1 74.505 Prec@5 86.510\n",
      " * Prec@1 74.449 Prec@5 86.336\n",
      " * Prec@1 74.515 Prec@5 86.347\n",
      " * Prec@1 74.279 Prec@5 86.178\n",
      " * Prec@1 74.405 Prec@5 86.250\n",
      " * Prec@1 74.351 Prec@5 86.144\n",
      " * Prec@1 74.357 Prec@5 86.157\n",
      " * Prec@1 74.421 Prec@5 86.169\n",
      " * Prec@1 74.369 Prec@5 86.181\n",
      " * Prec@1 74.375 Prec@5 86.193\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.501 (0.512)\n",
      "\n",
      "Loss 1.7203 (1.5592)\n",
      "\n",
      "Prec@1 68.750 (74.324)\n",
      "\n",
      "Prec@5 87.500 (86.205)\n",
      "\n",
      " * Prec@1 74.324 Prec@5 86.205\n",
      " * Prec@1 74.386 Prec@5 86.217\n",
      " * Prec@1 74.502 Prec@5 86.228\n",
      " * Prec@1 74.397 Prec@5 86.294\n",
      " * Prec@1 74.511 Prec@5 86.359\n",
      " * Prec@1 74.623 Prec@5 86.422\n",
      " * Prec@1 74.466 Prec@5 86.378\n",
      " * Prec@1 74.576 Prec@5 86.441\n",
      " * Prec@1 74.527 Prec@5 86.450\n",
      " * Prec@1 74.635 Prec@5 86.510\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.490 (0.512)\n",
      "\n",
      "Loss 1.8114 (1.5433)\n",
      "\n",
      "Prec@1 62.500 (74.535)\n",
      "\n",
      "Prec@5 75.000 (86.415)\n",
      "\n",
      " * Prec@1 74.535 Prec@5 86.415\n",
      " * Prec@1 74.488 Prec@5 86.322\n",
      " * Prec@1 74.543 Prec@5 86.280\n",
      " * Prec@1 74.546 Prec@5 86.290\n",
      " * Prec@1 74.500 Prec@5 86.200\n",
      " * Prec@1 74.554 Prec@5 86.260\n",
      " * Prec@1 74.508 Prec@5 86.319\n",
      " * Prec@1 74.463 Prec@5 86.328\n",
      " * Prec@1 74.516 Prec@5 86.337\n",
      " * Prec@1 74.615 Prec@5 86.346\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.520 (0.511)\n",
      "\n",
      "Loss 1.8078 (1.5506)\n",
      "\n",
      "Prec@1 68.750 (74.571)\n",
      "\n",
      "Prec@5 81.250 (86.307)\n",
      "\n",
      " * Prec@1 74.571 Prec@5 86.307\n",
      " * Prec@1 74.716 Prec@5 86.364\n",
      " * Prec@1 74.718 Prec@5 86.372\n",
      " * Prec@1 74.813 Prec@5 86.427\n",
      " * Prec@1 74.907 Prec@5 86.528\n",
      " * Prec@1 74.770 Prec@5 86.305\n",
      " * Prec@1 74.863 Prec@5 86.314\n",
      " * Prec@1 74.955 Prec@5 86.368\n",
      " * Prec@1 74.955 Prec@5 86.331\n",
      " * Prec@1 74.910 Prec@5 86.290\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 100, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_100targets_weights_seed0802split'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_100_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.8 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b40d5a5d-e4ee-448a-99c2-167e09108a91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/vit_b_16_artsobservasjoner224_125targets_weights_Noneseed_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/728]\t\\Time 0.734 (0.734)\tData 0.449 (0.449)\tLoss 4.8297 (4.8297)\tPrec@1 0.000 (0.000)\tPrec@5 6.250 (6.250)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_CUDA:\n\u001b[0;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 18\u001b[0m train_model(model,LEARNING_RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-2\u001b[39m,NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mlong_running.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     prevent_standby()\n\u001b[1;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     31\u001b[0m     allow_standby()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[16], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, LEARNING_RATE, NUM_EPOCHS, init_learning_rate, load_best)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=> loaded checkpoint \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m           \u001b[38;5;241m.\u001b[39mformat(args_resume, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m train(train_loader, model, criterion, optimizer, epoch)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[0;32m     56\u001b[0m prec1 \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion,epoch,save_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# measure data loading time\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# print(input['image'].shape)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_CUDA:\n\u001b[0;32m     17\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:361\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:361\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m, in \u001b[0;36mImagesWithLocationDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     22\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     24\u001b[0m img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m---> 26\u001b[0m image \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(img_name)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# location_data = self.from_np_array(self.location_dataframe['count_in_1000'].iloc[idx])\u001b[39;00m\n\u001b[0;32m     28\u001b[0m target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m call_plugin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimread\u001b[39m\u001b[38;5;124m'\u001b[39m, fname, plugin\u001b[38;5;241m=\u001b[39mplugin, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_args)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(imageio_imread(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\imageio\\v3.py:54\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_kwargs) \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\imageio\\plugins\\pillow.py:231\u001b[0m, in \u001b[0;36mPillowPlugin.read\u001b[1;34m(self, index, mode, rotate, apply_gamma, writeable_output, pilmode, exifrotate, as_gray)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m# will raise IO error if index >= number of frames in image\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mseek(index)\n\u001b[1;32m--> 231\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_transforms(\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image, mode, rotate, apply_gamma, writeable_output\n\u001b[0;32m    233\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\n\u001b[0;32m    236\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    237\u001b[0m         rotate\u001b[38;5;241m=\u001b[39mrotate,\n\u001b[0;32m    238\u001b[0m         apply_gamma\u001b[38;5;241m=\u001b[39mapply_gamma,\n\u001b[0;32m    239\u001b[0m         writeable_output\u001b[38;5;241m=\u001b[39mwriteable_output,\n\u001b[0;32m    240\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\imageio\\plugins\\pillow.py:331\u001b[0m, in \u001b[0;36mPillowPlugin._apply_transforms\u001b[1;34m(self, image, mode, rotate, apply_gamma, writeable_output)\u001b[0m\n\u001b[0;32m    328\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(image)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writeable_output \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 331\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = None)\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 125, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_125targets_weights_Noneseed'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_125_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab6b5d64-25bf-499e-8e38-9a65a1d8043c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_19992\\3414169806.py:13: DtypeWarning: Columns (38,54,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.location_dataframe = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'saved_models/vit_b_16_artsobservasjoner224_200targets_weights_seed2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_artsobservasjoner224_200targets_weights_seed2_checkpoint.pth.tar' (epoch 1)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/987]\t\\Time 0.743 (0.743)\tData 0.381 (0.381)\tLoss 5.0149 (5.0149)\tPrec@1 12.500 (12.500)\tPrec@5 18.750 (18.750)\n",
      "Epoch: [1][100/987]\t\\Time 0.505 (0.490)\tData 0.388 (0.390)\tLoss 4.8673 (4.5374)\tPrec@1 0.000 (7.797)\tPrec@5 6.250 (23.205)\n",
      "Epoch: [1][200/987]\t\\Time 0.501 (0.495)\tData 0.380 (0.394)\tLoss 4.7782 (4.4105)\tPrec@1 0.000 (8.364)\tPrec@5 12.500 (25.746)\n",
      "Epoch: [1][300/987]\t\\Time 0.554 (0.512)\tData 0.438 (0.410)\tLoss 4.0635 (4.3413)\tPrec@1 12.500 (9.012)\tPrec@5 31.250 (26.827)\n",
      "Epoch: [1][400/987]\t\\Time 0.555 (0.519)\tData 0.444 (0.417)\tLoss 4.4421 (4.2576)\tPrec@1 18.750 (10.022)\tPrec@5 25.000 (28.803)\n",
      "Epoch: [1][500/987]\t\\Time 0.550 (0.525)\tData 0.440 (0.421)\tLoss 3.2465 (4.2055)\tPrec@1 18.750 (10.816)\tPrec@5 62.500 (29.965)\n",
      "Epoch: [1][600/987]\t\\Time 0.584 (0.527)\tData 0.481 (0.424)\tLoss 4.4623 (4.1432)\tPrec@1 12.500 (11.481)\tPrec@5 25.000 (31.510)\n",
      "Epoch: [1][700/987]\t\\Time 0.601 (0.531)\tData 0.491 (0.428)\tLoss 3.6236 (4.0720)\tPrec@1 12.500 (12.455)\tPrec@5 31.250 (33.042)\n",
      "Epoch: [1][800/987]\t\\Time 0.531 (0.534)\tData 0.421 (0.431)\tLoss 3.7586 (4.0204)\tPrec@1 25.000 (13.070)\tPrec@5 37.500 (34.262)\n",
      "Epoch: [1][900/987]\t\\Time 0.542 (0.533)\tData 0.432 (0.430)\tLoss 3.4147 (3.9572)\tPrec@1 18.750 (13.998)\tPrec@5 62.500 (35.814)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 0.492 (0.492)\n",
      "\n",
      "Loss 3.5017 (3.5017)\n",
      "\n",
      "Prec@1 31.250 (31.250)\n",
      "\n",
      "Prec@5 50.000 (50.000)\n",
      "\n",
      " * Prec@1 31.250 Prec@5 50.000\n",
      " * Prec@1 28.125 Prec@5 56.250\n",
      " * Prec@1 22.917 Prec@5 60.417\n",
      " * Prec@1 20.312 Prec@5 57.812\n",
      " * Prec@1 17.500 Prec@5 52.500\n",
      " * Prec@1 16.667 Prec@5 53.125\n",
      " * Prec@1 16.964 Prec@5 51.786\n",
      " * Prec@1 17.969 Prec@5 53.125\n",
      " * Prec@1 18.750 Prec@5 52.083\n",
      " * Prec@1 21.250 Prec@5 54.375\n",
      "Test: [10/110]\n",
      "\n",
      "Time 0.575 (1.131)\n",
      "\n",
      "Loss 2.9145 (3.2684)\n",
      "\n",
      "Prec@1 31.250 (22.159)\n",
      "\n",
      "Prec@5 62.500 (55.114)\n",
      "\n",
      " * Prec@1 22.159 Prec@5 55.114\n",
      " * Prec@1 21.875 Prec@5 55.729\n",
      " * Prec@1 22.596 Prec@5 55.288\n",
      " * Prec@1 23.214 Prec@5 55.804\n",
      " * Prec@1 22.083 Prec@5 55.417\n",
      " * Prec@1 22.656 Prec@5 55.469\n",
      " * Prec@1 22.794 Prec@5 55.147\n",
      " * Prec@1 22.222 Prec@5 55.208\n",
      " * Prec@1 21.711 Prec@5 55.263\n",
      " * Prec@1 22.500 Prec@5 56.250\n",
      "Test: [20/110]\n",
      "\n",
      "Time 0.552 (1.091)\n",
      "\n",
      "Loss 3.3495 (3.1673)\n",
      "\n",
      "Prec@1 12.500 (22.024)\n",
      "\n",
      "Prec@5 56.250 (56.250)\n",
      "\n",
      " * Prec@1 22.024 Prec@5 56.250\n",
      " * Prec@1 21.875 Prec@5 55.682\n",
      " * Prec@1 21.196 Prec@5 55.707\n",
      " * Prec@1 20.833 Prec@5 55.208\n",
      " * Prec@1 21.000 Prec@5 55.000\n",
      " * Prec@1 20.433 Prec@5 54.808\n",
      " * Prec@1 20.602 Prec@5 54.167\n",
      " * Prec@1 20.089 Prec@5 53.348\n",
      " * Prec@1 20.474 Prec@5 53.233\n",
      " * Prec@1 21.042 Prec@5 53.333\n",
      "Test: [30/110]\n",
      "\n",
      "Time 0.598 (1.075)\n",
      "\n",
      "Loss 3.9085 (3.2912)\n",
      "\n",
      "Prec@1 0.000 (20.363)\n",
      "\n",
      "Prec@5 37.500 (52.823)\n",
      "\n",
      " * Prec@1 20.363 Prec@5 52.823\n",
      " * Prec@1 20.898 Prec@5 53.320\n",
      " * Prec@1 21.212 Prec@5 53.409\n",
      " * Prec@1 21.691 Prec@5 53.493\n",
      " * Prec@1 21.250 Prec@5 53.036\n",
      " * Prec@1 21.181 Prec@5 52.951\n",
      " * Prec@1 21.115 Prec@5 52.872\n",
      " * Prec@1 21.053 Prec@5 52.632\n",
      " * Prec@1 20.994 Prec@5 52.564\n",
      " * Prec@1 20.938 Prec@5 52.188\n",
      "Test: [40/110]\n",
      "\n",
      "Time 0.594 (1.076)\n",
      "\n",
      "Loss 3.9128 (3.3295)\n",
      "\n",
      "Prec@1 12.500 (20.732)\n",
      "\n",
      "Prec@5 37.500 (51.829)\n",
      "\n",
      " * Prec@1 20.732 Prec@5 51.829\n",
      " * Prec@1 20.833 Prec@5 51.637\n",
      " * Prec@1 20.640 Prec@5 51.599\n",
      " * Prec@1 20.597 Prec@5 51.562\n",
      " * Prec@1 20.139 Prec@5 51.250\n",
      " * Prec@1 20.380 Prec@5 51.087\n",
      " * Prec@1 20.080 Prec@5 50.931\n",
      " * Prec@1 19.922 Prec@5 50.911\n",
      " * Prec@1 20.026 Prec@5 51.276\n",
      " * Prec@1 20.375 Prec@5 51.750\n",
      "Test: [50/110]\n",
      "\n",
      "Time 0.651 (1.075)\n",
      "\n",
      "Loss 2.9939 (3.3217)\n",
      "\n",
      "Prec@1 25.000 (20.466)\n",
      "\n",
      "Prec@5 56.250 (51.838)\n",
      "\n",
      " * Prec@1 20.466 Prec@5 51.838\n",
      " * Prec@1 20.433 Prec@5 51.683\n",
      " * Prec@1 20.401 Prec@5 51.769\n",
      " * Prec@1 20.602 Prec@5 51.620\n",
      " * Prec@1 20.455 Prec@5 51.250\n",
      " * Prec@1 20.536 Prec@5 51.228\n",
      " * Prec@1 20.724 Prec@5 50.987\n",
      " * Prec@1 20.905 Prec@5 50.970\n",
      " * Prec@1 21.186 Prec@5 50.953\n",
      " * Prec@1 21.250 Prec@5 51.042\n",
      "Test: [60/110]\n",
      "\n",
      "Time 0.601 (1.072)\n",
      "\n",
      "Loss 3.4782 (3.3287)\n",
      "\n",
      "Prec@1 12.500 (21.107)\n",
      "\n",
      "Prec@5 50.000 (51.025)\n",
      "\n",
      " * Prec@1 21.107 Prec@5 51.025\n",
      " * Prec@1 21.573 Prec@5 51.310\n",
      " * Prec@1 21.627 Prec@5 51.190\n",
      " * Prec@1 21.582 Prec@5 51.074\n",
      " * Prec@1 21.731 Prec@5 51.058\n",
      " * Prec@1 21.591 Prec@5 50.852\n",
      " * Prec@1 21.455 Prec@5 50.653\n",
      " * Prec@1 21.599 Prec@5 50.735\n",
      " * Prec@1 21.467 Prec@5 50.634\n",
      " * Prec@1 21.429 Prec@5 50.625\n",
      "Test: [70/110]\n",
      "\n",
      "Time 0.603 (1.071)\n",
      "\n",
      "Loss 3.3413 (3.3338)\n",
      "\n",
      "Prec@1 25.000 (21.479)\n",
      "\n",
      "Prec@5 37.500 (50.440)\n",
      "\n",
      " * Prec@1 21.479 Prec@5 50.440\n",
      " * Prec@1 21.528 Prec@5 50.347\n",
      " * Prec@1 21.575 Prec@5 50.514\n",
      " * Prec@1 21.537 Prec@5 50.676\n",
      " * Prec@1 21.667 Prec@5 50.750\n",
      " * Prec@1 21.628 Prec@5 50.658\n",
      " * Prec@1 21.753 Prec@5 50.731\n",
      " * Prec@1 21.955 Prec@5 50.962\n",
      " * Prec@1 21.994 Prec@5 50.949\n",
      " * Prec@1 22.188 Prec@5 51.016\n",
      "Test: [80/110]\n",
      "\n",
      "Time 0.555 (1.068)\n",
      "\n",
      "Loss 3.8815 (3.3124)\n",
      "\n",
      "Prec@1 18.750 (22.145)\n",
      "\n",
      "Prec@5 31.250 (50.772)\n",
      "\n",
      " * Prec@1 22.145 Prec@5 50.772\n",
      " * Prec@1 22.027 Prec@5 50.610\n",
      " * Prec@1 22.063 Prec@5 50.527\n",
      " * Prec@1 22.173 Prec@5 50.595\n",
      " * Prec@1 22.132 Prec@5 50.441\n",
      " * Prec@1 21.875 Prec@5 50.291\n",
      " * Prec@1 21.911 Prec@5 50.359\n",
      " * Prec@1 21.875 Prec@5 50.355\n",
      " * Prec@1 21.699 Prec@5 50.351\n",
      " * Prec@1 21.667 Prec@5 50.208\n",
      "Test: [90/110]\n",
      "\n",
      "Time 0.619 (1.064)\n",
      "\n",
      "Loss 3.5482 (3.3249)\n",
      "\n",
      "Prec@1 25.000 (21.703)\n",
      "\n",
      "Prec@5 50.000 (50.206)\n",
      "\n",
      " * Prec@1 21.703 Prec@5 50.206\n",
      " * Prec@1 21.671 Prec@5 50.272\n",
      " * Prec@1 21.573 Prec@5 50.336\n",
      " * Prec@1 21.543 Prec@5 50.332\n",
      " * Prec@1 21.579 Prec@5 50.263\n",
      " * Prec@1 21.549 Prec@5 50.195\n",
      " * Prec@1 21.585 Prec@5 50.129\n",
      " * Prec@1 21.556 Prec@5 50.255\n",
      " * Prec@1 21.780 Prec@5 50.442\n",
      " * Prec@1 21.875 Prec@5 50.625\n",
      "Test: [100/110]\n",
      "\n",
      "Time 0.596 (1.062)\n",
      "\n",
      "Loss 3.3468 (3.3213)\n",
      "\n",
      "Prec@1 12.500 (21.782)\n",
      "\n",
      "Prec@5 37.500 (50.495)\n",
      "\n",
      " * Prec@1 21.782 Prec@5 50.495\n",
      " * Prec@1 21.691 Prec@5 50.245\n",
      " * Prec@1 21.663 Prec@5 50.243\n",
      " * Prec@1 21.695 Prec@5 50.421\n",
      " * Prec@1 21.786 Prec@5 50.417\n",
      " * Prec@1 21.816 Prec@5 50.531\n",
      " * Prec@1 21.729 Prec@5 50.467\n",
      " * Prec@1 21.644 Prec@5 50.521\n",
      " * Prec@1 21.674 Prec@5 50.573\n",
      " * Prec@1 21.595 Prec@5 50.598\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/987]\t\\Time 0.990 (0.990)\tData 0.412 (0.412)\tLoss 3.3115 (3.3115)\tPrec@1 12.500 (12.500)\tPrec@5 43.750 (43.750)\n",
      "Epoch: [2][100/987]\t\\Time 1.938 (1.960)\tData 1.378 (1.418)\tLoss 3.2520 (3.0100)\tPrec@1 25.000 (28.651)\tPrec@5 50.000 (57.488)\n",
      "Epoch: [2][200/987]\t\\Time 2.031 (1.966)\tData 1.471 (1.424)\tLoss 2.8370 (3.0243)\tPrec@1 31.250 (28.047)\tPrec@5 56.250 (57.276)\n",
      "Epoch: [2][300/987]\t\\Time 1.940 (1.968)\tData 1.432 (1.426)\tLoss 2.3791 (3.0217)\tPrec@1 56.250 (28.675)\tPrec@5 81.250 (57.434)\n",
      "Epoch: [2][400/987]\t\\Time 1.945 (1.968)\tData 1.375 (1.427)\tLoss 2.2257 (3.0084)\tPrec@1 37.500 (28.663)\tPrec@5 62.500 (57.855)\n",
      "Epoch: [2][500/987]\t\\Time 2.032 (1.969)\tData 1.471 (1.428)\tLoss 3.1168 (2.9679)\tPrec@1 25.000 (29.516)\tPrec@5 62.500 (58.595)\n",
      "Epoch: [2][600/987]\t\\Time 1.941 (1.969)\tData 1.429 (1.428)\tLoss 2.7207 (2.9481)\tPrec@1 43.750 (30.085)\tPrec@5 75.000 (58.954)\n",
      "Epoch: [2][700/987]\t\\Time 1.934 (1.970)\tData 1.373 (1.428)\tLoss 3.3975 (2.9097)\tPrec@1 31.250 (30.902)\tPrec@5 43.750 (59.923)\n",
      "Epoch: [2][800/987]\t\\Time 2.024 (1.970)\tData 1.474 (1.428)\tLoss 2.9243 (2.8881)\tPrec@1 18.750 (31.375)\tPrec@5 56.250 (60.307)\n",
      "Epoch: [2][900/987]\t\\Time 1.946 (1.970)\tData 1.435 (1.429)\tLoss 2.3844 (2.8560)\tPrec@1 37.500 (32.242)\tPrec@5 62.500 (60.794)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.977 (1.977)\n",
      "\n",
      "Loss 3.0424 (3.0424)\n",
      "\n",
      "Prec@1 37.500 (37.500)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 68.750\n",
      " * Prec@1 37.500 Prec@5 71.875\n",
      " * Prec@1 41.667 Prec@5 72.917\n",
      " * Prec@1 40.625 Prec@5 68.750\n",
      " * Prec@1 36.250 Prec@5 66.250\n",
      " * Prec@1 35.417 Prec@5 66.667\n",
      " * Prec@1 34.821 Prec@5 65.179\n",
      " * Prec@1 37.500 Prec@5 66.406\n",
      " * Prec@1 36.111 Prec@5 64.583\n",
      " * Prec@1 36.875 Prec@5 66.875\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.070 (1.243)\n",
      "\n",
      "Loss 2.4821 (2.6245)\n",
      "\n",
      "Prec@1 31.250 (36.364)\n",
      "\n",
      "Prec@5 56.250 (65.909)\n",
      "\n",
      " * Prec@1 36.364 Prec@5 65.909\n",
      " * Prec@1 36.458 Prec@5 65.104\n",
      " * Prec@1 35.577 Prec@5 65.865\n",
      " * Prec@1 37.054 Prec@5 66.964\n",
      " * Prec@1 37.917 Prec@5 67.083\n",
      " * Prec@1 37.891 Prec@5 67.969\n",
      " * Prec@1 38.603 Prec@5 68.015\n",
      " * Prec@1 37.500 Prec@5 68.056\n",
      " * Prec@1 37.500 Prec@5 67.434\n",
      " * Prec@1 39.062 Prec@5 67.812\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.122 (1.239)\n",
      "\n",
      "Loss 2.8916 (2.5235)\n",
      "\n",
      "Prec@1 37.500 (38.988)\n",
      "\n",
      "Prec@5 56.250 (67.262)\n",
      "\n",
      " * Prec@1 38.988 Prec@5 67.262\n",
      " * Prec@1 38.068 Prec@5 67.045\n",
      " * Prec@1 38.043 Prec@5 66.576\n",
      " * Prec@1 37.500 Prec@5 65.885\n",
      " * Prec@1 38.000 Prec@5 66.000\n",
      " * Prec@1 38.462 Prec@5 65.865\n",
      " * Prec@1 38.889 Prec@5 65.972\n",
      " * Prec@1 38.839 Prec@5 65.848\n",
      " * Prec@1 38.147 Prec@5 65.733\n",
      " * Prec@1 37.708 Prec@5 66.250\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.210 (1.266)\n",
      "\n",
      "Loss 2.5253 (2.5763)\n",
      "\n",
      "Prec@1 43.750 (37.903)\n",
      "\n",
      "Prec@5 75.000 (66.532)\n",
      "\n",
      " * Prec@1 37.903 Prec@5 66.532\n",
      " * Prec@1 38.867 Prec@5 66.992\n",
      " * Prec@1 38.636 Prec@5 67.424\n",
      " * Prec@1 38.419 Prec@5 67.831\n",
      " * Prec@1 37.679 Prec@5 67.321\n",
      " * Prec@1 37.153 Prec@5 66.840\n",
      " * Prec@1 36.993 Prec@5 66.723\n",
      " * Prec@1 36.678 Prec@5 66.447\n",
      " * Prec@1 36.859 Prec@5 66.667\n",
      " * Prec@1 36.406 Prec@5 66.875\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.119 (1.256)\n",
      "\n",
      "Loss 2.7090 (2.6095)\n",
      "\n",
      "Prec@1 25.000 (36.128)\n",
      "\n",
      "Prec@5 50.000 (66.463)\n",
      "\n",
      " * Prec@1 36.128 Prec@5 66.463\n",
      " * Prec@1 36.012 Prec@5 66.369\n",
      " * Prec@1 36.192 Prec@5 66.134\n",
      " * Prec@1 36.506 Prec@5 66.193\n",
      " * Prec@1 36.111 Prec@5 65.694\n",
      " * Prec@1 35.734 Prec@5 65.353\n",
      " * Prec@1 35.638 Prec@5 65.293\n",
      " * Prec@1 35.547 Prec@5 65.104\n",
      " * Prec@1 35.587 Prec@5 65.179\n",
      " * Prec@1 35.375 Prec@5 65.500\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.153 (1.246)\n",
      "\n",
      "Loss 2.5735 (2.6467)\n",
      "\n",
      "Prec@1 43.750 (35.539)\n",
      "\n",
      "Prec@5 62.500 (65.441)\n",
      "\n",
      " * Prec@1 35.539 Prec@5 65.441\n",
      " * Prec@1 35.457 Prec@5 65.144\n",
      " * Prec@1 35.613 Prec@5 65.094\n",
      " * Prec@1 35.532 Prec@5 64.815\n",
      " * Prec@1 35.682 Prec@5 64.773\n",
      " * Prec@1 35.491 Prec@5 64.509\n",
      " * Prec@1 35.307 Prec@5 64.364\n",
      " * Prec@1 35.022 Prec@5 64.440\n",
      " * Prec@1 34.958 Prec@5 64.407\n",
      " * Prec@1 35.000 Prec@5 64.479\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.161 (1.243)\n",
      "\n",
      "Loss 3.6928 (2.6920)\n",
      "\n",
      "Prec@1 12.500 (34.631)\n",
      "\n",
      "Prec@5 50.000 (64.242)\n",
      "\n",
      " * Prec@1 34.631 Prec@5 64.242\n",
      " * Prec@1 34.778 Prec@5 64.617\n",
      " * Prec@1 34.623 Prec@5 64.583\n",
      " * Prec@1 34.766 Prec@5 64.453\n",
      " * Prec@1 35.000 Prec@5 64.519\n",
      " * Prec@1 34.848 Prec@5 64.110\n",
      " * Prec@1 34.795 Prec@5 64.086\n",
      " * Prec@1 35.018 Prec@5 64.154\n",
      " * Prec@1 35.145 Prec@5 64.221\n",
      " * Prec@1 35.000 Prec@5 64.107\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.154 (1.244)\n",
      "\n",
      "Loss 2.5520 (2.6796)\n",
      "\n",
      "Prec@1 37.500 (35.035)\n",
      "\n",
      "Prec@5 56.250 (63.996)\n",
      "\n",
      " * Prec@1 35.035 Prec@5 63.996\n",
      " * Prec@1 34.896 Prec@5 64.149\n",
      " * Prec@1 34.932 Prec@5 64.212\n",
      " * Prec@1 35.135 Prec@5 64.358\n",
      " * Prec@1 35.250 Prec@5 64.667\n",
      " * Prec@1 35.197 Prec@5 64.720\n",
      " * Prec@1 35.390 Prec@5 64.773\n",
      " * Prec@1 35.577 Prec@5 64.984\n",
      " * Prec@1 35.443 Prec@5 65.032\n",
      " * Prec@1 35.156 Prec@5 64.922\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.191 (1.239)\n",
      "\n",
      "Loss 3.2619 (2.6714)\n",
      "\n",
      "Prec@1 31.250 (35.108)\n",
      "\n",
      "Prec@5 50.000 (64.738)\n",
      "\n",
      " * Prec@1 35.108 Prec@5 64.738\n",
      " * Prec@1 35.213 Prec@5 64.787\n",
      " * Prec@1 34.940 Prec@5 64.608\n",
      " * Prec@1 35.119 Prec@5 64.881\n",
      " * Prec@1 35.221 Prec@5 64.853\n",
      " * Prec@1 35.102 Prec@5 64.680\n",
      " * Prec@1 35.129 Prec@5 64.655\n",
      " * Prec@1 35.085 Prec@5 64.631\n",
      " * Prec@1 35.112 Prec@5 64.747\n",
      " * Prec@1 35.069 Prec@5 64.583\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.082 (1.229)\n",
      "\n",
      "Loss 3.0933 (2.6775)\n",
      "\n",
      "Prec@1 31.250 (35.027)\n",
      "\n",
      "Prec@5 43.750 (64.354)\n",
      "\n",
      " * Prec@1 35.027 Prec@5 64.354\n",
      " * Prec@1 34.986 Prec@5 64.334\n",
      " * Prec@1 35.081 Prec@5 64.315\n",
      " * Prec@1 35.040 Prec@5 64.162\n",
      " * Prec@1 35.132 Prec@5 64.211\n",
      " * Prec@1 35.221 Prec@5 64.193\n",
      " * Prec@1 35.052 Prec@5 64.175\n",
      " * Prec@1 35.013 Prec@5 64.031\n",
      " * Prec@1 34.912 Prec@5 64.078\n",
      " * Prec@1 35.000 Prec@5 64.125\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.226 (1.221)\n",
      "\n",
      "Loss 2.5067 (2.6837)\n",
      "\n",
      "Prec@1 37.500 (35.025)\n",
      "\n",
      "Prec@5 56.250 (64.047)\n",
      "\n",
      " * Prec@1 35.025 Prec@5 64.047\n",
      " * Prec@1 34.988 Prec@5 63.848\n",
      " * Prec@1 34.951 Prec@5 63.896\n",
      " * Prec@1 34.976 Prec@5 63.822\n",
      " * Prec@1 34.881 Prec@5 63.869\n",
      " * Prec@1 34.965 Prec@5 63.797\n",
      " * Prec@1 34.871 Prec@5 63.902\n",
      " * Prec@1 35.012 Prec@5 63.889\n",
      " * Prec@1 35.092 Prec@5 63.933\n",
      " * Prec@1 34.986 Prec@5 63.875\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/987]\t\\Time 1.131 (1.131)\tData 0.460 (0.460)\tLoss 1.6343 (1.6343)\tPrec@1 50.000 (50.000)\tPrec@5 87.500 (87.500)\n",
      "Epoch: [3][100/987]\t\\Time 2.056 (2.066)\tData 1.442 (1.480)\tLoss 1.9145 (2.0631)\tPrec@1 43.750 (49.010)\tPrec@5 75.000 (77.413)\n",
      "Epoch: [3][200/987]\t\\Time 2.058 (2.070)\tData 1.448 (1.484)\tLoss 2.0646 (2.0701)\tPrec@1 31.250 (48.476)\tPrec@5 75.000 (76.803)\n",
      "Epoch: [3][300/987]\t\\Time 2.065 (2.072)\tData 1.445 (1.485)\tLoss 1.9499 (2.0522)\tPrec@1 75.000 (49.024)\tPrec@5 81.250 (77.471)\n",
      "Epoch: [3][400/987]\t\\Time 2.075 (2.073)\tData 1.451 (1.486)\tLoss 1.2146 (2.0542)\tPrec@1 75.000 (49.049)\tPrec@5 87.500 (77.011)\n",
      "Epoch: [3][500/987]\t\\Time 2.067 (2.073)\tData 1.448 (1.487)\tLoss 1.9168 (2.0272)\tPrec@1 43.750 (49.351)\tPrec@5 81.250 (77.320)\n",
      "Epoch: [3][600/987]\t\\Time 2.059 (2.074)\tData 1.449 (1.487)\tLoss 2.9521 (2.0155)\tPrec@1 25.000 (49.511)\tPrec@5 43.750 (77.558)\n",
      "Epoch: [3][700/987]\t\\Time 2.062 (2.074)\tData 1.449 (1.487)\tLoss 2.2216 (2.0045)\tPrec@1 37.500 (49.973)\tPrec@5 81.250 (77.746)\n",
      "Epoch: [3][800/987]\t\\Time 2.073 (2.074)\tData 1.449 (1.487)\tLoss 2.2409 (1.9923)\tPrec@1 50.000 (50.398)\tPrec@5 75.000 (77.871)\n",
      "Epoch: [3][900/987]\t\\Time 2.056 (2.074)\tData 1.441 (1.487)\tLoss 2.0247 (1.9804)\tPrec@1 43.750 (50.728)\tPrec@5 87.500 (77.955)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.818 (1.818)\n",
      "\n",
      "Loss 2.1669 (2.1669)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 75.000\n",
      " * Prec@1 56.250 Prec@5 75.000\n",
      " * Prec@1 58.333 Prec@5 79.167\n",
      " * Prec@1 57.812 Prec@5 78.125\n",
      " * Prec@1 58.750 Prec@5 81.250\n",
      " * Prec@1 61.458 Prec@5 81.250\n",
      " * Prec@1 59.821 Prec@5 82.143\n",
      " * Prec@1 62.500 Prec@5 84.375\n",
      " * Prec@1 61.111 Prec@5 81.944\n",
      " * Prec@1 61.250 Prec@5 82.500\n",
      "Test: [10/110]\n",
      "\n",
      "Time 0.992 (1.143)\n",
      "\n",
      "Loss 1.7319 (1.7285)\n",
      "\n",
      "Prec@1 43.750 (59.659)\n",
      "\n",
      "Prec@5 93.750 (83.523)\n",
      "\n",
      " * Prec@1 59.659 Prec@5 83.523\n",
      " * Prec@1 58.854 Prec@5 81.771\n",
      " * Prec@1 56.731 Prec@5 82.212\n",
      " * Prec@1 57.589 Prec@5 83.482\n",
      " * Prec@1 57.917 Prec@5 83.333\n",
      " * Prec@1 58.203 Prec@5 84.375\n",
      " * Prec@1 58.088 Prec@5 84.559\n",
      " * Prec@1 57.986 Prec@5 84.722\n",
      " * Prec@1 57.237 Prec@5 84.539\n",
      " * Prec@1 58.125 Prec@5 84.688\n",
      "Test: [20/110]\n",
      "\n",
      "Time 0.979 (1.126)\n",
      "\n",
      "Loss 2.3329 (1.7441)\n",
      "\n",
      "Prec@1 43.750 (57.440)\n",
      "\n",
      "Prec@5 75.000 (84.226)\n",
      "\n",
      " * Prec@1 57.440 Prec@5 84.226\n",
      " * Prec@1 57.386 Prec@5 83.807\n",
      " * Prec@1 56.793 Prec@5 83.696\n",
      " * Prec@1 55.990 Prec@5 82.812\n",
      " * Prec@1 55.750 Prec@5 83.000\n",
      " * Prec@1 55.529 Prec@5 83.173\n",
      " * Prec@1 55.556 Prec@5 83.333\n",
      " * Prec@1 55.580 Prec@5 83.705\n",
      " * Prec@1 54.957 Prec@5 83.190\n",
      " * Prec@1 55.000 Prec@5 83.333\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.000 (1.114)\n",
      "\n",
      "Loss 2.6779 (1.8764)\n",
      "\n",
      "Prec@1 37.500 (54.435)\n",
      "\n",
      "Prec@5 81.250 (83.266)\n",
      "\n",
      " * Prec@1 54.435 Prec@5 83.266\n",
      " * Prec@1 54.492 Prec@5 83.203\n",
      " * Prec@1 54.356 Prec@5 83.144\n",
      " * Prec@1 55.331 Prec@5 83.272\n",
      " * Prec@1 55.179 Prec@5 82.857\n",
      " * Prec@1 54.688 Prec@5 82.812\n",
      " * Prec@1 54.899 Prec@5 82.601\n",
      " * Prec@1 54.112 Prec@5 82.072\n",
      " * Prec@1 54.167 Prec@5 81.571\n",
      " * Prec@1 54.688 Prec@5 81.875\n",
      "Test: [40/110]\n",
      "\n",
      "Time 0.964 (1.108)\n",
      "\n",
      "Loss 1.9899 (1.9039)\n",
      "\n",
      "Prec@1 37.500 (54.268)\n",
      "\n",
      "Prec@5 87.500 (82.012)\n",
      "\n",
      " * Prec@1 54.268 Prec@5 82.012\n",
      " * Prec@1 54.315 Prec@5 81.994\n",
      " * Prec@1 54.215 Prec@5 81.686\n",
      " * Prec@1 54.545 Prec@5 81.534\n",
      " * Prec@1 54.444 Prec@5 81.389\n",
      " * Prec@1 54.755 Prec@5 81.386\n",
      " * Prec@1 54.388 Prec@5 81.250\n",
      " * Prec@1 54.167 Prec@5 80.990\n",
      " * Prec@1 54.082 Prec@5 80.740\n",
      " * Prec@1 54.500 Prec@5 81.000\n",
      "Test: [50/110]\n",
      "\n",
      "Time 0.992 (1.108)\n",
      "\n",
      "Loss 1.7832 (1.9301)\n",
      "\n",
      "Prec@1 56.250 (54.534)\n",
      "\n",
      "Prec@5 81.250 (81.005)\n",
      "\n",
      " * Prec@1 54.534 Prec@5 81.005\n",
      " * Prec@1 54.207 Prec@5 80.649\n",
      " * Prec@1 54.245 Prec@5 80.542\n",
      " * Prec@1 54.398 Prec@5 80.440\n",
      " * Prec@1 54.091 Prec@5 80.114\n",
      " * Prec@1 54.129 Prec@5 79.911\n",
      " * Prec@1 54.276 Prec@5 79.934\n",
      " * Prec@1 54.526 Prec@5 80.065\n",
      " * Prec@1 54.555 Prec@5 80.191\n",
      " * Prec@1 55.104 Prec@5 80.521\n",
      "Test: [60/110]\n",
      "\n",
      "Time 0.974 (1.104)\n",
      "\n",
      "Loss 3.1204 (1.9693)\n",
      "\n",
      "Prec@1 31.250 (54.713)\n",
      "\n",
      "Prec@5 68.750 (80.328)\n",
      "\n",
      " * Prec@1 54.713 Prec@5 80.328\n",
      " * Prec@1 55.040 Prec@5 80.645\n",
      " * Prec@1 54.960 Prec@5 80.456\n",
      " * Prec@1 54.688 Prec@5 80.176\n",
      " * Prec@1 54.712 Prec@5 80.192\n",
      " * Prec@1 54.545 Prec@5 80.208\n",
      " * Prec@1 54.478 Prec@5 80.037\n",
      " * Prec@1 54.779 Prec@5 80.147\n",
      " * Prec@1 54.710 Prec@5 80.072\n",
      " * Prec@1 54.464 Prec@5 80.000\n",
      "Test: [70/110]\n",
      "\n",
      "Time 0.980 (1.102)\n",
      "\n",
      "Loss 1.7450 (1.9576)\n",
      "\n",
      "Prec@1 50.000 (54.401)\n",
      "\n",
      "Prec@5 81.250 (80.018)\n",
      "\n",
      " * Prec@1 54.401 Prec@5 80.018\n",
      " * Prec@1 54.253 Prec@5 79.948\n",
      " * Prec@1 54.623 Prec@5 80.137\n",
      " * Prec@1 54.392 Prec@5 79.814\n",
      " * Prec@1 54.417 Prec@5 79.917\n",
      " * Prec@1 54.112 Prec@5 79.770\n",
      " * Prec@1 54.302 Prec@5 79.870\n",
      " * Prec@1 54.487 Prec@5 79.968\n",
      " * Prec@1 54.509 Prec@5 79.905\n",
      " * Prec@1 54.297 Prec@5 79.922\n",
      "Test: [80/110]\n",
      "\n",
      "Time 0.978 (1.101)\n",
      "\n",
      "Loss 2.1671 (1.9537)\n",
      "\n",
      "Prec@1 43.750 (54.167)\n",
      "\n",
      "Prec@5 75.000 (79.861)\n",
      "\n",
      " * Prec@1 54.167 Prec@5 79.861\n",
      " * Prec@1 54.192 Prec@5 79.954\n",
      " * Prec@1 54.066 Prec@5 79.970\n",
      " * Prec@1 54.241 Prec@5 80.060\n",
      " * Prec@1 54.044 Prec@5 79.926\n",
      " * Prec@1 53.924 Prec@5 79.797\n",
      " * Prec@1 53.807 Prec@5 79.813\n",
      " * Prec@1 53.835 Prec@5 79.830\n",
      " * Prec@1 54.073 Prec@5 79.846\n",
      " * Prec@1 54.028 Prec@5 79.583\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.101 (1.101)\n",
      "\n",
      "Loss 2.3499 (1.9715)\n",
      "\n",
      "Prec@1 43.750 (53.915)\n",
      "\n",
      "Prec@5 81.250 (79.602)\n",
      "\n",
      " * Prec@1 53.915 Prec@5 79.602\n",
      " * Prec@1 54.008 Prec@5 79.688\n",
      " * Prec@1 54.032 Prec@5 79.704\n",
      " * Prec@1 53.856 Prec@5 79.588\n",
      " * Prec@1 53.618 Prec@5 79.408\n",
      " * Prec@1 53.711 Prec@5 79.427\n",
      " * Prec@1 53.673 Prec@5 79.317\n",
      " * Prec@1 53.571 Prec@5 79.337\n",
      " * Prec@1 53.283 Prec@5 79.356\n",
      " * Prec@1 53.438 Prec@5 79.250\n",
      "Test: [100/110]\n",
      "\n",
      "Time 0.984 (1.099)\n",
      "\n",
      "Loss 1.1657 (1.9741)\n",
      "\n",
      "Prec@1 68.750 (53.589)\n",
      "\n",
      "Prec@5 87.500 (79.332)\n",
      "\n",
      " * Prec@1 53.589 Prec@5 79.332\n",
      " * Prec@1 53.431 Prec@5 79.044\n",
      " * Prec@1 53.459 Prec@5 79.187\n",
      " * Prec@1 53.606 Prec@5 79.267\n",
      " * Prec@1 53.512 Prec@5 79.345\n",
      " * Prec@1 53.479 Prec@5 79.304\n",
      " * Prec@1 53.446 Prec@5 79.322\n",
      " * Prec@1 53.472 Prec@5 79.340\n",
      " * Prec@1 53.498 Prec@5 79.415\n",
      " * Prec@1 53.333 Prec@5 79.259\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/987]\t\\Time 0.997 (0.997)\tData 0.417 (0.417)\tLoss 0.9459 (0.9459)\tPrec@1 68.750 (68.750)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [4][100/987]\t\\Time 2.015 (2.010)\tData 1.442 (1.428)\tLoss 0.6660 (1.1949)\tPrec@1 81.250 (68.441)\tPrec@5 93.750 (89.480)\n",
      "Epoch: [4][200/987]\t\\Time 2.019 (2.016)\tData 1.440 (1.434)\tLoss 0.4613 (1.1630)\tPrec@1 87.500 (69.185)\tPrec@5 100.000 (90.174)\n",
      "Epoch: [4][300/987]\t\\Time 2.007 (2.018)\tData 1.434 (1.436)\tLoss 0.8443 (1.2209)\tPrec@1 81.250 (67.899)\tPrec@5 87.500 (89.348)\n",
      "Epoch: [4][400/987]\t\\Time 2.021 (2.018)\tData 1.438 (1.436)\tLoss 1.3014 (1.2510)\tPrec@1 62.500 (67.285)\tPrec@5 93.750 (88.825)\n",
      "Epoch: [4][500/987]\t\\Time 2.014 (2.018)\tData 1.433 (1.437)\tLoss 1.2833 (1.2621)\tPrec@1 62.500 (66.804)\tPrec@5 100.000 (88.860)\n",
      "Epoch: [4][600/987]\t\\Time 2.025 (2.019)\tData 1.440 (1.437)\tLoss 0.8258 (1.2616)\tPrec@1 87.500 (67.169)\tPrec@5 93.750 (88.873)\n",
      "Epoch: [4][700/987]\t\\Time 2.008 (2.019)\tData 1.438 (1.437)\tLoss 1.4707 (1.2703)\tPrec@1 62.500 (66.949)\tPrec@5 87.500 (88.650)\n",
      "Epoch: [4][800/987]\t\\Time 2.024 (2.019)\tData 1.444 (1.437)\tLoss 0.7179 (1.2759)\tPrec@1 87.500 (66.831)\tPrec@5 93.750 (88.483)\n",
      "Epoch: [4][900/987]\t\\Time 2.022 (2.019)\tData 1.442 (1.438)\tLoss 1.6580 (1.2735)\tPrec@1 62.500 (66.884)\tPrec@5 75.000 (88.464)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.751 (1.751)\n",
      "\n",
      "Loss 1.3438 (1.3438)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 70.833 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 85.938\n",
      " * Prec@1 67.500 Prec@5 86.250\n",
      " * Prec@1 68.750 Prec@5 86.458\n",
      " * Prec@1 67.857 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 89.062\n",
      " * Prec@1 65.278 Prec@5 86.806\n",
      " * Prec@1 66.250 Prec@5 87.500\n",
      "Test: [10/110]\n",
      "\n",
      "Time 0.969 (1.140)\n",
      "\n",
      "Loss 1.5402 (1.4465)\n",
      "\n",
      "Prec@1 56.250 (65.341)\n",
      "\n",
      "Prec@5 81.250 (86.932)\n",
      "\n",
      " * Prec@1 65.341 Prec@5 86.932\n",
      " * Prec@1 63.542 Prec@5 85.417\n",
      " * Prec@1 64.423 Prec@5 85.577\n",
      " * Prec@1 64.286 Prec@5 86.607\n",
      " * Prec@1 64.583 Prec@5 86.250\n",
      " * Prec@1 65.234 Prec@5 86.719\n",
      " * Prec@1 65.441 Prec@5 86.397\n",
      " * Prec@1 63.542 Prec@5 86.806\n",
      " * Prec@1 63.158 Prec@5 86.184\n",
      " * Prec@1 63.750 Prec@5 86.562\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.030 (1.149)\n",
      "\n",
      "Loss 1.7998 (1.5401)\n",
      "\n",
      "Prec@1 56.250 (63.393)\n",
      "\n",
      "Prec@5 75.000 (86.012)\n",
      "\n",
      " * Prec@1 63.393 Prec@5 86.012\n",
      " * Prec@1 62.500 Prec@5 85.511\n",
      " * Prec@1 62.772 Prec@5 85.598\n",
      " * Prec@1 62.500 Prec@5 85.417\n",
      " * Prec@1 62.000 Prec@5 85.250\n",
      " * Prec@1 62.019 Prec@5 85.337\n",
      " * Prec@1 61.806 Prec@5 84.954\n",
      " * Prec@1 62.277 Prec@5 85.045\n",
      " * Prec@1 62.069 Prec@5 84.914\n",
      " * Prec@1 62.292 Prec@5 85.000\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.023 (1.146)\n",
      "\n",
      "Loss 2.4022 (1.6520)\n",
      "\n",
      "Prec@1 31.250 (61.290)\n",
      "\n",
      "Prec@5 81.250 (84.879)\n",
      "\n",
      " * Prec@1 61.290 Prec@5 84.879\n",
      " * Prec@1 61.523 Prec@5 85.352\n",
      " * Prec@1 61.553 Prec@5 85.227\n",
      " * Prec@1 61.397 Prec@5 85.294\n",
      " * Prec@1 61.250 Prec@5 85.000\n",
      " * Prec@1 61.285 Prec@5 84.896\n",
      " * Prec@1 61.318 Prec@5 84.797\n",
      " * Prec@1 60.691 Prec@5 84.046\n",
      " * Prec@1 60.417 Prec@5 83.814\n",
      " * Prec@1 60.781 Prec@5 84.062\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.023 (1.136)\n",
      "\n",
      "Loss 1.4036 (1.6719)\n",
      "\n",
      "Prec@1 62.500 (60.823)\n",
      "\n",
      "Prec@5 81.250 (83.994)\n",
      "\n",
      " * Prec@1 60.823 Prec@5 83.994\n",
      " * Prec@1 60.714 Prec@5 83.631\n",
      " * Prec@1 60.465 Prec@5 83.576\n",
      " * Prec@1 60.653 Prec@5 83.523\n",
      " * Prec@1 60.833 Prec@5 83.472\n",
      " * Prec@1 60.462 Prec@5 83.424\n",
      " * Prec@1 60.904 Prec@5 83.777\n",
      " * Prec@1 60.547 Prec@5 83.724\n",
      " * Prec@1 60.332 Prec@5 83.673\n",
      " * Prec@1 60.750 Prec@5 83.750\n",
      "Test: [50/110]\n",
      "\n",
      "Time 0.996 (1.125)\n",
      "\n",
      "Loss 1.3209 (1.6654)\n",
      "\n",
      "Prec@1 62.500 (60.784)\n",
      "\n",
      "Prec@5 75.000 (83.578)\n",
      "\n",
      " * Prec@1 60.784 Prec@5 83.578\n",
      " * Prec@1 60.457 Prec@5 83.413\n",
      " * Prec@1 60.259 Prec@5 83.255\n",
      " * Prec@1 60.069 Prec@5 83.218\n",
      " * Prec@1 59.773 Prec@5 82.955\n",
      " * Prec@1 59.487 Prec@5 82.924\n",
      " * Prec@1 59.649 Prec@5 83.004\n",
      " * Prec@1 59.698 Prec@5 82.974\n",
      " * Prec@1 59.852 Prec@5 83.051\n",
      " * Prec@1 60.104 Prec@5 83.125\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.040 (1.113)\n",
      "\n",
      "Loss 3.0638 (1.7253)\n",
      "\n",
      "Prec@1 37.500 (59.734)\n",
      "\n",
      "Prec@5 62.500 (82.787)\n",
      "\n",
      " * Prec@1 59.734 Prec@5 82.787\n",
      " * Prec@1 59.879 Prec@5 82.863\n",
      " * Prec@1 59.623 Prec@5 82.639\n",
      " * Prec@1 59.668 Prec@5 82.715\n",
      " * Prec@1 59.808 Prec@5 82.692\n",
      " * Prec@1 59.848 Prec@5 82.670\n",
      " * Prec@1 59.701 Prec@5 82.649\n",
      " * Prec@1 59.926 Prec@5 82.721\n",
      " * Prec@1 59.964 Prec@5 82.790\n",
      " * Prec@1 60.000 Prec@5 82.946\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.111 (1.114)\n",
      "\n",
      "Loss 1.1960 (1.6897)\n",
      "\n",
      "Prec@1 62.500 (60.035)\n",
      "\n",
      "Prec@5 87.500 (83.011)\n",
      "\n",
      " * Prec@1 60.035 Prec@5 83.011\n",
      " * Prec@1 59.983 Prec@5 83.073\n",
      " * Prec@1 60.360 Prec@5 83.219\n",
      " * Prec@1 60.473 Prec@5 83.108\n",
      " * Prec@1 60.583 Prec@5 83.250\n",
      " * Prec@1 60.362 Prec@5 82.977\n",
      " * Prec@1 60.471 Prec@5 82.955\n",
      " * Prec@1 60.497 Prec@5 82.933\n",
      " * Prec@1 60.522 Prec@5 82.991\n",
      " * Prec@1 60.391 Prec@5 83.047\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.080 (1.116)\n",
      "\n",
      "Loss 1.9397 (1.6865)\n",
      "\n",
      "Prec@1 68.750 (60.494)\n",
      "\n",
      "Prec@5 75.000 (82.948)\n",
      "\n",
      " * Prec@1 60.494 Prec@5 82.948\n",
      " * Prec@1 60.595 Prec@5 83.003\n",
      " * Prec@1 60.392 Prec@5 82.982\n",
      " * Prec@1 60.491 Prec@5 82.961\n",
      " * Prec@1 60.294 Prec@5 82.941\n",
      " * Prec@1 60.247 Prec@5 82.922\n",
      " * Prec@1 60.201 Prec@5 82.902\n",
      " * Prec@1 60.085 Prec@5 82.812\n",
      " * Prec@1 60.323 Prec@5 82.865\n",
      " * Prec@1 60.208 Prec@5 82.778\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.040 (1.113)\n",
      "\n",
      "Loss 2.0020 (1.6997)\n",
      "\n",
      "Prec@1 56.250 (60.165)\n",
      "\n",
      "Prec@5 68.750 (82.624)\n",
      "\n",
      " * Prec@1 60.165 Prec@5 82.624\n",
      " * Prec@1 60.054 Prec@5 82.677\n",
      " * Prec@1 60.148 Prec@5 82.796\n",
      " * Prec@1 60.040 Prec@5 82.713\n",
      " * Prec@1 60.000 Prec@5 82.763\n",
      " * Prec@1 60.156 Prec@5 82.747\n",
      " * Prec@1 60.116 Prec@5 82.603\n",
      " * Prec@1 60.013 Prec@5 82.717\n",
      " * Prec@1 60.038 Prec@5 82.702\n",
      " * Prec@1 59.938 Prec@5 82.688\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.034 (1.108)\n",
      "\n",
      "Loss 1.1324 (1.7027)\n",
      "\n",
      "Prec@1 68.750 (60.025)\n",
      "\n",
      "Prec@5 93.750 (82.797)\n",
      "\n",
      " * Prec@1 60.025 Prec@5 82.797\n",
      " * Prec@1 60.049 Prec@5 82.782\n",
      " * Prec@1 60.073 Prec@5 82.767\n",
      " * Prec@1 60.036 Prec@5 82.752\n",
      " * Prec@1 60.000 Prec@5 82.738\n",
      " * Prec@1 59.965 Prec@5 82.842\n",
      " * Prec@1 59.871 Prec@5 82.769\n",
      " * Prec@1 59.838 Prec@5 82.755\n",
      " * Prec@1 59.920 Prec@5 82.913\n",
      " * Prec@1 59.715 Prec@5 82.678\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/987]\t\\Time 0.912 (0.912)\tData 0.375 (0.375)\tLoss 1.1795 (1.1795)\tPrec@1 75.000 (75.000)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [5][100/987]\t\\Time 2.022 (2.043)\tData 1.411 (1.424)\tLoss 0.8516 (0.5875)\tPrec@1 81.250 (83.292)\tPrec@5 93.750 (97.030)\n",
      "Epoch: [5][200/987]\t\\Time 2.031 (2.047)\tData 1.381 (1.422)\tLoss 0.8608 (0.6312)\tPrec@1 87.500 (81.934)\tPrec@5 93.750 (96.953)\n",
      "Epoch: [5][300/987]\t\\Time 2.095 (2.048)\tData 1.483 (1.422)\tLoss 1.2963 (0.6651)\tPrec@1 68.750 (81.084)\tPrec@5 93.750 (96.262)\n",
      "Epoch: [5][400/987]\t\\Time 2.040 (2.049)\tData 1.423 (1.422)\tLoss 0.5183 (0.6994)\tPrec@1 81.250 (80.549)\tPrec@5 100.000 (95.916)\n",
      "Epoch: [5][500/987]\t\\Time 2.039 (2.049)\tData 1.369 (1.421)\tLoss 0.3934 (0.7078)\tPrec@1 93.750 (80.289)\tPrec@5 100.000 (95.833)\n",
      "Epoch: [5][600/987]\t\\Time 2.101 (2.050)\tData 1.486 (1.421)\tLoss 1.6995 (0.7176)\tPrec@1 56.250 (80.085)\tPrec@5 93.750 (95.726)\n",
      "Epoch: [5][700/987]\t\\Time 2.021 (2.050)\tData 1.406 (1.421)\tLoss 1.0151 (0.7301)\tPrec@1 81.250 (79.752)\tPrec@5 93.750 (95.426)\n",
      "Epoch: [5][800/987]\t\\Time 2.022 (2.050)\tData 1.361 (1.421)\tLoss 1.5427 (0.7466)\tPrec@1 62.500 (79.260)\tPrec@5 81.250 (95.178)\n",
      "Epoch: [5][900/987]\t\\Time 2.102 (2.050)\tData 1.479 (1.421)\tLoss 0.9275 (0.7570)\tPrec@1 81.250 (79.107)\tPrec@5 87.500 (94.964)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.883 (1.883)\n",
      "\n",
      "Loss 1.7301 (1.7301)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 87.500\n",
      " * Prec@1 56.250 Prec@5 84.375\n",
      " * Prec@1 62.500 Prec@5 85.417\n",
      " * Prec@1 64.062 Prec@5 85.938\n",
      " * Prec@1 63.750 Prec@5 87.500\n",
      " * Prec@1 64.583 Prec@5 86.458\n",
      " * Prec@1 64.286 Prec@5 87.500\n",
      " * Prec@1 67.188 Prec@5 89.062\n",
      " * Prec@1 64.583 Prec@5 87.500\n",
      " * Prec@1 63.750 Prec@5 88.125\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.007 (1.177)\n",
      "\n",
      "Loss 1.9416 (1.4339)\n",
      "\n",
      "Prec@1 56.250 (63.068)\n",
      "\n",
      "Prec@5 81.250 (87.500)\n",
      "\n",
      " * Prec@1 63.068 Prec@5 87.500\n",
      " * Prec@1 61.979 Prec@5 85.938\n",
      " * Prec@1 62.019 Prec@5 86.058\n",
      " * Prec@1 63.839 Prec@5 86.607\n",
      " * Prec@1 63.750 Prec@5 87.083\n",
      " * Prec@1 65.625 Prec@5 87.891\n",
      " * Prec@1 65.809 Prec@5 88.235\n",
      " * Prec@1 65.625 Prec@5 87.847\n",
      " * Prec@1 65.789 Prec@5 87.829\n",
      " * Prec@1 66.875 Prec@5 88.125\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.025 (1.153)\n",
      "\n",
      "Loss 1.7531 (1.3693)\n",
      "\n",
      "Prec@1 75.000 (67.262)\n",
      "\n",
      "Prec@5 81.250 (87.798)\n",
      "\n",
      " * Prec@1 67.262 Prec@5 87.798\n",
      " * Prec@1 67.330 Prec@5 87.500\n",
      " * Prec@1 67.391 Prec@5 87.228\n",
      " * Prec@1 67.708 Prec@5 86.979\n",
      " * Prec@1 67.500 Prec@5 86.750\n",
      " * Prec@1 67.548 Prec@5 86.538\n",
      " * Prec@1 67.824 Prec@5 86.343\n",
      " * Prec@1 68.080 Prec@5 86.384\n",
      " * Prec@1 68.103 Prec@5 86.207\n",
      " * Prec@1 68.333 Prec@5 86.250\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.050 (1.146)\n",
      "\n",
      "Loss 1.3142 (1.4405)\n",
      "\n",
      "Prec@1 62.500 (68.145)\n",
      "\n",
      "Prec@5 93.750 (86.492)\n",
      "\n",
      " * Prec@1 68.145 Prec@5 86.492\n",
      " * Prec@1 68.555 Prec@5 86.719\n",
      " * Prec@1 68.371 Prec@5 86.742\n",
      " * Prec@1 68.382 Prec@5 86.949\n",
      " * Prec@1 68.214 Prec@5 86.607\n",
      " * Prec@1 67.882 Prec@5 86.632\n",
      " * Prec@1 68.074 Prec@5 86.486\n",
      " * Prec@1 67.599 Prec@5 86.020\n",
      " * Prec@1 67.468 Prec@5 85.737\n",
      " * Prec@1 67.656 Prec@5 85.938\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.071 (1.147)\n",
      "\n",
      "Loss 1.1443 (1.4691)\n",
      "\n",
      "Prec@1 68.750 (67.683)\n",
      "\n",
      "Prec@5 93.750 (86.128)\n",
      "\n",
      " * Prec@1 67.683 Prec@5 86.128\n",
      " * Prec@1 67.262 Prec@5 85.714\n",
      " * Prec@1 67.151 Prec@5 85.465\n",
      " * Prec@1 67.330 Prec@5 85.511\n",
      " * Prec@1 67.361 Prec@5 85.417\n",
      " * Prec@1 66.984 Prec@5 85.326\n",
      " * Prec@1 67.154 Prec@5 85.505\n",
      " * Prec@1 66.797 Prec@5 85.156\n",
      " * Prec@1 66.709 Prec@5 85.204\n",
      " * Prec@1 66.625 Prec@5 85.125\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.063 (1.147)\n",
      "\n",
      "Loss 1.3556 (1.4937)\n",
      "\n",
      "Prec@1 81.250 (66.912)\n",
      "\n",
      "Prec@5 87.500 (85.172)\n",
      "\n",
      " * Prec@1 66.912 Prec@5 85.172\n",
      " * Prec@1 66.346 Prec@5 84.976\n",
      " * Prec@1 66.156 Prec@5 84.670\n",
      " * Prec@1 66.319 Prec@5 84.838\n",
      " * Prec@1 66.023 Prec@5 84.659\n",
      " * Prec@1 66.071 Prec@5 84.487\n",
      " * Prec@1 66.009 Prec@5 84.649\n",
      " * Prec@1 66.056 Prec@5 84.698\n",
      " * Prec@1 65.996 Prec@5 84.640\n",
      " * Prec@1 66.250 Prec@5 84.896\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.043 (1.144)\n",
      "\n",
      "Loss 2.5451 (1.5646)\n",
      "\n",
      "Prec@1 56.250 (66.086)\n",
      "\n",
      "Prec@5 75.000 (84.734)\n",
      "\n",
      " * Prec@1 66.086 Prec@5 84.734\n",
      " * Prec@1 66.230 Prec@5 84.980\n",
      " * Prec@1 66.071 Prec@5 84.722\n",
      " * Prec@1 66.016 Prec@5 84.668\n",
      " * Prec@1 65.865 Prec@5 84.808\n",
      " * Prec@1 65.814 Prec@5 84.659\n",
      " * Prec@1 65.858 Prec@5 84.701\n",
      " * Prec@1 65.993 Prec@5 84.835\n",
      " * Prec@1 66.033 Prec@5 84.873\n",
      " * Prec@1 66.250 Prec@5 85.000\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.033 (1.144)\n",
      "\n",
      "Loss 0.8511 (1.5432)\n",
      "\n",
      "Prec@1 75.000 (66.373)\n",
      "\n",
      "Prec@5 93.750 (85.123)\n",
      "\n",
      " * Prec@1 66.373 Prec@5 85.123\n",
      " * Prec@1 66.580 Prec@5 85.243\n",
      " * Prec@1 66.866 Prec@5 85.274\n",
      " * Prec@1 66.639 Prec@5 85.135\n",
      " * Prec@1 66.750 Prec@5 85.250\n",
      " * Prec@1 66.859 Prec@5 85.197\n",
      " * Prec@1 66.964 Prec@5 85.390\n",
      " * Prec@1 67.067 Prec@5 85.497\n",
      " * Prec@1 67.089 Prec@5 85.443\n",
      " * Prec@1 66.953 Prec@5 85.391\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.052 (1.143)\n",
      "\n",
      "Loss 1.2275 (1.5069)\n",
      "\n",
      "Prec@1 81.250 (67.130)\n",
      "\n",
      "Prec@5 87.500 (85.417)\n",
      "\n",
      " * Prec@1 67.130 Prec@5 85.417\n",
      " * Prec@1 67.149 Prec@5 85.442\n",
      " * Prec@1 67.018 Prec@5 85.542\n",
      " * Prec@1 67.113 Prec@5 85.565\n",
      " * Prec@1 66.838 Prec@5 85.515\n",
      " * Prec@1 66.933 Prec@5 85.610\n",
      " * Prec@1 66.882 Prec@5 85.489\n",
      " * Prec@1 66.974 Prec@5 85.440\n",
      " * Prec@1 67.135 Prec@5 85.534\n",
      " * Prec@1 67.153 Prec@5 85.486\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.075 (1.143)\n",
      "\n",
      "Loss 1.8025 (1.5042)\n",
      "\n",
      "Prec@1 68.750 (67.170)\n",
      "\n",
      "Prec@5 81.250 (85.440)\n",
      "\n",
      " * Prec@1 67.170 Prec@5 85.440\n",
      " * Prec@1 67.323 Prec@5 85.530\n",
      " * Prec@1 67.406 Prec@5 85.551\n",
      " * Prec@1 67.487 Prec@5 85.572\n",
      " * Prec@1 67.566 Prec@5 85.658\n",
      " * Prec@1 67.578 Prec@5 85.612\n",
      " * Prec@1 67.655 Prec@5 85.503\n",
      " * Prec@1 67.666 Prec@5 85.459\n",
      " * Prec@1 67.740 Prec@5 85.543\n",
      " * Prec@1 67.688 Prec@5 85.562\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.051 (1.142)\n",
      "\n",
      "Loss 0.6815 (1.4887)\n",
      "\n",
      "Prec@1 81.250 (67.822)\n",
      "\n",
      "Prec@5 93.750 (85.644)\n",
      "\n",
      " * Prec@1 67.822 Prec@5 85.644\n",
      " * Prec@1 67.708 Prec@5 85.600\n",
      " * Prec@1 67.718 Prec@5 85.558\n",
      " * Prec@1 67.668 Prec@5 85.637\n",
      " * Prec@1 67.500 Prec@5 85.536\n",
      " * Prec@1 67.512 Prec@5 85.436\n",
      " * Prec@1 67.465 Prec@5 85.397\n",
      " * Prec@1 67.477 Prec@5 85.359\n",
      " * Prec@1 67.546 Prec@5 85.436\n",
      " * Prec@1 67.293 Prec@5 85.185\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/987]\t\\Time 1.174 (1.174)\tData 0.480 (0.480)\tLoss 0.6198 (0.6198)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [6][100/987]\t\\Time 2.108 (2.111)\tData 1.480 (1.485)\tLoss 0.2086 (0.3226)\tPrec@1 100.000 (90.285)\tPrec@5 100.000 (99.257)\n",
      "Epoch: [6][200/987]\t\\Time 2.108 (2.109)\tData 1.474 (1.480)\tLoss 0.2029 (0.3206)\tPrec@1 93.750 (90.174)\tPrec@5 100.000 (99.036)\n",
      "Epoch: [6][300/987]\t\\Time 2.105 (2.108)\tData 1.483 (1.479)\tLoss 0.2666 (0.3223)\tPrec@1 93.750 (90.345)\tPrec@5 100.000 (99.003)\n",
      "Epoch: [6][400/987]\t\\Time 2.097 (2.108)\tData 1.479 (1.478)\tLoss 0.3646 (0.3275)\tPrec@1 87.500 (90.337)\tPrec@5 100.000 (98.940)\n",
      "Epoch: [6][500/987]\t\\Time 2.142 (2.108)\tData 1.469 (1.478)\tLoss 0.4480 (0.3373)\tPrec@1 87.500 (89.958)\tPrec@5 93.750 (98.852)\n",
      "Epoch: [6][600/987]\t\\Time 2.108 (2.108)\tData 1.477 (1.477)\tLoss 0.2124 (0.3448)\tPrec@1 93.750 (89.819)\tPrec@5 100.000 (98.762)\n",
      "Epoch: [6][700/987]\t\\Time 2.092 (2.107)\tData 1.471 (1.477)\tLoss 0.3900 (0.3552)\tPrec@1 93.750 (89.667)\tPrec@5 100.000 (98.672)\n",
      "Epoch: [6][800/987]\t\\Time 2.107 (2.108)\tData 1.473 (1.477)\tLoss 0.3558 (0.3674)\tPrec@1 87.500 (89.380)\tPrec@5 100.000 (98.564)\n",
      "Epoch: [6][900/987]\t\\Time 2.099 (2.108)\tData 1.474 (1.477)\tLoss 0.2746 (0.3822)\tPrec@1 93.750 (88.922)\tPrec@5 100.000 (98.391)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 2.043 (2.043)\n",
      "\n",
      "Loss 1.2301 (1.2301)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      " * Prec@1 79.167 Prec@5 91.667\n",
      " * Prec@1 78.125 Prec@5 89.062\n",
      " * Prec@1 77.500 Prec@5 88.750\n",
      " * Prec@1 76.042 Prec@5 87.500\n",
      " * Prec@1 77.679 Prec@5 88.393\n",
      " * Prec@1 79.688 Prec@5 89.844\n",
      " * Prec@1 78.472 Prec@5 89.583\n",
      " * Prec@1 79.375 Prec@5 90.000\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.062 (1.220)\n",
      "\n",
      "Loss 1.6740 (1.2116)\n",
      "\n",
      "Prec@1 56.250 (77.273)\n",
      "\n",
      "Prec@5 87.500 (89.773)\n",
      "\n",
      " * Prec@1 77.273 Prec@5 89.773\n",
      " * Prec@1 76.042 Prec@5 88.021\n",
      " * Prec@1 75.000 Prec@5 87.981\n",
      " * Prec@1 75.000 Prec@5 88.839\n",
      " * Prec@1 74.583 Prec@5 89.167\n",
      " * Prec@1 76.172 Prec@5 89.844\n",
      " * Prec@1 76.103 Prec@5 89.338\n",
      " * Prec@1 75.694 Prec@5 89.236\n",
      " * Prec@1 74.671 Prec@5 88.816\n",
      " * Prec@1 75.312 Prec@5 88.750\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.081 (1.193)\n",
      "\n",
      "Loss 1.4249 (1.2536)\n",
      "\n",
      "Prec@1 75.000 (75.298)\n",
      "\n",
      "Prec@5 81.250 (88.393)\n",
      "\n",
      " * Prec@1 75.298 Prec@5 88.393\n",
      " * Prec@1 75.284 Prec@5 88.068\n",
      " * Prec@1 75.272 Prec@5 87.772\n",
      " * Prec@1 75.260 Prec@5 88.021\n",
      " * Prec@1 75.000 Prec@5 88.000\n",
      " * Prec@1 75.000 Prec@5 87.981\n",
      " * Prec@1 75.231 Prec@5 87.963\n",
      " * Prec@1 75.446 Prec@5 87.946\n",
      " * Prec@1 75.647 Prec@5 88.147\n",
      " * Prec@1 75.417 Prec@5 87.708\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.128 (1.188)\n",
      "\n",
      "Loss 1.3300 (1.3424)\n",
      "\n",
      "Prec@1 75.000 (75.403)\n",
      "\n",
      "Prec@5 93.750 (87.903)\n",
      "\n",
      " * Prec@1 75.403 Prec@5 87.903\n",
      " * Prec@1 75.781 Prec@5 88.281\n",
      " * Prec@1 75.758 Prec@5 88.447\n",
      " * Prec@1 76.103 Prec@5 88.603\n",
      " * Prec@1 75.893 Prec@5 88.393\n",
      " * Prec@1 75.868 Prec@5 88.368\n",
      " * Prec@1 75.676 Prec@5 88.176\n",
      " * Prec@1 74.671 Prec@5 87.664\n",
      " * Prec@1 74.519 Prec@5 87.340\n",
      " * Prec@1 74.688 Prec@5 87.344\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.092 (1.185)\n",
      "\n",
      "Loss 0.7796 (1.3587)\n",
      "\n",
      "Prec@1 87.500 (75.000)\n",
      "\n",
      "Prec@5 87.500 (87.348)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 87.348\n",
      " * Prec@1 74.851 Prec@5 87.054\n",
      " * Prec@1 74.709 Prec@5 86.919\n",
      " * Prec@1 74.858 Prec@5 87.074\n",
      " * Prec@1 75.000 Prec@5 86.944\n",
      " * Prec@1 75.136 Prec@5 87.092\n",
      " * Prec@1 74.867 Prec@5 87.367\n",
      " * Prec@1 74.479 Prec@5 87.240\n",
      " * Prec@1 74.107 Prec@5 87.372\n",
      " * Prec@1 74.250 Prec@5 87.375\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.104 (1.184)\n",
      "\n",
      "Loss 0.6174 (1.3557)\n",
      "\n",
      "Prec@1 81.250 (74.387)\n",
      "\n",
      "Prec@5 100.000 (87.623)\n",
      "\n",
      " * Prec@1 74.387 Prec@5 87.623\n",
      " * Prec@1 73.918 Prec@5 87.500\n",
      " * Prec@1 73.703 Prec@5 87.264\n",
      " * Prec@1 73.843 Prec@5 87.269\n",
      " * Prec@1 73.523 Prec@5 86.932\n",
      " * Prec@1 73.214 Prec@5 86.942\n",
      " * Prec@1 73.136 Prec@5 86.952\n",
      " * Prec@1 73.276 Prec@5 87.069\n",
      " * Prec@1 73.305 Prec@5 87.182\n",
      " * Prec@1 73.438 Prec@5 87.396\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.107 (1.181)\n",
      "\n",
      "Loss 2.9580 (1.4114)\n",
      "\n",
      "Prec@1 50.000 (73.053)\n",
      "\n",
      "Prec@5 68.750 (87.090)\n",
      "\n",
      " * Prec@1 73.053 Prec@5 87.090\n",
      " * Prec@1 73.085 Prec@5 87.298\n",
      " * Prec@1 72.917 Prec@5 87.202\n",
      " * Prec@1 73.242 Prec@5 87.305\n",
      " * Prec@1 73.462 Prec@5 87.500\n",
      " * Prec@1 73.580 Prec@5 87.500\n",
      " * Prec@1 73.601 Prec@5 87.407\n",
      " * Prec@1 73.805 Prec@5 87.500\n",
      " * Prec@1 73.913 Prec@5 87.500\n",
      " * Prec@1 74.018 Prec@5 87.589\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.096 (1.180)\n",
      "\n",
      "Loss 1.1528 (1.3680)\n",
      "\n",
      "Prec@1 68.750 (73.944)\n",
      "\n",
      "Prec@5 93.750 (87.676)\n",
      "\n",
      " * Prec@1 73.944 Prec@5 87.676\n",
      " * Prec@1 73.958 Prec@5 87.760\n",
      " * Prec@1 74.229 Prec@5 87.928\n",
      " * Prec@1 74.324 Prec@5 87.922\n",
      " * Prec@1 74.417 Prec@5 88.000\n",
      " * Prec@1 74.342 Prec@5 87.747\n",
      " * Prec@1 74.432 Prec@5 87.744\n",
      " * Prec@1 74.519 Prec@5 87.821\n",
      " * Prec@1 74.446 Prec@5 87.816\n",
      " * Prec@1 74.297 Prec@5 87.656\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.081 (1.178)\n",
      "\n",
      "Loss 2.0757 (1.3433)\n",
      "\n",
      "Prec@1 68.750 (74.228)\n",
      "\n",
      "Prec@5 75.000 (87.500)\n",
      "\n",
      " * Prec@1 74.228 Prec@5 87.500\n",
      " * Prec@1 74.162 Prec@5 87.500\n",
      " * Prec@1 74.322 Prec@5 87.500\n",
      " * Prec@1 74.405 Prec@5 87.574\n",
      " * Prec@1 74.191 Prec@5 87.574\n",
      " * Prec@1 74.055 Prec@5 87.645\n",
      " * Prec@1 73.922 Prec@5 87.572\n",
      " * Prec@1 73.864 Prec@5 87.358\n",
      " * Prec@1 74.017 Prec@5 87.500\n",
      " * Prec@1 73.889 Prec@5 87.431\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.092 (1.178)\n",
      "\n",
      "Loss 1.3586 (1.3614)\n",
      "\n",
      "Prec@1 87.500 (74.038)\n",
      "\n",
      "Prec@5 87.500 (87.431)\n",
      "\n",
      " * Prec@1 74.038 Prec@5 87.431\n",
      " * Prec@1 74.049 Prec@5 87.432\n",
      " * Prec@1 73.992 Prec@5 87.433\n",
      " * Prec@1 73.936 Prec@5 87.500\n",
      " * Prec@1 73.882 Prec@5 87.500\n",
      " * Prec@1 73.958 Prec@5 87.435\n",
      " * Prec@1 73.905 Prec@5 87.371\n",
      " * Prec@1 73.852 Prec@5 87.309\n",
      " * Prec@1 73.864 Prec@5 87.311\n",
      " * Prec@1 73.875 Prec@5 87.312\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.084 (1.178)\n",
      "\n",
      "Loss 0.5301 (1.3627)\n",
      "\n",
      "Prec@1 93.750 (74.072)\n",
      "\n",
      "Prec@5 93.750 (87.376)\n",
      "\n",
      " * Prec@1 74.072 Prec@5 87.376\n",
      " * Prec@1 74.020 Prec@5 87.255\n",
      " * Prec@1 74.090 Prec@5 87.318\n",
      " * Prec@1 74.038 Prec@5 87.320\n",
      " * Prec@1 73.929 Prec@5 87.262\n",
      " * Prec@1 73.762 Prec@5 87.146\n",
      " * Prec@1 73.715 Prec@5 87.150\n",
      " * Prec@1 73.785 Prec@5 87.095\n",
      " * Prec@1 73.911 Prec@5 87.213\n",
      " * Prec@1 73.618 Prec@5 87.009\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/987]\t\\Time 1.057 (1.057)\tData 0.368 (0.368)\tLoss 0.0863 (0.0863)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/987]\t\\Time 2.055 (2.050)\tData 1.436 (1.430)\tLoss 0.1031 (0.1817)\tPrec@1 100.000 (95.792)\tPrec@5 100.000 (99.567)\n",
      "Epoch: [7][200/987]\t\\Time 2.061 (2.054)\tData 1.445 (1.434)\tLoss 0.1536 (0.1830)\tPrec@1 93.750 (95.211)\tPrec@5 100.000 (99.689)\n",
      "Epoch: [7][300/987]\t\\Time 2.065 (2.055)\tData 1.444 (1.435)\tLoss 0.0155 (0.1583)\tPrec@1 100.000 (95.972)\tPrec@5 100.000 (99.792)\n",
      "Epoch: [7][400/987]\t\\Time 2.054 (2.056)\tData 1.443 (1.436)\tLoss 0.2673 (0.1702)\tPrec@1 81.250 (95.387)\tPrec@5 100.000 (99.719)\n",
      "Epoch: [7][500/987]\t\\Time 2.053 (2.056)\tData 1.438 (1.436)\tLoss 0.0180 (0.1698)\tPrec@1 100.000 (95.359)\tPrec@5 100.000 (99.738)\n",
      "Epoch: [7][600/987]\t\\Time 2.061 (2.056)\tData 1.444 (1.437)\tLoss 0.0487 (0.1683)\tPrec@1 100.000 (95.445)\tPrec@5 100.000 (99.719)\n",
      "Epoch: [7][700/987]\t\\Time 2.056 (2.057)\tData 1.444 (1.437)\tLoss 0.1898 (0.1666)\tPrec@1 93.750 (95.480)\tPrec@5 100.000 (99.724)\n",
      "Epoch: [7][800/987]\t\\Time 2.058 (2.057)\tData 1.435 (1.437)\tLoss 0.6506 (0.1626)\tPrec@1 93.750 (95.638)\tPrec@5 93.750 (99.735)\n",
      "Epoch: [7][900/987]\t\\Time 2.063 (2.057)\tData 1.444 (1.437)\tLoss 0.0788 (0.1660)\tPrec@1 93.750 (95.547)\tPrec@5 100.000 (99.736)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.822 (1.822)\n",
      "\n",
      "Loss 1.0016 (1.0016)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 93.750\n",
      " * Prec@1 81.250 Prec@5 93.750\n",
      " * Prec@1 81.250 Prec@5 91.667\n",
      " * Prec@1 79.688 Prec@5 89.062\n",
      " * Prec@1 76.250 Prec@5 88.750\n",
      " * Prec@1 76.042 Prec@5 89.583\n",
      " * Prec@1 78.571 Prec@5 91.071\n",
      " * Prec@1 80.469 Prec@5 92.188\n",
      " * Prec@1 78.472 Prec@5 89.583\n",
      " * Prec@1 79.375 Prec@5 90.000\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.023 (1.160)\n",
      "\n",
      "Loss 1.2104 (1.0619)\n",
      "\n",
      "Prec@1 62.500 (77.841)\n",
      "\n",
      "Prec@5 81.250 (89.205)\n",
      "\n",
      " * Prec@1 77.841 Prec@5 89.205\n",
      " * Prec@1 76.042 Prec@5 88.021\n",
      " * Prec@1 75.481 Prec@5 87.500\n",
      " * Prec@1 76.786 Prec@5 88.393\n",
      " * Prec@1 77.500 Prec@5 88.333\n",
      " * Prec@1 78.125 Prec@5 89.062\n",
      " * Prec@1 77.941 Prec@5 89.338\n",
      " * Prec@1 77.083 Prec@5 89.583\n",
      " * Prec@1 76.316 Prec@5 89.474\n",
      " * Prec@1 77.188 Prec@5 89.688\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.009 (1.161)\n",
      "\n",
      "Loss 1.4606 (1.1701)\n",
      "\n",
      "Prec@1 81.250 (77.381)\n",
      "\n",
      "Prec@5 87.500 (89.583)\n",
      "\n",
      " * Prec@1 77.381 Prec@5 89.583\n",
      " * Prec@1 77.273 Prec@5 89.205\n",
      " * Prec@1 76.630 Prec@5 89.130\n",
      " * Prec@1 76.042 Prec@5 89.062\n",
      " * Prec@1 76.000 Prec@5 89.000\n",
      " * Prec@1 75.721 Prec@5 88.942\n",
      " * Prec@1 75.694 Prec@5 88.889\n",
      " * Prec@1 75.893 Prec@5 88.839\n",
      " * Prec@1 76.293 Prec@5 89.009\n",
      " * Prec@1 76.250 Prec@5 88.750\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.155 (1.176)\n",
      "\n",
      "Loss 1.8443 (1.2944)\n",
      "\n",
      "Prec@1 68.750 (76.008)\n",
      "\n",
      "Prec@5 81.250 (88.508)\n",
      "\n",
      " * Prec@1 76.008 Prec@5 88.508\n",
      " * Prec@1 76.562 Prec@5 88.867\n",
      " * Prec@1 76.515 Prec@5 88.826\n",
      " * Prec@1 76.838 Prec@5 88.971\n",
      " * Prec@1 76.786 Prec@5 88.750\n",
      " * Prec@1 76.910 Prec@5 88.715\n",
      " * Prec@1 76.858 Prec@5 88.682\n",
      " * Prec@1 75.987 Prec@5 88.158\n",
      " * Prec@1 75.801 Prec@5 87.981\n",
      " * Prec@1 75.938 Prec@5 87.969\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.041 (1.178)\n",
      "\n",
      "Loss 0.5907 (1.3201)\n",
      "\n",
      "Prec@1 81.250 (76.067)\n",
      "\n",
      "Prec@5 93.750 (88.110)\n",
      "\n",
      " * Prec@1 76.067 Prec@5 88.110\n",
      " * Prec@1 75.595 Prec@5 87.798\n",
      " * Prec@1 75.727 Prec@5 87.791\n",
      " * Prec@1 75.852 Prec@5 87.784\n",
      " * Prec@1 75.972 Prec@5 87.778\n",
      " * Prec@1 76.087 Prec@5 87.908\n",
      " * Prec@1 76.330 Prec@5 88.165\n",
      " * Prec@1 76.042 Prec@5 88.021\n",
      " * Prec@1 76.020 Prec@5 88.138\n",
      " * Prec@1 76.250 Prec@5 88.125\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.089 (1.175)\n",
      "\n",
      "Loss 0.6851 (1.2850)\n",
      "\n",
      "Prec@1 87.500 (76.471)\n",
      "\n",
      "Prec@5 93.750 (88.235)\n",
      "\n",
      " * Prec@1 76.471 Prec@5 88.235\n",
      " * Prec@1 76.202 Prec@5 88.221\n",
      " * Prec@1 76.061 Prec@5 87.972\n",
      " * Prec@1 76.042 Prec@5 87.963\n",
      " * Prec@1 75.568 Prec@5 87.614\n",
      " * Prec@1 75.446 Prec@5 87.388\n",
      " * Prec@1 75.439 Prec@5 87.500\n",
      " * Prec@1 75.431 Prec@5 87.500\n",
      " * Prec@1 75.424 Prec@5 87.394\n",
      " * Prec@1 75.521 Prec@5 87.500\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.040 (1.172)\n",
      "\n",
      "Loss 3.6660 (1.3738)\n",
      "\n",
      "Prec@1 56.250 (75.205)\n",
      "\n",
      "Prec@5 62.500 (87.090)\n",
      "\n",
      " * Prec@1 75.205 Prec@5 87.090\n",
      " * Prec@1 75.302 Prec@5 87.198\n",
      " * Prec@1 75.198 Prec@5 87.202\n",
      " * Prec@1 75.488 Prec@5 87.305\n",
      " * Prec@1 75.673 Prec@5 87.500\n",
      " * Prec@1 75.663 Prec@5 87.500\n",
      " * Prec@1 75.746 Prec@5 87.593\n",
      " * Prec@1 75.919 Prec@5 87.592\n",
      " * Prec@1 75.906 Prec@5 87.500\n",
      " * Prec@1 76.161 Prec@5 87.679\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.170 (1.174)\n",
      "\n",
      "Loss 1.2106 (1.3023)\n",
      "\n",
      "Prec@1 81.250 (76.232)\n",
      "\n",
      "Prec@5 87.500 (87.676)\n",
      "\n",
      " * Prec@1 76.232 Prec@5 87.676\n",
      " * Prec@1 76.389 Prec@5 87.847\n",
      " * Prec@1 76.627 Prec@5 88.014\n",
      " * Prec@1 76.605 Prec@5 87.922\n",
      " * Prec@1 76.667 Prec@5 87.917\n",
      " * Prec@1 76.562 Prec@5 87.829\n",
      " * Prec@1 76.542 Prec@5 87.825\n",
      " * Prec@1 76.522 Prec@5 87.901\n",
      " * Prec@1 76.661 Prec@5 87.975\n",
      " * Prec@1 76.719 Prec@5 88.047\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.109 (1.169)\n",
      "\n",
      "Loss 1.8051 (1.2669)\n",
      "\n",
      "Prec@1 75.000 (76.698)\n",
      "\n",
      "Prec@5 75.000 (87.886)\n",
      "\n",
      " * Prec@1 76.698 Prec@5 87.886\n",
      " * Prec@1 76.753 Prec@5 87.957\n",
      " * Prec@1 76.581 Prec@5 87.952\n",
      " * Prec@1 76.637 Prec@5 88.021\n",
      " * Prec@1 76.471 Prec@5 88.015\n",
      " * Prec@1 76.381 Prec@5 87.936\n",
      " * Prec@1 76.293 Prec@5 87.859\n",
      " * Prec@1 76.278 Prec@5 87.784\n",
      " * Prec@1 76.475 Prec@5 87.851\n",
      " * Prec@1 76.250 Prec@5 87.847\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.018 (1.156)\n",
      "\n",
      "Loss 0.9091 (1.2753)\n",
      "\n",
      "Prec@1 87.500 (76.374)\n",
      "\n",
      "Prec@5 93.750 (87.912)\n",
      "\n",
      " * Prec@1 76.374 Prec@5 87.912\n",
      " * Prec@1 76.359 Prec@5 87.976\n",
      " * Prec@1 76.478 Prec@5 87.970\n",
      " * Prec@1 76.529 Prec@5 87.965\n",
      " * Prec@1 76.447 Prec@5 87.961\n",
      " * Prec@1 76.497 Prec@5 87.956\n",
      " * Prec@1 76.482 Prec@5 87.887\n",
      " * Prec@1 76.339 Prec@5 87.819\n",
      " * Prec@1 76.263 Prec@5 87.816\n",
      " * Prec@1 76.312 Prec@5 87.812\n",
      "Test: [100/110]\n",
      "\n",
      "Time 0.994 (1.147)\n",
      "\n",
      "Loss 0.4807 (1.2708)\n",
      "\n",
      "Prec@1 93.750 (76.485)\n",
      "\n",
      "Prec@5 93.750 (87.871)\n",
      "\n",
      " * Prec@1 76.485 Prec@5 87.871\n",
      " * Prec@1 76.409 Prec@5 87.868\n",
      " * Prec@1 76.214 Prec@5 87.985\n",
      " * Prec@1 76.202 Prec@5 88.041\n",
      " * Prec@1 76.071 Prec@5 87.976\n",
      " * Prec@1 76.061 Prec@5 87.972\n",
      " * Prec@1 76.110 Prec@5 87.967\n",
      " * Prec@1 76.100 Prec@5 87.905\n",
      " * Prec@1 76.261 Prec@5 88.016\n",
      " * Prec@1 76.011 Prec@5 87.749\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/987]\t\\Time 0.975 (0.975)\tData 0.401 (0.401)\tLoss 0.0905 (0.0905)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/987]\t\\Time 2.051 (2.065)\tData 1.464 (1.476)\tLoss 0.0084 (0.0525)\tPrec@1 100.000 (98.762)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [8][200/987]\t\\Time 2.052 (2.072)\tData 1.459 (1.483)\tLoss 0.2007 (0.0637)\tPrec@1 93.750 (98.476)\tPrec@5 93.750 (99.876)\n",
      "Epoch: [8][300/987]\t\\Time 2.051 (2.074)\tData 1.460 (1.485)\tLoss 0.0824 (0.0690)\tPrec@1 93.750 (98.360)\tPrec@5 100.000 (99.896)\n",
      "Epoch: [8][400/987]\t\\Time 2.048 (2.074)\tData 1.462 (1.486)\tLoss 0.0444 (0.0671)\tPrec@1 100.000 (98.473)\tPrec@5 100.000 (99.922)\n",
      "Epoch: [8][500/987]\t\\Time 2.054 (2.074)\tData 1.461 (1.486)\tLoss 0.0093 (0.0665)\tPrec@1 100.000 (98.478)\tPrec@5 100.000 (99.913)\n",
      "Epoch: [8][600/987]\t\\Time 2.043 (2.074)\tData 1.461 (1.486)\tLoss 0.1851 (0.0660)\tPrec@1 93.750 (98.544)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [8][700/987]\t\\Time 2.041 (2.074)\tData 1.458 (1.486)\tLoss 0.0192 (0.0630)\tPrec@1 100.000 (98.645)\tPrec@5 100.000 (99.920)\n",
      "Epoch: [8][800/987]\t\\Time 2.063 (2.074)\tData 1.474 (1.486)\tLoss 0.0469 (0.0663)\tPrec@1 100.000 (98.549)\tPrec@5 100.000 (99.922)\n",
      "Epoch: [8][900/987]\t\\Time 2.065 (2.074)\tData 1.472 (1.487)\tLoss 0.2189 (0.0656)\tPrec@1 87.500 (98.564)\tPrec@5 100.000 (99.931)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.805 (1.805)\n",
      "\n",
      "Loss 1.1989 (1.1989)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      " * Prec@1 81.250 Prec@5 89.583\n",
      " * Prec@1 78.125 Prec@5 87.500\n",
      " * Prec@1 77.500 Prec@5 88.750\n",
      " * Prec@1 77.083 Prec@5 88.542\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 82.031 Prec@5 91.406\n",
      " * Prec@1 80.556 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 90.000\n",
      "Test: [10/110]\n",
      "\n",
      "Time 0.955 (1.122)\n",
      "\n",
      "Loss 1.5066 (1.0555)\n",
      "\n",
      "Prec@1 62.500 (79.545)\n",
      "\n",
      "Prec@5 87.500 (89.773)\n",
      "\n",
      " * Prec@1 79.545 Prec@5 89.773\n",
      " * Prec@1 77.604 Prec@5 89.062\n",
      " * Prec@1 77.404 Prec@5 89.423\n",
      " * Prec@1 78.571 Prec@5 90.179\n",
      " * Prec@1 78.333 Prec@5 89.583\n",
      " * Prec@1 79.688 Prec@5 90.234\n",
      " * Prec@1 79.412 Prec@5 90.074\n",
      " * Prec@1 78.819 Prec@5 90.278\n",
      " * Prec@1 78.618 Prec@5 90.461\n",
      " * Prec@1 79.062 Prec@5 90.625\n",
      "Test: [20/110]\n",
      "\n",
      "Time 0.982 (1.104)\n",
      "\n",
      "Loss 1.3001 (1.1347)\n",
      "\n",
      "Prec@1 81.250 (79.167)\n",
      "\n",
      "Prec@5 87.500 (90.476)\n",
      "\n",
      " * Prec@1 79.167 Prec@5 90.476\n",
      " * Prec@1 79.261 Prec@5 90.057\n",
      " * Prec@1 79.348 Prec@5 89.946\n",
      " * Prec@1 79.167 Prec@5 89.844\n",
      " * Prec@1 79.000 Prec@5 89.750\n",
      " * Prec@1 79.087 Prec@5 89.663\n",
      " * Prec@1 79.398 Prec@5 89.583\n",
      " * Prec@1 79.464 Prec@5 89.732\n",
      " * Prec@1 79.957 Prec@5 89.871\n",
      " * Prec@1 79.792 Prec@5 89.792\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.004 (1.096)\n",
      "\n",
      "Loss 1.9487 (1.1988)\n",
      "\n",
      "Prec@1 75.000 (79.637)\n",
      "\n",
      "Prec@5 87.500 (89.718)\n",
      "\n",
      " * Prec@1 79.637 Prec@5 89.718\n",
      " * Prec@1 80.078 Prec@5 90.039\n",
      " * Prec@1 80.303 Prec@5 90.152\n",
      " * Prec@1 80.515 Prec@5 90.441\n",
      " * Prec@1 80.357 Prec@5 90.179\n",
      " * Prec@1 80.556 Prec@5 90.104\n",
      " * Prec@1 80.574 Prec@5 90.203\n",
      " * Prec@1 79.770 Prec@5 89.474\n",
      " * Prec@1 79.327 Prec@5 89.423\n",
      " * Prec@1 79.531 Prec@5 89.688\n",
      "Test: [40/110]\n",
      "\n",
      "Time 0.972 (1.097)\n",
      "\n",
      "Loss 0.8106 (1.2046)\n",
      "\n",
      "Prec@1 81.250 (79.573)\n",
      "\n",
      "Prec@5 87.500 (89.634)\n",
      "\n",
      " * Prec@1 79.573 Prec@5 89.634\n",
      " * Prec@1 79.464 Prec@5 89.435\n",
      " * Prec@1 79.506 Prec@5 89.390\n",
      " * Prec@1 79.688 Prec@5 89.347\n",
      " * Prec@1 79.722 Prec@5 89.306\n",
      " * Prec@1 79.755 Prec@5 89.266\n",
      " * Prec@1 80.053 Prec@5 89.495\n",
      " * Prec@1 79.557 Prec@5 89.323\n",
      " * Prec@1 79.592 Prec@5 89.541\n",
      " * Prec@1 79.625 Prec@5 89.625\n",
      "Test: [50/110]\n",
      "\n",
      "Time 0.987 (1.098)\n",
      "\n",
      "Loss 1.2158 (1.1776)\n",
      "\n",
      "Prec@1 81.250 (79.657)\n",
      "\n",
      "Prec@5 87.500 (89.583)\n",
      "\n",
      " * Prec@1 79.657 Prec@5 89.583\n",
      " * Prec@1 79.207 Prec@5 89.423\n",
      " * Prec@1 79.009 Prec@5 89.151\n",
      " * Prec@1 79.051 Prec@5 89.352\n",
      " * Prec@1 78.750 Prec@5 89.091\n",
      " * Prec@1 78.683 Prec@5 89.174\n",
      " * Prec@1 78.618 Prec@5 89.145\n",
      " * Prec@1 78.556 Prec@5 89.116\n",
      " * Prec@1 78.602 Prec@5 88.983\n",
      " * Prec@1 78.646 Prec@5 89.062\n",
      "Test: [60/110]\n",
      "\n",
      "Time 0.981 (1.095)\n",
      "\n",
      "Loss 3.1089 (1.2493)\n",
      "\n",
      "Prec@1 50.000 (78.176)\n",
      "\n",
      "Prec@5 62.500 (88.627)\n",
      "\n",
      " * Prec@1 78.176 Prec@5 88.627\n",
      " * Prec@1 78.327 Prec@5 88.710\n",
      " * Prec@1 77.976 Prec@5 88.690\n",
      " * Prec@1 78.125 Prec@5 88.770\n",
      " * Prec@1 78.173 Prec@5 88.846\n",
      " * Prec@1 78.220 Prec@5 88.826\n",
      " * Prec@1 78.358 Prec@5 88.899\n",
      " * Prec@1 78.493 Prec@5 88.971\n",
      " * Prec@1 78.623 Prec@5 88.949\n",
      " * Prec@1 78.750 Prec@5 89.018\n",
      "Test: [70/110]\n",
      "\n",
      "Time 0.971 (1.094)\n",
      "\n",
      "Loss 1.2171 (1.1966)\n",
      "\n",
      "Prec@1 81.250 (78.785)\n",
      "\n",
      "Prec@5 93.750 (89.085)\n",
      "\n",
      " * Prec@1 78.785 Prec@5 89.085\n",
      " * Prec@1 78.819 Prec@5 89.236\n",
      " * Prec@1 79.024 Prec@5 89.384\n",
      " * Prec@1 79.054 Prec@5 89.274\n",
      " * Prec@1 79.083 Prec@5 89.333\n",
      " * Prec@1 78.783 Prec@5 89.145\n",
      " * Prec@1 78.896 Prec@5 89.123\n",
      " * Prec@1 78.926 Prec@5 89.103\n",
      " * Prec@1 78.956 Prec@5 89.082\n",
      " * Prec@1 78.828 Prec@5 88.906\n",
      "Test: [80/110]\n",
      "\n",
      "Time 0.983 (1.093)\n",
      "\n",
      "Loss 1.9857 (1.1855)\n",
      "\n",
      "Prec@1 75.000 (78.781)\n",
      "\n",
      "Prec@5 75.000 (88.735)\n",
      "\n",
      " * Prec@1 78.781 Prec@5 88.735\n",
      " * Prec@1 78.887 Prec@5 88.796\n",
      " * Prec@1 78.765 Prec@5 88.855\n",
      " * Prec@1 78.795 Prec@5 88.914\n",
      " * Prec@1 78.603 Prec@5 88.897\n",
      " * Prec@1 78.561 Prec@5 88.953\n",
      " * Prec@1 78.592 Prec@5 89.009\n",
      " * Prec@1 78.622 Prec@5 88.991\n",
      " * Prec@1 78.792 Prec@5 89.115\n",
      " * Prec@1 78.681 Prec@5 89.028\n",
      "Test: [90/110]\n",
      "\n",
      "Time 0.992 (1.092)\n",
      "\n",
      "Loss 1.2284 (1.1705)\n",
      "\n",
      "Prec@1 81.250 (78.709)\n",
      "\n",
      "Prec@5 87.500 (89.011)\n",
      "\n",
      " * Prec@1 78.709 Prec@5 89.011\n",
      " * Prec@1 78.804 Prec@5 89.062\n",
      " * Prec@1 78.898 Prec@5 89.113\n",
      " * Prec@1 78.923 Prec@5 89.029\n",
      " * Prec@1 78.882 Prec@5 89.013\n",
      " * Prec@1 78.906 Prec@5 88.932\n",
      " * Prec@1 78.930 Prec@5 88.853\n",
      " * Prec@1 78.890 Prec@5 88.839\n",
      " * Prec@1 78.914 Prec@5 88.889\n",
      " * Prec@1 78.875 Prec@5 88.875\n",
      "Test: [100/110]\n",
      "\n",
      "Time 0.999 (1.091)\n",
      "\n",
      "Loss 0.2894 (1.1574)\n",
      "\n",
      "Prec@1 93.750 (79.022)\n",
      "\n",
      "Prec@5 100.000 (88.985)\n",
      "\n",
      " * Prec@1 79.022 Prec@5 88.985\n",
      " * Prec@1 79.044 Prec@5 88.909\n",
      " * Prec@1 79.005 Prec@5 89.017\n",
      " * Prec@1 79.026 Prec@5 89.002\n",
      " * Prec@1 78.869 Prec@5 88.988\n",
      " * Prec@1 78.774 Prec@5 89.092\n",
      " * Prec@1 78.797 Prec@5 89.077\n",
      " * Prec@1 78.762 Prec@5 89.062\n",
      " * Prec@1 78.842 Prec@5 89.163\n",
      " * Prec@1 78.519 Prec@5 88.946\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/987]\t\\Time 1.021 (1.021)\tData 0.419 (0.419)\tLoss 0.0063 (0.0063)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/987]\t\\Time 2.022 (2.013)\tData 1.439 (1.431)\tLoss 0.0029 (0.0157)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][200/987]\t\\Time 2.041 (2.017)\tData 1.448 (1.435)\tLoss 0.0068 (0.0215)\tPrec@1 100.000 (99.658)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [9][300/987]\t\\Time 2.017 (2.018)\tData 1.438 (1.436)\tLoss 0.0016 (0.0202)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [9][400/987]\t\\Time 2.027 (2.018)\tData 1.434 (1.437)\tLoss 0.0048 (0.0230)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (99.953)\n",
      "Epoch: [9][500/987]\t\\Time 2.016 (2.019)\tData 1.434 (1.437)\tLoss 0.0028 (0.0238)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (99.950)\n",
      "Epoch: [9][600/987]\t\\Time 2.014 (2.019)\tData 1.439 (1.437)\tLoss 0.0060 (0.0232)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (99.948)\n",
      "Epoch: [9][700/987]\t\\Time 2.018 (2.019)\tData 1.436 (1.438)\tLoss 0.0090 (0.0218)\tPrec@1 100.000 (99.679)\tPrec@5 100.000 (99.947)\n",
      "Epoch: [9][800/987]\t\\Time 2.029 (2.019)\tData 1.446 (1.438)\tLoss 0.0028 (0.0222)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (99.945)\n",
      "Epoch: [9][900/987]\t\\Time 2.017 (2.019)\tData 1.436 (1.438)\tLoss 0.0018 (0.0230)\tPrec@1 100.000 (99.653)\tPrec@5 100.000 (99.951)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.755 (1.755)\n",
      "\n",
      "Loss 1.1416 (1.1416)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 83.929 Prec@5 89.286\n",
      " * Prec@1 85.938 Prec@5 90.625\n",
      " * Prec@1 84.028 Prec@5 88.889\n",
      " * Prec@1 85.000 Prec@5 90.000\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.000 (1.176)\n",
      "\n",
      "Loss 1.2705 (1.0139)\n",
      "\n",
      "Prec@1 56.250 (82.386)\n",
      "\n",
      "Prec@5 87.500 (89.773)\n",
      "\n",
      " * Prec@1 82.386 Prec@5 89.773\n",
      " * Prec@1 79.688 Prec@5 87.500\n",
      " * Prec@1 79.327 Prec@5 87.981\n",
      " * Prec@1 79.911 Prec@5 88.839\n",
      " * Prec@1 80.417 Prec@5 89.167\n",
      " * Prec@1 81.250 Prec@5 89.844\n",
      " * Prec@1 81.618 Prec@5 89.706\n",
      " * Prec@1 80.903 Prec@5 89.583\n",
      " * Prec@1 80.263 Prec@5 90.132\n",
      " * Prec@1 80.625 Prec@5 90.312\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.006 (1.180)\n",
      "\n",
      "Loss 1.3153 (1.0618)\n",
      "\n",
      "Prec@1 81.250 (80.655)\n",
      "\n",
      "Prec@5 87.500 (90.179)\n",
      "\n",
      " * Prec@1 80.655 Prec@5 90.179\n",
      " * Prec@1 80.682 Prec@5 89.773\n",
      " * Prec@1 80.163 Prec@5 89.674\n",
      " * Prec@1 80.208 Prec@5 89.844\n",
      " * Prec@1 80.250 Prec@5 89.750\n",
      " * Prec@1 80.529 Prec@5 89.663\n",
      " * Prec@1 80.556 Prec@5 89.583\n",
      " * Prec@1 81.027 Prec@5 89.732\n",
      " * Prec@1 81.466 Prec@5 89.871\n",
      " * Prec@1 81.250 Prec@5 89.792\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.033 (1.169)\n",
      "\n",
      "Loss 1.0040 (1.1035)\n",
      "\n",
      "Prec@1 75.000 (81.048)\n",
      "\n",
      "Prec@5 93.750 (89.919)\n",
      "\n",
      " * Prec@1 81.048 Prec@5 89.919\n",
      " * Prec@1 81.641 Prec@5 90.234\n",
      " * Prec@1 81.818 Prec@5 90.341\n",
      " * Prec@1 82.169 Prec@5 90.441\n",
      " * Prec@1 81.964 Prec@5 90.179\n",
      " * Prec@1 82.118 Prec@5 90.104\n",
      " * Prec@1 82.095 Prec@5 90.203\n",
      " * Prec@1 81.250 Prec@5 89.474\n",
      " * Prec@1 80.929 Prec@5 89.263\n",
      " * Prec@1 81.250 Prec@5 89.531\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.042 (1.173)\n",
      "\n",
      "Loss 0.6462 (1.1062)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 93.750 (89.634)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 89.634\n",
      " * Prec@1 80.804 Prec@5 89.435\n",
      " * Prec@1 80.814 Prec@5 89.244\n",
      " * Prec@1 80.824 Prec@5 89.205\n",
      " * Prec@1 80.833 Prec@5 89.167\n",
      " * Prec@1 80.842 Prec@5 89.130\n",
      " * Prec@1 81.117 Prec@5 89.229\n",
      " * Prec@1 80.859 Prec@5 89.193\n",
      " * Prec@1 80.995 Prec@5 89.413\n",
      " * Prec@1 80.875 Prec@5 89.500\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.054 (1.173)\n",
      "\n",
      "Loss 0.5764 (1.0892)\n",
      "\n",
      "Prec@1 93.750 (81.127)\n",
      "\n",
      "Prec@5 93.750 (89.583)\n",
      "\n",
      " * Prec@1 81.127 Prec@5 89.583\n",
      " * Prec@1 80.889 Prec@5 89.543\n",
      " * Prec@1 80.778 Prec@5 89.505\n",
      " * Prec@1 80.787 Prec@5 89.583\n",
      " * Prec@1 80.455 Prec@5 89.318\n",
      " * Prec@1 80.357 Prec@5 89.509\n",
      " * Prec@1 80.263 Prec@5 89.474\n",
      " * Prec@1 80.172 Prec@5 89.547\n",
      " * Prec@1 80.191 Prec@5 89.513\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.199 (1.204)\n",
      "\n",
      "Loss 3.0024 (1.1759)\n",
      "\n",
      "Prec@1 62.500 (79.918)\n",
      "\n",
      "Prec@5 81.250 (89.447)\n",
      "\n",
      " * Prec@1 79.918 Prec@5 89.447\n",
      " * Prec@1 80.141 Prec@5 89.617\n",
      " * Prec@1 79.861 Prec@5 89.484\n",
      " * Prec@1 80.078 Prec@5 89.551\n",
      " * Prec@1 80.192 Prec@5 89.712\n",
      " * Prec@1 80.303 Prec@5 89.773\n",
      " * Prec@1 80.317 Prec@5 89.832\n",
      " * Prec@1 80.515 Prec@5 89.890\n",
      " * Prec@1 80.616 Prec@5 89.946\n",
      " * Prec@1 80.714 Prec@5 90.089\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.137 (1.276)\n",
      "\n",
      "Loss 0.7499 (1.0984)\n",
      "\n",
      "Prec@1 87.500 (80.810)\n",
      "\n",
      "Prec@5 93.750 (90.141)\n",
      "\n",
      " * Prec@1 80.810 Prec@5 90.141\n",
      " * Prec@1 80.990 Prec@5 90.278\n",
      " * Prec@1 81.250 Prec@5 90.411\n",
      " * Prec@1 81.166 Prec@5 90.456\n",
      " * Prec@1 81.167 Prec@5 90.417\n",
      " * Prec@1 81.003 Prec@5 90.214\n",
      " * Prec@1 81.088 Prec@5 90.260\n",
      " * Prec@1 80.929 Prec@5 90.224\n",
      " * Prec@1 81.013 Prec@5 90.190\n",
      " * Prec@1 80.859 Prec@5 90.078\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.219 (1.286)\n",
      "\n",
      "Loss 1.9427 (1.0929)\n",
      "\n",
      "Prec@1 75.000 (80.787)\n",
      "\n",
      "Prec@5 81.250 (89.969)\n",
      "\n",
      " * Prec@1 80.787 Prec@5 89.969\n",
      " * Prec@1 80.869 Prec@5 90.015\n",
      " * Prec@1 80.798 Prec@5 90.060\n",
      " * Prec@1 80.804 Prec@5 90.104\n",
      " * Prec@1 80.515 Prec@5 90.074\n",
      " * Prec@1 80.451 Prec@5 90.116\n",
      " * Prec@1 80.460 Prec@5 90.014\n",
      " * Prec@1 80.469 Prec@5 89.986\n",
      " * Prec@1 80.618 Prec@5 90.098\n",
      " * Prec@1 80.486 Prec@5 90.069\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.101 (1.276)\n",
      "\n",
      "Loss 0.8703 (1.0887)\n",
      "\n",
      "Prec@1 81.250 (80.495)\n",
      "\n",
      "Prec@5 93.750 (90.110)\n",
      "\n",
      " * Prec@1 80.495 Prec@5 90.110\n",
      " * Prec@1 80.503 Prec@5 90.149\n",
      " * Prec@1 80.578 Prec@5 90.188\n",
      " * Prec@1 80.585 Prec@5 90.093\n",
      " * Prec@1 80.592 Prec@5 90.066\n",
      " * Prec@1 80.599 Prec@5 89.974\n",
      " * Prec@1 80.606 Prec@5 89.884\n",
      " * Prec@1 80.612 Prec@5 89.796\n",
      " * Prec@1 80.619 Prec@5 89.836\n",
      " * Prec@1 80.625 Prec@5 89.812\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.044 (1.265)\n",
      "\n",
      "Loss 0.3467 (1.0859)\n",
      "\n",
      "Prec@1 93.750 (80.755)\n",
      "\n",
      "Prec@5 100.000 (89.913)\n",
      "\n",
      " * Prec@1 80.755 Prec@5 89.913\n",
      " * Prec@1 80.699 Prec@5 89.890\n",
      " * Prec@1 80.704 Prec@5 89.988\n",
      " * Prec@1 80.649 Prec@5 89.964\n",
      " * Prec@1 80.595 Prec@5 90.000\n",
      " * Prec@1 80.542 Prec@5 90.035\n",
      " * Prec@1 80.432 Prec@5 90.012\n",
      " * Prec@1 80.324 Prec@5 89.988\n",
      " * Prec@1 80.390 Prec@5 90.080\n",
      " * Prec@1 80.057 Prec@5 89.801\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [10][0/987]\t\\Time 0.927 (0.927)\tData 0.404 (0.404)\tLoss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/987]\t\\Time 2.031 (2.043)\tData 1.407 (1.425)\tLoss 0.0025 (0.0262)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [10][200/987]\t\\Time 2.032 (2.047)\tData 1.369 (1.423)\tLoss 0.0010 (0.0226)\tPrec@1 100.000 (99.658)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [10][300/987]\t\\Time 2.089 (2.049)\tData 1.476 (1.422)\tLoss 0.0081 (0.0198)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [10][400/987]\t\\Time 2.025 (2.049)\tData 1.414 (1.422)\tLoss 0.0027 (0.0164)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [10][500/987]\t\\Time 2.021 (2.050)\tData 1.367 (1.422)\tLoss 0.0026 (0.0155)\tPrec@1 100.000 (99.738)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [10][600/987]\t\\Time 2.092 (2.050)\tData 1.478 (1.422)\tLoss 0.0008 (0.0139)\tPrec@1 100.000 (99.771)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [10][700/987]\t\\Time 2.018 (2.051)\tData 1.413 (1.422)\tLoss 0.0039 (0.0159)\tPrec@1 100.000 (99.724)\tPrec@5 100.000 (99.982)\n",
      "Epoch: [10][800/987]\t\\Time 2.038 (2.051)\tData 1.374 (1.422)\tLoss 0.3830 (0.0148)\tPrec@1 93.750 (99.750)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [10][900/987]\t\\Time 2.094 (2.051)\tData 1.481 (1.422)\tLoss 0.0020 (0.0156)\tPrec@1 100.000 (99.729)\tPrec@5 100.000 (99.986)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.884 (1.884)\n",
      "\n",
      "Loss 1.3734 (1.3734)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 88.542\n",
      " * Prec@1 83.929 Prec@5 90.179\n",
      " * Prec@1 85.938 Prec@5 91.406\n",
      " * Prec@1 84.028 Prec@5 89.583\n",
      " * Prec@1 85.000 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.062 (1.228)\n",
      "\n",
      "Loss 1.4666 (1.0705)\n",
      "\n",
      "Prec@1 56.250 (82.386)\n",
      "\n",
      "Prec@5 87.500 (90.341)\n",
      "\n",
      " * Prec@1 82.386 Prec@5 90.341\n",
      " * Prec@1 80.208 Prec@5 88.021\n",
      " * Prec@1 79.808 Prec@5 87.981\n",
      " * Prec@1 80.357 Prec@5 88.839\n",
      " * Prec@1 80.833 Prec@5 89.167\n",
      " * Prec@1 81.641 Prec@5 89.844\n",
      " * Prec@1 81.250 Prec@5 89.706\n",
      " * Prec@1 80.556 Prec@5 89.931\n",
      " * Prec@1 80.263 Prec@5 89.803\n",
      " * Prec@1 80.625 Prec@5 90.000\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.081 (1.206)\n",
      "\n",
      "Loss 1.1450 (1.1244)\n",
      "\n",
      "Prec@1 81.250 (80.655)\n",
      "\n",
      "Prec@5 87.500 (89.881)\n",
      "\n",
      " * Prec@1 80.655 Prec@5 89.881\n",
      " * Prec@1 80.682 Prec@5 89.489\n",
      " * Prec@1 80.163 Prec@5 89.402\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 80.000 Prec@5 89.750\n",
      " * Prec@1 80.048 Prec@5 89.663\n",
      " * Prec@1 80.093 Prec@5 89.583\n",
      " * Prec@1 80.580 Prec@5 89.732\n",
      " * Prec@1 81.034 Prec@5 89.871\n",
      " * Prec@1 80.833 Prec@5 89.792\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.113 (1.199)\n",
      "\n",
      "Loss 1.2845 (1.1616)\n",
      "\n",
      "Prec@1 68.750 (80.444)\n",
      "\n",
      "Prec@5 93.750 (89.919)\n",
      "\n",
      " * Prec@1 80.444 Prec@5 89.919\n",
      " * Prec@1 81.055 Prec@5 90.234\n",
      " * Prec@1 81.250 Prec@5 90.341\n",
      " * Prec@1 81.618 Prec@5 90.441\n",
      " * Prec@1 81.429 Prec@5 90.179\n",
      " * Prec@1 81.597 Prec@5 90.104\n",
      " * Prec@1 81.588 Prec@5 90.203\n",
      " * Prec@1 80.921 Prec@5 89.474\n",
      " * Prec@1 80.609 Prec@5 89.263\n",
      " * Prec@1 80.938 Prec@5 89.531\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.093 (1.199)\n",
      "\n",
      "Loss 0.5760 (1.1435)\n",
      "\n",
      "Prec@1 81.250 (80.945)\n",
      "\n",
      "Prec@5 93.750 (89.634)\n",
      "\n",
      " * Prec@1 80.945 Prec@5 89.634\n",
      " * Prec@1 80.655 Prec@5 89.583\n",
      " * Prec@1 80.523 Prec@5 89.390\n",
      " * Prec@1 80.540 Prec@5 89.347\n",
      " * Prec@1 80.556 Prec@5 89.306\n",
      " * Prec@1 80.571 Prec@5 89.266\n",
      " * Prec@1 80.851 Prec@5 89.495\n",
      " * Prec@1 80.469 Prec@5 89.323\n",
      " * Prec@1 80.485 Prec@5 89.413\n",
      " * Prec@1 80.500 Prec@5 89.375\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.082 (1.200)\n",
      "\n",
      "Loss 0.7023 (1.1240)\n",
      "\n",
      "Prec@1 87.500 (80.637)\n",
      "\n",
      "Prec@5 87.500 (89.338)\n",
      "\n",
      " * Prec@1 80.637 Prec@5 89.338\n",
      " * Prec@1 80.409 Prec@5 89.183\n",
      " * Prec@1 80.307 Prec@5 88.915\n",
      " * Prec@1 80.324 Prec@5 89.005\n",
      " * Prec@1 80.114 Prec@5 88.750\n",
      " * Prec@1 79.799 Prec@5 88.728\n",
      " * Prec@1 79.715 Prec@5 88.816\n",
      " * Prec@1 79.741 Prec@5 88.793\n",
      " * Prec@1 79.767 Prec@5 88.665\n",
      " * Prec@1 79.792 Prec@5 88.750\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.081 (1.196)\n",
      "\n",
      "Loss 3.0539 (1.2139)\n",
      "\n",
      "Prec@1 56.250 (79.406)\n",
      "\n",
      "Prec@5 75.000 (88.525)\n",
      "\n",
      " * Prec@1 79.406 Prec@5 88.525\n",
      " * Prec@1 79.637 Prec@5 88.710\n",
      " * Prec@1 79.365 Prec@5 88.790\n",
      " * Prec@1 79.590 Prec@5 88.867\n",
      " * Prec@1 79.615 Prec@5 89.038\n",
      " * Prec@1 79.735 Prec@5 89.110\n",
      " * Prec@1 79.757 Prec@5 89.272\n",
      " * Prec@1 79.871 Prec@5 89.338\n",
      " * Prec@1 79.982 Prec@5 89.402\n",
      " * Prec@1 80.089 Prec@5 89.464\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.061 (1.195)\n",
      "\n",
      "Loss 0.7679 (1.1284)\n",
      "\n",
      "Prec@1 87.500 (80.194)\n",
      "\n",
      "Prec@5 93.750 (89.525)\n",
      "\n",
      " * Prec@1 80.194 Prec@5 89.525\n",
      " * Prec@1 80.295 Prec@5 89.583\n",
      " * Prec@1 80.565 Prec@5 89.726\n",
      " * Prec@1 80.490 Prec@5 89.696\n",
      " * Prec@1 80.500 Prec@5 89.667\n",
      " * Prec@1 80.345 Prec@5 89.638\n",
      " * Prec@1 80.357 Prec@5 89.773\n",
      " * Prec@1 80.288 Prec@5 89.824\n",
      " * Prec@1 80.380 Prec@5 89.794\n",
      " * Prec@1 80.156 Prec@5 89.688\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.091 (1.194)\n",
      "\n",
      "Loss 1.4987 (1.1160)\n",
      "\n",
      "Prec@1 75.000 (80.093)\n",
      "\n",
      "Prec@5 87.500 (89.660)\n",
      "\n",
      " * Prec@1 80.093 Prec@5 89.660\n",
      " * Prec@1 80.183 Prec@5 89.710\n",
      " * Prec@1 80.271 Prec@5 89.759\n",
      " * Prec@1 80.283 Prec@5 89.732\n",
      " * Prec@1 80.147 Prec@5 89.632\n",
      " * Prec@1 79.942 Prec@5 89.608\n",
      " * Prec@1 79.885 Prec@5 89.511\n",
      " * Prec@1 79.901 Prec@5 89.489\n",
      " * Prec@1 80.056 Prec@5 89.607\n",
      " * Prec@1 80.000 Prec@5 89.514\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.133 (1.193)\n",
      "\n",
      "Loss 0.9510 (1.1167)\n",
      "\n",
      "Prec@1 87.500 (80.082)\n",
      "\n",
      "Prec@5 93.750 (89.560)\n",
      "\n",
      " * Prec@1 80.082 Prec@5 89.560\n",
      " * Prec@1 80.163 Prec@5 89.606\n",
      " * Prec@1 80.242 Prec@5 89.651\n",
      " * Prec@1 80.253 Prec@5 89.561\n",
      " * Prec@1 80.263 Prec@5 89.539\n",
      " * Prec@1 80.273 Prec@5 89.453\n",
      " * Prec@1 80.284 Prec@5 89.369\n",
      " * Prec@1 80.293 Prec@5 89.349\n",
      " * Prec@1 80.303 Prec@5 89.394\n",
      " * Prec@1 80.250 Prec@5 89.375\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.081 (1.192)\n",
      "\n",
      "Loss 0.3621 (1.1076)\n",
      "\n",
      "Prec@1 93.750 (80.384)\n",
      "\n",
      "Prec@5 100.000 (89.480)\n",
      "\n",
      " * Prec@1 80.384 Prec@5 89.480\n",
      " * Prec@1 80.392 Prec@5 89.400\n",
      " * Prec@1 80.340 Prec@5 89.502\n",
      " * Prec@1 80.288 Prec@5 89.543\n",
      " * Prec@1 80.179 Prec@5 89.524\n",
      " * Prec@1 80.189 Prec@5 89.505\n",
      " * Prec@1 80.140 Prec@5 89.428\n",
      " * Prec@1 80.150 Prec@5 89.352\n",
      " * Prec@1 80.218 Prec@5 89.450\n",
      " * Prec@1 79.886 Prec@5 89.231\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [11][0/987]\t\\Time 1.090 (1.090)\tData 0.490 (0.490)\tLoss 0.0046 (0.0046)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/987]\t\\Time 2.097 (2.108)\tData 1.476 (1.484)\tLoss 0.0057 (0.0164)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [11][200/987]\t\\Time 2.103 (2.107)\tData 1.472 (1.480)\tLoss 0.0020 (0.0129)\tPrec@1 100.000 (99.782)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [11][300/987]\t\\Time 2.102 (2.106)\tData 1.482 (1.478)\tLoss 0.0033 (0.0164)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [11][400/987]\t\\Time 2.109 (2.106)\tData 1.472 (1.477)\tLoss 0.0023 (0.0156)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [11][500/987]\t\\Time 2.093 (2.105)\tData 1.472 (1.477)\tLoss 0.0009 (0.0132)\tPrec@1 100.000 (99.738)\tPrec@5 100.000 (99.975)\n",
      "Epoch: [11][600/987]\t\\Time 2.106 (2.105)\tData 1.476 (1.477)\tLoss 0.0030 (0.0140)\tPrec@1 100.000 (99.719)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [11][700/987]\t\\Time 2.101 (2.105)\tData 1.481 (1.476)\tLoss 0.0022 (0.0149)\tPrec@1 100.000 (99.706)\tPrec@5 100.000 (99.982)\n",
      "Epoch: [11][800/987]\t\\Time 2.104 (2.105)\tData 1.473 (1.476)\tLoss 0.0017 (0.0147)\tPrec@1 100.000 (99.711)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [11][900/987]\t\\Time 2.134 (2.105)\tData 1.473 (1.476)\tLoss 0.0010 (0.0144)\tPrec@1 100.000 (99.716)\tPrec@5 100.000 (99.986)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 2.034 (2.034)\n",
      "\n",
      "Loss 1.1761 (1.1761)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 80.000 Prec@5 88.750\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 82.143 Prec@5 90.179\n",
      " * Prec@1 84.375 Prec@5 91.406\n",
      " * Prec@1 82.639 Prec@5 89.583\n",
      " * Prec@1 83.125 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.107 (1.264)\n",
      "\n",
      "Loss 1.2899 (0.9978)\n",
      "\n",
      "Prec@1 62.500 (81.250)\n",
      "\n",
      "Prec@5 81.250 (89.773)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 89.773\n",
      " * Prec@1 79.167 Prec@5 87.500\n",
      " * Prec@1 78.846 Prec@5 87.981\n",
      " * Prec@1 79.911 Prec@5 88.839\n",
      " * Prec@1 80.417 Prec@5 89.167\n",
      " * Prec@1 81.641 Prec@5 89.844\n",
      " * Prec@1 81.250 Prec@5 90.074\n",
      " * Prec@1 80.208 Prec@5 90.278\n",
      " * Prec@1 79.934 Prec@5 90.132\n",
      " * Prec@1 80.312 Prec@5 90.312\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.101 (1.237)\n",
      "\n",
      "Loss 1.3607 (1.0255)\n",
      "\n",
      "Prec@1 81.250 (80.357)\n",
      "\n",
      "Prec@5 87.500 (90.179)\n",
      "\n",
      " * Prec@1 80.357 Prec@5 90.179\n",
      " * Prec@1 80.398 Prec@5 89.773\n",
      " * Prec@1 80.435 Prec@5 89.674\n",
      " * Prec@1 80.469 Prec@5 89.844\n",
      " * Prec@1 80.250 Prec@5 89.750\n",
      " * Prec@1 80.529 Prec@5 89.663\n",
      " * Prec@1 80.556 Prec@5 89.583\n",
      " * Prec@1 81.027 Prec@5 89.732\n",
      " * Prec@1 81.466 Prec@5 89.871\n",
      " * Prec@1 81.250 Prec@5 89.583\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.143 (1.227)\n",
      "\n",
      "Loss 1.3201 (1.0659)\n",
      "\n",
      "Prec@1 75.000 (81.048)\n",
      "\n",
      "Prec@5 93.750 (89.718)\n",
      "\n",
      " * Prec@1 81.048 Prec@5 89.718\n",
      " * Prec@1 81.641 Prec@5 90.039\n",
      " * Prec@1 82.008 Prec@5 90.152\n",
      " * Prec@1 82.169 Prec@5 90.257\n",
      " * Prec@1 82.143 Prec@5 90.000\n",
      " * Prec@1 82.292 Prec@5 89.931\n",
      " * Prec@1 82.264 Prec@5 89.865\n",
      " * Prec@1 81.579 Prec@5 89.309\n",
      " * Prec@1 81.250 Prec@5 88.942\n",
      " * Prec@1 81.562 Prec@5 89.219\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.134 (1.228)\n",
      "\n",
      "Loss 0.4648 (1.0706)\n",
      "\n",
      "Prec@1 81.250 (81.555)\n",
      "\n",
      "Prec@5 100.000 (89.482)\n",
      "\n",
      " * Prec@1 81.555 Prec@5 89.482\n",
      " * Prec@1 81.250 Prec@5 89.435\n",
      " * Prec@1 81.250 Prec@5 89.244\n",
      " * Prec@1 81.392 Prec@5 89.489\n",
      " * Prec@1 81.389 Prec@5 89.444\n",
      " * Prec@1 81.386 Prec@5 89.402\n",
      " * Prec@1 81.649 Prec@5 89.628\n",
      " * Prec@1 81.250 Prec@5 89.453\n",
      " * Prec@1 81.250 Prec@5 89.541\n",
      " * Prec@1 81.125 Prec@5 89.500\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.142 (1.228)\n",
      "\n",
      "Loss 0.7979 (1.0450)\n",
      "\n",
      "Prec@1 81.250 (81.127)\n",
      "\n",
      "Prec@5 87.500 (89.461)\n",
      "\n",
      " * Prec@1 81.127 Prec@5 89.461\n",
      " * Prec@1 80.889 Prec@5 89.303\n",
      " * Prec@1 80.778 Prec@5 89.033\n",
      " * Prec@1 80.787 Prec@5 89.120\n",
      " * Prec@1 80.455 Prec@5 88.864\n",
      " * Prec@1 80.134 Prec@5 88.951\n",
      " * Prec@1 80.263 Prec@5 89.035\n",
      " * Prec@1 80.280 Prec@5 89.009\n",
      " * Prec@1 80.191 Prec@5 88.983\n",
      " * Prec@1 80.208 Prec@5 89.062\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.170 (1.227)\n",
      "\n",
      "Loss 2.8197 (1.1318)\n",
      "\n",
      "Prec@1 50.000 (79.713)\n",
      "\n",
      "Prec@5 75.000 (88.832)\n",
      "\n",
      " * Prec@1 79.713 Prec@5 88.832\n",
      " * Prec@1 79.940 Prec@5 89.012\n",
      " * Prec@1 79.563 Prec@5 89.087\n",
      " * Prec@1 79.785 Prec@5 89.160\n",
      " * Prec@1 79.808 Prec@5 89.327\n",
      " * Prec@1 79.830 Prec@5 89.299\n",
      " * Prec@1 79.851 Prec@5 89.459\n",
      " * Prec@1 80.055 Prec@5 89.522\n",
      " * Prec@1 80.163 Prec@5 89.493\n",
      " * Prec@1 80.268 Prec@5 89.554\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.101 (1.227)\n",
      "\n",
      "Loss 0.9681 (1.0671)\n",
      "\n",
      "Prec@1 87.500 (80.370)\n",
      "\n",
      "Prec@5 87.500 (89.525)\n",
      "\n",
      " * Prec@1 80.370 Prec@5 89.525\n",
      " * Prec@1 80.556 Prec@5 89.583\n",
      " * Prec@1 80.822 Prec@5 89.726\n",
      " * Prec@1 80.743 Prec@5 89.611\n",
      " * Prec@1 80.750 Prec@5 89.667\n",
      " * Prec@1 80.674 Prec@5 89.556\n",
      " * Prec@1 80.763 Prec@5 89.692\n",
      " * Prec@1 80.769 Prec@5 89.663\n",
      " * Prec@1 80.854 Prec@5 89.636\n",
      " * Prec@1 80.625 Prec@5 89.609\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.142 (1.225)\n",
      "\n",
      "Loss 1.6747 (1.0535)\n",
      "\n",
      "Prec@1 75.000 (80.556)\n",
      "\n",
      "Prec@5 87.500 (89.583)\n",
      "\n",
      " * Prec@1 80.556 Prec@5 89.583\n",
      " * Prec@1 80.564 Prec@5 89.634\n",
      " * Prec@1 80.572 Prec@5 89.684\n",
      " * Prec@1 80.580 Prec@5 89.658\n",
      " * Prec@1 80.441 Prec@5 89.632\n",
      " * Prec@1 80.378 Prec@5 89.608\n",
      " * Prec@1 80.316 Prec@5 89.511\n",
      " * Prec@1 80.327 Prec@5 89.489\n",
      " * Prec@1 80.478 Prec@5 89.607\n",
      " * Prec@1 80.347 Prec@5 89.514\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.185 (1.224)\n",
      "\n",
      "Loss 1.0369 (1.0538)\n",
      "\n",
      "Prec@1 81.250 (80.357)\n",
      "\n",
      "Prec@5 93.750 (89.560)\n",
      "\n",
      " * Prec@1 80.357 Prec@5 89.560\n",
      " * Prec@1 80.367 Prec@5 89.606\n",
      " * Prec@1 80.444 Prec@5 89.651\n",
      " * Prec@1 80.452 Prec@5 89.561\n",
      " * Prec@1 80.461 Prec@5 89.539\n",
      " * Prec@1 80.469 Prec@5 89.453\n",
      " * Prec@1 80.477 Prec@5 89.369\n",
      " * Prec@1 80.421 Prec@5 89.286\n",
      " * Prec@1 80.429 Prec@5 89.331\n",
      " * Prec@1 80.438 Prec@5 89.312\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.156 (1.224)\n",
      "\n",
      "Loss 0.3729 (1.0427)\n",
      "\n",
      "Prec@1 93.750 (80.569)\n",
      "\n",
      "Prec@5 93.750 (89.356)\n",
      "\n",
      " * Prec@1 80.569 Prec@5 89.356\n",
      " * Prec@1 80.576 Prec@5 89.338\n",
      " * Prec@1 80.583 Prec@5 89.442\n",
      " * Prec@1 80.529 Prec@5 89.423\n",
      " * Prec@1 80.417 Prec@5 89.405\n",
      " * Prec@1 80.366 Prec@5 89.446\n",
      " * Prec@1 80.257 Prec@5 89.428\n",
      " * Prec@1 80.266 Prec@5 89.410\n",
      " * Prec@1 80.333 Prec@5 89.507\n",
      " * Prec@1 80.000 Prec@5 89.402\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [12][0/987]\t\\Time 1.121 (1.121)\tData 0.429 (0.429)\tLoss 0.0077 (0.0077)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/987]\t\\Time 2.055 (2.053)\tData 1.435 (1.433)\tLoss 0.0017 (0.0055)\tPrec@1 100.000 (99.876)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][200/987]\t\\Time 2.054 (2.056)\tData 1.434 (1.437)\tLoss 0.0567 (0.0080)\tPrec@1 93.750 (99.782)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][300/987]\t\\Time 2.051 (2.056)\tData 1.440 (1.437)\tLoss 0.0012 (0.0092)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][400/987]\t\\Time 2.050 (2.056)\tData 1.440 (1.437)\tLoss 0.0015 (0.0079)\tPrec@1 100.000 (99.797)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][500/987]\t\\Time 2.052 (2.056)\tData 1.442 (1.438)\tLoss 0.0022 (0.0081)\tPrec@1 100.000 (99.800)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][600/987]\t\\Time 2.047 (2.057)\tData 1.436 (1.438)\tLoss 0.0017 (0.0097)\tPrec@1 100.000 (99.771)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][700/987]\t\\Time 2.056 (2.057)\tData 1.432 (1.438)\tLoss 0.0072 (0.0102)\tPrec@1 100.000 (99.768)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][800/987]\t\\Time 2.061 (2.057)\tData 1.441 (1.438)\tLoss 0.0046 (0.0112)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][900/987]\t\\Time 2.056 (2.057)\tData 1.438 (1.438)\tLoss 0.0024 (0.0122)\tPrec@1 100.000 (99.723)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.822 (1.822)\n",
      "\n",
      "Loss 1.2578 (1.2578)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 81.250 Prec@5 88.750\n",
      " * Prec@1 80.208 Prec@5 88.542\n",
      " * Prec@1 83.036 Prec@5 90.179\n",
      " * Prec@1 85.156 Prec@5 91.406\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 83.750 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.071 (1.199)\n",
      "\n",
      "Loss 1.1012 (0.9665)\n",
      "\n",
      "Prec@1 68.750 (82.386)\n",
      "\n",
      "Prec@5 87.500 (90.341)\n",
      "\n",
      " * Prec@1 82.386 Prec@5 90.341\n",
      " * Prec@1 80.208 Prec@5 89.062\n",
      " * Prec@1 79.808 Prec@5 89.423\n",
      " * Prec@1 80.357 Prec@5 89.732\n",
      " * Prec@1 80.833 Prec@5 90.000\n",
      " * Prec@1 82.031 Prec@5 90.625\n",
      " * Prec@1 81.985 Prec@5 90.441\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      " * Prec@1 80.921 Prec@5 90.461\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.029 (1.197)\n",
      "\n",
      "Loss 1.3502 (1.0326)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (90.179)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.179\n",
      " * Prec@1 81.250 Prec@5 89.773\n",
      " * Prec@1 81.250 Prec@5 89.674\n",
      " * Prec@1 81.250 Prec@5 89.844\n",
      " * Prec@1 81.000 Prec@5 90.000\n",
      " * Prec@1 81.010 Prec@5 89.904\n",
      " * Prec@1 81.019 Prec@5 89.815\n",
      " * Prec@1 81.473 Prec@5 89.955\n",
      " * Prec@1 81.897 Prec@5 90.086\n",
      " * Prec@1 81.667 Prec@5 90.000\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.173 (1.210)\n",
      "\n",
      "Loss 1.2059 (1.0625)\n",
      "\n",
      "Prec@1 75.000 (81.452)\n",
      "\n",
      "Prec@5 93.750 (90.121)\n",
      "\n",
      " * Prec@1 81.452 Prec@5 90.121\n",
      " * Prec@1 82.031 Prec@5 90.430\n",
      " * Prec@1 82.197 Prec@5 90.530\n",
      " * Prec@1 82.537 Prec@5 90.625\n",
      " * Prec@1 82.500 Prec@5 90.357\n",
      " * Prec@1 82.639 Prec@5 90.278\n",
      " * Prec@1 82.432 Prec@5 90.203\n",
      " * Prec@1 81.743 Prec@5 89.474\n",
      " * Prec@1 81.410 Prec@5 89.263\n",
      " * Prec@1 81.875 Prec@5 89.531\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.083 (1.212)\n",
      "\n",
      "Loss 0.6601 (1.0688)\n",
      "\n",
      "Prec@1 81.250 (81.860)\n",
      "\n",
      "Prec@5 100.000 (89.787)\n",
      "\n",
      " * Prec@1 81.860 Prec@5 89.787\n",
      " * Prec@1 81.399 Prec@5 89.583\n",
      " * Prec@1 81.395 Prec@5 89.390\n",
      " * Prec@1 81.392 Prec@5 89.631\n",
      " * Prec@1 81.389 Prec@5 89.583\n",
      " * Prec@1 81.522 Prec@5 89.538\n",
      " * Prec@1 81.782 Prec@5 89.761\n",
      " * Prec@1 81.380 Prec@5 89.714\n",
      " * Prec@1 81.378 Prec@5 89.923\n",
      " * Prec@1 81.250 Prec@5 89.875\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.151 (1.213)\n",
      "\n",
      "Loss 0.7245 (1.0394)\n",
      "\n",
      "Prec@1 87.500 (81.373)\n",
      "\n",
      "Prec@5 87.500 (89.828)\n",
      "\n",
      " * Prec@1 81.373 Prec@5 89.828\n",
      " * Prec@1 81.130 Prec@5 89.663\n",
      " * Prec@1 81.014 Prec@5 89.505\n",
      " * Prec@1 81.019 Prec@5 89.583\n",
      " * Prec@1 80.682 Prec@5 89.318\n",
      " * Prec@1 80.580 Prec@5 89.397\n",
      " * Prec@1 80.482 Prec@5 89.474\n",
      " * Prec@1 80.496 Prec@5 89.440\n",
      " * Prec@1 80.508 Prec@5 89.407\n",
      " * Prec@1 80.521 Prec@5 89.479\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.082 (1.207)\n",
      "\n",
      "Loss 2.9003 (1.1183)\n",
      "\n",
      "Prec@1 50.000 (80.020)\n",
      "\n",
      "Prec@5 75.000 (89.242)\n",
      "\n",
      " * Prec@1 80.020 Prec@5 89.242\n",
      " * Prec@1 80.242 Prec@5 89.415\n",
      " * Prec@1 79.960 Prec@5 89.286\n",
      " * Prec@1 80.176 Prec@5 89.355\n",
      " * Prec@1 80.288 Prec@5 89.519\n",
      " * Prec@1 80.398 Prec@5 89.583\n",
      " * Prec@1 80.410 Prec@5 89.739\n",
      " * Prec@1 80.607 Prec@5 89.798\n",
      " * Prec@1 80.707 Prec@5 89.855\n",
      " * Prec@1 80.804 Prec@5 89.911\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.163 (1.209)\n",
      "\n",
      "Loss 0.8794 (1.0462)\n",
      "\n",
      "Prec@1 87.500 (80.898)\n",
      "\n",
      "Prec@5 93.750 (89.965)\n",
      "\n",
      " * Prec@1 80.898 Prec@5 89.965\n",
      " * Prec@1 81.076 Prec@5 90.104\n",
      " * Prec@1 81.336 Prec@5 90.240\n",
      " * Prec@1 81.250 Prec@5 90.203\n",
      " * Prec@1 81.333 Prec@5 90.250\n",
      " * Prec@1 81.250 Prec@5 90.214\n",
      " * Prec@1 81.331 Prec@5 90.341\n",
      " * Prec@1 81.250 Prec@5 90.385\n",
      " * Prec@1 81.329 Prec@5 90.348\n",
      " * Prec@1 81.172 Prec@5 90.234\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.152 (1.204)\n",
      "\n",
      "Loss 1.6924 (1.0374)\n",
      "\n",
      "Prec@1 75.000 (81.096)\n",
      "\n",
      "Prec@5 87.500 (90.201)\n",
      "\n",
      " * Prec@1 81.096 Prec@5 90.201\n",
      " * Prec@1 81.098 Prec@5 90.244\n",
      " * Prec@1 81.024 Prec@5 90.286\n",
      " * Prec@1 81.027 Prec@5 90.253\n",
      " * Prec@1 80.882 Prec@5 90.147\n",
      " * Prec@1 80.741 Prec@5 90.116\n",
      " * Prec@1 80.675 Prec@5 90.014\n",
      " * Prec@1 80.682 Prec@5 89.915\n",
      " * Prec@1 80.829 Prec@5 90.028\n",
      " * Prec@1 80.694 Prec@5 89.931\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.057 (1.190)\n",
      "\n",
      "Loss 0.9481 (1.0498)\n",
      "\n",
      "Prec@1 87.500 (80.769)\n",
      "\n",
      "Prec@5 93.750 (89.973)\n",
      "\n",
      " * Prec@1 80.769 Prec@5 89.973\n",
      " * Prec@1 80.774 Prec@5 90.014\n",
      " * Prec@1 80.847 Prec@5 90.054\n",
      " * Prec@1 80.851 Prec@5 89.960\n",
      " * Prec@1 80.789 Prec@5 89.934\n",
      " * Prec@1 80.794 Prec@5 89.844\n",
      " * Prec@1 80.799 Prec@5 89.755\n",
      " * Prec@1 80.804 Prec@5 89.732\n",
      " * Prec@1 80.808 Prec@5 89.773\n",
      " * Prec@1 80.812 Prec@5 89.750\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.003 (1.179)\n",
      "\n",
      "Loss 0.3244 (1.0440)\n",
      "\n",
      "Prec@1 93.750 (80.941)\n",
      "\n",
      "Prec@5 100.000 (89.851)\n",
      "\n",
      " * Prec@1 80.941 Prec@5 89.851\n",
      " * Prec@1 80.944 Prec@5 89.890\n",
      " * Prec@1 81.007 Prec@5 89.988\n",
      " * Prec@1 80.950 Prec@5 89.904\n",
      " * Prec@1 80.833 Prec@5 89.881\n",
      " * Prec@1 80.778 Prec@5 89.858\n",
      " * Prec@1 80.666 Prec@5 89.836\n",
      " * Prec@1 80.671 Prec@5 89.815\n",
      " * Prec@1 80.734 Prec@5 89.908\n",
      " * Prec@1 80.399 Prec@5 89.687\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [13][0/987]\t\\Time 1.006 (1.006)\tData 0.445 (0.445)\tLoss 0.0115 (0.0115)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/987]\t\\Time 2.044 (2.058)\tData 1.462 (1.472)\tLoss 0.0017 (0.0085)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][200/987]\t\\Time 2.046 (2.066)\tData 1.464 (1.479)\tLoss 0.0034 (0.0087)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][300/987]\t\\Time 2.045 (2.069)\tData 1.463 (1.482)\tLoss 0.0010 (0.0082)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][400/987]\t\\Time 2.056 (2.070)\tData 1.474 (1.483)\tLoss 0.0152 (0.0096)\tPrec@1 100.000 (99.766)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][500/987]\t\\Time 2.051 (2.071)\tData 1.461 (1.484)\tLoss 0.0029 (0.0107)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][600/987]\t\\Time 2.071 (2.071)\tData 1.461 (1.485)\tLoss 0.0011 (0.0098)\tPrec@1 100.000 (99.771)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][700/987]\t\\Time 2.053 (2.071)\tData 1.465 (1.485)\tLoss 0.0017 (0.0101)\tPrec@1 100.000 (99.768)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][800/987]\t\\Time 2.056 (2.072)\tData 1.464 (1.485)\tLoss 0.0014 (0.0098)\tPrec@1 100.000 (99.766)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][900/987]\t\\Time 2.048 (2.072)\tData 1.466 (1.486)\tLoss 0.0017 (0.0108)\tPrec@1 100.000 (99.743)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.807 (1.807)\n",
      "\n",
      "Loss 1.1250 (1.1250)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 78.750 Prec@5 88.750\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 82.143 Prec@5 90.179\n",
      " * Prec@1 84.375 Prec@5 91.406\n",
      " * Prec@1 82.639 Prec@5 89.583\n",
      " * Prec@1 83.125 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.007 (1.165)\n",
      "\n",
      "Loss 1.1016 (0.9445)\n",
      "\n",
      "Prec@1 62.500 (81.250)\n",
      "\n",
      "Prec@5 87.500 (90.341)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.341\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 79.327 Prec@5 88.942\n",
      " * Prec@1 80.357 Prec@5 89.732\n",
      " * Prec@1 80.833 Prec@5 90.000\n",
      " * Prec@1 81.641 Prec@5 90.625\n",
      " * Prec@1 81.618 Prec@5 90.441\n",
      " * Prec@1 80.903 Prec@5 90.625\n",
      " * Prec@1 80.592 Prec@5 90.461\n",
      " * Prec@1 80.938 Prec@5 90.625\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.005 (1.148)\n",
      "\n",
      "Loss 1.3874 (0.9806)\n",
      "\n",
      "Prec@1 81.250 (80.952)\n",
      "\n",
      "Prec@5 81.250 (90.179)\n",
      "\n",
      " * Prec@1 80.952 Prec@5 90.179\n",
      " * Prec@1 80.966 Prec@5 89.773\n",
      " * Prec@1 80.978 Prec@5 89.674\n",
      " * Prec@1 80.990 Prec@5 89.844\n",
      " * Prec@1 80.750 Prec@5 89.750\n",
      " * Prec@1 80.769 Prec@5 89.663\n",
      " * Prec@1 80.787 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 89.732\n",
      " * Prec@1 81.681 Prec@5 89.871\n",
      " * Prec@1 81.458 Prec@5 89.792\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.042 (1.142)\n",
      "\n",
      "Loss 1.2477 (1.0300)\n",
      "\n",
      "Prec@1 75.000 (81.250)\n",
      "\n",
      "Prec@5 93.750 (89.919)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 89.919\n",
      " * Prec@1 81.836 Prec@5 90.234\n",
      " * Prec@1 81.818 Prec@5 90.341\n",
      " * Prec@1 81.985 Prec@5 90.441\n",
      " * Prec@1 81.786 Prec@5 90.179\n",
      " * Prec@1 81.944 Prec@5 90.278\n",
      " * Prec@1 81.926 Prec@5 90.203\n",
      " * Prec@1 81.250 Prec@5 89.638\n",
      " * Prec@1 80.929 Prec@5 89.263\n",
      " * Prec@1 81.094 Prec@5 89.531\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.059 (1.141)\n",
      "\n",
      "Loss 0.6182 (1.0447)\n",
      "\n",
      "Prec@1 81.250 (81.098)\n",
      "\n",
      "Prec@5 93.750 (89.634)\n",
      "\n",
      " * Prec@1 81.098 Prec@5 89.634\n",
      " * Prec@1 80.804 Prec@5 89.583\n",
      " * Prec@1 80.814 Prec@5 89.390\n",
      " * Prec@1 81.108 Prec@5 89.631\n",
      " * Prec@1 81.111 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 89.538\n",
      " * Prec@1 81.516 Prec@5 89.761\n",
      " * Prec@1 81.120 Prec@5 89.844\n",
      " * Prec@1 81.122 Prec@5 90.051\n",
      " * Prec@1 81.000 Prec@5 90.000\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.039 (1.141)\n",
      "\n",
      "Loss 0.6520 (1.0206)\n",
      "\n",
      "Prec@1 81.250 (81.005)\n",
      "\n",
      "Prec@5 93.750 (90.074)\n",
      "\n",
      " * Prec@1 81.005 Prec@5 90.074\n",
      " * Prec@1 80.889 Prec@5 89.904\n",
      " * Prec@1 80.660 Prec@5 89.858\n",
      " * Prec@1 80.671 Prec@5 89.931\n",
      " * Prec@1 80.341 Prec@5 89.659\n",
      " * Prec@1 80.022 Prec@5 89.621\n",
      " * Prec@1 79.934 Prec@5 89.693\n",
      " * Prec@1 79.957 Prec@5 89.655\n",
      " * Prec@1 79.979 Prec@5 89.619\n",
      " * Prec@1 80.000 Prec@5 89.688\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.053 (1.138)\n",
      "\n",
      "Loss 2.8100 (1.1075)\n",
      "\n",
      "Prec@1 56.250 (79.611)\n",
      "\n",
      "Prec@5 75.000 (89.447)\n",
      "\n",
      " * Prec@1 79.611 Prec@5 89.447\n",
      " * Prec@1 79.839 Prec@5 89.617\n",
      " * Prec@1 79.563 Prec@5 89.583\n",
      " * Prec@1 79.785 Prec@5 89.648\n",
      " * Prec@1 79.904 Prec@5 89.808\n",
      " * Prec@1 79.924 Prec@5 89.773\n",
      " * Prec@1 79.944 Prec@5 89.832\n",
      " * Prec@1 80.055 Prec@5 89.890\n",
      " * Prec@1 80.163 Prec@5 89.946\n",
      " * Prec@1 80.268 Prec@5 90.000\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.025 (1.137)\n",
      "\n",
      "Loss 0.9482 (1.0438)\n",
      "\n",
      "Prec@1 87.500 (80.370)\n",
      "\n",
      "Prec@5 87.500 (89.965)\n",
      "\n",
      " * Prec@1 80.370 Prec@5 89.965\n",
      " * Prec@1 80.556 Prec@5 90.017\n",
      " * Prec@1 80.822 Prec@5 90.154\n",
      " * Prec@1 80.743 Prec@5 90.118\n",
      " * Prec@1 80.833 Prec@5 90.167\n",
      " * Prec@1 80.674 Prec@5 90.049\n",
      " * Prec@1 80.763 Prec@5 90.097\n",
      " * Prec@1 80.849 Prec@5 90.064\n",
      " * Prec@1 80.934 Prec@5 90.032\n",
      " * Prec@1 80.781 Prec@5 90.000\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.022 (1.136)\n",
      "\n",
      "Loss 1.6411 (1.0305)\n",
      "\n",
      "Prec@1 75.000 (80.710)\n",
      "\n",
      "Prec@5 87.500 (89.969)\n",
      "\n",
      " * Prec@1 80.710 Prec@5 89.969\n",
      " * Prec@1 80.716 Prec@5 90.091\n",
      " * Prec@1 80.723 Prec@5 90.136\n",
      " * Prec@1 80.729 Prec@5 90.104\n",
      " * Prec@1 80.515 Prec@5 90.000\n",
      " * Prec@1 80.378 Prec@5 89.971\n",
      " * Prec@1 80.316 Prec@5 89.943\n",
      " * Prec@1 80.327 Prec@5 89.915\n",
      " * Prec@1 80.478 Prec@5 90.028\n",
      " * Prec@1 80.347 Prec@5 89.931\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.054 (1.134)\n",
      "\n",
      "Loss 0.8352 (1.0297)\n",
      "\n",
      "Prec@1 81.250 (80.357)\n",
      "\n",
      "Prec@5 93.750 (89.973)\n",
      "\n",
      " * Prec@1 80.357 Prec@5 89.973\n",
      " * Prec@1 80.435 Prec@5 90.014\n",
      " * Prec@1 80.511 Prec@5 90.054\n",
      " * Prec@1 80.519 Prec@5 89.960\n",
      " * Prec@1 80.461 Prec@5 89.934\n",
      " * Prec@1 80.469 Prec@5 89.844\n",
      " * Prec@1 80.477 Prec@5 89.755\n",
      " * Prec@1 80.485 Prec@5 89.732\n",
      " * Prec@1 80.492 Prec@5 89.773\n",
      " * Prec@1 80.500 Prec@5 89.750\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.033 (1.133)\n",
      "\n",
      "Loss 0.4519 (1.0209)\n",
      "\n",
      "Prec@1 93.750 (80.631)\n",
      "\n",
      "Prec@5 93.750 (89.790)\n",
      "\n",
      " * Prec@1 80.631 Prec@5 89.790\n",
      " * Prec@1 80.637 Prec@5 89.767\n",
      " * Prec@1 80.583 Prec@5 89.867\n",
      " * Prec@1 80.529 Prec@5 89.844\n",
      " * Prec@1 80.476 Prec@5 89.821\n",
      " * Prec@1 80.425 Prec@5 89.800\n",
      " * Prec@1 80.315 Prec@5 89.778\n",
      " * Prec@1 80.324 Prec@5 89.757\n",
      " * Prec@1 80.390 Prec@5 89.851\n",
      " * Prec@1 80.114 Prec@5 89.687\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [14][0/987]\t\\Time 1.069 (1.069)\tData 0.463 (0.463)\tLoss 0.0016 (0.0016)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/987]\t\\Time 2.013 (2.013)\tData 1.432 (1.432)\tLoss 0.0023 (0.0049)\tPrec@1 100.000 (99.938)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/987]\t\\Time 2.018 (2.016)\tData 1.436 (1.436)\tLoss 0.0015 (0.0074)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][300/987]\t\\Time 2.021 (2.017)\tData 1.441 (1.437)\tLoss 0.0019 (0.0070)\tPrec@1 100.000 (99.855)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][400/987]\t\\Time 2.013 (2.017)\tData 1.443 (1.437)\tLoss 0.0017 (0.0077)\tPrec@1 100.000 (99.829)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][500/987]\t\\Time 2.024 (2.019)\tData 1.443 (1.438)\tLoss 0.0017 (0.0080)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][600/987]\t\\Time 2.020 (2.019)\tData 1.445 (1.438)\tLoss 0.0124 (0.0094)\tPrec@1 100.000 (99.771)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][700/987]\t\\Time 2.012 (2.019)\tData 1.442 (1.438)\tLoss 0.0041 (0.0099)\tPrec@1 100.000 (99.768)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][800/987]\t\\Time 2.016 (2.019)\tData 1.443 (1.438)\tLoss 0.0019 (0.0106)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][900/987]\t\\Time 2.022 (2.019)\tData 1.441 (1.439)\tLoss 0.0021 (0.0110)\tPrec@1 100.000 (99.736)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.761 (1.761)\n",
      "\n",
      "Loss 1.1308 (1.1308)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 91.667\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 80.000 Prec@5 90.000\n",
      " * Prec@1 79.167 Prec@5 89.583\n",
      " * Prec@1 82.143 Prec@5 91.071\n",
      " * Prec@1 84.375 Prec@5 92.188\n",
      " * Prec@1 82.639 Prec@5 90.278\n",
      " * Prec@1 83.125 Prec@5 91.250\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.034 (1.197)\n",
      "\n",
      "Loss 1.0393 (0.9249)\n",
      "\n",
      "Prec@1 68.750 (81.818)\n",
      "\n",
      "Prec@5 93.750 (91.477)\n",
      "\n",
      " * Prec@1 81.818 Prec@5 91.477\n",
      " * Prec@1 79.688 Prec@5 90.104\n",
      " * Prec@1 79.327 Prec@5 90.385\n",
      " * Prec@1 80.357 Prec@5 91.071\n",
      " * Prec@1 80.833 Prec@5 91.250\n",
      " * Prec@1 82.031 Prec@5 91.797\n",
      " * Prec@1 81.985 Prec@5 91.544\n",
      " * Prec@1 81.597 Prec@5 91.319\n",
      " * Prec@1 81.250 Prec@5 91.118\n",
      " * Prec@1 81.562 Prec@5 91.250\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.047 (1.198)\n",
      "\n",
      "Loss 1.3692 (0.9641)\n",
      "\n",
      "Prec@1 81.250 (81.548)\n",
      "\n",
      "Prec@5 81.250 (90.774)\n",
      "\n",
      " * Prec@1 81.548 Prec@5 90.774\n",
      " * Prec@1 81.534 Prec@5 90.341\n",
      " * Prec@1 81.522 Prec@5 90.217\n",
      " * Prec@1 81.510 Prec@5 90.365\n",
      " * Prec@1 81.500 Prec@5 90.250\n",
      " * Prec@1 81.731 Prec@5 90.144\n",
      " * Prec@1 81.713 Prec@5 90.046\n",
      " * Prec@1 82.143 Prec@5 90.179\n",
      " * Prec@1 82.543 Prec@5 90.302\n",
      " * Prec@1 82.292 Prec@5 90.208\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.073 (1.192)\n",
      "\n",
      "Loss 1.1414 (1.0070)\n",
      "\n",
      "Prec@1 75.000 (82.056)\n",
      "\n",
      "Prec@5 93.750 (90.323)\n",
      "\n",
      " * Prec@1 82.056 Prec@5 90.323\n",
      " * Prec@1 82.617 Prec@5 90.625\n",
      " * Prec@1 82.765 Prec@5 90.720\n",
      " * Prec@1 82.904 Prec@5 90.809\n",
      " * Prec@1 82.679 Prec@5 90.536\n",
      " * Prec@1 82.812 Prec@5 90.625\n",
      " * Prec@1 82.770 Prec@5 90.541\n",
      " * Prec@1 82.072 Prec@5 89.967\n",
      " * Prec@1 81.731 Prec@5 89.583\n",
      " * Prec@1 82.031 Prec@5 89.844\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.073 (1.185)\n",
      "\n",
      "Loss 0.7122 (1.0292)\n",
      "\n",
      "Prec@1 81.250 (82.012)\n",
      "\n",
      "Prec@5 93.750 (89.939)\n",
      "\n",
      " * Prec@1 82.012 Prec@5 89.939\n",
      " * Prec@1 81.548 Prec@5 89.881\n",
      " * Prec@1 81.541 Prec@5 89.680\n",
      " * Prec@1 81.534 Prec@5 89.773\n",
      " * Prec@1 81.528 Prec@5 89.722\n",
      " * Prec@1 81.522 Prec@5 89.674\n",
      " * Prec@1 81.782 Prec@5 89.894\n",
      " * Prec@1 81.380 Prec@5 89.974\n",
      " * Prec@1 81.378 Prec@5 90.179\n",
      " * Prec@1 81.250 Prec@5 90.125\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.035 (1.172)\n",
      "\n",
      "Loss 0.5385 (1.0046)\n",
      "\n",
      "Prec@1 93.750 (81.495)\n",
      "\n",
      "Prec@5 93.750 (90.196)\n",
      "\n",
      " * Prec@1 81.495 Prec@5 90.196\n",
      " * Prec@1 81.250 Prec@5 90.144\n",
      " * Prec@1 81.014 Prec@5 90.094\n",
      " * Prec@1 81.019 Prec@5 90.162\n",
      " * Prec@1 80.682 Prec@5 89.886\n",
      " * Prec@1 80.357 Prec@5 89.844\n",
      " * Prec@1 80.263 Prec@5 89.803\n",
      " * Prec@1 80.280 Prec@5 89.763\n",
      " * Prec@1 80.297 Prec@5 89.725\n",
      " * Prec@1 80.312 Prec@5 89.792\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.085 (1.159)\n",
      "\n",
      "Loss 2.7819 (1.0884)\n",
      "\n",
      "Prec@1 56.250 (79.918)\n",
      "\n",
      "Prec@5 81.250 (89.652)\n",
      "\n",
      " * Prec@1 79.918 Prec@5 89.652\n",
      " * Prec@1 80.141 Prec@5 89.819\n",
      " * Prec@1 79.960 Prec@5 89.782\n",
      " * Prec@1 80.176 Prec@5 89.844\n",
      " * Prec@1 80.192 Prec@5 90.000\n",
      " * Prec@1 80.208 Prec@5 90.057\n",
      " * Prec@1 80.224 Prec@5 90.112\n",
      " * Prec@1 80.423 Prec@5 90.165\n",
      " * Prec@1 80.525 Prec@5 90.217\n",
      " * Prec@1 80.625 Prec@5 90.268\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.161 (1.159)\n",
      "\n",
      "Loss 0.8522 (1.0199)\n",
      "\n",
      "Prec@1 87.500 (80.722)\n",
      "\n",
      "Prec@5 87.500 (90.229)\n",
      "\n",
      " * Prec@1 80.722 Prec@5 90.229\n",
      " * Prec@1 80.903 Prec@5 90.278\n",
      " * Prec@1 81.164 Prec@5 90.411\n",
      " * Prec@1 81.081 Prec@5 90.372\n",
      " * Prec@1 81.083 Prec@5 90.417\n",
      " * Prec@1 81.003 Prec@5 90.378\n",
      " * Prec@1 81.088 Prec@5 90.341\n",
      " * Prec@1 81.090 Prec@5 90.304\n",
      " * Prec@1 81.171 Prec@5 90.269\n",
      " * Prec@1 81.016 Prec@5 90.156\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.114 (1.160)\n",
      "\n",
      "Loss 1.5809 (1.0104)\n",
      "\n",
      "Prec@1 75.000 (80.941)\n",
      "\n",
      "Prec@5 87.500 (90.123)\n",
      "\n",
      " * Prec@1 80.941 Prec@5 90.123\n",
      " * Prec@1 80.945 Prec@5 90.168\n",
      " * Prec@1 80.873 Prec@5 90.211\n",
      " * Prec@1 80.878 Prec@5 90.179\n",
      " * Prec@1 80.662 Prec@5 90.074\n",
      " * Prec@1 80.523 Prec@5 90.044\n",
      " * Prec@1 80.532 Prec@5 89.943\n",
      " * Prec@1 80.540 Prec@5 89.915\n",
      " * Prec@1 80.688 Prec@5 90.028\n",
      " * Prec@1 80.625 Prec@5 89.931\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.085 (1.157)\n",
      "\n",
      "Loss 0.7827 (1.0118)\n",
      "\n",
      "Prec@1 81.250 (80.632)\n",
      "\n",
      "Prec@5 93.750 (89.973)\n",
      "\n",
      " * Prec@1 80.632 Prec@5 89.973\n",
      " * Prec@1 80.639 Prec@5 90.014\n",
      " * Prec@1 80.712 Prec@5 90.054\n",
      " * Prec@1 80.718 Prec@5 89.960\n",
      " * Prec@1 80.658 Prec@5 89.934\n",
      " * Prec@1 80.664 Prec@5 89.844\n",
      " * Prec@1 80.670 Prec@5 89.755\n",
      " * Prec@1 80.612 Prec@5 89.732\n",
      " * Prec@1 80.619 Prec@5 89.773\n",
      " * Prec@1 80.625 Prec@5 89.750\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.081 (1.153)\n",
      "\n",
      "Loss 0.4295 (1.0053)\n",
      "\n",
      "Prec@1 93.750 (80.755)\n",
      "\n",
      "Prec@5 93.750 (89.790)\n",
      "\n",
      " * Prec@1 80.755 Prec@5 89.790\n",
      " * Prec@1 80.760 Prec@5 89.828\n",
      " * Prec@1 80.825 Prec@5 89.927\n",
      " * Prec@1 80.769 Prec@5 89.904\n",
      " * Prec@1 80.714 Prec@5 89.881\n",
      " * Prec@1 80.660 Prec@5 89.917\n",
      " * Prec@1 80.549 Prec@5 89.895\n",
      " * Prec@1 80.556 Prec@5 89.873\n",
      " * Prec@1 80.619 Prec@5 89.966\n",
      " * Prec@1 80.342 Prec@5 89.801\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [15][0/987]\t\\Time 1.000 (1.000)\tData 0.469 (0.469)\tLoss 0.0115 (0.0115)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/987]\t\\Time 2.029 (2.043)\tData 1.410 (1.425)\tLoss 0.0020 (0.0139)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/987]\t\\Time 2.027 (2.048)\tData 1.374 (1.423)\tLoss 0.0032 (0.0093)\tPrec@1 100.000 (99.782)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/987]\t\\Time 2.093 (2.049)\tData 1.483 (1.423)\tLoss 0.0015 (0.0076)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][400/987]\t\\Time 2.021 (2.049)\tData 1.410 (1.422)\tLoss 0.0016 (0.0084)\tPrec@1 100.000 (99.797)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][500/987]\t\\Time 2.033 (2.050)\tData 1.372 (1.422)\tLoss 0.0022 (0.0071)\tPrec@1 100.000 (99.838)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][600/987]\t\\Time 2.096 (2.050)\tData 1.471 (1.422)\tLoss 0.0018 (0.0072)\tPrec@1 100.000 (99.834)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][700/987]\t\\Time 2.027 (2.050)\tData 1.423 (1.422)\tLoss 0.0019 (0.0084)\tPrec@1 100.000 (99.795)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][800/987]\t\\Time 2.075 (2.050)\tData 1.372 (1.422)\tLoss 0.0022 (0.0087)\tPrec@1 100.000 (99.797)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][900/987]\t\\Time 2.094 (2.050)\tData 1.473 (1.422)\tLoss 0.0015 (0.0090)\tPrec@1 100.000 (99.785)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.882 (1.882)\n",
      "\n",
      "Loss 1.0757 (1.0757)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 91.667\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 80.000 Prec@5 90.000\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 83.036 Prec@5 91.071\n",
      " * Prec@1 85.156 Prec@5 92.188\n",
      " * Prec@1 83.333 Prec@5 90.278\n",
      " * Prec@1 83.125 Prec@5 91.250\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.061 (1.225)\n",
      "\n",
      "Loss 1.2321 (0.9615)\n",
      "\n",
      "Prec@1 62.500 (81.250)\n",
      "\n",
      "Prec@5 81.250 (90.341)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.341\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 79.327 Prec@5 88.942\n",
      " * Prec@1 80.357 Prec@5 89.732\n",
      " * Prec@1 80.833 Prec@5 90.000\n",
      " * Prec@1 81.641 Prec@5 90.625\n",
      " * Prec@1 81.618 Prec@5 90.441\n",
      " * Prec@1 80.903 Prec@5 90.625\n",
      " * Prec@1 80.592 Prec@5 90.789\n",
      " * Prec@1 81.250 Prec@5 90.938\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.082 (1.202)\n",
      "\n",
      "Loss 1.3235 (0.9911)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (90.476)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.476\n",
      " * Prec@1 81.250 Prec@5 90.057\n",
      " * Prec@1 80.978 Prec@5 89.946\n",
      " * Prec@1 80.729 Prec@5 90.104\n",
      " * Prec@1 80.500 Prec@5 90.250\n",
      " * Prec@1 80.529 Prec@5 90.144\n",
      " * Prec@1 80.556 Prec@5 90.046\n",
      " * Prec@1 81.027 Prec@5 90.179\n",
      " * Prec@1 81.466 Prec@5 90.302\n",
      " * Prec@1 81.250 Prec@5 90.208\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.107 (1.194)\n",
      "\n",
      "Loss 1.1245 (1.0319)\n",
      "\n",
      "Prec@1 75.000 (81.048)\n",
      "\n",
      "Prec@5 93.750 (90.323)\n",
      "\n",
      " * Prec@1 81.048 Prec@5 90.323\n",
      " * Prec@1 81.641 Prec@5 90.625\n",
      " * Prec@1 81.629 Prec@5 90.720\n",
      " * Prec@1 81.801 Prec@5 90.809\n",
      " * Prec@1 81.607 Prec@5 90.536\n",
      " * Prec@1 81.597 Prec@5 90.625\n",
      " * Prec@1 81.588 Prec@5 90.541\n",
      " * Prec@1 80.921 Prec@5 89.967\n",
      " * Prec@1 80.609 Prec@5 89.744\n",
      " * Prec@1 80.781 Prec@5 90.000\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.132 (1.195)\n",
      "\n",
      "Loss 0.6385 (1.0397)\n",
      "\n",
      "Prec@1 81.250 (80.793)\n",
      "\n",
      "Prec@5 93.750 (90.091)\n",
      "\n",
      " * Prec@1 80.793 Prec@5 90.091\n",
      " * Prec@1 80.506 Prec@5 89.881\n",
      " * Prec@1 80.523 Prec@5 89.680\n",
      " * Prec@1 80.682 Prec@5 89.915\n",
      " * Prec@1 80.694 Prec@5 89.861\n",
      " * Prec@1 80.707 Prec@5 89.946\n",
      " * Prec@1 80.984 Prec@5 90.160\n",
      " * Prec@1 80.599 Prec@5 89.974\n",
      " * Prec@1 80.612 Prec@5 90.179\n",
      " * Prec@1 80.500 Prec@5 90.125\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.114 (1.193)\n",
      "\n",
      "Loss 0.7242 (1.0192)\n",
      "\n",
      "Prec@1 81.250 (80.515)\n",
      "\n",
      "Prec@5 93.750 (90.196)\n",
      "\n",
      " * Prec@1 80.515 Prec@5 90.196\n",
      " * Prec@1 80.288 Prec@5 90.144\n",
      " * Prec@1 80.189 Prec@5 90.094\n",
      " * Prec@1 80.208 Prec@5 90.162\n",
      " * Prec@1 79.886 Prec@5 89.886\n",
      " * Prec@1 79.576 Prec@5 89.844\n",
      " * Prec@1 79.605 Prec@5 89.912\n",
      " * Prec@1 79.634 Prec@5 89.871\n",
      " * Prec@1 79.661 Prec@5 89.725\n",
      " * Prec@1 79.688 Prec@5 89.792\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.111 (1.189)\n",
      "\n",
      "Loss 2.8957 (1.1052)\n",
      "\n",
      "Prec@1 56.250 (79.303)\n",
      "\n",
      "Prec@5 68.750 (89.447)\n",
      "\n",
      " * Prec@1 79.303 Prec@5 89.447\n",
      " * Prec@1 79.536 Prec@5 89.617\n",
      " * Prec@1 79.365 Prec@5 89.484\n",
      " * Prec@1 79.590 Prec@5 89.551\n",
      " * Prec@1 79.712 Prec@5 89.712\n",
      " * Prec@1 79.735 Prec@5 89.773\n",
      " * Prec@1 79.851 Prec@5 89.832\n",
      " * Prec@1 79.963 Prec@5 89.890\n",
      " * Prec@1 80.072 Prec@5 89.946\n",
      " * Prec@1 80.179 Prec@5 90.000\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.071 (1.188)\n",
      "\n",
      "Loss 0.7859 (1.0369)\n",
      "\n",
      "Prec@1 87.500 (80.282)\n",
      "\n",
      "Prec@5 100.000 (90.141)\n",
      "\n",
      " * Prec@1 80.282 Prec@5 90.141\n",
      " * Prec@1 80.382 Prec@5 90.191\n",
      " * Prec@1 80.651 Prec@5 90.325\n",
      " * Prec@1 80.574 Prec@5 90.372\n",
      " * Prec@1 80.667 Prec@5 90.417\n",
      " * Prec@1 80.592 Prec@5 90.378\n",
      " * Prec@1 80.682 Prec@5 90.503\n",
      " * Prec@1 80.769 Prec@5 90.545\n",
      " * Prec@1 80.854 Prec@5 90.506\n",
      " * Prec@1 80.703 Prec@5 90.469\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.090 (1.186)\n",
      "\n",
      "Loss 1.5969 (1.0197)\n",
      "\n",
      "Prec@1 75.000 (80.633)\n",
      "\n",
      "Prec@5 81.250 (90.355)\n",
      "\n",
      " * Prec@1 80.633 Prec@5 90.355\n",
      " * Prec@1 80.640 Prec@5 90.396\n",
      " * Prec@1 80.723 Prec@5 90.437\n",
      " * Prec@1 80.729 Prec@5 90.476\n",
      " * Prec@1 80.588 Prec@5 90.441\n",
      " * Prec@1 80.451 Prec@5 90.407\n",
      " * Prec@1 80.388 Prec@5 90.302\n",
      " * Prec@1 80.469 Prec@5 90.270\n",
      " * Prec@1 80.618 Prec@5 90.379\n",
      " * Prec@1 80.556 Prec@5 90.278\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.090 (1.185)\n",
      "\n",
      "Loss 0.8515 (1.0122)\n",
      "\n",
      "Prec@1 81.250 (80.563)\n",
      "\n",
      "Prec@5 93.750 (90.316)\n",
      "\n",
      " * Prec@1 80.563 Prec@5 90.316\n",
      " * Prec@1 80.571 Prec@5 90.353\n",
      " * Prec@1 80.645 Prec@5 90.390\n",
      " * Prec@1 80.652 Prec@5 90.426\n",
      " * Prec@1 80.658 Prec@5 90.395\n",
      " * Prec@1 80.664 Prec@5 90.299\n",
      " * Prec@1 80.670 Prec@5 90.206\n",
      " * Prec@1 80.612 Prec@5 90.179\n",
      " * Prec@1 80.619 Prec@5 90.215\n",
      " * Prec@1 80.562 Prec@5 90.188\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.124 (1.183)\n",
      "\n",
      "Loss 0.4501 (1.0043)\n",
      "\n",
      "Prec@1 93.750 (80.693)\n",
      "\n",
      "Prec@5 93.750 (90.223)\n",
      "\n",
      " * Prec@1 80.693 Prec@5 90.223\n",
      " * Prec@1 80.699 Prec@5 90.196\n",
      " * Prec@1 80.643 Prec@5 90.291\n",
      " * Prec@1 80.649 Prec@5 90.264\n",
      " * Prec@1 80.536 Prec@5 90.238\n",
      " * Prec@1 80.483 Prec@5 90.271\n",
      " * Prec@1 80.432 Prec@5 90.245\n",
      " * Prec@1 80.440 Prec@5 90.220\n",
      " * Prec@1 80.505 Prec@5 90.310\n",
      " * Prec@1 80.228 Prec@5 90.142\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [16][0/987]\t\\Time 1.073 (1.073)\tData 0.472 (0.472)\tLoss 0.0019 (0.0019)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/987]\t\\Time 2.104 (2.107)\tData 1.472 (1.483)\tLoss 0.0018 (0.0105)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/987]\t\\Time 2.113 (2.106)\tData 1.483 (1.479)\tLoss 0.0016 (0.0065)\tPrec@1 100.000 (99.907)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][300/987]\t\\Time 2.140 (2.106)\tData 1.478 (1.478)\tLoss 0.0012 (0.0065)\tPrec@1 100.000 (99.855)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][400/987]\t\\Time 2.105 (2.106)\tData 1.474 (1.477)\tLoss 0.0017 (0.0057)\tPrec@1 100.000 (99.860)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][500/987]\t\\Time 2.112 (2.105)\tData 1.482 (1.477)\tLoss 0.0029 (0.0080)\tPrec@1 100.000 (99.788)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][600/987]\t\\Time 2.102 (2.105)\tData 1.476 (1.477)\tLoss 0.0019 (0.0095)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][700/987]\t\\Time 2.100 (2.105)\tData 1.473 (1.477)\tLoss 0.0724 (0.0094)\tPrec@1 93.750 (99.733)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][800/987]\t\\Time 2.099 (2.105)\tData 1.472 (1.476)\tLoss 0.0020 (0.0098)\tPrec@1 100.000 (99.719)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][900/987]\t\\Time 2.095 (2.105)\tData 1.472 (1.476)\tLoss 0.0023 (0.0104)\tPrec@1 100.000 (99.702)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 2.032 (2.032)\n",
      "\n",
      "Loss 1.1480 (1.1480)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 80.000 Prec@5 88.750\n",
      " * Prec@1 80.208 Prec@5 88.542\n",
      " * Prec@1 83.036 Prec@5 90.179\n",
      " * Prec@1 85.156 Prec@5 91.406\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 83.750 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 1.134 (1.276)\n",
      "\n",
      "Loss 1.0328 (0.9339)\n",
      "\n",
      "Prec@1 68.750 (82.386)\n",
      "\n",
      "Prec@5 93.750 (90.909)\n",
      "\n",
      " * Prec@1 82.386 Prec@5 90.909\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 79.808 Prec@5 89.904\n",
      " * Prec@1 80.357 Prec@5 90.625\n",
      " * Prec@1 80.833 Prec@5 90.833\n",
      " * Prec@1 81.641 Prec@5 91.406\n",
      " * Prec@1 81.985 Prec@5 91.176\n",
      " * Prec@1 81.597 Prec@5 90.972\n",
      " * Prec@1 81.250 Prec@5 90.789\n",
      " * Prec@1 81.875 Prec@5 90.938\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.136 (1.250)\n",
      "\n",
      "Loss 1.2776 (1.0051)\n",
      "\n",
      "Prec@1 81.250 (81.845)\n",
      "\n",
      "Prec@5 81.250 (90.476)\n",
      "\n",
      " * Prec@1 81.845 Prec@5 90.476\n",
      " * Prec@1 81.818 Prec@5 90.057\n",
      " * Prec@1 81.793 Prec@5 89.946\n",
      " * Prec@1 81.771 Prec@5 90.104\n",
      " * Prec@1 81.500 Prec@5 90.250\n",
      " * Prec@1 81.250 Prec@5 90.144\n",
      " * Prec@1 81.250 Prec@5 90.046\n",
      " * Prec@1 81.696 Prec@5 90.179\n",
      " * Prec@1 82.112 Prec@5 90.302\n",
      " * Prec@1 81.875 Prec@5 90.208\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.201 (1.248)\n",
      "\n",
      "Loss 1.1901 (1.0327)\n",
      "\n",
      "Prec@1 75.000 (81.653)\n",
      "\n",
      "Prec@5 93.750 (90.323)\n",
      "\n",
      " * Prec@1 81.653 Prec@5 90.323\n",
      " * Prec@1 82.227 Prec@5 90.625\n",
      " * Prec@1 82.386 Prec@5 90.720\n",
      " * Prec@1 82.537 Prec@5 90.809\n",
      " * Prec@1 82.321 Prec@5 90.536\n",
      " * Prec@1 82.292 Prec@5 90.625\n",
      " * Prec@1 82.095 Prec@5 90.541\n",
      " * Prec@1 81.414 Prec@5 89.967\n",
      " * Prec@1 81.090 Prec@5 89.583\n",
      " * Prec@1 81.406 Prec@5 89.844\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.137 (1.246)\n",
      "\n",
      "Loss 0.6064 (1.0408)\n",
      "\n",
      "Prec@1 81.250 (81.402)\n",
      "\n",
      "Prec@5 93.750 (89.939)\n",
      "\n",
      " * Prec@1 81.402 Prec@5 89.939\n",
      " * Prec@1 81.101 Prec@5 89.732\n",
      " * Prec@1 81.105 Prec@5 89.535\n",
      " * Prec@1 81.250 Prec@5 89.773\n",
      " * Prec@1 81.250 Prec@5 89.722\n",
      " * Prec@1 81.250 Prec@5 89.674\n",
      " * Prec@1 81.516 Prec@5 89.894\n",
      " * Prec@1 81.120 Prec@5 89.844\n",
      " * Prec@1 81.122 Prec@5 90.051\n",
      " * Prec@1 81.000 Prec@5 90.000\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.307 (1.258)\n",
      "\n",
      "Loss 0.6401 (1.0179)\n",
      "\n",
      "Prec@1 87.500 (81.127)\n",
      "\n",
      "Prec@5 93.750 (90.074)\n",
      "\n",
      " * Prec@1 81.127 Prec@5 90.074\n",
      " * Prec@1 80.889 Prec@5 89.904\n",
      " * Prec@1 80.778 Prec@5 89.858\n",
      " * Prec@1 80.787 Prec@5 89.931\n",
      " * Prec@1 80.455 Prec@5 89.659\n",
      " * Prec@1 80.134 Prec@5 89.621\n",
      " * Prec@1 80.154 Prec@5 89.693\n",
      " * Prec@1 80.172 Prec@5 89.655\n",
      " * Prec@1 80.191 Prec@5 89.619\n",
      " * Prec@1 80.208 Prec@5 89.688\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.118 (1.259)\n",
      "\n",
      "Loss 2.6259 (1.0893)\n",
      "\n",
      "Prec@1 62.500 (79.918)\n",
      "\n",
      "Prec@5 81.250 (89.549)\n",
      "\n",
      " * Prec@1 79.918 Prec@5 89.549\n",
      " * Prec@1 80.141 Prec@5 89.718\n",
      " * Prec@1 79.960 Prec@5 89.683\n",
      " * Prec@1 80.176 Prec@5 89.746\n",
      " * Prec@1 80.192 Prec@5 89.808\n",
      " * Prec@1 80.208 Prec@5 89.867\n",
      " * Prec@1 80.224 Prec@5 89.925\n",
      " * Prec@1 80.331 Prec@5 89.982\n",
      " * Prec@1 80.435 Prec@5 90.036\n",
      " * Prec@1 80.536 Prec@5 90.089\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.157 (1.256)\n",
      "\n",
      "Loss 0.8110 (1.0203)\n",
      "\n",
      "Prec@1 87.500 (80.634)\n",
      "\n",
      "Prec@5 93.750 (90.141)\n",
      "\n",
      " * Prec@1 80.634 Prec@5 90.141\n",
      " * Prec@1 80.816 Prec@5 90.191\n",
      " * Prec@1 81.079 Prec@5 90.325\n",
      " * Prec@1 80.997 Prec@5 90.372\n",
      " * Prec@1 81.000 Prec@5 90.417\n",
      " * Prec@1 80.921 Prec@5 90.296\n",
      " * Prec@1 81.006 Prec@5 90.341\n",
      " * Prec@1 81.090 Prec@5 90.385\n",
      " * Prec@1 81.171 Prec@5 90.348\n",
      " * Prec@1 81.016 Prec@5 90.234\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.266 (1.258)\n",
      "\n",
      "Loss 1.5095 (1.0079)\n",
      "\n",
      "Prec@1 75.000 (80.941)\n",
      "\n",
      "Prec@5 87.500 (90.201)\n",
      "\n",
      " * Prec@1 80.941 Prec@5 90.201\n",
      " * Prec@1 81.021 Prec@5 90.168\n",
      " * Prec@1 80.949 Prec@5 90.211\n",
      " * Prec@1 80.952 Prec@5 90.253\n",
      " * Prec@1 80.735 Prec@5 90.147\n",
      " * Prec@1 80.596 Prec@5 90.116\n",
      " * Prec@1 80.603 Prec@5 90.014\n",
      " * Prec@1 80.611 Prec@5 89.986\n",
      " * Prec@1 80.758 Prec@5 90.098\n",
      " * Prec@1 80.694 Prec@5 90.000\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.117 (1.253)\n",
      "\n",
      "Loss 0.7806 (1.0084)\n",
      "\n",
      "Prec@1 81.250 (80.701)\n",
      "\n",
      "Prec@5 93.750 (90.041)\n",
      "\n",
      " * Prec@1 80.701 Prec@5 90.041\n",
      " * Prec@1 80.707 Prec@5 90.082\n",
      " * Prec@1 80.780 Prec@5 90.121\n",
      " * Prec@1 80.785 Prec@5 90.093\n",
      " * Prec@1 80.789 Prec@5 90.066\n",
      " * Prec@1 80.794 Prec@5 89.974\n",
      " * Prec@1 80.799 Prec@5 89.884\n",
      " * Prec@1 80.804 Prec@5 89.860\n",
      " * Prec@1 80.808 Prec@5 89.899\n",
      " * Prec@1 80.812 Prec@5 89.875\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.170 (1.253)\n",
      "\n",
      "Loss 0.4453 (1.0014)\n",
      "\n",
      "Prec@1 93.750 (80.941)\n",
      "\n",
      "Prec@5 93.750 (89.913)\n",
      "\n",
      " * Prec@1 80.941 Prec@5 89.913\n",
      " * Prec@1 80.944 Prec@5 89.951\n",
      " * Prec@1 81.007 Prec@5 90.049\n",
      " * Prec@1 80.950 Prec@5 90.024\n",
      " * Prec@1 80.833 Prec@5 90.000\n",
      " * Prec@1 80.778 Prec@5 89.976\n",
      " * Prec@1 80.724 Prec@5 89.953\n",
      " * Prec@1 80.729 Prec@5 89.931\n",
      " * Prec@1 80.791 Prec@5 90.023\n",
      " * Prec@1 80.513 Prec@5 89.801\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [17][0/987]\t\\Time 1.566 (1.566)\tData 0.465 (0.465)\tLoss 0.0018 (0.0018)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/987]\t\\Time 2.060 (2.056)\tData 1.435 (1.432)\tLoss 0.0025 (0.0089)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][200/987]\t\\Time 2.058 (2.057)\tData 1.438 (1.435)\tLoss 0.0014 (0.0090)\tPrec@1 100.000 (99.782)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][300/987]\t\\Time 2.058 (2.058)\tData 1.438 (1.437)\tLoss 0.0025 (0.0099)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][400/987]\t\\Time 2.056 (2.059)\tData 1.440 (1.438)\tLoss 0.0020 (0.0099)\tPrec@1 100.000 (99.735)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][500/987]\t\\Time 2.054 (2.060)\tData 1.438 (1.438)\tLoss 0.0029 (0.0114)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][600/987]\t\\Time 2.057 (2.060)\tData 1.440 (1.439)\tLoss 0.0026 (0.0104)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][700/987]\t\\Time 2.061 (2.060)\tData 1.438 (1.439)\tLoss 0.0019 (0.0097)\tPrec@1 100.000 (99.733)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][800/987]\t\\Time 2.054 (2.060)\tData 1.438 (1.439)\tLoss 0.0023 (0.0101)\tPrec@1 100.000 (99.727)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][900/987]\t\\Time 2.060 (2.060)\tData 1.438 (1.439)\tLoss 0.0031 (0.0097)\tPrec@1 100.000 (99.736)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.825 (1.825)\n",
      "\n",
      "Loss 1.1653 (1.1653)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 91.667\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 80.000 Prec@5 90.000\n",
      " * Prec@1 80.208 Prec@5 89.583\n",
      " * Prec@1 83.036 Prec@5 91.071\n",
      " * Prec@1 85.156 Prec@5 92.188\n",
      " * Prec@1 83.333 Prec@5 90.278\n",
      " * Prec@1 83.750 Prec@5 91.250\n",
      "Test: [10/110]\n",
      "\n",
      "Time 2.013 (1.267)\n",
      "\n",
      "Loss 1.2175 (0.9344)\n",
      "\n",
      "Prec@1 56.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (90.341)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.341\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 78.846 Prec@5 88.942\n",
      " * Prec@1 79.911 Prec@5 89.732\n",
      " * Prec@1 80.417 Prec@5 90.000\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      " * Prec@1 81.250 Prec@5 90.441\n",
      " * Prec@1 80.903 Prec@5 90.625\n",
      " * Prec@1 80.592 Prec@5 90.461\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      "Test: [20/110]\n",
      "\n",
      "Time 1.202 (1.343)\n",
      "\n",
      "Loss 1.1713 (0.9638)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 87.500 (90.476)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.476\n",
      " * Prec@1 81.250 Prec@5 90.057\n",
      " * Prec@1 80.978 Prec@5 89.946\n",
      " * Prec@1 80.729 Prec@5 90.104\n",
      " * Prec@1 80.250 Prec@5 90.000\n",
      " * Prec@1 80.288 Prec@5 89.904\n",
      " * Prec@1 80.324 Prec@5 89.815\n",
      " * Prec@1 80.804 Prec@5 89.955\n",
      " * Prec@1 81.250 Prec@5 90.086\n",
      " * Prec@1 81.042 Prec@5 90.000\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.397 (1.349)\n",
      "\n",
      "Loss 1.1106 (1.0067)\n",
      "\n",
      "Prec@1 75.000 (80.847)\n",
      "\n",
      "Prec@5 93.750 (90.121)\n",
      "\n",
      " * Prec@1 80.847 Prec@5 90.121\n",
      " * Prec@1 81.445 Prec@5 90.430\n",
      " * Prec@1 81.439 Prec@5 90.530\n",
      " * Prec@1 81.618 Prec@5 90.625\n",
      " * Prec@1 81.429 Prec@5 90.357\n",
      " * Prec@1 81.597 Prec@5 90.451\n",
      " * Prec@1 81.588 Prec@5 90.541\n",
      " * Prec@1 80.921 Prec@5 89.967\n",
      " * Prec@1 80.609 Prec@5 89.583\n",
      " * Prec@1 80.781 Prec@5 89.844\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.087 (1.338)\n",
      "\n",
      "Loss 0.4778 (1.0144)\n",
      "\n",
      "Prec@1 81.250 (80.793)\n",
      "\n",
      "Prec@5 100.000 (90.091)\n",
      "\n",
      " * Prec@1 80.793 Prec@5 90.091\n",
      " * Prec@1 80.506 Prec@5 89.881\n",
      " * Prec@1 80.523 Prec@5 89.680\n",
      " * Prec@1 80.824 Prec@5 89.773\n",
      " * Prec@1 80.833 Prec@5 89.722\n",
      " * Prec@1 80.842 Prec@5 89.674\n",
      " * Prec@1 81.117 Prec@5 89.894\n",
      " * Prec@1 80.729 Prec@5 89.844\n",
      " * Prec@1 80.740 Prec@5 90.051\n",
      " * Prec@1 80.625 Prec@5 90.000\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.107 (1.309)\n",
      "\n",
      "Loss 0.7649 (0.9987)\n",
      "\n",
      "Prec@1 81.250 (80.637)\n",
      "\n",
      "Prec@5 87.500 (89.951)\n",
      "\n",
      " * Prec@1 80.637 Prec@5 89.951\n",
      " * Prec@1 80.409 Prec@5 89.904\n",
      " * Prec@1 80.307 Prec@5 89.741\n",
      " * Prec@1 80.324 Prec@5 89.815\n",
      " * Prec@1 80.000 Prec@5 89.545\n",
      " * Prec@1 79.688 Prec@5 89.509\n",
      " * Prec@1 79.605 Prec@5 89.583\n",
      " * Prec@1 79.634 Prec@5 89.547\n",
      " * Prec@1 79.661 Prec@5 89.407\n",
      " * Prec@1 79.688 Prec@5 89.479\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.075 (1.290)\n",
      "\n",
      "Loss 2.6163 (1.0767)\n",
      "\n",
      "Prec@1 62.500 (79.406)\n",
      "\n",
      "Prec@5 81.250 (89.344)\n",
      "\n",
      " * Prec@1 79.406 Prec@5 89.344\n",
      " * Prec@1 79.637 Prec@5 89.516\n",
      " * Prec@1 79.365 Prec@5 89.484\n",
      " * Prec@1 79.590 Prec@5 89.551\n",
      " * Prec@1 79.615 Prec@5 89.615\n",
      " * Prec@1 79.640 Prec@5 89.583\n",
      " * Prec@1 79.664 Prec@5 89.739\n",
      " * Prec@1 79.779 Prec@5 89.798\n",
      " * Prec@1 79.891 Prec@5 89.855\n",
      " * Prec@1 80.000 Prec@5 89.911\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.137 (1.282)\n",
      "\n",
      "Loss 0.8734 (1.0113)\n",
      "\n",
      "Prec@1 87.500 (80.106)\n",
      "\n",
      "Prec@5 93.750 (89.965)\n",
      "\n",
      " * Prec@1 80.106 Prec@5 89.965\n",
      " * Prec@1 80.208 Prec@5 90.017\n",
      " * Prec@1 80.479 Prec@5 90.154\n",
      " * Prec@1 80.405 Prec@5 90.203\n",
      " * Prec@1 80.500 Prec@5 90.250\n",
      " * Prec@1 80.428 Prec@5 90.132\n",
      " * Prec@1 80.519 Prec@5 90.260\n",
      " * Prec@1 80.609 Prec@5 90.224\n",
      " * Prec@1 80.696 Prec@5 90.190\n",
      " * Prec@1 80.547 Prec@5 90.078\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.172 (1.297)\n",
      "\n",
      "Loss 1.6202 (1.0005)\n",
      "\n",
      "Prec@1 75.000 (80.478)\n",
      "\n",
      "Prec@5 87.500 (90.046)\n",
      "\n",
      " * Prec@1 80.478 Prec@5 90.046\n",
      " * Prec@1 80.564 Prec@5 90.168\n",
      " * Prec@1 80.648 Prec@5 90.211\n",
      " * Prec@1 80.655 Prec@5 90.179\n",
      " * Prec@1 80.515 Prec@5 90.147\n",
      " * Prec@1 80.451 Prec@5 90.116\n",
      " * Prec@1 80.460 Prec@5 90.014\n",
      " * Prec@1 80.469 Prec@5 89.986\n",
      " * Prec@1 80.618 Prec@5 90.098\n",
      " * Prec@1 80.486 Prec@5 90.000\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.032 (1.284)\n",
      "\n",
      "Loss 0.8856 (0.9972)\n",
      "\n",
      "Prec@1 87.500 (80.563)\n",
      "\n",
      "Prec@5 93.750 (90.041)\n",
      "\n",
      " * Prec@1 80.563 Prec@5 90.041\n",
      " * Prec@1 80.639 Prec@5 90.082\n",
      " * Prec@1 80.712 Prec@5 90.121\n",
      " * Prec@1 80.718 Prec@5 90.093\n",
      " * Prec@1 80.724 Prec@5 90.066\n",
      " * Prec@1 80.729 Prec@5 89.974\n",
      " * Prec@1 80.735 Prec@5 89.884\n",
      " * Prec@1 80.740 Prec@5 89.796\n",
      " * Prec@1 80.745 Prec@5 89.836\n",
      " * Prec@1 80.688 Prec@5 89.812\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.008 (1.284)\n",
      "\n",
      "Loss 0.4069 (0.9872)\n",
      "\n",
      "Prec@1 93.750 (80.817)\n",
      "\n",
      "Prec@5 93.750 (89.851)\n",
      "\n",
      " * Prec@1 80.817 Prec@5 89.851\n",
      " * Prec@1 80.821 Prec@5 89.890\n",
      " * Prec@1 80.825 Prec@5 89.988\n",
      " * Prec@1 80.829 Prec@5 90.024\n",
      " * Prec@1 80.714 Prec@5 90.060\n",
      " * Prec@1 80.660 Prec@5 90.094\n",
      " * Prec@1 80.607 Prec@5 90.129\n",
      " * Prec@1 80.613 Prec@5 90.104\n",
      " * Prec@1 80.677 Prec@5 90.195\n",
      " * Prec@1 80.399 Prec@5 90.028\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [18][0/987]\t\\Time 1.116 (1.116)\tData 0.559 (0.559)\tLoss 0.0021 (0.0021)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/987]\t\\Time 2.055 (2.059)\tData 1.472 (1.474)\tLoss 0.0012 (0.0111)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][200/987]\t\\Time 2.052 (2.066)\tData 1.468 (1.481)\tLoss 0.0029 (0.0074)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][300/987]\t\\Time 2.050 (2.068)\tData 1.461 (1.483)\tLoss 0.0015 (0.0066)\tPrec@1 100.000 (99.834)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][400/987]\t\\Time 2.049 (2.069)\tData 1.458 (1.484)\tLoss 0.2512 (0.0072)\tPrec@1 93.750 (99.829)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][500/987]\t\\Time 2.057 (2.070)\tData 1.466 (1.484)\tLoss 0.0039 (0.0072)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][600/987]\t\\Time 2.051 (2.071)\tData 1.467 (1.485)\tLoss 0.0016 (0.0071)\tPrec@1 100.000 (99.823)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][700/987]\t\\Time 2.043 (2.071)\tData 1.460 (1.485)\tLoss 0.0016 (0.0069)\tPrec@1 100.000 (99.831)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][800/987]\t\\Time 2.052 (2.072)\tData 1.468 (1.485)\tLoss 0.0012 (0.0077)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][900/987]\t\\Time 2.056 (2.072)\tData 1.467 (1.485)\tLoss 0.0027 (0.0089)\tPrec@1 100.000 (99.785)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.805 (1.805)\n",
      "\n",
      "Loss 1.0885 (1.0885)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 80.000 Prec@5 88.750\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 82.143 Prec@5 90.179\n",
      " * Prec@1 84.375 Prec@5 91.406\n",
      " * Prec@1 82.639 Prec@5 89.583\n",
      " * Prec@1 83.125 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 0.965 (1.120)\n",
      "\n",
      "Loss 1.1930 (0.9560)\n",
      "\n",
      "Prec@1 62.500 (81.250)\n",
      "\n",
      "Prec@5 81.250 (89.773)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 89.773\n",
      " * Prec@1 79.167 Prec@5 88.021\n",
      " * Prec@1 78.846 Prec@5 88.462\n",
      " * Prec@1 79.464 Prec@5 89.286\n",
      " * Prec@1 80.000 Prec@5 89.167\n",
      " * Prec@1 81.250 Prec@5 89.844\n",
      " * Prec@1 80.882 Prec@5 89.706\n",
      " * Prec@1 79.861 Prec@5 89.931\n",
      " * Prec@1 79.605 Prec@5 89.803\n",
      " * Prec@1 80.312 Prec@5 90.000\n",
      "Test: [20/110]\n",
      "\n",
      "Time 0.972 (1.112)\n",
      "\n",
      "Loss 1.2678 (0.9951)\n",
      "\n",
      "Prec@1 81.250 (80.357)\n",
      "\n",
      "Prec@5 81.250 (89.583)\n",
      "\n",
      " * Prec@1 80.357 Prec@5 89.583\n",
      " * Prec@1 80.398 Prec@5 89.205\n",
      " * Prec@1 80.435 Prec@5 89.130\n",
      " * Prec@1 80.469 Prec@5 89.323\n",
      " * Prec@1 80.500 Prec@5 89.250\n",
      " * Prec@1 80.529 Prec@5 89.183\n",
      " * Prec@1 80.556 Prec@5 89.120\n",
      " * Prec@1 80.804 Prec@5 89.286\n",
      " * Prec@1 81.250 Prec@5 89.440\n",
      " * Prec@1 81.042 Prec@5 89.375\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.108 (1.113)\n",
      "\n",
      "Loss 1.3201 (1.0282)\n",
      "\n",
      "Prec@1 68.750 (80.645)\n",
      "\n",
      "Prec@5 93.750 (89.516)\n",
      "\n",
      " * Prec@1 80.645 Prec@5 89.516\n",
      " * Prec@1 81.250 Prec@5 89.844\n",
      " * Prec@1 81.250 Prec@5 89.962\n",
      " * Prec@1 81.434 Prec@5 90.074\n",
      " * Prec@1 81.250 Prec@5 89.821\n",
      " * Prec@1 81.424 Prec@5 89.931\n",
      " * Prec@1 81.419 Prec@5 90.034\n",
      " * Prec@1 80.592 Prec@5 89.474\n",
      " * Prec@1 80.288 Prec@5 89.263\n",
      " * Prec@1 80.312 Prec@5 89.531\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.058 (1.129)\n",
      "\n",
      "Loss 0.5358 (1.0369)\n",
      "\n",
      "Prec@1 81.250 (80.335)\n",
      "\n",
      "Prec@5 93.750 (89.634)\n",
      "\n",
      " * Prec@1 80.335 Prec@5 89.634\n",
      " * Prec@1 80.060 Prec@5 89.435\n",
      " * Prec@1 80.087 Prec@5 89.244\n",
      " * Prec@1 80.398 Prec@5 89.347\n",
      " * Prec@1 80.417 Prec@5 89.306\n",
      " * Prec@1 80.571 Prec@5 89.266\n",
      " * Prec@1 80.851 Prec@5 89.495\n",
      " * Prec@1 80.469 Prec@5 89.583\n",
      " * Prec@1 80.485 Prec@5 89.796\n",
      " * Prec@1 80.375 Prec@5 89.875\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.128 (1.133)\n",
      "\n",
      "Loss 0.5263 (1.0075)\n",
      "\n",
      "Prec@1 87.500 (80.515)\n",
      "\n",
      "Prec@5 93.750 (89.951)\n",
      "\n",
      " * Prec@1 80.515 Prec@5 89.951\n",
      " * Prec@1 80.288 Prec@5 89.784\n",
      " * Prec@1 80.071 Prec@5 89.623\n",
      " * Prec@1 80.093 Prec@5 89.699\n",
      " * Prec@1 79.773 Prec@5 89.432\n",
      " * Prec@1 79.464 Prec@5 89.397\n",
      " * Prec@1 79.386 Prec@5 89.474\n",
      " * Prec@1 79.418 Prec@5 89.440\n",
      " * Prec@1 79.449 Prec@5 89.301\n",
      " * Prec@1 79.479 Prec@5 89.375\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.014 (1.130)\n",
      "\n",
      "Loss 2.6242 (1.0853)\n",
      "\n",
      "Prec@1 62.500 (79.201)\n",
      "\n",
      "Prec@5 68.750 (89.037)\n",
      "\n",
      " * Prec@1 79.201 Prec@5 89.037\n",
      " * Prec@1 79.435 Prec@5 89.214\n",
      " * Prec@1 79.167 Prec@5 89.286\n",
      " * Prec@1 79.395 Prec@5 89.355\n",
      " * Prec@1 79.615 Prec@5 89.519\n",
      " * Prec@1 79.735 Prec@5 89.583\n",
      " * Prec@1 79.851 Prec@5 89.646\n",
      " * Prec@1 80.055 Prec@5 89.706\n",
      " * Prec@1 80.163 Prec@5 89.764\n",
      " * Prec@1 80.268 Prec@5 89.821\n",
      "Test: [70/110]\n",
      "\n",
      "Time 0.981 (1.128)\n",
      "\n",
      "Loss 0.8553 (1.0175)\n",
      "\n",
      "Prec@1 87.500 (80.370)\n",
      "\n",
      "Prec@5 93.750 (89.877)\n",
      "\n",
      " * Prec@1 80.370 Prec@5 89.877\n",
      " * Prec@1 80.469 Prec@5 89.931\n",
      " * Prec@1 80.736 Prec@5 90.068\n",
      " * Prec@1 80.659 Prec@5 90.118\n",
      " * Prec@1 80.750 Prec@5 90.167\n",
      " * Prec@1 80.674 Prec@5 90.132\n",
      " * Prec@1 80.763 Prec@5 90.097\n",
      " * Prec@1 80.849 Prec@5 90.144\n",
      " * Prec@1 80.934 Prec@5 90.111\n",
      " * Prec@1 80.703 Prec@5 90.000\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.181 (1.127)\n",
      "\n",
      "Loss 1.5474 (1.0078)\n",
      "\n",
      "Prec@1 75.000 (80.633)\n",
      "\n",
      "Prec@5 87.500 (89.969)\n",
      "\n",
      " * Prec@1 80.633 Prec@5 89.969\n",
      " * Prec@1 80.640 Prec@5 90.015\n",
      " * Prec@1 80.648 Prec@5 90.060\n",
      " * Prec@1 80.655 Prec@5 90.030\n",
      " * Prec@1 80.441 Prec@5 89.926\n",
      " * Prec@1 80.378 Prec@5 89.898\n",
      " * Prec@1 80.388 Prec@5 89.871\n",
      " * Prec@1 80.398 Prec@5 89.773\n",
      " * Prec@1 80.548 Prec@5 89.888\n",
      " * Prec@1 80.417 Prec@5 89.792\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.002 (1.134)\n",
      "\n",
      "Loss 0.7425 (1.0101)\n",
      "\n",
      "Prec@1 81.250 (80.426)\n",
      "\n",
      "Prec@5 93.750 (89.835)\n",
      "\n",
      " * Prec@1 80.426 Prec@5 89.835\n",
      " * Prec@1 80.435 Prec@5 89.878\n",
      " * Prec@1 80.511 Prec@5 89.919\n",
      " * Prec@1 80.519 Prec@5 89.894\n",
      " * Prec@1 80.526 Prec@5 89.868\n",
      " * Prec@1 80.534 Prec@5 89.779\n",
      " * Prec@1 80.541 Prec@5 89.691\n",
      " * Prec@1 80.548 Prec@5 89.668\n",
      " * Prec@1 80.556 Prec@5 89.710\n",
      " * Prec@1 80.500 Prec@5 89.688\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.030 (1.142)\n",
      "\n",
      "Loss 0.4681 (1.0055)\n",
      "\n",
      "Prec@1 93.750 (80.631)\n",
      "\n",
      "Prec@5 93.750 (89.728)\n",
      "\n",
      " * Prec@1 80.631 Prec@5 89.728\n",
      " * Prec@1 80.637 Prec@5 89.767\n",
      " * Prec@1 80.643 Prec@5 89.867\n",
      " * Prec@1 80.589 Prec@5 89.844\n",
      " * Prec@1 80.417 Prec@5 89.881\n",
      " * Prec@1 80.366 Prec@5 89.917\n",
      " * Prec@1 80.315 Prec@5 89.895\n",
      " * Prec@1 80.324 Prec@5 89.873\n",
      " * Prec@1 80.390 Prec@5 89.966\n",
      " * Prec@1 80.114 Prec@5 89.801\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [19][0/987]\t\\Time 0.965 (0.965)\tData 0.364 (0.364)\tLoss 0.0018 (0.0018)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][100/987]\t\\Time 2.017 (2.020)\tData 1.437 (1.436)\tLoss 0.0019 (0.0077)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][200/987]\t\\Time 2.021 (2.019)\tData 1.443 (1.438)\tLoss 0.0020 (0.0078)\tPrec@1 100.000 (99.782)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][300/987]\t\\Time 2.012 (2.019)\tData 1.436 (1.438)\tLoss 0.0016 (0.0070)\tPrec@1 100.000 (99.792)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][400/987]\t\\Time 2.014 (2.019)\tData 1.433 (1.438)\tLoss 0.0009 (0.0073)\tPrec@1 100.000 (99.766)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][500/987]\t\\Time 2.019 (2.019)\tData 1.436 (1.438)\tLoss 0.0032 (0.0083)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][600/987]\t\\Time 2.017 (2.019)\tData 1.434 (1.438)\tLoss 0.0018 (0.0081)\tPrec@1 100.000 (99.761)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][700/987]\t\\Time 2.026 (2.019)\tData 1.446 (1.438)\tLoss 0.0023 (0.0082)\tPrec@1 100.000 (99.768)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][800/987]\t\\Time 2.010 (2.019)\tData 1.440 (1.438)\tLoss 0.0025 (0.0084)\tPrec@1 100.000 (99.766)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][900/987]\t\\Time 2.018 (2.019)\tData 1.437 (1.438)\tLoss 0.0029 (0.0089)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/110]\n",
      "\n",
      "Time 1.755 (1.755)\n",
      "\n",
      "Loss 1.0941 (1.0941)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 87.500\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 80.000 Prec@5 88.750\n",
      " * Prec@1 79.167 Prec@5 88.542\n",
      " * Prec@1 82.143 Prec@5 90.179\n",
      " * Prec@1 84.375 Prec@5 91.406\n",
      " * Prec@1 82.639 Prec@5 89.583\n",
      " * Prec@1 83.125 Prec@5 90.625\n",
      "Test: [10/110]\n",
      "\n",
      "Time 0.957 (1.158)\n",
      "\n",
      "Loss 1.2074 (0.9294)\n",
      "\n",
      "Prec@1 68.750 (81.818)\n",
      "\n",
      "Prec@5 81.250 (89.773)\n",
      "\n",
      " * Prec@1 81.818 Prec@5 89.773\n",
      " * Prec@1 79.688 Prec@5 87.500\n",
      " * Prec@1 79.327 Prec@5 87.981\n",
      " * Prec@1 80.357 Prec@5 88.839\n",
      " * Prec@1 80.833 Prec@5 88.750\n",
      " * Prec@1 82.031 Prec@5 89.453\n",
      " * Prec@1 81.985 Prec@5 89.338\n",
      " * Prec@1 81.250 Prec@5 89.583\n",
      " * Prec@1 80.921 Prec@5 89.474\n",
      " * Prec@1 81.562 Prec@5 89.688\n",
      "Test: [20/110]\n",
      "\n",
      "Time 0.978 (1.164)\n",
      "\n",
      "Loss 1.2370 (0.9773)\n",
      "\n",
      "Prec@1 81.250 (81.548)\n",
      "\n",
      "Prec@5 81.250 (89.286)\n",
      "\n",
      " * Prec@1 81.548 Prec@5 89.286\n",
      " * Prec@1 81.534 Prec@5 88.920\n",
      " * Prec@1 81.250 Prec@5 88.859\n",
      " * Prec@1 80.990 Prec@5 89.062\n",
      " * Prec@1 80.750 Prec@5 89.000\n",
      " * Prec@1 80.769 Prec@5 88.942\n",
      " * Prec@1 81.019 Prec@5 88.889\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 81.681 Prec@5 89.224\n",
      " * Prec@1 81.458 Prec@5 89.167\n",
      "Test: [30/110]\n",
      "\n",
      "Time 1.038 (1.159)\n",
      "\n",
      "Loss 1.1161 (1.0125)\n",
      "\n",
      "Prec@1 75.000 (81.250)\n",
      "\n",
      "Prec@5 93.750 (89.315)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 89.315\n",
      " * Prec@1 81.836 Prec@5 89.648\n",
      " * Prec@1 81.818 Prec@5 89.773\n",
      " * Prec@1 81.985 Prec@5 89.890\n",
      " * Prec@1 81.786 Prec@5 89.643\n",
      " * Prec@1 81.771 Prec@5 89.757\n",
      " * Prec@1 81.757 Prec@5 89.696\n",
      " * Prec@1 81.086 Prec@5 89.145\n",
      " * Prec@1 80.769 Prec@5 88.942\n",
      " * Prec@1 81.094 Prec@5 89.219\n",
      "Test: [40/110]\n",
      "\n",
      "Time 1.031 (1.151)\n",
      "\n",
      "Loss 0.5951 (1.0180)\n",
      "\n",
      "Prec@1 81.250 (81.098)\n",
      "\n",
      "Prec@5 93.750 (89.329)\n",
      "\n",
      " * Prec@1 81.098 Prec@5 89.329\n",
      " * Prec@1 80.952 Prec@5 89.137\n",
      " * Prec@1 80.959 Prec@5 88.953\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 81.250 Prec@5 89.028\n",
      " * Prec@1 81.250 Prec@5 88.995\n",
      " * Prec@1 81.516 Prec@5 89.229\n",
      " * Prec@1 81.120 Prec@5 89.062\n",
      " * Prec@1 81.122 Prec@5 89.286\n",
      " * Prec@1 81.000 Prec@5 89.250\n",
      "Test: [50/110]\n",
      "\n",
      "Time 1.000 (1.136)\n",
      "\n",
      "Loss 0.6919 (0.9975)\n",
      "\n",
      "Prec@1 81.250 (81.005)\n",
      "\n",
      "Prec@5 93.750 (89.338)\n",
      "\n",
      " * Prec@1 81.005 Prec@5 89.338\n",
      " * Prec@1 80.769 Prec@5 89.303\n",
      " * Prec@1 80.542 Prec@5 89.033\n",
      " * Prec@1 80.556 Prec@5 89.120\n",
      " * Prec@1 80.227 Prec@5 88.864\n",
      " * Prec@1 79.911 Prec@5 88.839\n",
      " * Prec@1 79.825 Prec@5 88.925\n",
      " * Prec@1 79.849 Prec@5 88.901\n",
      " * Prec@1 79.873 Prec@5 88.877\n",
      " * Prec@1 79.896 Prec@5 88.958\n",
      "Test: [60/110]\n",
      "\n",
      "Time 1.040 (1.124)\n",
      "\n",
      "Loss 2.6527 (1.0717)\n",
      "\n",
      "Prec@1 62.500 (79.611)\n",
      "\n",
      "Prec@5 75.000 (88.730)\n",
      "\n",
      " * Prec@1 79.611 Prec@5 88.730\n",
      " * Prec@1 79.839 Prec@5 88.911\n",
      " * Prec@1 79.563 Prec@5 88.988\n",
      " * Prec@1 79.785 Prec@5 89.062\n",
      " * Prec@1 79.904 Prec@5 89.135\n",
      " * Prec@1 79.924 Prec@5 89.205\n",
      " * Prec@1 79.944 Prec@5 89.272\n",
      " * Prec@1 80.055 Prec@5 89.338\n",
      " * Prec@1 80.163 Prec@5 89.402\n",
      " * Prec@1 80.268 Prec@5 89.464\n",
      "Test: [70/110]\n",
      "\n",
      "Time 1.144 (1.126)\n",
      "\n",
      "Loss 0.8024 (1.0040)\n",
      "\n",
      "Prec@1 87.500 (80.370)\n",
      "\n",
      "Prec@5 93.750 (89.525)\n",
      "\n",
      " * Prec@1 80.370 Prec@5 89.525\n",
      " * Prec@1 80.469 Prec@5 89.583\n",
      " * Prec@1 80.736 Prec@5 89.726\n",
      " * Prec@1 80.659 Prec@5 89.780\n",
      " * Prec@1 80.750 Prec@5 89.833\n",
      " * Prec@1 80.674 Prec@5 89.803\n",
      " * Prec@1 80.763 Prec@5 89.935\n",
      " * Prec@1 80.769 Prec@5 89.904\n",
      " * Prec@1 80.854 Prec@5 89.873\n",
      " * Prec@1 80.625 Prec@5 89.844\n",
      "Test: [80/110]\n",
      "\n",
      "Time 1.086 (1.127)\n",
      "\n",
      "Loss 1.6032 (0.9894)\n",
      "\n",
      "Prec@1 75.000 (80.556)\n",
      "\n",
      "Prec@5 81.250 (89.738)\n",
      "\n",
      " * Prec@1 80.556 Prec@5 89.738\n",
      " * Prec@1 80.640 Prec@5 89.787\n",
      " * Prec@1 80.798 Prec@5 89.834\n",
      " * Prec@1 80.804 Prec@5 89.807\n",
      " * Prec@1 80.662 Prec@5 89.706\n",
      " * Prec@1 80.596 Prec@5 89.680\n",
      " * Prec@1 80.532 Prec@5 89.583\n",
      " * Prec@1 80.540 Prec@5 89.560\n",
      " * Prec@1 80.688 Prec@5 89.677\n",
      " * Prec@1 80.556 Prec@5 89.583\n",
      "Test: [90/110]\n",
      "\n",
      "Time 1.041 (1.124)\n",
      "\n",
      "Loss 0.8080 (0.9859)\n",
      "\n",
      "Prec@1 87.500 (80.632)\n",
      "\n",
      "Prec@5 87.500 (89.560)\n",
      "\n",
      " * Prec@1 80.632 Prec@5 89.560\n",
      " * Prec@1 80.707 Prec@5 89.606\n",
      " * Prec@1 80.780 Prec@5 89.651\n",
      " * Prec@1 80.785 Prec@5 89.628\n",
      " * Prec@1 80.789 Prec@5 89.605\n",
      " * Prec@1 80.794 Prec@5 89.518\n",
      " * Prec@1 80.799 Prec@5 89.433\n",
      " * Prec@1 80.804 Prec@5 89.349\n",
      " * Prec@1 80.808 Prec@5 89.394\n",
      " * Prec@1 80.750 Prec@5 89.375\n",
      "Test: [100/110]\n",
      "\n",
      "Time 1.024 (1.119)\n",
      "\n",
      "Loss 0.4310 (0.9773)\n",
      "\n",
      "Prec@1 93.750 (80.879)\n",
      "\n",
      "Prec@5 93.750 (89.418)\n",
      "\n",
      " * Prec@1 80.879 Prec@5 89.418\n",
      " * Prec@1 80.882 Prec@5 89.400\n",
      " * Prec@1 80.825 Prec@5 89.502\n",
      " * Prec@1 80.829 Prec@5 89.543\n",
      " * Prec@1 80.655 Prec@5 89.524\n",
      " * Prec@1 80.601 Prec@5 89.564\n",
      " * Prec@1 80.549 Prec@5 89.544\n",
      " * Prec@1 80.556 Prec@5 89.525\n",
      " * Prec@1 80.619 Prec@5 89.622\n",
      " * Prec@1 80.285 Prec@5 89.459\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 200, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_200targets_weights_seed2'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_200_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "144fb0b2-3d8e-4c20-818f-f7527b384f73",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_19992\\3414169806.py:13: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.location_dataframe = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'saved_models/vit_b_16_artsobservasjoner224_300targets_weights_seed_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_artsobservasjoner224_300targets_weights_seed_checkpoint.pth.tar' (epoch 17)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17][0/1276]\t\\Time 0.838 (0.838)\tData 0.468 (0.468)\tLoss 0.0023 (0.0023)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/1276]\t\\Time 0.570 (0.536)\tData 0.460 (0.430)\tLoss 0.0021 (0.0078)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][200/1276]\t\\Time 0.550 (0.534)\tData 0.440 (0.430)\tLoss 0.0027 (0.0085)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][300/1276]\t\\Time 0.540 (0.536)\tData 0.430 (0.433)\tLoss 0.0025 (0.0088)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][400/1276]\t\\Time 0.598 (0.543)\tData 0.470 (0.440)\tLoss 0.0013 (0.0094)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][500/1276]\t\\Time 0.597 (0.553)\tData 0.486 (0.449)\tLoss 0.0033 (0.0096)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][600/1276]\t\\Time 0.541 (0.553)\tData 0.431 (0.450)\tLoss 0.0027 (0.0091)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][700/1276]\t\\Time 0.579 (0.554)\tData 0.479 (0.450)\tLoss 0.0716 (0.0102)\tPrec@1 93.750 (99.670)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][800/1276]\t\\Time 0.533 (0.554)\tData 0.432 (0.451)\tLoss 0.0031 (0.0098)\tPrec@1 100.000 (99.696)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][900/1276]\t\\Time 0.589 (0.555)\tData 0.472 (0.451)\tLoss 0.0029 (0.0106)\tPrec@1 100.000 (99.660)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1000/1276]\t\\Time 0.508 (0.555)\tData 0.428 (0.451)\tLoss 0.0618 (0.0106)\tPrec@1 93.750 (99.663)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1100/1276]\t\\Time 0.536 (0.554)\tData 0.470 (0.451)\tLoss 0.0036 (0.0109)\tPrec@1 100.000 (99.659)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1200/1276]\t\\Time 0.554 (0.554)\tData 0.443 (0.450)\tLoss 0.0017 (0.0107)\tPrec@1 100.000 (99.677)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.505 (0.505)\n",
      "\n",
      "Loss 1.0524 (1.0524)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 70.833 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 73.750 Prec@5 86.250\n",
      " * Prec@1 76.042 Prec@5 87.500\n",
      " * Prec@1 77.679 Prec@5 87.500\n",
      " * Prec@1 78.125 Prec@5 88.281\n",
      " * Prec@1 77.778 Prec@5 87.500\n",
      " * Prec@1 78.750 Prec@5 88.125\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.534 (0.558)\n",
      "\n",
      "Loss 0.8497 (0.9939)\n",
      "\n",
      "Prec@1 81.250 (78.977)\n",
      "\n",
      "Prec@5 87.500 (88.068)\n",
      "\n",
      " * Prec@1 78.977 Prec@5 88.068\n",
      " * Prec@1 79.688 Prec@5 88.021\n",
      " * Prec@1 80.769 Prec@5 88.942\n",
      " * Prec@1 81.250 Prec@5 89.732\n",
      " * Prec@1 82.500 Prec@5 90.417\n",
      " * Prec@1 82.031 Prec@5 90.625\n",
      " * Prec@1 82.721 Prec@5 91.176\n",
      " * Prec@1 82.986 Prec@5 91.319\n",
      " * Prec@1 82.895 Prec@5 91.118\n",
      " * Prec@1 82.812 Prec@5 91.250\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.592 (0.558)\n",
      "\n",
      "Loss 1.0458 (0.7927)\n",
      "\n",
      "Prec@1 87.500 (83.036)\n",
      "\n",
      "Prec@5 87.500 (91.071)\n",
      "\n",
      " * Prec@1 83.036 Prec@5 91.071\n",
      " * Prec@1 82.386 Prec@5 90.625\n",
      " * Prec@1 83.152 Prec@5 91.033\n",
      " * Prec@1 83.073 Prec@5 90.885\n",
      " * Prec@1 83.250 Prec@5 91.000\n",
      " * Prec@1 83.654 Prec@5 91.106\n",
      " * Prec@1 83.796 Prec@5 90.972\n",
      " * Prec@1 83.259 Prec@5 90.848\n",
      " * Prec@1 83.190 Prec@5 90.517\n",
      " * Prec@1 82.708 Prec@5 90.417\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.592 (0.577)\n",
      "\n",
      "Loss 1.1063 (0.8380)\n",
      "\n",
      "Prec@1 87.500 (82.863)\n",
      "\n",
      "Prec@5 87.500 (90.323)\n",
      "\n",
      " * Prec@1 82.863 Prec@5 90.323\n",
      " * Prec@1 83.203 Prec@5 90.430\n",
      " * Prec@1 83.144 Prec@5 90.530\n",
      " * Prec@1 82.904 Prec@5 90.625\n",
      " * Prec@1 83.214 Prec@5 90.714\n",
      " * Prec@1 83.160 Prec@5 90.625\n",
      " * Prec@1 83.108 Prec@5 90.541\n",
      " * Prec@1 83.224 Prec@5 90.625\n",
      " * Prec@1 82.692 Prec@5 90.385\n",
      " * Prec@1 82.500 Prec@5 90.469\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.506 (0.573)\n",
      "\n",
      "Loss 1.3909 (0.8654)\n",
      "\n",
      "Prec@1 75.000 (82.317)\n",
      "\n",
      "Prec@5 93.750 (90.549)\n",
      "\n",
      " * Prec@1 82.317 Prec@5 90.549\n",
      " * Prec@1 81.994 Prec@5 90.179\n",
      " * Prec@1 82.267 Prec@5 90.262\n",
      " * Prec@1 82.102 Prec@5 90.199\n",
      " * Prec@1 81.806 Prec@5 90.139\n",
      " * Prec@1 82.065 Prec@5 90.217\n",
      " * Prec@1 82.048 Prec@5 90.293\n",
      " * Prec@1 82.161 Prec@5 90.234\n",
      " * Prec@1 82.270 Prec@5 90.306\n",
      " * Prec@1 82.375 Prec@5 90.375\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.629 (0.577)\n",
      "\n",
      "Loss 0.0101 (0.8563)\n",
      "\n",
      "Prec@1 100.000 (82.721)\n",
      "\n",
      "Prec@5 100.000 (90.564)\n",
      "\n",
      " * Prec@1 82.721 Prec@5 90.564\n",
      " * Prec@1 82.572 Prec@5 90.385\n",
      " * Prec@1 82.193 Prec@5 90.330\n",
      " * Prec@1 82.292 Prec@5 90.278\n",
      " * Prec@1 82.386 Prec@5 90.227\n",
      " * Prec@1 82.366 Prec@5 90.290\n",
      " * Prec@1 82.018 Prec@5 90.241\n",
      " * Prec@1 82.004 Prec@5 90.302\n",
      " * Prec@1 81.886 Prec@5 90.254\n",
      " * Prec@1 81.979 Prec@5 90.312\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.595 (0.582)\n",
      "\n",
      "Loss 1.1626 (0.9088)\n",
      "\n",
      "Prec@1 81.250 (81.967)\n",
      "\n",
      "Prec@5 81.250 (90.164)\n",
      "\n",
      " * Prec@1 81.967 Prec@5 90.164\n",
      " * Prec@1 81.855 Prec@5 90.020\n",
      " * Prec@1 81.647 Prec@5 89.980\n",
      " * Prec@1 81.836 Prec@5 90.137\n",
      " * Prec@1 81.827 Prec@5 90.096\n",
      " * Prec@1 81.723 Prec@5 90.057\n",
      " * Prec@1 81.903 Prec@5 90.205\n",
      " * Prec@1 81.801 Prec@5 90.165\n",
      " * Prec@1 81.703 Prec@5 90.036\n",
      " * Prec@1 81.518 Prec@5 89.911\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.463 (0.588)\n",
      "\n",
      "Loss 1.0503 (0.9479)\n",
      "\n",
      "Prec@1 81.250 (81.514)\n",
      "\n",
      "Prec@5 93.750 (89.965)\n",
      "\n",
      " * Prec@1 81.514 Prec@5 89.965\n",
      " * Prec@1 81.424 Prec@5 89.931\n",
      " * Prec@1 81.421 Prec@5 90.068\n",
      " * Prec@1 81.081 Prec@5 89.780\n",
      " * Prec@1 81.083 Prec@5 89.750\n",
      " * Prec@1 81.168 Prec@5 89.803\n",
      " * Prec@1 81.169 Prec@5 89.935\n",
      " * Prec@1 81.250 Prec@5 89.984\n",
      " * Prec@1 81.250 Prec@5 89.953\n",
      " * Prec@1 81.172 Prec@5 89.922\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.712 (0.588)\n",
      "\n",
      "Loss 1.3004 (0.9576)\n",
      "\n",
      "Prec@1 81.250 (81.173)\n",
      "\n",
      "Prec@5 81.250 (89.815)\n",
      "\n",
      " * Prec@1 81.173 Prec@5 89.815\n",
      " * Prec@1 81.174 Prec@5 89.787\n",
      " * Prec@1 81.024 Prec@5 89.759\n",
      " * Prec@1 81.176 Prec@5 89.807\n",
      " * Prec@1 81.250 Prec@5 89.779\n",
      " * Prec@1 81.105 Prec@5 89.898\n",
      " * Prec@1 81.034 Prec@5 89.871\n",
      " * Prec@1 81.108 Prec@5 89.844\n",
      " * Prec@1 81.110 Prec@5 89.817\n",
      " * Prec@1 81.250 Prec@5 89.861\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.551 (0.590)\n",
      "\n",
      "Loss 1.4827 (0.9735)\n",
      "\n",
      "Prec@1 75.000 (81.181)\n",
      "\n",
      "Prec@5 87.500 (89.835)\n",
      "\n",
      " * Prec@1 81.181 Prec@5 89.835\n",
      " * Prec@1 81.114 Prec@5 89.810\n",
      " * Prec@1 81.183 Prec@5 89.852\n",
      " * Prec@1 81.117 Prec@5 89.694\n",
      " * Prec@1 81.053 Prec@5 89.605\n",
      " * Prec@1 81.120 Prec@5 89.583\n",
      " * Prec@1 81.250 Prec@5 89.626\n",
      " * Prec@1 81.186 Prec@5 89.541\n",
      " * Prec@1 81.124 Prec@5 89.583\n",
      " * Prec@1 81.188 Prec@5 89.562\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.582 (0.587)\n",
      "\n",
      "Loss 1.0386 (0.9867)\n",
      "\n",
      "Prec@1 81.250 (81.188)\n",
      "\n",
      "Prec@5 87.500 (89.542)\n",
      "\n",
      " * Prec@1 81.188 Prec@5 89.542\n",
      " * Prec@1 81.189 Prec@5 89.583\n",
      " * Prec@1 81.189 Prec@5 89.563\n",
      " * Prec@1 81.250 Prec@5 89.543\n",
      " * Prec@1 81.369 Prec@5 89.643\n",
      " * Prec@1 81.427 Prec@5 89.682\n",
      " * Prec@1 81.425 Prec@5 89.661\n",
      " * Prec@1 81.366 Prec@5 89.525\n",
      " * Prec@1 81.307 Prec@5 89.450\n",
      " * Prec@1 81.477 Prec@5 89.545\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.573 (0.588)\n",
      "\n",
      "Loss 0.7825 (0.9874)\n",
      "\n",
      "Prec@1 87.500 (81.532)\n",
      "\n",
      "Prec@5 93.750 (89.583)\n",
      "\n",
      " * Prec@1 81.532 Prec@5 89.583\n",
      " * Prec@1 81.585 Prec@5 89.621\n",
      " * Prec@1 81.637 Prec@5 89.602\n",
      " * Prec@1 81.524 Prec@5 89.583\n",
      " * Prec@1 81.522 Prec@5 89.620\n",
      " * Prec@1 81.519 Prec@5 89.601\n",
      " * Prec@1 81.357 Prec@5 89.530\n",
      " * Prec@1 81.356 Prec@5 89.513\n",
      " * Prec@1 81.408 Prec@5 89.496\n",
      " * Prec@1 81.510 Prec@5 89.531\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.553 (0.585)\n",
      "\n",
      "Loss 0.4059 (0.9912)\n",
      "\n",
      "Prec@1 93.750 (81.612)\n",
      "\n",
      "Prec@5 93.750 (89.566)\n",
      "\n",
      " * Prec@1 81.612 Prec@5 89.566\n",
      " * Prec@1 81.711 Prec@5 89.652\n",
      " * Prec@1 81.809 Prec@5 89.685\n",
      " * Prec@1 81.754 Prec@5 89.667\n",
      " * Prec@1 81.800 Prec@5 89.650\n",
      " * Prec@1 81.845 Prec@5 89.732\n",
      " * Prec@1 81.791 Prec@5 89.715\n",
      " * Prec@1 81.738 Prec@5 89.648\n",
      " * Prec@1 81.734 Prec@5 89.680\n",
      " * Prec@1 81.827 Prec@5 89.712\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.593 (0.584)\n",
      "\n",
      "Loss 1.1369 (0.9740)\n",
      "\n",
      "Prec@1 68.750 (81.727)\n",
      "\n",
      "Prec@5 87.500 (89.695)\n",
      "\n",
      " * Prec@1 81.727 Prec@5 89.695\n",
      " * Prec@1 81.818 Prec@5 89.725\n",
      " * Prec@1 81.767 Prec@5 89.756\n",
      " * Prec@1 81.670 Prec@5 89.646\n",
      " * Prec@1 81.713 Prec@5 89.676\n",
      " * Prec@1 81.618 Prec@5 89.660\n",
      " * Prec@1 81.569 Prec@5 89.599\n",
      " * Prec@1 81.612 Prec@5 89.629\n",
      " * Prec@1 81.655 Prec@5 89.658\n",
      " * Prec@1 81.696 Prec@5 89.688\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.515 (0.581)\n",
      "\n",
      "Loss 1.1600 (0.9732)\n",
      "\n",
      "Prec@1 87.500 (81.738)\n",
      "\n",
      "Prec@5 87.500 (89.672)\n",
      "\n",
      " * Prec@1 81.738 Prec@5 89.672\n",
      " * Prec@1 81.842 Prec@5 89.731\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [18][0/1276]\t\\Time 0.526 (0.526)\tData 0.418 (0.418)\tLoss 0.0014 (0.0014)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/1276]\t\\Time 0.517 (0.579)\tData 0.407 (0.472)\tLoss 0.0028 (0.0070)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][200/1276]\t\\Time 0.515 (0.557)\tData 0.406 (0.452)\tLoss 0.0059 (0.0093)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][300/1276]\t\\Time 0.549 (0.549)\tData 0.440 (0.445)\tLoss 0.0040 (0.0084)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][400/1276]\t\\Time 0.563 (0.547)\tData 0.453 (0.443)\tLoss 0.0028 (0.0081)\tPrec@1 100.000 (99.766)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][500/1276]\t\\Time 0.560 (0.547)\tData 0.444 (0.443)\tLoss 0.0029 (0.0079)\tPrec@1 100.000 (99.788)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][600/1276]\t\\Time 0.583 (0.548)\tData 0.467 (0.445)\tLoss 0.0026 (0.0087)\tPrec@1 100.000 (99.740)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][700/1276]\t\\Time 0.550 (0.548)\tData 0.423 (0.445)\tLoss 0.0023 (0.0098)\tPrec@1 100.000 (99.697)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][800/1276]\t\\Time 0.543 (0.549)\tData 0.423 (0.445)\tLoss 0.0030 (0.0095)\tPrec@1 100.000 (99.703)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][900/1276]\t\\Time 0.582 (0.549)\tData 0.472 (0.445)\tLoss 0.0466 (0.0104)\tPrec@1 100.000 (99.674)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1000/1276]\t\\Time 0.551 (0.548)\tData 0.441 (0.444)\tLoss 0.0023 (0.0101)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1100/1276]\t\\Time 0.511 (0.547)\tData 0.431 (0.443)\tLoss 0.0044 (0.0101)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1200/1276]\t\\Time 0.492 (0.546)\tData 0.391 (0.442)\tLoss 0.0035 (0.0102)\tPrec@1 100.000 (99.693)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.500 (0.500)\n",
      "\n",
      "Loss 1.0412 (1.0412)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 89.583\n",
      " * Prec@1 76.562 Prec@5 89.062\n",
      " * Prec@1 77.500 Prec@5 87.500\n",
      " * Prec@1 80.208 Prec@5 88.542\n",
      " * Prec@1 81.250 Prec@5 88.393\n",
      " * Prec@1 81.250 Prec@5 88.281\n",
      " * Prec@1 80.556 Prec@5 87.500\n",
      " * Prec@1 81.250 Prec@5 88.125\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.477 (0.530)\n",
      "\n",
      "Loss 0.9140 (0.9973)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 87.500 (88.068)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 88.068\n",
      " * Prec@1 81.771 Prec@5 88.021\n",
      " * Prec@1 83.173 Prec@5 88.942\n",
      " * Prec@1 83.929 Prec@5 89.732\n",
      " * Prec@1 85.000 Prec@5 90.417\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 84.926 Prec@5 91.176\n",
      " * Prec@1 85.069 Prec@5 91.319\n",
      " * Prec@1 84.868 Prec@5 91.118\n",
      " * Prec@1 84.688 Prec@5 91.250\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.549 (0.520)\n",
      "\n",
      "Loss 1.0050 (0.7961)\n",
      "\n",
      "Prec@1 87.500 (84.821)\n",
      "\n",
      "Prec@5 87.500 (91.071)\n",
      "\n",
      " * Prec@1 84.821 Prec@5 91.071\n",
      " * Prec@1 84.091 Prec@5 90.625\n",
      " * Prec@1 84.783 Prec@5 91.033\n",
      " * Prec@1 84.375 Prec@5 90.885\n",
      " * Prec@1 84.750 Prec@5 91.000\n",
      " * Prec@1 85.096 Prec@5 91.106\n",
      " * Prec@1 84.954 Prec@5 90.972\n",
      " * Prec@1 84.598 Prec@5 90.848\n",
      " * Prec@1 84.483 Prec@5 90.517\n",
      " * Prec@1 83.958 Prec@5 90.417\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.569 (0.524)\n",
      "\n",
      "Loss 1.2620 (0.8366)\n",
      "\n",
      "Prec@1 75.000 (83.669)\n",
      "\n",
      "Prec@5 87.500 (90.323)\n",
      "\n",
      " * Prec@1 83.669 Prec@5 90.323\n",
      " * Prec@1 83.984 Prec@5 90.430\n",
      " * Prec@1 84.091 Prec@5 90.530\n",
      " * Prec@1 84.007 Prec@5 90.625\n",
      " * Prec@1 84.286 Prec@5 90.714\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 84.291 Prec@5 90.541\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 83.814 Prec@5 90.224\n",
      " * Prec@1 83.594 Prec@5 90.312\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.461 (0.528)\n",
      "\n",
      "Loss 1.2318 (0.8519)\n",
      "\n",
      "Prec@1 75.000 (83.384)\n",
      "\n",
      "Prec@5 100.000 (90.549)\n",
      "\n",
      " * Prec@1 83.384 Prec@5 90.549\n",
      " * Prec@1 83.036 Prec@5 90.179\n",
      " * Prec@1 83.140 Prec@5 90.262\n",
      " * Prec@1 82.955 Prec@5 90.199\n",
      " * Prec@1 82.500 Prec@5 90.139\n",
      " * Prec@1 82.745 Prec@5 90.217\n",
      " * Prec@1 82.713 Prec@5 90.293\n",
      " * Prec@1 82.812 Prec@5 90.234\n",
      " * Prec@1 83.036 Prec@5 90.306\n",
      " * Prec@1 83.250 Prec@5 90.375\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.511 (0.525)\n",
      "\n",
      "Loss 0.0154 (0.8443)\n",
      "\n",
      "Prec@1 100.000 (83.578)\n",
      "\n",
      "Prec@5 100.000 (90.564)\n",
      "\n",
      " * Prec@1 83.578 Prec@5 90.564\n",
      " * Prec@1 83.413 Prec@5 90.385\n",
      " * Prec@1 83.019 Prec@5 90.448\n",
      " * Prec@1 83.102 Prec@5 90.394\n",
      " * Prec@1 83.182 Prec@5 90.341\n",
      " * Prec@1 83.147 Prec@5 90.402\n",
      " * Prec@1 82.785 Prec@5 90.241\n",
      " * Prec@1 82.759 Prec@5 90.302\n",
      " * Prec@1 82.627 Prec@5 90.254\n",
      " * Prec@1 82.708 Prec@5 90.312\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.490 (0.524)\n",
      "\n",
      "Loss 1.1712 (0.8963)\n",
      "\n",
      "Prec@1 75.000 (82.582)\n",
      "\n",
      "Prec@5 87.500 (90.266)\n",
      "\n",
      " * Prec@1 82.582 Prec@5 90.266\n",
      " * Prec@1 82.460 Prec@5 90.020\n",
      " * Prec@1 82.242 Prec@5 89.980\n",
      " * Prec@1 82.422 Prec@5 90.137\n",
      " * Prec@1 82.404 Prec@5 90.096\n",
      " * Prec@1 82.197 Prec@5 90.057\n",
      " * Prec@1 82.369 Prec@5 90.205\n",
      " * Prec@1 82.261 Prec@5 90.165\n",
      " * Prec@1 82.156 Prec@5 90.036\n",
      " * Prec@1 81.964 Prec@5 89.821\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.501 (0.527)\n",
      "\n",
      "Loss 1.0901 (0.9398)\n",
      "\n",
      "Prec@1 81.250 (81.954)\n",
      "\n",
      "Prec@5 93.750 (89.877)\n",
      "\n",
      " * Prec@1 81.954 Prec@5 89.877\n",
      " * Prec@1 81.858 Prec@5 89.844\n",
      " * Prec@1 81.849 Prec@5 89.897\n",
      " * Prec@1 81.503 Prec@5 89.611\n",
      " * Prec@1 81.417 Prec@5 89.583\n",
      " * Prec@1 81.579 Prec@5 89.638\n",
      " * Prec@1 81.575 Prec@5 89.773\n",
      " * Prec@1 81.651 Prec@5 89.824\n",
      " * Prec@1 81.646 Prec@5 89.794\n",
      " * Prec@1 81.484 Prec@5 89.766\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.551 (0.527)\n",
      "\n",
      "Loss 1.3356 (0.9665)\n",
      "\n",
      "Prec@1 81.250 (81.481)\n",
      "\n",
      "Prec@5 81.250 (89.660)\n",
      "\n",
      " * Prec@1 81.481 Prec@5 89.660\n",
      " * Prec@1 81.479 Prec@5 89.634\n",
      " * Prec@1 81.325 Prec@5 89.608\n",
      " * Prec@1 81.473 Prec@5 89.658\n",
      " * Prec@1 81.544 Prec@5 89.632\n",
      " * Prec@1 81.395 Prec@5 89.680\n",
      " * Prec@1 81.322 Prec@5 89.655\n",
      " * Prec@1 81.392 Prec@5 89.631\n",
      " * Prec@1 81.390 Prec@5 89.677\n",
      " * Prec@1 81.458 Prec@5 89.792\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.481 (0.528)\n",
      "\n",
      "Loss 1.3426 (0.9790)\n",
      "\n",
      "Prec@1 75.000 (81.387)\n",
      "\n",
      "Prec@5 87.500 (89.766)\n",
      "\n",
      " * Prec@1 81.387 Prec@5 89.766\n",
      " * Prec@1 81.318 Prec@5 89.742\n",
      " * Prec@1 81.384 Prec@5 89.785\n",
      " * Prec@1 81.316 Prec@5 89.628\n",
      " * Prec@1 81.250 Prec@5 89.539\n",
      " * Prec@1 81.315 Prec@5 89.518\n",
      " * Prec@1 81.443 Prec@5 89.626\n",
      " * Prec@1 81.378 Prec@5 89.541\n",
      " * Prec@1 81.313 Prec@5 89.520\n",
      " * Prec@1 81.375 Prec@5 89.500\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.531 (0.529)\n",
      "\n",
      "Loss 0.9858 (0.9937)\n",
      "\n",
      "Prec@1 81.250 (81.374)\n",
      "\n",
      "Prec@5 87.500 (89.480)\n",
      "\n",
      " * Prec@1 81.374 Prec@5 89.480\n",
      " * Prec@1 81.373 Prec@5 89.522\n",
      " * Prec@1 81.371 Prec@5 89.502\n",
      " * Prec@1 81.430 Prec@5 89.483\n",
      " * Prec@1 81.548 Prec@5 89.583\n",
      " * Prec@1 81.545 Prec@5 89.623\n",
      " * Prec@1 81.542 Prec@5 89.603\n",
      " * Prec@1 81.481 Prec@5 89.468\n",
      " * Prec@1 81.422 Prec@5 89.392\n",
      " * Prec@1 81.591 Prec@5 89.489\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.562 (0.528)\n",
      "\n",
      "Loss 0.8391 (0.9944)\n",
      "\n",
      "Prec@1 87.500 (81.644)\n",
      "\n",
      "Prec@5 93.750 (89.527)\n",
      "\n",
      " * Prec@1 81.644 Prec@5 89.527\n",
      " * Prec@1 81.752 Prec@5 89.565\n",
      " * Prec@1 81.803 Prec@5 89.546\n",
      " * Prec@1 81.634 Prec@5 89.529\n",
      " * Prec@1 81.630 Prec@5 89.565\n",
      " * Prec@1 81.573 Prec@5 89.547\n",
      " * Prec@1 81.410 Prec@5 89.476\n",
      " * Prec@1 81.356 Prec@5 89.460\n",
      " * Prec@1 81.408 Prec@5 89.443\n",
      " * Prec@1 81.510 Prec@5 89.479\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.549 (0.528)\n",
      "\n",
      "Loss 0.2715 (0.9949)\n",
      "\n",
      "Prec@1 93.750 (81.612)\n",
      "\n",
      "Prec@5 93.750 (89.514)\n",
      "\n",
      " * Prec@1 81.612 Prec@5 89.514\n",
      " * Prec@1 81.711 Prec@5 89.600\n",
      " * Prec@1 81.809 Prec@5 89.634\n",
      " * Prec@1 81.754 Prec@5 89.617\n",
      " * Prec@1 81.800 Prec@5 89.600\n",
      " * Prec@1 81.895 Prec@5 89.683\n",
      " * Prec@1 81.841 Prec@5 89.715\n",
      " * Prec@1 81.738 Prec@5 89.648\n",
      " * Prec@1 81.734 Prec@5 89.680\n",
      " * Prec@1 81.827 Prec@5 89.712\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.602 (0.531)\n",
      "\n",
      "Loss 1.0162 (0.9814)\n",
      "\n",
      "Prec@1 75.000 (81.775)\n",
      "\n",
      "Prec@5 87.500 (89.695)\n",
      "\n",
      " * Prec@1 81.775 Prec@5 89.695\n",
      " * Prec@1 81.866 Prec@5 89.725\n",
      " * Prec@1 81.814 Prec@5 89.756\n",
      " * Prec@1 81.716 Prec@5 89.646\n",
      " * Prec@1 81.759 Prec@5 89.676\n",
      " * Prec@1 81.664 Prec@5 89.660\n",
      " * Prec@1 81.615 Prec@5 89.599\n",
      " * Prec@1 81.658 Prec@5 89.629\n",
      " * Prec@1 81.700 Prec@5 89.658\n",
      " * Prec@1 81.741 Prec@5 89.688\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.506 (0.530)\n",
      "\n",
      "Loss 1.1290 (0.9814)\n",
      "\n",
      "Prec@1 87.500 (81.782)\n",
      "\n",
      "Prec@5 87.500 (89.672)\n",
      "\n",
      " * Prec@1 81.782 Prec@5 89.672\n",
      " * Prec@1 81.886 Prec@5 89.731\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [19][0/1276]\t\\Time 0.604 (0.604)\tData 0.454 (0.454)\tLoss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][100/1276]\t\\Time 0.553 (0.533)\tData 0.451 (0.430)\tLoss 0.0154 (0.0080)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][200/1276]\t\\Time 0.489 (0.536)\tData 0.419 (0.432)\tLoss 0.0029 (0.0091)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][300/1276]\t\\Time 0.491 (0.534)\tData 0.423 (0.431)\tLoss 0.0028 (0.0110)\tPrec@1 100.000 (99.689)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][400/1276]\t\\Time 0.564 (0.536)\tData 0.453 (0.432)\tLoss 0.0031 (0.0110)\tPrec@1 100.000 (99.704)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][500/1276]\t\\Time 0.470 (0.536)\tData 0.400 (0.432)\tLoss 0.0032 (0.0113)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][600/1276]\t\\Time 0.631 (0.537)\tData 0.501 (0.433)\tLoss 0.0026 (0.0103)\tPrec@1 100.000 (99.719)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][700/1276]\t\\Time 0.529 (0.539)\tData 0.409 (0.435)\tLoss 0.0029 (0.0099)\tPrec@1 100.000 (99.733)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][800/1276]\t\\Time 0.560 (0.541)\tData 0.460 (0.437)\tLoss 0.0066 (0.0102)\tPrec@1 100.000 (99.727)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][900/1276]\t\\Time 0.522 (0.542)\tData 0.416 (0.438)\tLoss 0.1989 (0.0112)\tPrec@1 93.750 (99.681)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1000/1276]\t\\Time 0.491 (0.541)\tData 0.401 (0.437)\tLoss 0.0031 (0.0114)\tPrec@1 100.000 (99.669)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1100/1276]\t\\Time 0.538 (0.540)\tData 0.428 (0.437)\tLoss 0.0264 (0.0113)\tPrec@1 100.000 (99.671)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1200/1276]\t\\Time 0.591 (0.539)\tData 0.480 (0.436)\tLoss 0.0048 (0.0110)\tPrec@1 100.000 (99.683)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.482 (0.482)\n",
      "\n",
      "Loss 1.2042 (1.2042)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 90.625\n",
      " * Prec@1 75.000 Prec@5 91.667\n",
      " * Prec@1 75.000 Prec@5 90.625\n",
      " * Prec@1 76.250 Prec@5 90.000\n",
      " * Prec@1 78.125 Prec@5 90.625\n",
      " * Prec@1 79.464 Prec@5 90.179\n",
      " * Prec@1 80.469 Prec@5 89.844\n",
      " * Prec@1 79.861 Prec@5 88.889\n",
      " * Prec@1 80.625 Prec@5 89.375\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.483 (0.516)\n",
      "\n",
      "Loss 0.8554 (0.9896)\n",
      "\n",
      "Prec@1 81.250 (80.682)\n",
      "\n",
      "Prec@5 87.500 (89.205)\n",
      "\n",
      " * Prec@1 80.682 Prec@5 89.205\n",
      " * Prec@1 81.250 Prec@5 89.062\n",
      " * Prec@1 82.212 Prec@5 89.904\n",
      " * Prec@1 82.589 Prec@5 90.625\n",
      " * Prec@1 83.750 Prec@5 91.250\n",
      " * Prec@1 83.203 Prec@5 91.406\n",
      " * Prec@1 83.824 Prec@5 91.912\n",
      " * Prec@1 84.028 Prec@5 92.014\n",
      " * Prec@1 83.553 Prec@5 91.776\n",
      " * Prec@1 83.438 Prec@5 92.188\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.562 (0.519)\n",
      "\n",
      "Loss 1.0782 (0.7847)\n",
      "\n",
      "Prec@1 87.500 (83.631)\n",
      "\n",
      "Prec@5 87.500 (91.964)\n",
      "\n",
      " * Prec@1 83.631 Prec@5 91.964\n",
      " * Prec@1 82.955 Prec@5 91.761\n",
      " * Prec@1 83.696 Prec@5 92.120\n",
      " * Prec@1 83.333 Prec@5 91.927\n",
      " * Prec@1 83.500 Prec@5 92.000\n",
      " * Prec@1 83.894 Prec@5 92.067\n",
      " * Prec@1 83.796 Prec@5 91.898\n",
      " * Prec@1 83.259 Prec@5 91.964\n",
      " * Prec@1 82.974 Prec@5 91.595\n",
      " * Prec@1 82.708 Prec@5 91.458\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.530 (0.517)\n",
      "\n",
      "Loss 1.1517 (0.8353)\n",
      "\n",
      "Prec@1 75.000 (82.460)\n",
      "\n",
      "Prec@5 87.500 (91.331)\n",
      "\n",
      " * Prec@1 82.460 Prec@5 91.331\n",
      " * Prec@1 82.812 Prec@5 91.406\n",
      " * Prec@1 82.955 Prec@5 91.477\n",
      " * Prec@1 82.721 Prec@5 91.544\n",
      " * Prec@1 83.036 Prec@5 91.607\n",
      " * Prec@1 82.986 Prec@5 91.493\n",
      " * Prec@1 82.939 Prec@5 91.385\n",
      " * Prec@1 83.059 Prec@5 91.447\n",
      " * Prec@1 82.532 Prec@5 91.026\n",
      " * Prec@1 82.344 Prec@5 91.094\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.481 (0.516)\n",
      "\n",
      "Loss 1.3634 (0.8617)\n",
      "\n",
      "Prec@1 75.000 (82.165)\n",
      "\n",
      "Prec@5 93.750 (91.159)\n",
      "\n",
      " * Prec@1 82.165 Prec@5 91.159\n",
      " * Prec@1 81.696 Prec@5 90.774\n",
      " * Prec@1 81.977 Prec@5 90.843\n",
      " * Prec@1 81.818 Prec@5 90.767\n",
      " * Prec@1 81.528 Prec@5 90.694\n",
      " * Prec@1 81.658 Prec@5 90.761\n",
      " * Prec@1 81.649 Prec@5 90.824\n",
      " * Prec@1 81.641 Prec@5 90.755\n",
      " * Prec@1 81.760 Prec@5 90.816\n",
      " * Prec@1 81.875 Prec@5 90.875\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.511 (0.519)\n",
      "\n",
      "Loss 0.0124 (0.8501)\n",
      "\n",
      "Prec@1 100.000 (82.230)\n",
      "\n",
      "Prec@5 100.000 (91.054)\n",
      "\n",
      " * Prec@1 82.230 Prec@5 91.054\n",
      " * Prec@1 82.212 Prec@5 90.865\n",
      " * Prec@1 81.840 Prec@5 90.802\n",
      " * Prec@1 81.944 Prec@5 90.741\n",
      " * Prec@1 82.045 Prec@5 90.682\n",
      " * Prec@1 82.031 Prec@5 90.737\n",
      " * Prec@1 81.689 Prec@5 90.680\n",
      " * Prec@1 81.789 Prec@5 90.625\n",
      " * Prec@1 81.568 Prec@5 90.466\n",
      " * Prec@1 81.667 Prec@5 90.417\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.503 (0.519)\n",
      "\n",
      "Loss 1.2047 (0.9020)\n",
      "\n",
      "Prec@1 81.250 (81.660)\n",
      "\n",
      "Prec@5 81.250 (90.266)\n",
      "\n",
      " * Prec@1 81.660 Prec@5 90.266\n",
      " * Prec@1 81.552 Prec@5 90.020\n",
      " * Prec@1 81.349 Prec@5 89.980\n",
      " * Prec@1 81.543 Prec@5 90.137\n",
      " * Prec@1 81.538 Prec@5 90.096\n",
      " * Prec@1 81.439 Prec@5 89.962\n",
      " * Prec@1 81.623 Prec@5 90.112\n",
      " * Prec@1 81.618 Prec@5 90.074\n",
      " * Prec@1 81.522 Prec@5 89.946\n",
      " * Prec@1 81.339 Prec@5 89.821\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.501 (0.522)\n",
      "\n",
      "Loss 1.0547 (0.9489)\n",
      "\n",
      "Prec@1 75.000 (81.250)\n",
      "\n",
      "Prec@5 93.750 (89.877)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 89.877\n",
      " * Prec@1 81.163 Prec@5 89.844\n",
      " * Prec@1 81.250 Prec@5 89.983\n",
      " * Prec@1 80.912 Prec@5 89.696\n",
      " * Prec@1 80.917 Prec@5 89.667\n",
      " * Prec@1 81.003 Prec@5 89.720\n",
      " * Prec@1 81.006 Prec@5 89.854\n",
      " * Prec@1 81.090 Prec@5 89.904\n",
      " * Prec@1 81.013 Prec@5 89.873\n",
      " * Prec@1 80.938 Prec@5 89.844\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.561 (0.523)\n",
      "\n",
      "Loss 1.1662 (0.9542)\n",
      "\n",
      "Prec@1 81.250 (80.941)\n",
      "\n",
      "Prec@5 81.250 (89.738)\n",
      "\n",
      " * Prec@1 80.941 Prec@5 89.738\n",
      " * Prec@1 81.021 Prec@5 89.710\n",
      " * Prec@1 80.873 Prec@5 89.684\n",
      " * Prec@1 81.027 Prec@5 89.732\n",
      " * Prec@1 81.103 Prec@5 89.706\n",
      " * Prec@1 80.959 Prec@5 89.753\n",
      " * Prec@1 80.891 Prec@5 89.727\n",
      " * Prec@1 80.966 Prec@5 89.702\n",
      " * Prec@1 80.969 Prec@5 89.817\n",
      " * Prec@1 80.972 Prec@5 89.931\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.470 (0.522)\n",
      "\n",
      "Loss 1.2928 (0.9652)\n",
      "\n",
      "Prec@1 75.000 (80.907)\n",
      "\n",
      "Prec@5 87.500 (89.904)\n",
      "\n",
      " * Prec@1 80.907 Prec@5 89.904\n",
      " * Prec@1 80.842 Prec@5 89.878\n",
      " * Prec@1 80.914 Prec@5 89.919\n",
      " * Prec@1 80.851 Prec@5 89.761\n",
      " * Prec@1 80.789 Prec@5 89.671\n",
      " * Prec@1 80.859 Prec@5 89.648\n",
      " * Prec@1 80.992 Prec@5 89.691\n",
      " * Prec@1 80.931 Prec@5 89.605\n",
      " * Prec@1 80.934 Prec@5 89.646\n",
      " * Prec@1 80.938 Prec@5 89.625\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.566 (0.522)\n",
      "\n",
      "Loss 1.1136 (0.9780)\n",
      "\n",
      "Prec@1 81.250 (80.941)\n",
      "\n",
      "Prec@5 87.500 (89.604)\n",
      "\n",
      " * Prec@1 80.941 Prec@5 89.604\n",
      " * Prec@1 80.944 Prec@5 89.645\n",
      " * Prec@1 80.947 Prec@5 89.563\n",
      " * Prec@1 81.010 Prec@5 89.543\n",
      " * Prec@1 81.131 Prec@5 89.643\n",
      " * Prec@1 81.191 Prec@5 89.682\n",
      " * Prec@1 81.192 Prec@5 89.661\n",
      " * Prec@1 81.134 Prec@5 89.525\n",
      " * Prec@1 81.135 Prec@5 89.450\n",
      " * Prec@1 81.307 Prec@5 89.545\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.564 (0.523)\n",
      "\n",
      "Loss 0.7477 (0.9760)\n",
      "\n",
      "Prec@1 93.750 (81.419)\n",
      "\n",
      "Prec@5 93.750 (89.583)\n",
      "\n",
      " * Prec@1 81.419 Prec@5 89.583\n",
      " * Prec@1 81.473 Prec@5 89.621\n",
      " * Prec@1 81.527 Prec@5 89.602\n",
      " * Prec@1 81.360 Prec@5 89.583\n",
      " * Prec@1 81.359 Prec@5 89.620\n",
      " * Prec@1 81.304 Prec@5 89.601\n",
      " * Prec@1 81.143 Prec@5 89.530\n",
      " * Prec@1 81.091 Prec@5 89.513\n",
      " * Prec@1 81.145 Prec@5 89.496\n",
      " * Prec@1 81.250 Prec@5 89.531\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.558 (0.523)\n",
      "\n",
      "Loss 0.3764 (0.9811)\n",
      "\n",
      "Prec@1 93.750 (81.353)\n",
      "\n",
      "Prec@5 93.750 (89.566)\n",
      "\n",
      " * Prec@1 81.353 Prec@5 89.566\n",
      " * Prec@1 81.455 Prec@5 89.652\n",
      " * Prec@1 81.555 Prec@5 89.685\n",
      " * Prec@1 81.552 Prec@5 89.667\n",
      " * Prec@1 81.550 Prec@5 89.650\n",
      " * Prec@1 81.647 Prec@5 89.732\n",
      " * Prec@1 81.644 Prec@5 89.764\n",
      " * Prec@1 81.592 Prec@5 89.697\n",
      " * Prec@1 81.589 Prec@5 89.729\n",
      " * Prec@1 81.683 Prec@5 89.760\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.560 (0.526)\n",
      "\n",
      "Loss 1.0434 (0.9665)\n",
      "\n",
      "Prec@1 75.000 (81.632)\n",
      "\n",
      "Prec@5 87.500 (89.742)\n",
      "\n",
      " * Prec@1 81.632 Prec@5 89.742\n",
      " * Prec@1 81.723 Prec@5 89.773\n",
      " * Prec@1 81.673 Prec@5 89.803\n",
      " * Prec@1 81.576 Prec@5 89.739\n",
      " * Prec@1 81.620 Prec@5 89.769\n",
      " * Prec@1 81.526 Prec@5 89.706\n",
      " * Prec@1 81.478 Prec@5 89.690\n",
      " * Prec@1 81.567 Prec@5 89.719\n",
      " * Prec@1 81.610 Prec@5 89.748\n",
      " * Prec@1 81.652 Prec@5 89.777\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.511 (0.524)\n",
      "\n",
      "Loss 1.0495 (0.9650)\n",
      "\n",
      "Prec@1 87.500 (81.693)\n",
      "\n",
      "Prec@5 87.500 (89.761)\n",
      "\n",
      " * Prec@1 81.693 Prec@5 89.761\n",
      " * Prec@1 81.798 Prec@5 89.819\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 300, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_300targets_weights_seed'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_300_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d1e3035-2eb3-4fdd-9103-b09329fa0fe3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_19992\\3414169806.py:13: DtypeWarning: Columns (38,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.location_dataframe = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'saved_models/vit_b_16_artsobservasjoner224_400targets_weights_Noneseed_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_artsobservasjoner224_400targets_weights_Noneseed_checkpoint.pth.tar' (epoch 1)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1515]\t\\Time 4.584 (4.584)\tData 3.899 (3.899)\tLoss 2.9420 (2.9420)\tPrec@1 31.250 (31.250)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [1][100/1515]\t\\Time 0.509 (0.556)\tData 0.403 (0.449)\tLoss 2.7180 (3.0243)\tPrec@1 50.000 (34.777)\tPrec@5 62.500 (60.705)\n",
      "Epoch: [1][200/1515]\t\\Time 0.532 (0.553)\tData 0.424 (0.447)\tLoss 2.7477 (2.9791)\tPrec@1 31.250 (35.292)\tPrec@5 62.500 (61.070)\n",
      "Epoch: [1][300/1515]\t\\Time 0.580 (0.551)\tData 0.460 (0.447)\tLoss 1.9841 (2.9450)\tPrec@1 56.250 (35.424)\tPrec@5 75.000 (62.022)\n",
      "Epoch: [1][400/1515]\t\\Time 0.592 (0.558)\tData 0.481 (0.453)\tLoss 2.8659 (2.8995)\tPrec@1 25.000 (36.066)\tPrec@5 62.500 (62.749)\n",
      "Epoch: [1][500/1515]\t\\Time 0.579 (0.557)\tData 0.469 (0.452)\tLoss 2.2432 (2.8484)\tPrec@1 43.750 (37.188)\tPrec@5 81.250 (63.348)\n",
      "Epoch: [1][600/1515]\t\\Time 0.547 (0.556)\tData 0.447 (0.452)\tLoss 1.8772 (2.8152)\tPrec@1 43.750 (37.750)\tPrec@5 75.000 (63.738)\n",
      "Epoch: [1][700/1515]\t\\Time 0.532 (0.557)\tData 0.421 (0.453)\tLoss 1.7446 (2.7411)\tPrec@1 62.500 (39.149)\tPrec@5 87.500 (65.139)\n",
      "Epoch: [1][800/1515]\t\\Time 0.524 (0.557)\tData 0.454 (0.452)\tLoss 1.7387 (2.6775)\tPrec@1 56.250 (40.223)\tPrec@5 75.000 (66.245)\n",
      "Epoch: [1][900/1515]\t\\Time 0.725 (0.558)\tData 0.597 (0.454)\tLoss 1.5369 (2.6120)\tPrec@1 56.250 (41.343)\tPrec@5 81.250 (67.383)\n",
      "Epoch: [1][1000/1515]\t\\Time 0.522 (0.557)\tData 0.411 (0.453)\tLoss 2.3977 (2.5662)\tPrec@1 62.500 (42.245)\tPrec@5 68.750 (68.063)\n",
      "Epoch: [1][1100/1515]\t\\Time 0.583 (0.556)\tData 0.471 (0.452)\tLoss 1.8943 (2.5119)\tPrec@1 56.250 (43.290)\tPrec@5 81.250 (68.977)\n",
      "Epoch: [1][1200/1515]\t\\Time 0.480 (0.556)\tData 0.410 (0.452)\tLoss 2.0984 (2.4464)\tPrec@1 43.750 (44.593)\tPrec@5 68.750 (70.041)\n",
      "Epoch: [1][1300/1515]\t\\Time 0.587 (0.555)\tData 0.469 (0.452)\tLoss 1.6263 (2.3971)\tPrec@1 50.000 (45.542)\tPrec@5 81.250 (70.753)\n",
      "Epoch: [1][1400/1515]\t\\Time 0.480 (0.555)\tData 0.410 (0.451)\tLoss 1.5676 (2.3466)\tPrec@1 62.500 (46.636)\tPrec@5 87.500 (71.565)\n",
      "Epoch: [1][1500/1515]\t\\Time 0.580 (0.555)\tData 0.470 (0.452)\tLoss 1.4630 (2.2969)\tPrec@1 62.500 (47.710)\tPrec@5 81.250 (72.402)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.502 (0.502)\n",
      "\n",
      "Loss 1.6261 (1.6261)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 81.250\n",
      " * Prec@1 65.625 Prec@5 81.250\n",
      " * Prec@1 68.750 Prec@5 83.333\n",
      " * Prec@1 62.500 Prec@5 81.250\n",
      " * Prec@1 61.250 Prec@5 81.250\n",
      " * Prec@1 60.417 Prec@5 79.167\n",
      " * Prec@1 58.929 Prec@5 76.786\n",
      " * Prec@1 57.031 Prec@5 77.344\n",
      " * Prec@1 56.944 Prec@5 77.083\n",
      " * Prec@1 55.625 Prec@5 75.000\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.542 (0.543)\n",
      "\n",
      "Loss 1.3678 (1.9999)\n",
      "\n",
      "Prec@1 56.250 (55.682)\n",
      "\n",
      "Prec@5 87.500 (76.136)\n",
      "\n",
      " * Prec@1 55.682 Prec@5 76.136\n",
      " * Prec@1 56.250 Prec@5 76.562\n",
      " * Prec@1 55.769 Prec@5 77.404\n",
      " * Prec@1 54.464 Prec@5 75.893\n",
      " * Prec@1 54.167 Prec@5 75.833\n",
      " * Prec@1 53.516 Prec@5 75.000\n",
      " * Prec@1 52.941 Prec@5 75.000\n",
      " * Prec@1 52.778 Prec@5 74.653\n",
      " * Prec@1 52.961 Prec@5 74.342\n",
      " * Prec@1 53.750 Prec@5 75.312\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.563 (0.545)\n",
      "\n",
      "Loss 2.9674 (2.1912)\n",
      "\n",
      "Prec@1 43.750 (53.274)\n",
      "\n",
      "Prec@5 62.500 (74.702)\n",
      "\n",
      " * Prec@1 53.274 Prec@5 74.702\n",
      " * Prec@1 53.125 Prec@5 73.580\n",
      " * Prec@1 53.261 Prec@5 73.098\n",
      " * Prec@1 53.385 Prec@5 73.698\n",
      " * Prec@1 53.750 Prec@5 74.000\n",
      " * Prec@1 54.087 Prec@5 74.519\n",
      " * Prec@1 54.630 Prec@5 74.537\n",
      " * Prec@1 54.464 Prec@5 74.330\n",
      " * Prec@1 54.095 Prec@5 74.569\n",
      " * Prec@1 53.542 Prec@5 74.583\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.523 (0.551)\n",
      "\n",
      "Loss 1.6474 (2.1651)\n",
      "\n",
      "Prec@1 62.500 (53.831)\n",
      "\n",
      "Prec@5 75.000 (74.597)\n",
      "\n",
      " * Prec@1 53.831 Prec@5 74.597\n",
      " * Prec@1 54.102 Prec@5 74.805\n",
      " * Prec@1 53.788 Prec@5 74.242\n",
      " * Prec@1 52.757 Prec@5 73.529\n",
      " * Prec@1 52.500 Prec@5 73.214\n",
      " * Prec@1 52.604 Prec@5 73.438\n",
      " * Prec@1 52.027 Prec@5 73.142\n",
      " * Prec@1 51.974 Prec@5 73.191\n",
      " * Prec@1 52.083 Prec@5 73.397\n",
      " * Prec@1 52.031 Prec@5 73.281\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.550 (0.548)\n",
      "\n",
      "Loss 2.1475 (2.2433)\n",
      "\n",
      "Prec@1 62.500 (52.287)\n",
      "\n",
      "Prec@5 68.750 (73.171)\n",
      "\n",
      " * Prec@1 52.287 Prec@5 73.171\n",
      " * Prec@1 51.935 Prec@5 72.917\n",
      " * Prec@1 52.180 Prec@5 72.820\n",
      " * Prec@1 52.131 Prec@5 72.727\n",
      " * Prec@1 52.222 Prec@5 72.917\n",
      " * Prec@1 52.174 Prec@5 72.554\n",
      " * Prec@1 52.128 Prec@5 72.340\n",
      " * Prec@1 52.083 Prec@5 72.005\n",
      " * Prec@1 52.041 Prec@5 72.066\n",
      " * Prec@1 52.125 Prec@5 72.125\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.540 (0.548)\n",
      "\n",
      "Loss 3.4940 (2.2911)\n",
      "\n",
      "Prec@1 43.750 (51.961)\n",
      "\n",
      "Prec@5 50.000 (71.691)\n",
      "\n",
      " * Prec@1 51.961 Prec@5 71.691\n",
      " * Prec@1 52.163 Prec@5 71.875\n",
      " * Prec@1 52.005 Prec@5 71.698\n",
      " * Prec@1 51.736 Prec@5 71.875\n",
      " * Prec@1 51.705 Prec@5 72.159\n",
      " * Prec@1 51.786 Prec@5 72.321\n",
      " * Prec@1 51.206 Prec@5 72.478\n",
      " * Prec@1 51.078 Prec@5 72.198\n",
      " * Prec@1 50.847 Prec@5 72.352\n",
      " * Prec@1 50.521 Prec@5 72.396\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.522 (0.550)\n",
      "\n",
      "Loss 2.1172 (2.2839)\n",
      "\n",
      "Prec@1 56.250 (50.615)\n",
      "\n",
      "Prec@5 68.750 (72.336)\n",
      "\n",
      " * Prec@1 50.615 Prec@5 72.336\n",
      " * Prec@1 50.806 Prec@5 72.278\n",
      " * Prec@1 50.992 Prec@5 72.421\n",
      " * Prec@1 51.074 Prec@5 72.754\n",
      " * Prec@1 50.865 Prec@5 72.500\n",
      " * Prec@1 51.042 Prec@5 72.727\n",
      " * Prec@1 51.119 Prec@5 72.948\n",
      " * Prec@1 51.287 Prec@5 72.978\n",
      " * Prec@1 51.359 Prec@5 73.098\n",
      " * Prec@1 51.250 Prec@5 72.946\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.520 (0.544)\n",
      "\n",
      "Loss 1.3138 (2.2458)\n",
      "\n",
      "Prec@1 62.500 (51.408)\n",
      "\n",
      "Prec@5 87.500 (73.151)\n",
      "\n",
      " * Prec@1 51.408 Prec@5 73.151\n",
      " * Prec@1 51.562 Prec@5 73.351\n",
      " * Prec@1 51.627 Prec@5 73.288\n",
      " * Prec@1 51.689 Prec@5 73.311\n",
      " * Prec@1 51.750 Prec@5 73.500\n",
      " * Prec@1 51.727 Prec@5 73.520\n",
      " * Prec@1 51.948 Prec@5 73.701\n",
      " * Prec@1 51.843 Prec@5 73.718\n",
      " * Prec@1 51.820 Prec@5 73.734\n",
      " * Prec@1 51.719 Prec@5 73.516\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.508 (0.544)\n",
      "\n",
      "Loss 3.5661 (2.2441)\n",
      "\n",
      "Prec@1 25.000 (51.389)\n",
      "\n",
      "Prec@5 43.750 (73.148)\n",
      "\n",
      " * Prec@1 51.389 Prec@5 73.148\n",
      " * Prec@1 51.296 Prec@5 73.171\n",
      " * Prec@1 51.054 Prec@5 73.193\n",
      " * Prec@1 50.818 Prec@5 72.991\n",
      " * Prec@1 50.882 Prec@5 73.015\n",
      " * Prec@1 50.654 Prec@5 72.965\n",
      " * Prec@1 50.647 Prec@5 72.989\n",
      " * Prec@1 50.355 Prec@5 72.798\n",
      " * Prec@1 50.492 Prec@5 72.823\n",
      " * Prec@1 50.486 Prec@5 72.986\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.469 (0.542)\n",
      "\n",
      "Loss 1.2094 (2.2523)\n",
      "\n",
      "Prec@1 62.500 (50.618)\n",
      "\n",
      "Prec@5 93.750 (73.214)\n",
      "\n",
      " * Prec@1 50.618 Prec@5 73.214\n",
      " * Prec@1 50.679 Prec@5 73.166\n",
      " * Prec@1 50.806 Prec@5 73.253\n",
      " * Prec@1 50.931 Prec@5 73.271\n",
      " * Prec@1 50.855 Prec@5 73.158\n",
      " * Prec@1 50.781 Prec@5 73.047\n",
      " * Prec@1 50.709 Prec@5 73.003\n",
      " * Prec@1 50.574 Prec@5 72.895\n",
      " * Prec@1 50.568 Prec@5 72.980\n",
      " * Prec@1 50.688 Prec@5 73.125\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.627 (0.547)\n",
      "\n",
      "Loss 2.5881 (2.2628)\n",
      "\n",
      "Prec@1 43.750 (50.619)\n",
      "\n",
      "Prec@5 62.500 (73.020)\n",
      "\n",
      " * Prec@1 50.619 Prec@5 73.020\n",
      " * Prec@1 50.797 Prec@5 73.100\n",
      " * Prec@1 50.910 Prec@5 73.119\n",
      " * Prec@1 50.962 Prec@5 73.197\n",
      " * Prec@1 50.952 Prec@5 73.274\n",
      " * Prec@1 50.943 Prec@5 73.408\n",
      " * Prec@1 50.993 Prec@5 73.540\n",
      " * Prec@1 51.042 Prec@5 73.553\n",
      " * Prec@1 51.204 Prec@5 73.681\n",
      " * Prec@1 51.023 Prec@5 73.807\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.549 (0.551)\n",
      "\n",
      "Loss 2.7328 (2.2321)\n",
      "\n",
      "Prec@1 50.000 (51.014)\n",
      "\n",
      "Prec@5 56.250 (73.649)\n",
      "\n",
      " * Prec@1 51.014 Prec@5 73.649\n",
      " * Prec@1 50.949 Prec@5 73.605\n",
      " * Prec@1 50.940 Prec@5 73.728\n",
      " * Prec@1 50.932 Prec@5 73.739\n",
      " * Prec@1 50.924 Prec@5 73.804\n",
      " * Prec@1 50.808 Prec@5 73.761\n",
      " * Prec@1 50.748 Prec@5 73.718\n",
      " * Prec@1 50.477 Prec@5 73.729\n",
      " * Prec@1 50.473 Prec@5 73.739\n",
      " * Prec@1 50.365 Prec@5 73.802\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.501 (0.550)\n",
      "\n",
      "Loss 1.8388 (2.2267)\n",
      "\n",
      "Prec@1 68.750 (50.517)\n",
      "\n",
      "Prec@5 75.000 (73.812)\n",
      "\n",
      " * Prec@1 50.517 Prec@5 73.812\n",
      " * Prec@1 50.564 Prec@5 73.770\n",
      " * Prec@1 50.661 Prec@5 73.882\n",
      " * Prec@1 50.806 Prec@5 73.891\n",
      " * Prec@1 50.900 Prec@5 73.950\n",
      " * Prec@1 50.992 Prec@5 74.008\n",
      " * Prec@1 50.935 Prec@5 74.065\n",
      " * Prec@1 51.025 Prec@5 74.170\n",
      " * Prec@1 50.969 Prec@5 74.225\n",
      " * Prec@1 51.106 Prec@5 74.375\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.582 (0.548)\n",
      "\n",
      "Loss 1.7672 (2.1845)\n",
      "\n",
      "Prec@1 62.500 (51.193)\n",
      "\n",
      "Prec@5 75.000 (74.380)\n",
      "\n",
      " * Prec@1 51.193 Prec@5 74.380\n",
      " * Prec@1 51.136 Prec@5 74.432\n",
      " * Prec@1 51.128 Prec@5 74.483\n",
      " * Prec@1 50.886 Prec@5 74.300\n",
      " * Prec@1 50.880 Prec@5 74.259\n",
      " * Prec@1 50.873 Prec@5 74.173\n",
      " * Prec@1 50.912 Prec@5 74.179\n",
      " * Prec@1 50.815 Prec@5 74.094\n",
      " * Prec@1 50.989 Prec@5 74.191\n",
      " * Prec@1 50.893 Prec@5 74.152\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.561 (0.547)\n",
      "\n",
      "Loss 2.7348 (2.1967)\n",
      "\n",
      "Prec@1 43.750 (50.842)\n",
      "\n",
      "Prec@5 68.750 (74.113)\n",
      "\n",
      " * Prec@1 50.842 Prec@5 74.113\n",
      " * Prec@1 50.748 Prec@5 74.120\n",
      " * Prec@1 50.743 Prec@5 74.082\n",
      " * Prec@1 50.694 Prec@5 74.089\n",
      " * Prec@1 50.905 Prec@5 74.181\n",
      " * Prec@1 50.813 Prec@5 74.058\n",
      " * Prec@1 50.765 Prec@5 74.065\n",
      " * Prec@1 50.802 Prec@5 74.155\n",
      " * Prec@1 50.839 Prec@5 74.203\n",
      " * Prec@1 51.000 Prec@5 74.250\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.520 (0.548)\n",
      "\n",
      "Loss 1.8122 (2.1923)\n",
      "\n",
      "Prec@1 68.750 (51.118)\n",
      "\n",
      "Prec@5 81.250 (74.296)\n",
      "\n",
      " * Prec@1 51.118 Prec@5 74.296\n",
      " * Prec@1 51.234 Prec@5 74.465\n",
      " * Prec@1 51.307 Prec@5 74.510\n",
      " * Prec@1 51.380 Prec@5 74.472\n",
      " * Prec@1 51.532 Prec@5 74.556\n",
      " * Prec@1 51.442 Prec@5 74.479\n",
      " * Prec@1 51.314 Prec@5 74.443\n",
      " * Prec@1 51.345 Prec@5 74.446\n",
      " * Prec@1 51.297 Prec@5 74.450\n",
      " * Prec@1 51.328 Prec@5 74.453\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.543 (0.547)\n",
      "\n",
      "Loss 1.4396 (2.1707)\n",
      "\n",
      "Prec@1 68.750 (51.436)\n",
      "\n",
      "Prec@5 81.250 (74.495)\n",
      "\n",
      " * Prec@1 51.436 Prec@5 74.495\n",
      " * Prec@1 51.505 Prec@5 74.498\n",
      " * Prec@1 51.572 Prec@5 74.502\n",
      " * Prec@1 51.562 Prec@5 74.505\n",
      " * Prec@1 51.553 Prec@5 74.470\n",
      " * Prec@1 51.619 Prec@5 74.511\n",
      " * Prec@1 51.534 Prec@5 74.476\n",
      " * Prec@1 51.414 Prec@5 74.330\n",
      " * Prec@1 51.430 Prec@5 74.304\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1515]\t\\Time 0.530 (0.530)\tData 0.420 (0.420)\tLoss 1.0398 (1.0398)\tPrec@1 75.000 (75.000)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [2][100/1515]\t\\Time 0.541 (0.532)\tData 0.441 (0.429)\tLoss 1.8911 (1.2857)\tPrec@1 68.750 (68.379)\tPrec@5 81.250 (89.295)\n",
      "Epoch: [2][200/1515]\t\\Time 0.539 (0.532)\tData 0.439 (0.430)\tLoss 1.0155 (1.2595)\tPrec@1 75.000 (69.590)\tPrec@5 93.750 (88.713)\n",
      "Epoch: [2][300/1515]\t\\Time 0.540 (0.533)\tData 0.470 (0.431)\tLoss 0.6822 (1.2827)\tPrec@1 93.750 (68.833)\tPrec@5 100.000 (87.978)\n",
      "Epoch: [2][400/1515]\t\\Time 0.561 (0.534)\tData 0.451 (0.431)\tLoss 1.4707 (1.3147)\tPrec@1 62.500 (68.204)\tPrec@5 87.500 (87.484)\n",
      "Epoch: [2][500/1515]\t\\Time 0.548 (0.535)\tData 0.478 (0.432)\tLoss 1.4254 (1.3336)\tPrec@1 68.750 (67.702)\tPrec@5 87.500 (87.126)\n",
      "Epoch: [2][600/1515]\t\\Time 0.531 (0.536)\tData 0.460 (0.433)\tLoss 1.3925 (1.3379)\tPrec@1 68.750 (67.388)\tPrec@5 87.500 (87.178)\n",
      "Epoch: [2][700/1515]\t\\Time 0.550 (0.539)\tData 0.432 (0.435)\tLoss 1.2782 (1.3394)\tPrec@1 62.500 (67.323)\tPrec@5 93.750 (87.259)\n",
      "Epoch: [2][800/1515]\t\\Time 0.501 (0.538)\tData 0.401 (0.435)\tLoss 1.8497 (1.3397)\tPrec@1 50.000 (67.455)\tPrec@5 75.000 (87.235)\n",
      "Epoch: [2][900/1515]\t\\Time 0.491 (0.538)\tData 0.411 (0.435)\tLoss 1.7824 (1.3323)\tPrec@1 43.750 (67.342)\tPrec@5 87.500 (87.451)\n",
      "Epoch: [2][1000/1515]\t\\Time 0.560 (0.538)\tData 0.440 (0.434)\tLoss 1.7611 (1.3356)\tPrec@1 62.500 (67.308)\tPrec@5 75.000 (87.350)\n",
      "Epoch: [2][1100/1515]\t\\Time 0.490 (0.537)\tData 0.390 (0.434)\tLoss 0.5429 (1.3382)\tPrec@1 87.500 (67.274)\tPrec@5 100.000 (87.296)\n",
      "Epoch: [2][1200/1515]\t\\Time 0.551 (0.537)\tData 0.480 (0.434)\tLoss 1.1349 (1.3315)\tPrec@1 75.000 (67.387)\tPrec@5 93.750 (87.391)\n",
      "Epoch: [2][1300/1515]\t\\Time 0.610 (0.537)\tData 0.490 (0.434)\tLoss 0.9107 (1.3296)\tPrec@1 75.000 (67.419)\tPrec@5 93.750 (87.471)\n",
      "Epoch: [2][1400/1515]\t\\Time 0.560 (0.537)\tData 0.490 (0.434)\tLoss 1.8221 (1.3298)\tPrec@1 75.000 (67.501)\tPrec@5 81.250 (87.433)\n",
      "Epoch: [2][1500/1515]\t\\Time 0.541 (0.538)\tData 0.431 (0.434)\tLoss 1.1294 (1.3210)\tPrec@1 68.750 (67.676)\tPrec@5 87.500 (87.571)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.471 (0.471)\n",
      "\n",
      "Loss 0.5509 (0.5509)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 100.000\n",
      " * Prec@1 71.875 Prec@5 96.875\n",
      " * Prec@1 72.917 Prec@5 95.833\n",
      " * Prec@1 67.188 Prec@5 93.750\n",
      " * Prec@1 67.500 Prec@5 93.750\n",
      " * Prec@1 63.542 Prec@5 92.708\n",
      " * Prec@1 62.500 Prec@5 91.071\n",
      " * Prec@1 64.062 Prec@5 91.406\n",
      " * Prec@1 64.583 Prec@5 90.278\n",
      " * Prec@1 63.750 Prec@5 88.750\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.511 (0.545)\n",
      "\n",
      "Loss 0.7547 (1.3675)\n",
      "\n",
      "Prec@1 62.500 (63.636)\n",
      "\n",
      "Prec@5 100.000 (89.773)\n",
      "\n",
      " * Prec@1 63.636 Prec@5 89.773\n",
      " * Prec@1 65.104 Prec@5 90.104\n",
      " * Prec@1 66.346 Prec@5 90.385\n",
      " * Prec@1 65.179 Prec@5 89.286\n",
      " * Prec@1 63.750 Prec@5 88.750\n",
      " * Prec@1 64.062 Prec@5 89.453\n",
      " * Prec@1 63.235 Prec@5 87.868\n",
      " * Prec@1 63.542 Prec@5 87.500\n",
      " * Prec@1 63.158 Prec@5 86.513\n",
      " * Prec@1 63.438 Prec@5 86.562\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.530 (0.528)\n",
      "\n",
      "Loss 1.1291 (1.5350)\n",
      "\n",
      "Prec@1 81.250 (64.286)\n",
      "\n",
      "Prec@5 87.500 (86.607)\n",
      "\n",
      " * Prec@1 64.286 Prec@5 86.607\n",
      " * Prec@1 63.636 Prec@5 86.364\n",
      " * Prec@1 63.587 Prec@5 86.413\n",
      " * Prec@1 63.802 Prec@5 86.979\n",
      " * Prec@1 64.250 Prec@5 87.250\n",
      " * Prec@1 64.904 Prec@5 87.740\n",
      " * Prec@1 64.815 Prec@5 87.731\n",
      " * Prec@1 64.286 Prec@5 87.054\n",
      " * Prec@1 64.655 Prec@5 87.069\n",
      " * Prec@1 64.375 Prec@5 86.667\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.551 (0.528)\n",
      "\n",
      "Loss 0.8205 (1.5024)\n",
      "\n",
      "Prec@1 81.250 (64.919)\n",
      "\n",
      "Prec@5 93.750 (86.895)\n",
      "\n",
      " * Prec@1 64.919 Prec@5 86.895\n",
      " * Prec@1 65.430 Prec@5 87.109\n",
      " * Prec@1 65.152 Prec@5 86.742\n",
      " * Prec@1 64.154 Prec@5 86.029\n",
      " * Prec@1 64.107 Prec@5 85.536\n",
      " * Prec@1 63.715 Prec@5 85.243\n",
      " * Prec@1 63.176 Prec@5 84.966\n",
      " * Prec@1 62.993 Prec@5 85.033\n",
      " * Prec@1 63.141 Prec@5 84.936\n",
      " * Prec@1 62.969 Prec@5 85.156\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.520 (0.532)\n",
      "\n",
      "Loss 1.3579 (1.6065)\n",
      "\n",
      "Prec@1 75.000 (63.262)\n",
      "\n",
      "Prec@5 81.250 (85.061)\n",
      "\n",
      " * Prec@1 63.262 Prec@5 85.061\n",
      " * Prec@1 63.095 Prec@5 84.821\n",
      " * Prec@1 63.517 Prec@5 85.029\n",
      " * Prec@1 63.352 Prec@5 84.659\n",
      " * Prec@1 63.333 Prec@5 84.583\n",
      " * Prec@1 63.043 Prec@5 84.375\n",
      " * Prec@1 63.298 Prec@5 84.441\n",
      " * Prec@1 62.891 Prec@5 84.115\n",
      " * Prec@1 62.628 Prec@5 83.929\n",
      " * Prec@1 62.375 Prec@5 84.000\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.494 (0.528)\n",
      "\n",
      "Loss 3.2158 (1.6771)\n",
      "\n",
      "Prec@1 43.750 (62.010)\n",
      "\n",
      "Prec@5 62.500 (83.578)\n",
      "\n",
      " * Prec@1 62.010 Prec@5 83.578\n",
      " * Prec@1 62.139 Prec@5 83.534\n",
      " * Prec@1 62.146 Prec@5 83.491\n",
      " * Prec@1 61.921 Prec@5 83.102\n",
      " * Prec@1 61.705 Prec@5 83.182\n",
      " * Prec@1 61.607 Prec@5 83.259\n",
      " * Prec@1 61.513 Prec@5 83.114\n",
      " * Prec@1 61.530 Prec@5 83.082\n",
      " * Prec@1 61.547 Prec@5 83.157\n",
      " * Prec@1 61.771 Prec@5 83.333\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.552 (0.532)\n",
      "\n",
      "Loss 1.9385 (1.6986)\n",
      "\n",
      "Prec@1 56.250 (61.680)\n",
      "\n",
      "Prec@5 75.000 (83.197)\n",
      "\n",
      " * Prec@1 61.680 Prec@5 83.197\n",
      " * Prec@1 61.794 Prec@5 83.367\n",
      " * Prec@1 61.806 Prec@5 83.135\n",
      " * Prec@1 61.719 Prec@5 83.105\n",
      " * Prec@1 61.827 Prec@5 83.077\n",
      " * Prec@1 62.121 Prec@5 83.239\n",
      " * Prec@1 62.034 Prec@5 83.302\n",
      " * Prec@1 62.040 Prec@5 83.180\n",
      " * Prec@1 62.138 Prec@5 83.243\n",
      " * Prec@1 62.054 Prec@5 83.125\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.491 (0.531)\n",
      "\n",
      "Loss 0.2616 (1.6631)\n",
      "\n",
      "Prec@1 93.750 (62.500)\n",
      "\n",
      "Prec@5 100.000 (83.363)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 83.363\n",
      " * Prec@1 62.587 Prec@5 83.594\n",
      " * Prec@1 62.414 Prec@5 83.562\n",
      " * Prec@1 62.584 Prec@5 83.615\n",
      " * Prec@1 62.583 Prec@5 83.583\n",
      " * Prec@1 62.664 Prec@5 83.553\n",
      " * Prec@1 62.744 Prec@5 83.685\n",
      " * Prec@1 62.821 Prec@5 83.654\n",
      " * Prec@1 62.816 Prec@5 83.703\n",
      " * Prec@1 62.812 Prec@5 83.672\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.480 (0.530)\n",
      "\n",
      "Loss 2.6742 (1.6544)\n",
      "\n",
      "Prec@1 56.250 (62.731)\n",
      "\n",
      "Prec@5 75.000 (83.565)\n",
      "\n",
      " * Prec@1 62.731 Prec@5 83.565\n",
      " * Prec@1 62.729 Prec@5 83.613\n",
      " * Prec@1 62.651 Prec@5 83.509\n",
      " * Prec@1 62.574 Prec@5 83.482\n",
      " * Prec@1 62.574 Prec@5 83.529\n",
      " * Prec@1 62.500 Prec@5 83.430\n",
      " * Prec@1 62.356 Prec@5 83.477\n",
      " * Prec@1 62.216 Prec@5 83.239\n",
      " * Prec@1 62.360 Prec@5 83.146\n",
      " * Prec@1 62.361 Prec@5 83.194\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.461 (0.528)\n",
      "\n",
      "Loss 0.8457 (1.6549)\n",
      "\n",
      "Prec@1 87.500 (62.637)\n",
      "\n",
      "Prec@5 87.500 (83.242)\n",
      "\n",
      " * Prec@1 62.637 Prec@5 83.242\n",
      " * Prec@1 62.636 Prec@5 83.288\n",
      " * Prec@1 62.970 Prec@5 83.401\n",
      " * Prec@1 63.165 Prec@5 83.444\n",
      " * Prec@1 63.224 Prec@5 83.553\n",
      " * Prec@1 63.086 Prec@5 83.398\n",
      " * Prec@1 63.144 Prec@5 83.312\n",
      " * Prec@1 62.946 Prec@5 83.163\n",
      " * Prec@1 62.942 Prec@5 83.144\n",
      " * Prec@1 63.125 Prec@5 83.188\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.602 (0.530)\n",
      "\n",
      "Loss 1.5070 (1.6417)\n",
      "\n",
      "Prec@1 68.750 (63.181)\n",
      "\n",
      "Prec@5 87.500 (83.230)\n",
      "\n",
      " * Prec@1 63.181 Prec@5 83.230\n",
      " * Prec@1 63.113 Prec@5 83.395\n",
      " * Prec@1 63.228 Prec@5 83.434\n",
      " * Prec@1 63.281 Prec@5 83.474\n",
      " * Prec@1 63.214 Prec@5 83.512\n",
      " * Prec@1 63.149 Prec@5 83.491\n",
      " * Prec@1 63.143 Prec@5 83.586\n",
      " * Prec@1 63.252 Prec@5 83.738\n",
      " * Prec@1 63.245 Prec@5 83.773\n",
      " * Prec@1 63.068 Prec@5 83.750\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.490 (0.529)\n",
      "\n",
      "Loss 2.3796 (1.6283)\n",
      "\n",
      "Prec@1 50.000 (62.950)\n",
      "\n",
      "Prec@5 68.750 (83.615)\n",
      "\n",
      " * Prec@1 62.950 Prec@5 83.615\n",
      " * Prec@1 62.891 Prec@5 83.538\n",
      " * Prec@1 62.942 Prec@5 83.518\n",
      " * Prec@1 62.939 Prec@5 83.553\n",
      " * Prec@1 63.098 Prec@5 83.641\n",
      " * Prec@1 62.985 Prec@5 83.675\n",
      " * Prec@1 62.981 Prec@5 83.494\n",
      " * Prec@1 62.765 Prec@5 83.316\n",
      " * Prec@1 62.815 Prec@5 83.403\n",
      " * Prec@1 62.760 Prec@5 83.438\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.511 (0.528)\n",
      "\n",
      "Loss 0.8911 (1.6177)\n",
      "\n",
      "Prec@1 81.250 (62.913)\n",
      "\n",
      "Prec@5 87.500 (83.471)\n",
      "\n",
      " * Prec@1 62.913 Prec@5 83.471\n",
      " * Prec@1 63.012 Prec@5 83.555\n",
      " * Prec@1 63.008 Prec@5 83.587\n",
      " * Prec@1 62.903 Prec@5 83.468\n",
      " * Prec@1 63.050 Prec@5 83.600\n",
      " * Prec@1 63.046 Prec@5 83.631\n",
      " * Prec@1 62.943 Prec@5 83.612\n",
      " * Prec@1 62.988 Prec@5 83.691\n",
      " * Prec@1 62.984 Prec@5 83.769\n",
      " * Prec@1 63.029 Prec@5 83.750\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.627 (0.528)\n",
      "\n",
      "Loss 1.3372 (1.5871)\n",
      "\n",
      "Prec@1 68.750 (63.073)\n",
      "\n",
      "Prec@5 93.750 (83.826)\n",
      "\n",
      " * Prec@1 63.073 Prec@5 83.826\n",
      " * Prec@1 63.163 Prec@5 83.854\n",
      " * Prec@1 63.252 Prec@5 83.929\n",
      " * Prec@1 63.246 Prec@5 83.909\n",
      " * Prec@1 63.148 Prec@5 83.750\n",
      " * Prec@1 63.051 Prec@5 83.686\n",
      " * Prec@1 63.093 Prec@5 83.714\n",
      " * Prec@1 62.998 Prec@5 83.650\n",
      " * Prec@1 63.085 Prec@5 83.678\n",
      " * Prec@1 63.125 Prec@5 83.616\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.551 (0.529)\n",
      "\n",
      "Loss 3.1361 (1.6083)\n",
      "\n",
      "Prec@1 37.500 (62.943)\n",
      "\n",
      "Prec@5 56.250 (83.422)\n",
      "\n",
      " * Prec@1 62.943 Prec@5 83.422\n",
      " * Prec@1 62.896 Prec@5 83.319\n",
      " * Prec@1 62.981 Prec@5 83.304\n",
      " * Prec@1 63.021 Prec@5 83.247\n",
      " * Prec@1 62.974 Prec@5 83.233\n",
      " * Prec@1 62.800 Prec@5 83.048\n",
      " * Prec@1 62.840 Prec@5 83.078\n",
      " * Prec@1 62.838 Prec@5 83.108\n",
      " * Prec@1 62.836 Prec@5 83.096\n",
      " * Prec@1 62.917 Prec@5 83.083\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.527 (0.532)\n",
      "\n",
      "Loss 1.7344 (1.6218)\n",
      "\n",
      "Prec@1 68.750 (62.955)\n",
      "\n",
      "Prec@5 75.000 (83.030)\n",
      "\n",
      " * Prec@1 62.955 Prec@5 83.030\n",
      " * Prec@1 63.199 Prec@5 83.141\n",
      " * Prec@1 63.317 Prec@5 83.129\n",
      " * Prec@1 63.393 Prec@5 83.157\n",
      " * Prec@1 63.589 Prec@5 83.226\n",
      " * Prec@1 63.502 Prec@5 83.093\n",
      " * Prec@1 63.575 Prec@5 83.041\n",
      " * Prec@1 63.726 Prec@5 83.070\n",
      " * Prec@1 63.679 Prec@5 82.940\n",
      " * Prec@1 63.633 Prec@5 82.891\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.530 (0.533)\n",
      "\n",
      "Loss 1.0236 (1.6011)\n",
      "\n",
      "Prec@1 75.000 (63.703)\n",
      "\n",
      "Prec@5 93.750 (82.958)\n",
      "\n",
      " * Prec@1 63.703 Prec@5 82.958\n",
      " * Prec@1 63.735 Prec@5 82.986\n",
      " * Prec@1 63.727 Prec@5 82.975\n",
      " * Prec@1 63.758 Prec@5 83.003\n",
      " * Prec@1 63.826 Prec@5 82.992\n",
      " * Prec@1 63.855 Prec@5 82.982\n",
      " * Prec@1 63.847 Prec@5 82.972\n",
      " * Prec@1 63.802 Prec@5 82.961\n",
      " * Prec@1 63.795 Prec@5 82.919\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1515]\t\\Time 0.600 (0.600)\tData 0.450 (0.450)\tLoss 0.7623 (0.7623)\tPrec@1 87.500 (87.500)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [3][100/1515]\t\\Time 0.511 (0.532)\tData 0.411 (0.428)\tLoss 0.9089 (0.6368)\tPrec@1 75.000 (83.045)\tPrec@5 93.750 (96.163)\n",
      "Epoch: [3][200/1515]\t\\Time 0.630 (0.532)\tData 0.521 (0.428)\tLoss 0.6244 (0.6159)\tPrec@1 81.250 (83.769)\tPrec@5 100.000 (96.331)\n",
      "Epoch: [3][300/1515]\t\\Time 0.580 (0.530)\tData 0.482 (0.428)\tLoss 0.5447 (0.6028)\tPrec@1 87.500 (84.468)\tPrec@5 93.750 (96.262)\n",
      "Epoch: [3][400/1515]\t\\Time 0.520 (0.533)\tData 0.420 (0.430)\tLoss 0.7404 (0.5994)\tPrec@1 87.500 (84.648)\tPrec@5 93.750 (96.431)\n",
      "Epoch: [3][500/1515]\t\\Time 0.491 (0.535)\tData 0.411 (0.433)\tLoss 0.7832 (0.6044)\tPrec@1 87.500 (84.319)\tPrec@5 87.500 (96.395)\n",
      "Epoch: [3][600/1515]\t\\Time 0.551 (0.538)\tData 0.432 (0.436)\tLoss 0.3971 (0.6009)\tPrec@1 93.750 (84.359)\tPrec@5 100.000 (96.360)\n",
      "Epoch: [3][700/1515]\t\\Time 0.565 (0.540)\tData 0.455 (0.438)\tLoss 0.6887 (0.6063)\tPrec@1 81.250 (84.192)\tPrec@5 100.000 (96.336)\n",
      "Epoch: [3][800/1515]\t\\Time 0.491 (0.542)\tData 0.421 (0.439)\tLoss 1.8144 (0.6215)\tPrec@1 62.500 (83.809)\tPrec@5 75.000 (96.130)\n",
      "Epoch: [3][900/1515]\t\\Time 0.443 (0.541)\tData 0.374 (0.439)\tLoss 0.9318 (0.6278)\tPrec@1 75.000 (83.602)\tPrec@5 87.500 (96.032)\n",
      "Epoch: [3][1000/1515]\t\\Time 0.510 (0.541)\tData 0.420 (0.438)\tLoss 0.9706 (0.6431)\tPrec@1 68.750 (83.192)\tPrec@5 87.500 (95.854)\n",
      "Epoch: [3][1100/1515]\t\\Time 0.540 (0.540)\tData 0.430 (0.437)\tLoss 0.7938 (0.6558)\tPrec@1 75.000 (82.936)\tPrec@5 100.000 (95.697)\n",
      "Epoch: [3][1200/1515]\t\\Time 0.500 (0.540)\tData 0.430 (0.437)\tLoss 0.4839 (0.6678)\tPrec@1 93.750 (82.645)\tPrec@5 100.000 (95.525)\n",
      "Epoch: [3][1300/1515]\t\\Time 0.480 (0.540)\tData 0.410 (0.437)\tLoss 0.5102 (0.6677)\tPrec@1 81.250 (82.576)\tPrec@5 100.000 (95.537)\n",
      "Epoch: [3][1400/1515]\t\\Time 0.551 (0.539)\tData 0.441 (0.436)\tLoss 0.7231 (0.6683)\tPrec@1 87.500 (82.562)\tPrec@5 87.500 (95.508)\n",
      "Epoch: [3][1500/1515]\t\\Time 0.593 (0.540)\tData 0.493 (0.437)\tLoss 0.8279 (0.6794)\tPrec@1 75.000 (82.337)\tPrec@5 93.750 (95.370)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.470 (0.470)\n",
      "\n",
      "Loss 0.6908 (0.6908)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 93.750\n",
      " * Prec@1 75.000 Prec@5 93.750\n",
      " * Prec@1 77.083 Prec@5 93.750\n",
      " * Prec@1 76.562 Prec@5 92.188\n",
      " * Prec@1 78.750 Prec@5 93.750\n",
      " * Prec@1 75.000 Prec@5 93.750\n",
      " * Prec@1 75.000 Prec@5 92.857\n",
      " * Prec@1 77.344 Prec@5 92.969\n",
      " * Prec@1 76.389 Prec@5 91.667\n",
      " * Prec@1 75.625 Prec@5 90.625\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.531 (0.548)\n",
      "\n",
      "Loss 1.3193 (1.1724)\n",
      "\n",
      "Prec@1 81.250 (76.136)\n",
      "\n",
      "Prec@5 87.500 (90.341)\n",
      "\n",
      " * Prec@1 76.136 Prec@5 90.341\n",
      " * Prec@1 77.083 Prec@5 91.146\n",
      " * Prec@1 77.885 Prec@5 91.827\n",
      " * Prec@1 76.339 Prec@5 91.071\n",
      " * Prec@1 75.417 Prec@5 90.417\n",
      " * Prec@1 75.781 Prec@5 90.625\n",
      " * Prec@1 74.632 Prec@5 88.603\n",
      " * Prec@1 73.958 Prec@5 87.847\n",
      " * Prec@1 73.684 Prec@5 87.171\n",
      " * Prec@1 74.062 Prec@5 87.500\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.518 (0.544)\n",
      "\n",
      "Loss 1.1677 (1.3027)\n",
      "\n",
      "Prec@1 81.250 (74.405)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 74.405 Prec@5 87.500\n",
      " * Prec@1 73.011 Prec@5 86.648\n",
      " * Prec@1 73.098 Prec@5 86.957\n",
      " * Prec@1 73.698 Prec@5 87.240\n",
      " * Prec@1 73.500 Prec@5 87.000\n",
      " * Prec@1 74.279 Prec@5 87.260\n",
      " * Prec@1 74.074 Prec@5 87.269\n",
      " * Prec@1 73.884 Prec@5 87.277\n",
      " * Prec@1 73.276 Prec@5 86.853\n",
      " * Prec@1 72.917 Prec@5 86.667\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.531 (0.543)\n",
      "\n",
      "Loss 0.6457 (1.2815)\n",
      "\n",
      "Prec@1 87.500 (73.387)\n",
      "\n",
      "Prec@5 93.750 (86.895)\n",
      "\n",
      " * Prec@1 73.387 Prec@5 86.895\n",
      " * Prec@1 73.828 Prec@5 87.109\n",
      " * Prec@1 73.485 Prec@5 86.932\n",
      " * Prec@1 73.162 Prec@5 86.581\n",
      " * Prec@1 72.679 Prec@5 86.250\n",
      " * Prec@1 72.396 Prec@5 86.111\n",
      " * Prec@1 71.959 Prec@5 85.642\n",
      " * Prec@1 72.039 Prec@5 86.020\n",
      " * Prec@1 71.955 Prec@5 85.737\n",
      " * Prec@1 71.875 Prec@5 85.781\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.540 (0.545)\n",
      "\n",
      "Loss 0.8951 (1.3470)\n",
      "\n",
      "Prec@1 87.500 (72.256)\n",
      "\n",
      "Prec@5 87.500 (85.823)\n",
      "\n",
      " * Prec@1 72.256 Prec@5 85.823\n",
      " * Prec@1 71.875 Prec@5 85.417\n",
      " * Prec@1 72.093 Prec@5 85.756\n",
      " * Prec@1 72.017 Prec@5 85.795\n",
      " * Prec@1 72.083 Prec@5 85.833\n",
      " * Prec@1 72.283 Prec@5 85.870\n",
      " * Prec@1 72.606 Prec@5 86.037\n",
      " * Prec@1 72.135 Prec@5 85.938\n",
      " * Prec@1 72.194 Prec@5 86.097\n",
      " * Prec@1 72.125 Prec@5 86.125\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.506 (0.544)\n",
      "\n",
      "Loss 2.3554 (1.3629)\n",
      "\n",
      "Prec@1 62.500 (71.936)\n",
      "\n",
      "Prec@5 68.750 (85.784)\n",
      "\n",
      " * Prec@1 71.936 Prec@5 85.784\n",
      " * Prec@1 71.995 Prec@5 85.938\n",
      " * Prec@1 72.052 Prec@5 86.203\n",
      " * Prec@1 71.991 Prec@5 86.111\n",
      " * Prec@1 71.818 Prec@5 86.250\n",
      " * Prec@1 71.875 Prec@5 86.272\n",
      " * Prec@1 72.039 Prec@5 86.404\n",
      " * Prec@1 72.091 Prec@5 86.315\n",
      " * Prec@1 72.034 Prec@5 86.123\n",
      " * Prec@1 71.979 Prec@5 86.354\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.555 (0.546)\n",
      "\n",
      "Loss 2.2373 (1.3701)\n",
      "\n",
      "Prec@1 56.250 (71.721)\n",
      "\n",
      "Prec@5 75.000 (86.168)\n",
      "\n",
      " * Prec@1 71.721 Prec@5 86.168\n",
      " * Prec@1 71.875 Prec@5 86.190\n",
      " * Prec@1 71.925 Prec@5 86.210\n",
      " * Prec@1 72.070 Prec@5 86.328\n",
      " * Prec@1 72.115 Prec@5 86.154\n",
      " * Prec@1 72.443 Prec@5 86.269\n",
      " * Prec@1 72.481 Prec@5 86.381\n",
      " * Prec@1 72.610 Prec@5 86.489\n",
      " * Prec@1 72.645 Prec@5 86.504\n",
      " * Prec@1 72.589 Prec@5 86.518\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.546 (0.545)\n",
      "\n",
      "Loss 0.5434 (1.3374)\n",
      "\n",
      "Prec@1 87.500 (72.799)\n",
      "\n",
      "Prec@5 93.750 (86.620)\n",
      "\n",
      " * Prec@1 72.799 Prec@5 86.620\n",
      " * Prec@1 73.003 Prec@5 86.719\n",
      " * Prec@1 73.031 Prec@5 86.729\n",
      " * Prec@1 73.226 Prec@5 86.824\n",
      " * Prec@1 73.333 Prec@5 86.750\n",
      " * Prec@1 73.438 Prec@5 86.760\n",
      " * Prec@1 73.539 Prec@5 86.932\n",
      " * Prec@1 73.558 Prec@5 86.939\n",
      " * Prec@1 73.497 Prec@5 86.788\n",
      " * Prec@1 73.359 Prec@5 86.719\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.504 (0.547)\n",
      "\n",
      "Loss 2.0326 (1.3389)\n",
      "\n",
      "Prec@1 68.750 (73.302)\n",
      "\n",
      "Prec@5 75.000 (86.574)\n",
      "\n",
      " * Prec@1 73.302 Prec@5 86.574\n",
      " * Prec@1 73.171 Prec@5 86.662\n",
      " * Prec@1 73.042 Prec@5 86.596\n",
      " * Prec@1 72.917 Prec@5 86.533\n",
      " * Prec@1 73.088 Prec@5 86.618\n",
      " * Prec@1 73.110 Prec@5 86.628\n",
      " * Prec@1 73.132 Prec@5 86.710\n",
      " * Prec@1 73.011 Prec@5 86.577\n",
      " * Prec@1 73.104 Prec@5 86.587\n",
      " * Prec@1 73.333 Prec@5 86.736\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.429 (0.543)\n",
      "\n",
      "Loss 0.1525 (1.3086)\n",
      "\n",
      "Prec@1 100.000 (73.626)\n",
      "\n",
      "Prec@5 100.000 (86.882)\n",
      "\n",
      " * Prec@1 73.626 Prec@5 86.882\n",
      " * Prec@1 73.777 Prec@5 86.957\n",
      " * Prec@1 73.925 Prec@5 87.030\n",
      " * Prec@1 73.936 Prec@5 87.035\n",
      " * Prec@1 73.947 Prec@5 87.105\n",
      " * Prec@1 73.763 Prec@5 86.979\n",
      " * Prec@1 73.776 Prec@5 86.985\n",
      " * Prec@1 73.724 Prec@5 86.862\n",
      " * Prec@1 73.674 Prec@5 86.932\n",
      " * Prec@1 73.812 Prec@5 87.062\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.543 (0.541)\n",
      "\n",
      "Loss 1.6330 (1.3079)\n",
      "\n",
      "Prec@1 62.500 (73.700)\n",
      "\n",
      "Prec@5 87.500 (87.067)\n",
      "\n",
      " * Prec@1 73.700 Prec@5 87.067\n",
      " * Prec@1 73.775 Prec@5 87.194\n",
      " * Prec@1 73.665 Prec@5 87.136\n",
      " * Prec@1 73.738 Prec@5 87.200\n",
      " * Prec@1 73.690 Prec@5 87.143\n",
      " * Prec@1 73.703 Prec@5 87.205\n",
      " * Prec@1 73.890 Prec@5 87.325\n",
      " * Prec@1 74.016 Prec@5 87.442\n",
      " * Prec@1 74.025 Prec@5 87.500\n",
      " * Prec@1 73.750 Prec@5 87.500\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.502 (0.540)\n",
      "\n",
      "Loss 1.4421 (1.2835)\n",
      "\n",
      "Prec@1 75.000 (73.761)\n",
      "\n",
      "Prec@5 81.250 (87.444)\n",
      "\n",
      " * Prec@1 73.761 Prec@5 87.444\n",
      " * Prec@1 73.605 Prec@5 87.444\n",
      " * Prec@1 73.507 Prec@5 87.445\n",
      " * Prec@1 73.520 Prec@5 87.390\n",
      " * Prec@1 73.533 Prec@5 87.446\n",
      " * Prec@1 73.653 Prec@5 87.446\n",
      " * Prec@1 73.611 Prec@5 87.447\n",
      " * Prec@1 73.517 Prec@5 87.341\n",
      " * Prec@1 73.424 Prec@5 87.395\n",
      " * Prec@1 73.438 Prec@5 87.396\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.531 (0.539)\n",
      "\n",
      "Loss 0.3313 (1.2785)\n",
      "\n",
      "Prec@1 87.500 (73.554)\n",
      "\n",
      "Prec@5 100.000 (87.500)\n",
      "\n",
      " * Prec@1 73.554 Prec@5 87.500\n",
      " * Prec@1 73.412 Prec@5 87.500\n",
      " * Prec@1 73.526 Prec@5 87.602\n",
      " * Prec@1 73.538 Prec@5 87.651\n",
      " * Prec@1 73.550 Prec@5 87.700\n",
      " * Prec@1 73.462 Prec@5 87.698\n",
      " * Prec@1 73.425 Prec@5 87.648\n",
      " * Prec@1 73.535 Prec@5 87.646\n",
      " * Prec@1 73.498 Prec@5 87.645\n",
      " * Prec@1 73.510 Prec@5 87.644\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.594 (0.538)\n",
      "\n",
      "Loss 1.3821 (1.2647)\n",
      "\n",
      "Prec@1 68.750 (73.473)\n",
      "\n",
      "Prec@5 93.750 (87.691)\n",
      "\n",
      " * Prec@1 73.473 Prec@5 87.691\n",
      " * Prec@1 73.485 Prec@5 87.689\n",
      " * Prec@1 73.496 Prec@5 87.735\n",
      " * Prec@1 73.461 Prec@5 87.733\n",
      " * Prec@1 73.472 Prec@5 87.731\n",
      " * Prec@1 73.346 Prec@5 87.638\n",
      " * Prec@1 73.312 Prec@5 87.591\n",
      " * Prec@1 73.279 Prec@5 87.545\n",
      " * Prec@1 73.381 Prec@5 87.590\n",
      " * Prec@1 73.259 Prec@5 87.500\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.553 (0.539)\n",
      "\n",
      "Loss 1.3629 (1.2785)\n",
      "\n",
      "Prec@1 75.000 (73.271)\n",
      "\n",
      "Prec@5 81.250 (87.456)\n",
      "\n",
      " * Prec@1 73.271 Prec@5 87.456\n",
      " * Prec@1 73.195 Prec@5 87.324\n",
      " * Prec@1 73.208 Prec@5 87.281\n",
      " * Prec@1 73.177 Prec@5 87.326\n",
      " * Prec@1 73.103 Prec@5 87.371\n",
      " * Prec@1 72.988 Prec@5 87.158\n",
      " * Prec@1 72.874 Prec@5 87.117\n",
      " * Prec@1 72.846 Prec@5 87.078\n",
      " * Prec@1 72.819 Prec@5 86.997\n",
      " * Prec@1 72.875 Prec@5 87.000\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.551 (0.541)\n",
      "\n",
      "Loss 1.4299 (1.3186)\n",
      "\n",
      "Prec@1 75.000 (72.889)\n",
      "\n",
      "Prec@5 81.250 (86.962)\n",
      "\n",
      " * Prec@1 72.889 Prec@5 86.962\n",
      " * Prec@1 73.026 Prec@5 87.048\n",
      " * Prec@1 72.998 Prec@5 87.132\n",
      " * Prec@1 73.133 Prec@5 87.216\n",
      " * Prec@1 73.266 Prec@5 87.298\n",
      " * Prec@1 73.157 Prec@5 87.220\n",
      " * Prec@1 73.049 Prec@5 87.102\n",
      " * Prec@1 73.180 Prec@5 87.144\n",
      " * Prec@1 73.192 Prec@5 87.107\n",
      " * Prec@1 73.203 Prec@5 87.109\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.555 (0.542)\n",
      "\n",
      "Loss 0.7259 (1.2950)\n",
      "\n",
      "Prec@1 81.250 (73.253)\n",
      "\n",
      "Prec@5 93.750 (87.151)\n",
      "\n",
      " * Prec@1 73.253 Prec@5 87.151\n",
      " * Prec@1 73.302 Prec@5 87.191\n",
      " * Prec@1 73.275 Prec@5 87.155\n",
      " * Prec@1 73.399 Prec@5 87.195\n",
      " * Prec@1 73.447 Prec@5 87.235\n",
      " * Prec@1 73.494 Prec@5 87.199\n",
      " * Prec@1 73.428 Prec@5 87.163\n",
      " * Prec@1 73.363 Prec@5 87.165\n",
      " * Prec@1 73.301 Prec@5 87.152\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1515]\t\\Time 0.558 (0.558)\tData 0.440 (0.440)\tLoss 0.2880 (0.2880)\tPrec@1 93.750 (93.750)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [4][100/1515]\t\\Time 0.544 (0.529)\tData 0.436 (0.429)\tLoss 0.0816 (0.3125)\tPrec@1 100.000 (90.965)\tPrec@5 100.000 (99.010)\n",
      "Epoch: [4][200/1515]\t\\Time 0.581 (0.533)\tData 0.458 (0.430)\tLoss 0.2209 (0.3067)\tPrec@1 93.750 (91.947)\tPrec@5 100.000 (99.005)\n",
      "Epoch: [4][300/1515]\t\\Time 0.540 (0.535)\tData 0.438 (0.432)\tLoss 0.1733 (0.3000)\tPrec@1 93.750 (92.255)\tPrec@5 100.000 (98.941)\n",
      "Epoch: [4][400/1515]\t\\Time 0.551 (0.536)\tData 0.439 (0.432)\tLoss 0.2261 (0.2804)\tPrec@1 93.750 (92.565)\tPrec@5 100.000 (99.096)\n",
      "Epoch: [4][500/1515]\t\\Time 0.504 (0.536)\tData 0.429 (0.433)\tLoss 0.4840 (0.2767)\tPrec@1 81.250 (92.727)\tPrec@5 100.000 (99.127)\n",
      "Epoch: [4][600/1515]\t\\Time 0.481 (0.535)\tData 0.411 (0.433)\tLoss 0.0610 (0.2709)\tPrec@1 100.000 (92.814)\tPrec@5 100.000 (99.137)\n",
      "Epoch: [4][700/1515]\t\\Time 0.557 (0.537)\tData 0.451 (0.434)\tLoss 0.2259 (0.2712)\tPrec@1 93.750 (92.841)\tPrec@5 100.000 (99.153)\n",
      "Epoch: [4][800/1515]\t\\Time 0.551 (0.537)\tData 0.441 (0.435)\tLoss 0.4180 (0.2696)\tPrec@1 93.750 (92.970)\tPrec@5 100.000 (99.173)\n",
      "Epoch: [4][900/1515]\t\\Time 0.585 (0.540)\tData 0.476 (0.437)\tLoss 0.5908 (0.2707)\tPrec@1 81.250 (92.952)\tPrec@5 100.000 (99.161)\n",
      "Epoch: [4][1000/1515]\t\\Time 0.503 (0.541)\tData 0.403 (0.438)\tLoss 0.8037 (0.2793)\tPrec@1 81.250 (92.757)\tPrec@5 100.000 (99.107)\n",
      "Epoch: [4][1100/1515]\t\\Time 0.471 (0.542)\tData 0.401 (0.439)\tLoss 0.1102 (0.2785)\tPrec@1 100.000 (92.751)\tPrec@5 100.000 (99.092)\n",
      "Epoch: [4][1200/1515]\t\\Time 0.553 (0.543)\tData 0.447 (0.439)\tLoss 0.7075 (0.2832)\tPrec@1 68.750 (92.595)\tPrec@5 93.750 (99.022)\n",
      "Epoch: [4][1300/1515]\t\\Time 0.492 (0.542)\tData 0.422 (0.439)\tLoss 0.1980 (0.2855)\tPrec@1 93.750 (92.482)\tPrec@5 100.000 (99.020)\n",
      "Epoch: [4][1400/1515]\t\\Time 0.551 (0.543)\tData 0.431 (0.439)\tLoss 0.2947 (0.2884)\tPrec@1 93.750 (92.372)\tPrec@5 100.000 (98.996)\n",
      "Epoch: [4][1500/1515]\t\\Time 0.527 (0.542)\tData 0.449 (0.439)\tLoss 0.2216 (0.2939)\tPrec@1 93.750 (92.259)\tPrec@5 100.000 (98.955)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.480 (0.480)\n",
      "\n",
      "Loss 0.2227 (0.2227)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 100.000\n",
      " * Prec@1 93.750 Prec@5 96.875\n",
      " * Prec@1 93.750 Prec@5 95.833\n",
      " * Prec@1 92.188 Prec@5 95.312\n",
      " * Prec@1 91.250 Prec@5 96.250\n",
      " * Prec@1 86.458 Prec@5 94.792\n",
      " * Prec@1 83.036 Prec@5 92.857\n",
      " * Prec@1 83.594 Prec@5 93.750\n",
      " * Prec@1 82.639 Prec@5 91.667\n",
      " * Prec@1 81.875 Prec@5 90.625\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.544 (0.546)\n",
      "\n",
      "Loss 0.4373 (0.9492)\n",
      "\n",
      "Prec@1 81.250 (81.818)\n",
      "\n",
      "Prec@5 93.750 (90.909)\n",
      "\n",
      " * Prec@1 81.818 Prec@5 90.909\n",
      " * Prec@1 80.729 Prec@5 91.146\n",
      " * Prec@1 81.250 Prec@5 91.346\n",
      " * Prec@1 81.250 Prec@5 90.625\n",
      " * Prec@1 81.250 Prec@5 90.000\n",
      " * Prec@1 80.469 Prec@5 90.234\n",
      " * Prec@1 79.412 Prec@5 88.971\n",
      " * Prec@1 78.125 Prec@5 88.194\n",
      " * Prec@1 77.632 Prec@5 87.829\n",
      " * Prec@1 77.812 Prec@5 87.500\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.735 (0.550)\n",
      "\n",
      "Loss 1.3286 (1.2192)\n",
      "\n",
      "Prec@1 81.250 (77.976)\n",
      "\n",
      "Prec@5 93.750 (87.798)\n",
      "\n",
      " * Prec@1 77.976 Prec@5 87.798\n",
      " * Prec@1 77.841 Prec@5 87.216\n",
      " * Prec@1 77.446 Prec@5 87.228\n",
      " * Prec@1 77.344 Prec@5 87.240\n",
      " * Prec@1 77.750 Prec@5 87.500\n",
      " * Prec@1 78.125 Prec@5 87.740\n",
      " * Prec@1 78.241 Prec@5 87.963\n",
      " * Prec@1 77.902 Prec@5 87.946\n",
      " * Prec@1 78.017 Prec@5 87.931\n",
      " * Prec@1 77.500 Prec@5 87.708\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.552 (0.564)\n",
      "\n",
      "Loss 0.8491 (1.2208)\n",
      "\n",
      "Prec@1 81.250 (77.621)\n",
      "\n",
      "Prec@5 93.750 (87.903)\n",
      "\n",
      " * Prec@1 77.621 Prec@5 87.903\n",
      " * Prec@1 77.930 Prec@5 88.086\n",
      " * Prec@1 77.841 Prec@5 87.879\n",
      " * Prec@1 77.206 Prec@5 87.132\n",
      " * Prec@1 76.964 Prec@5 87.143\n",
      " * Prec@1 76.910 Prec@5 86.979\n",
      " * Prec@1 77.027 Prec@5 87.162\n",
      " * Prec@1 76.645 Prec@5 87.500\n",
      " * Prec@1 76.442 Prec@5 87.500\n",
      " * Prec@1 76.094 Prec@5 87.812\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.525 (0.564)\n",
      "\n",
      "Loss 1.3853 (1.2891)\n",
      "\n",
      "Prec@1 75.000 (76.067)\n",
      "\n",
      "Prec@5 87.500 (87.805)\n",
      "\n",
      " * Prec@1 76.067 Prec@5 87.805\n",
      " * Prec@1 75.744 Prec@5 87.500\n",
      " * Prec@1 75.872 Prec@5 87.791\n",
      " * Prec@1 76.136 Prec@5 87.926\n",
      " * Prec@1 76.111 Prec@5 87.917\n",
      " * Prec@1 76.087 Prec@5 87.908\n",
      " * Prec@1 76.330 Prec@5 88.032\n",
      " * Prec@1 76.172 Prec@5 88.021\n",
      " * Prec@1 76.148 Prec@5 88.138\n",
      " * Prec@1 76.125 Prec@5 88.125\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.558 (0.564)\n",
      "\n",
      "Loss 1.9163 (1.2807)\n",
      "\n",
      "Prec@1 62.500 (75.858)\n",
      "\n",
      "Prec@5 75.000 (87.868)\n",
      "\n",
      " * Prec@1 75.858 Prec@5 87.868\n",
      " * Prec@1 75.721 Prec@5 87.861\n",
      " * Prec@1 75.943 Prec@5 87.972\n",
      " * Prec@1 75.926 Prec@5 87.847\n",
      " * Prec@1 75.682 Prec@5 87.614\n",
      " * Prec@1 75.781 Prec@5 87.723\n",
      " * Prec@1 75.877 Prec@5 87.719\n",
      " * Prec@1 75.970 Prec@5 87.823\n",
      " * Prec@1 75.530 Prec@5 87.500\n",
      " * Prec@1 75.625 Prec@5 87.708\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.643 (0.574)\n",
      "\n",
      "Loss 2.3769 (1.3009)\n",
      "\n",
      "Prec@1 56.250 (75.307)\n",
      "\n",
      "Prec@5 75.000 (87.500)\n",
      "\n",
      " * Prec@1 75.307 Prec@5 87.500\n",
      " * Prec@1 75.403 Prec@5 87.399\n",
      " * Prec@1 75.397 Prec@5 87.401\n",
      " * Prec@1 75.195 Prec@5 87.402\n",
      " * Prec@1 75.000 Prec@5 87.212\n",
      " * Prec@1 75.189 Prec@5 87.216\n",
      " * Prec@1 75.466 Prec@5 87.313\n",
      " * Prec@1 75.368 Prec@5 87.316\n",
      " * Prec@1 75.362 Prec@5 87.228\n",
      " * Prec@1 75.268 Prec@5 87.232\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.523 (0.583)\n",
      "\n",
      "Loss 0.4616 (1.3161)\n",
      "\n",
      "Prec@1 87.500 (75.440)\n",
      "\n",
      "Prec@5 100.000 (87.412)\n",
      "\n",
      " * Prec@1 75.440 Prec@5 87.412\n",
      " * Prec@1 75.434 Prec@5 87.413\n",
      " * Prec@1 75.428 Prec@5 87.500\n",
      " * Prec@1 75.507 Prec@5 87.584\n",
      " * Prec@1 75.667 Prec@5 87.583\n",
      " * Prec@1 75.740 Prec@5 87.500\n",
      " * Prec@1 75.812 Prec@5 87.581\n",
      " * Prec@1 75.881 Prec@5 87.580\n",
      " * Prec@1 75.712 Prec@5 87.500\n",
      " * Prec@1 75.625 Prec@5 87.422\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.499 (0.582)\n",
      "\n",
      "Loss 2.2297 (1.3308)\n",
      "\n",
      "Prec@1 62.500 (75.463)\n",
      "\n",
      "Prec@5 81.250 (87.346)\n",
      "\n",
      " * Prec@1 75.463 Prec@5 87.346\n",
      " * Prec@1 75.686 Prec@5 87.424\n",
      " * Prec@1 75.678 Prec@5 87.274\n",
      " * Prec@1 75.670 Prec@5 87.351\n",
      " * Prec@1 75.662 Prec@5 87.279\n",
      " * Prec@1 75.727 Prec@5 87.282\n",
      " * Prec@1 75.934 Prec@5 87.356\n",
      " * Prec@1 75.852 Prec@5 87.287\n",
      " * Prec@1 75.913 Prec@5 87.360\n",
      " * Prec@1 76.042 Prec@5 87.361\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.450 (0.573)\n",
      "\n",
      "Loss 0.1383 (1.2974)\n",
      "\n",
      "Prec@1 100.000 (76.305)\n",
      "\n",
      "Prec@5 100.000 (87.500)\n",
      "\n",
      " * Prec@1 76.305 Prec@5 87.500\n",
      " * Prec@1 76.427 Prec@5 87.568\n",
      " * Prec@1 76.546 Prec@5 87.634\n",
      " * Prec@1 76.662 Prec@5 87.633\n",
      " * Prec@1 76.579 Prec@5 87.566\n",
      " * Prec@1 76.432 Prec@5 87.435\n",
      " * Prec@1 76.418 Prec@5 87.371\n",
      " * Prec@1 76.339 Prec@5 87.181\n",
      " * Prec@1 76.263 Prec@5 87.184\n",
      " * Prec@1 76.312 Prec@5 87.312\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.536 (0.570)\n",
      "\n",
      "Loss 1.1418 (1.2926)\n",
      "\n",
      "Prec@1 75.000 (76.300)\n",
      "\n",
      "Prec@5 93.750 (87.376)\n",
      "\n",
      " * Prec@1 76.300 Prec@5 87.376\n",
      " * Prec@1 76.409 Prec@5 87.377\n",
      " * Prec@1 76.456 Prec@5 87.439\n",
      " * Prec@1 76.502 Prec@5 87.440\n",
      " * Prec@1 76.548 Prec@5 87.440\n",
      " * Prec@1 76.592 Prec@5 87.559\n",
      " * Prec@1 76.752 Prec@5 87.675\n",
      " * Prec@1 76.910 Prec@5 87.789\n",
      " * Prec@1 76.950 Prec@5 87.901\n",
      " * Prec@1 76.932 Prec@5 87.955\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.496 (0.565)\n",
      "\n",
      "Loss 1.8987 (1.2527)\n",
      "\n",
      "Prec@1 81.250 (76.971)\n",
      "\n",
      "Prec@5 87.500 (87.950)\n",
      "\n",
      " * Prec@1 76.971 Prec@5 87.950\n",
      " * Prec@1 76.897 Prec@5 87.891\n",
      " * Prec@1 76.881 Prec@5 87.887\n",
      " * Prec@1 76.919 Prec@5 87.884\n",
      " * Prec@1 76.957 Prec@5 87.880\n",
      " * Prec@1 76.994 Prec@5 87.931\n",
      " * Prec@1 76.870 Prec@5 87.874\n",
      " * Prec@1 76.801 Prec@5 87.871\n",
      " * Prec@1 76.943 Prec@5 87.973\n",
      " * Prec@1 76.927 Prec@5 87.969\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.557 (0.564)\n",
      "\n",
      "Loss 0.0967 (1.2375)\n",
      "\n",
      "Prec@1 93.750 (77.066)\n",
      "\n",
      "Prec@5 100.000 (88.068)\n",
      "\n",
      " * Prec@1 77.066 Prec@5 88.068\n",
      " * Prec@1 76.998 Prec@5 88.012\n",
      " * Prec@1 77.083 Prec@5 88.059\n",
      " * Prec@1 77.117 Prec@5 88.004\n",
      " * Prec@1 77.200 Prec@5 88.050\n",
      " * Prec@1 77.282 Prec@5 88.145\n",
      " * Prec@1 77.264 Prec@5 88.189\n",
      " * Prec@1 77.295 Prec@5 88.232\n",
      " * Prec@1 77.374 Prec@5 88.275\n",
      " * Prec@1 77.356 Prec@5 88.269\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.555 (0.562)\n",
      "\n",
      "Loss 0.8484 (1.2099)\n",
      "\n",
      "Prec@1 68.750 (77.290)\n",
      "\n",
      "Prec@5 93.750 (88.311)\n",
      "\n",
      " * Prec@1 77.290 Prec@5 88.311\n",
      " * Prec@1 77.273 Prec@5 88.352\n",
      " * Prec@1 77.350 Prec@5 88.440\n",
      " * Prec@1 77.146 Prec@5 88.386\n",
      " * Prec@1 77.130 Prec@5 88.472\n",
      " * Prec@1 77.022 Prec@5 88.373\n",
      " * Prec@1 77.007 Prec@5 88.321\n",
      " * Prec@1 77.038 Prec@5 88.315\n",
      " * Prec@1 77.113 Prec@5 88.354\n",
      " * Prec@1 77.009 Prec@5 88.259\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.535 (0.559)\n",
      "\n",
      "Loss 1.9062 (1.2295)\n",
      "\n",
      "Prec@1 68.750 (76.950)\n",
      "\n",
      "Prec@5 81.250 (88.209)\n",
      "\n",
      " * Prec@1 76.950 Prec@5 88.209\n",
      " * Prec@1 76.849 Prec@5 88.072\n",
      " * Prec@1 76.748 Prec@5 88.068\n",
      " * Prec@1 76.736 Prec@5 88.108\n",
      " * Prec@1 76.810 Prec@5 88.147\n",
      " * Prec@1 76.627 Prec@5 87.928\n",
      " * Prec@1 76.573 Prec@5 87.925\n",
      " * Prec@1 76.562 Prec@5 87.880\n",
      " * Prec@1 76.552 Prec@5 87.794\n",
      " * Prec@1 76.542 Prec@5 87.833\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.561 (0.559)\n",
      "\n",
      "Loss 1.9047 (1.2716)\n",
      "\n",
      "Prec@1 75.000 (76.531)\n",
      "\n",
      "Prec@5 75.000 (87.748)\n",
      "\n",
      " * Prec@1 76.531 Prec@5 87.748\n",
      " * Prec@1 76.645 Prec@5 87.829\n",
      " * Prec@1 76.675 Prec@5 87.908\n",
      " * Prec@1 76.745 Prec@5 87.946\n",
      " * Prec@1 76.855 Prec@5 88.024\n",
      " * Prec@1 76.803 Prec@5 87.941\n",
      " * Prec@1 76.672 Prec@5 87.898\n",
      " * Prec@1 76.701 Prec@5 87.935\n",
      " * Prec@1 76.730 Prec@5 87.932\n",
      " * Prec@1 76.719 Prec@5 87.930\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.547 (0.560)\n",
      "\n",
      "Loss 0.9002 (1.2523)\n",
      "\n",
      "Prec@1 75.000 (76.708)\n",
      "\n",
      "Prec@5 93.750 (87.966)\n",
      "\n",
      " * Prec@1 76.708 Prec@5 87.966\n",
      " * Prec@1 76.813 Prec@5 88.002\n",
      " * Prec@1 76.802 Prec@5 87.922\n",
      " * Prec@1 76.867 Prec@5 87.957\n",
      " * Prec@1 76.894 Prec@5 87.992\n",
      " * Prec@1 76.958 Prec@5 88.027\n",
      " * Prec@1 76.909 Prec@5 88.024\n",
      " * Prec@1 76.897 Prec@5 87.946\n",
      " * Prec@1 76.866 Prec@5 87.895\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1515]\t\\Time 0.578 (0.578)\tData 0.427 (0.427)\tLoss 0.1754 (0.1754)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [5][100/1515]\t\\Time 0.507 (0.543)\tData 0.396 (0.438)\tLoss 0.0687 (0.1325)\tPrec@1 100.000 (96.535)\tPrec@5 100.000 (99.691)\n",
      "Epoch: [5][200/1515]\t\\Time 0.525 (0.551)\tData 0.419 (0.446)\tLoss 0.6124 (0.1109)\tPrec@1 93.750 (97.295)\tPrec@5 93.750 (99.813)\n",
      "Epoch: [5][300/1515]\t\\Time 0.529 (0.552)\tData 0.425 (0.447)\tLoss 0.5826 (0.1090)\tPrec@1 93.750 (97.280)\tPrec@5 93.750 (99.813)\n",
      "Epoch: [5][400/1515]\t\\Time 0.490 (0.555)\tData 0.411 (0.451)\tLoss 0.0363 (0.1054)\tPrec@1 100.000 (97.397)\tPrec@5 100.000 (99.844)\n",
      "Epoch: [5][500/1515]\t\\Time 0.554 (0.554)\tData 0.444 (0.450)\tLoss 0.1174 (0.1048)\tPrec@1 93.750 (97.505)\tPrec@5 100.000 (99.813)\n",
      "Epoch: [5][600/1515]\t\\Time 0.569 (0.555)\tData 0.453 (0.451)\tLoss 0.0122 (0.1034)\tPrec@1 100.000 (97.598)\tPrec@5 100.000 (99.802)\n",
      "Epoch: [5][700/1515]\t\\Time 0.574 (0.554)\tData 0.456 (0.450)\tLoss 0.0260 (0.1065)\tPrec@1 100.000 (97.468)\tPrec@5 100.000 (99.813)\n",
      "Epoch: [5][800/1515]\t\\Time 0.500 (0.554)\tData 0.429 (0.450)\tLoss 0.0190 (0.1060)\tPrec@1 100.000 (97.503)\tPrec@5 100.000 (99.821)\n",
      "Epoch: [5][900/1515]\t\\Time 0.644 (0.553)\tData 0.531 (0.449)\tLoss 0.2693 (0.1061)\tPrec@1 93.750 (97.475)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [5][1000/1515]\t\\Time 0.627 (0.554)\tData 0.512 (0.449)\tLoss 0.2044 (0.1075)\tPrec@1 87.500 (97.415)\tPrec@5 100.000 (99.825)\n",
      "Epoch: [5][1100/1515]\t\\Time 0.520 (0.552)\tData 0.419 (0.448)\tLoss 0.0210 (0.1075)\tPrec@1 100.000 (97.468)\tPrec@5 100.000 (99.830)\n",
      "Epoch: [5][1200/1515]\t\\Time 0.610 (0.551)\tData 0.491 (0.447)\tLoss 0.1009 (0.1075)\tPrec@1 93.750 (97.466)\tPrec@5 100.000 (99.833)\n",
      "Epoch: [5][1300/1515]\t\\Time 0.584 (0.552)\tData 0.474 (0.448)\tLoss 0.0516 (0.1074)\tPrec@1 100.000 (97.492)\tPrec@5 100.000 (99.837)\n",
      "Epoch: [5][1400/1515]\t\\Time 0.473 (0.551)\tData 0.376 (0.447)\tLoss 0.0454 (0.1071)\tPrec@1 100.000 (97.515)\tPrec@5 100.000 (99.835)\n",
      "Epoch: [5][1500/1515]\t\\Time 0.618 (0.551)\tData 0.501 (0.446)\tLoss 0.0194 (0.1053)\tPrec@1 100.000 (97.535)\tPrec@5 100.000 (99.846)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.467 (0.467)\n",
      "\n",
      "Loss 0.6818 (0.6818)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 93.750\n",
      " * Prec@1 81.250 Prec@5 93.750\n",
      " * Prec@1 85.417 Prec@5 93.750\n",
      " * Prec@1 85.938 Prec@5 92.188\n",
      " * Prec@1 88.750 Prec@5 93.750\n",
      " * Prec@1 86.458 Prec@5 91.667\n",
      " * Prec@1 85.714 Prec@5 91.071\n",
      " * Prec@1 85.938 Prec@5 92.188\n",
      " * Prec@1 85.417 Prec@5 91.667\n",
      " * Prec@1 85.000 Prec@5 90.625\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.507 (0.508)\n",
      "\n",
      "Loss 0.4653 (0.9230)\n",
      "\n",
      "Prec@1 87.500 (85.227)\n",
      "\n",
      "Prec@5 100.000 (91.477)\n",
      "\n",
      " * Prec@1 85.227 Prec@5 91.477\n",
      " * Prec@1 85.417 Prec@5 92.188\n",
      " * Prec@1 86.058 Prec@5 92.308\n",
      " * Prec@1 85.268 Prec@5 91.518\n",
      " * Prec@1 85.000 Prec@5 90.833\n",
      " * Prec@1 84.766 Prec@5 91.406\n",
      " * Prec@1 83.456 Prec@5 90.074\n",
      " * Prec@1 81.944 Prec@5 89.236\n",
      " * Prec@1 81.250 Prec@5 88.487\n",
      " * Prec@1 81.562 Prec@5 88.750\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.536 (0.517)\n",
      "\n",
      "Loss 0.8681 (1.1158)\n",
      "\n",
      "Prec@1 93.750 (82.143)\n",
      "\n",
      "Prec@5 93.750 (88.988)\n",
      "\n",
      " * Prec@1 82.143 Prec@5 88.988\n",
      " * Prec@1 81.534 Prec@5 88.636\n",
      " * Prec@1 81.250 Prec@5 89.130\n",
      " * Prec@1 80.729 Prec@5 89.323\n",
      " * Prec@1 80.500 Prec@5 89.250\n",
      " * Prec@1 81.010 Prec@5 89.423\n",
      " * Prec@1 81.481 Prec@5 89.815\n",
      " * Prec@1 81.250 Prec@5 89.732\n",
      " * Prec@1 81.034 Prec@5 89.871\n",
      " * Prec@1 80.833 Prec@5 89.792\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.529 (0.519)\n",
      "\n",
      "Loss 0.7287 (1.0693)\n",
      "\n",
      "Prec@1 87.500 (81.048)\n",
      "\n",
      "Prec@5 93.750 (89.919)\n",
      "\n",
      " * Prec@1 81.048 Prec@5 89.919\n",
      " * Prec@1 81.250 Prec@5 90.039\n",
      " * Prec@1 80.871 Prec@5 89.962\n",
      " * Prec@1 80.515 Prec@5 89.522\n",
      " * Prec@1 80.357 Prec@5 89.286\n",
      " * Prec@1 80.382 Prec@5 89.236\n",
      " * Prec@1 80.405 Prec@5 89.189\n",
      " * Prec@1 80.592 Prec@5 89.474\n",
      " * Prec@1 80.288 Prec@5 89.423\n",
      " * Prec@1 80.156 Prec@5 89.531\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.521 (0.517)\n",
      "\n",
      "Loss 0.7281 (1.0891)\n",
      "\n",
      "Prec@1 81.250 (80.183)\n",
      "\n",
      "Prec@5 93.750 (89.634)\n",
      "\n",
      " * Prec@1 80.183 Prec@5 89.634\n",
      " * Prec@1 80.060 Prec@5 89.583\n",
      " * Prec@1 80.233 Prec@5 89.826\n",
      " * Prec@1 80.256 Prec@5 89.915\n",
      " * Prec@1 80.278 Prec@5 90.000\n",
      " * Prec@1 80.163 Prec@5 89.946\n",
      " * Prec@1 80.585 Prec@5 90.160\n",
      " * Prec@1 80.599 Prec@5 89.974\n",
      " * Prec@1 80.867 Prec@5 90.051\n",
      " * Prec@1 81.000 Prec@5 90.125\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.524 (0.523)\n",
      "\n",
      "Loss 2.0676 (1.0555)\n",
      "\n",
      "Prec@1 62.500 (80.637)\n",
      "\n",
      "Prec@5 75.000 (89.828)\n",
      "\n",
      " * Prec@1 80.637 Prec@5 89.828\n",
      " * Prec@1 80.649 Prec@5 89.904\n",
      " * Prec@1 80.896 Prec@5 90.094\n",
      " * Prec@1 80.903 Prec@5 90.046\n",
      " * Prec@1 80.682 Prec@5 90.000\n",
      " * Prec@1 80.692 Prec@5 89.955\n",
      " * Prec@1 80.811 Prec@5 89.912\n",
      " * Prec@1 80.819 Prec@5 89.978\n",
      " * Prec@1 80.720 Prec@5 89.831\n",
      " * Prec@1 80.625 Prec@5 89.896\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.510 (0.524)\n",
      "\n",
      "Loss 1.9154 (1.0719)\n",
      "\n",
      "Prec@1 68.750 (80.430)\n",
      "\n",
      "Prec@5 68.750 (89.549)\n",
      "\n",
      " * Prec@1 80.430 Prec@5 89.549\n",
      " * Prec@1 80.343 Prec@5 89.415\n",
      " * Prec@1 80.159 Prec@5 89.484\n",
      " * Prec@1 80.078 Prec@5 89.453\n",
      " * Prec@1 79.808 Prec@5 89.135\n",
      " * Prec@1 80.019 Prec@5 89.205\n",
      " * Prec@1 80.131 Prec@5 89.272\n",
      " * Prec@1 80.147 Prec@5 89.338\n",
      " * Prec@1 80.254 Prec@5 89.402\n",
      " * Prec@1 80.268 Prec@5 89.375\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.494 (0.523)\n",
      "\n",
      "Loss 0.1608 (1.0816)\n",
      "\n",
      "Prec@1 93.750 (80.458)\n",
      "\n",
      "Prec@5 100.000 (89.525)\n",
      "\n",
      " * Prec@1 80.458 Prec@5 89.525\n",
      " * Prec@1 80.469 Prec@5 89.583\n",
      " * Prec@1 80.394 Prec@5 89.640\n",
      " * Prec@1 80.490 Prec@5 89.696\n",
      " * Prec@1 80.583 Prec@5 89.667\n",
      " * Prec@1 80.674 Prec@5 89.638\n",
      " * Prec@1 80.844 Prec@5 89.773\n",
      " * Prec@1 80.849 Prec@5 89.744\n",
      " * Prec@1 80.696 Prec@5 89.715\n",
      " * Prec@1 80.625 Prec@5 89.609\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.484 (0.524)\n",
      "\n",
      "Loss 1.9750 (1.0734)\n",
      "\n",
      "Prec@1 68.750 (80.478)\n",
      "\n",
      "Prec@5 81.250 (89.506)\n",
      "\n",
      " * Prec@1 80.478 Prec@5 89.506\n",
      " * Prec@1 80.564 Prec@5 89.634\n",
      " * Prec@1 80.497 Prec@5 89.684\n",
      " * Prec@1 80.432 Prec@5 89.732\n",
      " * Prec@1 80.368 Prec@5 89.706\n",
      " * Prec@1 80.378 Prec@5 89.753\n",
      " * Prec@1 80.316 Prec@5 89.799\n",
      " * Prec@1 80.185 Prec@5 89.702\n",
      " * Prec@1 80.267 Prec@5 89.817\n",
      " * Prec@1 80.347 Prec@5 89.861\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.454 (0.522)\n",
      "\n",
      "Loss 0.0274 (1.0390)\n",
      "\n",
      "Prec@1 100.000 (80.563)\n",
      "\n",
      "Prec@5 100.000 (89.973)\n",
      "\n",
      " * Prec@1 80.563 Prec@5 89.973\n",
      " * Prec@1 80.707 Prec@5 90.014\n",
      " * Prec@1 80.847 Prec@5 90.054\n",
      " * Prec@1 80.918 Prec@5 90.093\n",
      " * Prec@1 80.987 Prec@5 90.197\n",
      " * Prec@1 80.794 Prec@5 90.039\n",
      " * Prec@1 80.735 Prec@5 89.884\n",
      " * Prec@1 80.612 Prec@5 89.732\n",
      " * Prec@1 80.619 Prec@5 89.773\n",
      " * Prec@1 80.812 Prec@5 89.875\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.550 (0.522)\n",
      "\n",
      "Loss 1.3239 (1.0529)\n",
      "\n",
      "Prec@1 81.250 (80.817)\n",
      "\n",
      "Prec@5 87.500 (89.851)\n",
      "\n",
      " * Prec@1 80.817 Prec@5 89.851\n",
      " * Prec@1 80.944 Prec@5 89.951\n",
      " * Prec@1 80.825 Prec@5 89.927\n",
      " * Prec@1 80.950 Prec@5 89.964\n",
      " * Prec@1 81.012 Prec@5 89.940\n",
      " * Prec@1 81.073 Prec@5 89.917\n",
      " * Prec@1 81.250 Prec@5 90.012\n",
      " * Prec@1 81.308 Prec@5 90.104\n",
      " * Prec@1 81.365 Prec@5 90.138\n",
      " * Prec@1 81.250 Prec@5 90.057\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.475 (0.522)\n",
      "\n",
      "Loss 0.9080 (1.0278)\n",
      "\n",
      "Prec@1 87.500 (81.306)\n",
      "\n",
      "Prec@5 93.750 (90.090)\n",
      "\n",
      " * Prec@1 81.306 Prec@5 90.090\n",
      " * Prec@1 81.138 Prec@5 90.067\n",
      " * Prec@1 81.139 Prec@5 90.155\n",
      " * Prec@1 81.140 Prec@5 90.077\n",
      " * Prec@1 81.196 Prec@5 90.109\n",
      " * Prec@1 81.196 Prec@5 90.194\n",
      " * Prec@1 81.197 Prec@5 90.224\n",
      " * Prec@1 81.091 Prec@5 90.148\n",
      " * Prec@1 81.197 Prec@5 90.231\n",
      " * Prec@1 81.146 Prec@5 90.208\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.511 (0.522)\n",
      "\n",
      "Loss 0.2649 (1.0197)\n",
      "\n",
      "Prec@1 93.750 (81.250)\n",
      "\n",
      "Prec@5 100.000 (90.289)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.289\n",
      " * Prec@1 81.250 Prec@5 90.266\n",
      " * Prec@1 81.301 Prec@5 90.295\n",
      " * Prec@1 81.300 Prec@5 90.373\n",
      " * Prec@1 81.250 Prec@5 90.350\n",
      " * Prec@1 81.250 Prec@5 90.427\n",
      " * Prec@1 81.250 Prec@5 90.404\n",
      " * Prec@1 81.250 Prec@5 90.430\n",
      " * Prec@1 81.298 Prec@5 90.455\n",
      " * Prec@1 81.442 Prec@5 90.529\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.609 (0.521)\n",
      "\n",
      "Loss 0.9761 (0.9942)\n",
      "\n",
      "Prec@1 68.750 (81.345)\n",
      "\n",
      "Prec@5 87.500 (90.506)\n",
      "\n",
      " * Prec@1 81.345 Prec@5 90.506\n",
      " * Prec@1 81.439 Prec@5 90.530\n",
      " * Prec@1 81.532 Prec@5 90.602\n",
      " * Prec@1 81.437 Prec@5 90.532\n",
      " * Prec@1 81.481 Prec@5 90.556\n",
      " * Prec@1 81.342 Prec@5 90.487\n",
      " * Prec@1 81.296 Prec@5 90.420\n",
      " * Prec@1 81.250 Prec@5 90.353\n",
      " * Prec@1 81.295 Prec@5 90.378\n",
      " * Prec@1 81.205 Prec@5 90.312\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.520 (0.521)\n",
      "\n",
      "Loss 1.8662 (1.0093)\n",
      "\n",
      "Prec@1 81.250 (81.206)\n",
      "\n",
      "Prec@5 81.250 (90.248)\n",
      "\n",
      " * Prec@1 81.206 Prec@5 90.248\n",
      " * Prec@1 81.074 Prec@5 90.097\n",
      " * Prec@1 80.988 Prec@5 90.035\n",
      " * Prec@1 80.990 Prec@5 90.061\n",
      " * Prec@1 80.991 Prec@5 90.086\n",
      " * Prec@1 80.736 Prec@5 89.897\n",
      " * Prec@1 80.697 Prec@5 89.838\n",
      " * Prec@1 80.743 Prec@5 89.823\n",
      " * Prec@1 80.747 Prec@5 89.765\n",
      " * Prec@1 80.792 Prec@5 89.792\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.522 (0.522)\n",
      "\n",
      "Loss 1.3448 (1.0462)\n",
      "\n",
      "Prec@1 75.000 (80.753)\n",
      "\n",
      "Prec@5 87.500 (89.776)\n",
      "\n",
      " * Prec@1 80.753 Prec@5 89.776\n",
      " * Prec@1 80.880 Prec@5 89.844\n",
      " * Prec@1 80.923 Prec@5 89.910\n",
      " * Prec@1 81.006 Prec@5 89.976\n",
      " * Prec@1 81.129 Prec@5 90.040\n",
      " * Prec@1 81.010 Prec@5 89.944\n",
      " * Prec@1 80.852 Prec@5 89.889\n",
      " * Prec@1 80.973 Prec@5 89.953\n",
      " * Prec@1 80.936 Prec@5 89.937\n",
      " * Prec@1 80.977 Prec@5 89.961\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.534 (0.523)\n",
      "\n",
      "Loss 0.7204 (1.0247)\n",
      "\n",
      "Prec@1 75.000 (80.939)\n",
      "\n",
      "Prec@5 100.000 (90.023)\n",
      "\n",
      " * Prec@1 80.939 Prec@5 90.023\n",
      " * Prec@1 80.980 Prec@5 90.046\n",
      " * Prec@1 80.905 Prec@5 89.992\n",
      " * Prec@1 80.983 Prec@5 90.015\n",
      " * Prec@1 80.947 Prec@5 90.038\n",
      " * Prec@1 81.024 Prec@5 90.060\n",
      " * Prec@1 80.951 Prec@5 90.082\n",
      " * Prec@1 80.915 Prec@5 90.030\n",
      " * Prec@1 80.876 Prec@5 90.048\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1515]\t\\Time 0.541 (0.541)\tData 0.421 (0.421)\tLoss 0.2378 (0.2378)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [6][100/1515]\t\\Time 0.482 (0.540)\tData 0.410 (0.438)\tLoss 0.0038 (0.0486)\tPrec@1 100.000 (99.319)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [6][200/1515]\t\\Time 0.600 (0.538)\tData 0.493 (0.435)\tLoss 0.0067 (0.0361)\tPrec@1 100.000 (99.378)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [6][300/1515]\t\\Time 0.508 (0.536)\tData 0.394 (0.433)\tLoss 0.1687 (0.0449)\tPrec@1 93.750 (99.315)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [6][400/1515]\t\\Time 0.573 (0.538)\tData 0.473 (0.435)\tLoss 0.0020 (0.0426)\tPrec@1 100.000 (99.314)\tPrec@5 100.000 (99.953)\n",
      "Epoch: [6][500/1515]\t\\Time 0.618 (0.540)\tData 0.497 (0.437)\tLoss 0.0116 (0.0398)\tPrec@1 100.000 (99.351)\tPrec@5 100.000 (99.963)\n",
      "Epoch: [6][600/1515]\t\\Time 0.536 (0.541)\tData 0.423 (0.438)\tLoss 0.0101 (0.0381)\tPrec@1 100.000 (99.355)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [6][700/1515]\t\\Time 0.558 (0.543)\tData 0.448 (0.439)\tLoss 0.0037 (0.0370)\tPrec@1 100.000 (99.367)\tPrec@5 100.000 (99.973)\n",
      "Epoch: [6][800/1515]\t\\Time 0.527 (0.543)\tData 0.419 (0.440)\tLoss 0.0176 (0.0374)\tPrec@1 100.000 (99.360)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [6][900/1515]\t\\Time 0.586 (0.542)\tData 0.485 (0.439)\tLoss 0.0075 (0.0387)\tPrec@1 100.000 (99.362)\tPrec@5 100.000 (99.951)\n",
      "Epoch: [6][1000/1515]\t\\Time 0.611 (0.543)\tData 0.500 (0.440)\tLoss 0.0097 (0.0367)\tPrec@1 100.000 (99.407)\tPrec@5 100.000 (99.950)\n",
      "Epoch: [6][1100/1515]\t\\Time 0.539 (0.544)\tData 0.420 (0.441)\tLoss 0.0021 (0.0360)\tPrec@1 100.000 (99.398)\tPrec@5 100.000 (99.955)\n",
      "Epoch: [6][1200/1515]\t\\Time 0.585 (0.545)\tData 0.465 (0.441)\tLoss 0.0056 (0.0358)\tPrec@1 100.000 (99.402)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [6][1300/1515]\t\\Time 0.491 (0.544)\tData 0.404 (0.441)\tLoss 0.0224 (0.0359)\tPrec@1 100.000 (99.404)\tPrec@5 100.000 (99.962)\n",
      "Epoch: [6][1400/1515]\t\\Time 0.530 (0.543)\tData 0.410 (0.440)\tLoss 0.0149 (0.0357)\tPrec@1 100.000 (99.411)\tPrec@5 100.000 (99.955)\n",
      "Epoch: [6][1500/1515]\t\\Time 0.563 (0.543)\tData 0.452 (0.439)\tLoss 0.0048 (0.0362)\tPrec@1 100.000 (99.413)\tPrec@5 100.000 (99.942)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.481 (0.481)\n",
      "\n",
      "Loss 0.4052 (0.4052)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 92.188 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 95.000\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 90.179 Prec@5 92.857\n",
      " * Prec@1 90.625 Prec@5 92.969\n",
      " * Prec@1 89.583 Prec@5 92.361\n",
      " * Prec@1 88.750 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.538 (0.521)\n",
      "\n",
      "Loss 0.3613 (0.6952)\n",
      "\n",
      "Prec@1 81.250 (88.068)\n",
      "\n",
      "Prec@5 100.000 (92.045)\n",
      "\n",
      " * Prec@1 88.068 Prec@5 92.045\n",
      " * Prec@1 88.021 Prec@5 92.708\n",
      " * Prec@1 88.462 Prec@5 93.269\n",
      " * Prec@1 87.946 Prec@5 92.411\n",
      " * Prec@1 87.083 Prec@5 91.667\n",
      " * Prec@1 86.719 Prec@5 92.188\n",
      " * Prec@1 85.294 Prec@5 91.176\n",
      " * Prec@1 84.028 Prec@5 90.278\n",
      " * Prec@1 83.224 Prec@5 90.132\n",
      " * Prec@1 83.125 Prec@5 90.000\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.558 (0.531)\n",
      "\n",
      "Loss 0.8299 (0.9463)\n",
      "\n",
      "Prec@1 87.500 (83.333)\n",
      "\n",
      "Prec@5 93.750 (90.179)\n",
      "\n",
      " * Prec@1 83.333 Prec@5 90.179\n",
      " * Prec@1 82.955 Prec@5 89.489\n",
      " * Prec@1 82.880 Prec@5 89.946\n",
      " * Prec@1 83.073 Prec@5 90.104\n",
      " * Prec@1 82.750 Prec@5 90.250\n",
      " * Prec@1 83.173 Prec@5 90.625\n",
      " * Prec@1 83.333 Prec@5 90.972\n",
      " * Prec@1 83.259 Prec@5 90.848\n",
      " * Prec@1 82.974 Prec@5 91.164\n",
      " * Prec@1 82.917 Prec@5 90.833\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.512 (0.528)\n",
      "\n",
      "Loss 0.4873 (0.8927)\n",
      "\n",
      "Prec@1 87.500 (83.065)\n",
      "\n",
      "Prec@5 93.750 (90.927)\n",
      "\n",
      " * Prec@1 83.065 Prec@5 90.927\n",
      " * Prec@1 83.203 Prec@5 91.016\n",
      " * Prec@1 82.765 Prec@5 90.530\n",
      " * Prec@1 82.353 Prec@5 90.074\n",
      " * Prec@1 82.143 Prec@5 90.000\n",
      " * Prec@1 82.118 Prec@5 89.931\n",
      " * Prec@1 82.095 Prec@5 89.865\n",
      " * Prec@1 81.908 Prec@5 90.132\n",
      " * Prec@1 81.731 Prec@5 90.064\n",
      " * Prec@1 81.719 Prec@5 90.156\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.505 (0.528)\n",
      "\n",
      "Loss 0.7233 (0.9466)\n",
      "\n",
      "Prec@1 87.500 (81.860)\n",
      "\n",
      "Prec@5 93.750 (90.244)\n",
      "\n",
      " * Prec@1 81.860 Prec@5 90.244\n",
      " * Prec@1 81.548 Prec@5 90.327\n",
      " * Prec@1 81.686 Prec@5 90.552\n",
      " * Prec@1 81.676 Prec@5 90.625\n",
      " * Prec@1 81.806 Prec@5 90.694\n",
      " * Prec@1 81.793 Prec@5 90.625\n",
      " * Prec@1 81.915 Prec@5 90.824\n",
      " * Prec@1 81.901 Prec@5 90.625\n",
      " * Prec@1 82.143 Prec@5 90.689\n",
      " * Prec@1 82.000 Prec@5 90.625\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.509 (0.527)\n",
      "\n",
      "Loss 1.6489 (0.9457)\n",
      "\n",
      "Prec@1 62.500 (81.618)\n",
      "\n",
      "Prec@5 75.000 (90.319)\n",
      "\n",
      " * Prec@1 81.618 Prec@5 90.319\n",
      " * Prec@1 81.490 Prec@5 90.385\n",
      " * Prec@1 81.722 Prec@5 90.566\n",
      " * Prec@1 81.597 Prec@5 90.509\n",
      " * Prec@1 81.250 Prec@5 90.455\n",
      " * Prec@1 81.250 Prec@5 90.513\n",
      " * Prec@1 81.360 Prec@5 90.461\n",
      " * Prec@1 81.358 Prec@5 90.517\n",
      " * Prec@1 81.250 Prec@5 90.572\n",
      " * Prec@1 81.354 Prec@5 90.625\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.526 (0.527)\n",
      "\n",
      "Loss 1.7934 (0.9652)\n",
      "\n",
      "Prec@1 68.750 (81.148)\n",
      "\n",
      "Prec@5 75.000 (90.369)\n",
      "\n",
      " * Prec@1 81.148 Prec@5 90.369\n",
      " * Prec@1 80.948 Prec@5 90.323\n",
      " * Prec@1 80.754 Prec@5 90.377\n",
      " * Prec@1 80.664 Prec@5 90.332\n",
      " * Prec@1 80.385 Prec@5 90.000\n",
      " * Prec@1 80.492 Prec@5 90.057\n",
      " * Prec@1 80.690 Prec@5 90.112\n",
      " * Prec@1 80.790 Prec@5 90.074\n",
      " * Prec@1 80.888 Prec@5 90.127\n",
      " * Prec@1 80.893 Prec@5 90.089\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.520 (0.526)\n",
      "\n",
      "Loss 0.1609 (0.9731)\n",
      "\n",
      "Prec@1 93.750 (81.074)\n",
      "\n",
      "Prec@5 100.000 (90.229)\n",
      "\n",
      " * Prec@1 81.074 Prec@5 90.229\n",
      " * Prec@1 81.076 Prec@5 90.278\n",
      " * Prec@1 81.164 Prec@5 90.325\n",
      " * Prec@1 81.250 Prec@5 90.372\n",
      " * Prec@1 81.250 Prec@5 90.333\n",
      " * Prec@1 81.332 Prec@5 90.296\n",
      " * Prec@1 81.494 Prec@5 90.422\n",
      " * Prec@1 81.571 Prec@5 90.465\n",
      " * Prec@1 81.487 Prec@5 90.348\n",
      " * Prec@1 81.406 Prec@5 90.234\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.511 (0.531)\n",
      "\n",
      "Loss 2.3197 (0.9865)\n",
      "\n",
      "Prec@1 68.750 (81.250)\n",
      "\n",
      "Prec@5 75.000 (90.046)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.046\n",
      " * Prec@1 81.250 Prec@5 90.091\n",
      " * Prec@1 81.250 Prec@5 90.060\n",
      " * Prec@1 81.176 Prec@5 90.104\n",
      " * Prec@1 81.176 Prec@5 90.074\n",
      " * Prec@1 81.250 Prec@5 90.116\n",
      " * Prec@1 81.250 Prec@5 90.158\n",
      " * Prec@1 81.179 Prec@5 90.128\n",
      " * Prec@1 81.180 Prec@5 90.169\n",
      " * Prec@1 81.250 Prec@5 90.278\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.476 (0.531)\n",
      "\n",
      "Loss 0.0050 (0.9605)\n",
      "\n",
      "Prec@1 100.000 (81.456)\n",
      "\n",
      "Prec@5 100.000 (90.385)\n",
      "\n",
      " * Prec@1 81.456 Prec@5 90.385\n",
      " * Prec@1 81.522 Prec@5 90.421\n",
      " * Prec@1 81.653 Prec@5 90.457\n",
      " * Prec@1 81.715 Prec@5 90.492\n",
      " * Prec@1 81.711 Prec@5 90.592\n",
      " * Prec@1 81.576 Prec@5 90.430\n",
      " * Prec@1 81.508 Prec@5 90.335\n",
      " * Prec@1 81.441 Prec@5 90.179\n",
      " * Prec@1 81.376 Prec@5 90.215\n",
      " * Prec@1 81.562 Prec@5 90.312\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.566 (0.531)\n",
      "\n",
      "Loss 1.2121 (0.9713)\n",
      "\n",
      "Prec@1 75.000 (81.498)\n",
      "\n",
      "Prec@5 87.500 (90.285)\n",
      "\n",
      " * Prec@1 81.498 Prec@5 90.285\n",
      " * Prec@1 81.618 Prec@5 90.380\n",
      " * Prec@1 81.493 Prec@5 90.352\n",
      " * Prec@1 81.490 Prec@5 90.325\n",
      " * Prec@1 81.488 Prec@5 90.298\n",
      " * Prec@1 81.545 Prec@5 90.330\n",
      " * Prec@1 81.717 Prec@5 90.421\n",
      " * Prec@1 81.829 Prec@5 90.509\n",
      " * Prec@1 81.881 Prec@5 90.596\n",
      " * Prec@1 81.818 Prec@5 90.682\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.489 (0.531)\n",
      "\n",
      "Loss 1.7211 (0.9550)\n",
      "\n",
      "Prec@1 81.250 (81.813)\n",
      "\n",
      "Prec@5 87.500 (90.653)\n",
      "\n",
      " * Prec@1 81.813 Prec@5 90.653\n",
      " * Prec@1 81.641 Prec@5 90.625\n",
      " * Prec@1 81.637 Prec@5 90.708\n",
      " * Prec@1 81.579 Prec@5 90.680\n",
      " * Prec@1 81.630 Prec@5 90.707\n",
      " * Prec@1 81.681 Prec@5 90.787\n",
      " * Prec@1 81.624 Prec@5 90.812\n",
      " * Prec@1 81.515 Prec@5 90.731\n",
      " * Prec@1 81.618 Prec@5 90.809\n",
      " * Prec@1 81.562 Prec@5 90.781\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.522 (0.531)\n",
      "\n",
      "Loss 0.6671 (0.9470)\n",
      "\n",
      "Prec@1 93.750 (81.663)\n",
      "\n",
      "Prec@5 93.750 (90.806)\n",
      "\n",
      " * Prec@1 81.663 Prec@5 90.806\n",
      " * Prec@1 81.711 Prec@5 90.779\n",
      " * Prec@1 81.809 Prec@5 90.854\n",
      " * Prec@1 81.855 Prec@5 90.927\n",
      " * Prec@1 81.850 Prec@5 91.000\n",
      " * Prec@1 81.796 Prec@5 91.022\n",
      " * Prec@1 81.841 Prec@5 91.043\n",
      " * Prec@1 81.934 Prec@5 91.113\n",
      " * Prec@1 82.025 Prec@5 91.134\n",
      " * Prec@1 82.115 Prec@5 91.154\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.581 (0.529)\n",
      "\n",
      "Loss 1.6000 (0.9213)\n",
      "\n",
      "Prec@1 68.750 (82.013)\n",
      "\n",
      "Prec@5 81.250 (91.078)\n",
      "\n",
      " * Prec@1 82.013 Prec@5 91.078\n",
      " * Prec@1 82.102 Prec@5 91.098\n",
      " * Prec@1 82.237 Prec@5 91.165\n",
      " * Prec@1 82.136 Prec@5 91.138\n",
      " * Prec@1 82.130 Prec@5 91.204\n",
      " * Prec@1 81.985 Prec@5 91.085\n",
      " * Prec@1 81.934 Prec@5 91.013\n",
      " * Prec@1 81.929 Prec@5 90.942\n",
      " * Prec@1 82.014 Prec@5 90.962\n",
      " * Prec@1 81.964 Prec@5 90.893\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.522 (0.530)\n",
      "\n",
      "Loss 1.6150 (0.9359)\n",
      "\n",
      "Prec@1 81.250 (81.959)\n",
      "\n",
      "Prec@5 81.250 (90.824)\n",
      "\n",
      " * Prec@1 81.959 Prec@5 90.824\n",
      " * Prec@1 81.822 Prec@5 90.669\n",
      " * Prec@1 81.731 Prec@5 90.603\n",
      " * Prec@1 81.727 Prec@5 90.668\n",
      " * Prec@1 81.767 Prec@5 90.690\n",
      " * Prec@1 81.507 Prec@5 90.497\n",
      " * Prec@1 81.463 Prec@5 90.476\n",
      " * Prec@1 81.461 Prec@5 90.498\n",
      " * Prec@1 81.418 Prec@5 90.436\n",
      " * Prec@1 81.458 Prec@5 90.458\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.514 (0.530)\n",
      "\n",
      "Loss 1.6326 (0.9732)\n",
      "\n",
      "Prec@1 75.000 (81.416)\n",
      "\n",
      "Prec@5 87.500 (90.439)\n",
      "\n",
      " * Prec@1 81.416 Prec@5 90.439\n",
      " * Prec@1 81.538 Prec@5 90.502\n",
      " * Prec@1 81.577 Prec@5 90.564\n",
      " * Prec@1 81.696 Prec@5 90.625\n",
      " * Prec@1 81.815 Prec@5 90.685\n",
      " * Prec@1 81.731 Prec@5 90.585\n",
      " * Prec@1 81.608 Prec@5 90.525\n",
      " * Prec@1 81.685 Prec@5 90.585\n",
      " * Prec@1 81.604 Prec@5 90.566\n",
      " * Prec@1 81.602 Prec@5 90.586\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.530 (0.530)\n",
      "\n",
      "Loss 0.5254 (0.9548)\n",
      "\n",
      "Prec@1 81.250 (81.599)\n",
      "\n",
      "Prec@5 100.000 (90.644)\n",
      "\n",
      " * Prec@1 81.599 Prec@5 90.644\n",
      " * Prec@1 81.636 Prec@5 90.664\n",
      " * Prec@1 81.633 Prec@5 90.606\n",
      " * Prec@1 81.707 Prec@5 90.625\n",
      " * Prec@1 81.742 Prec@5 90.644\n",
      " * Prec@1 81.815 Prec@5 90.663\n",
      " * Prec@1 81.737 Prec@5 90.644\n",
      " * Prec@1 81.734 Prec@5 90.588\n",
      " * Prec@1 81.730 Prec@5 90.605\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1515]\t\\Time 0.557 (0.557)\tData 0.445 (0.445)\tLoss 0.0012 (0.0012)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/1515]\t\\Time 0.513 (0.544)\tData 0.413 (0.445)\tLoss 0.0018 (0.0383)\tPrec@1 100.000 (99.319)\tPrec@5 100.000 (99.814)\n",
      "Epoch: [7][200/1515]\t\\Time 0.476 (0.548)\tData 0.386 (0.446)\tLoss 0.0013 (0.0308)\tPrec@1 100.000 (99.347)\tPrec@5 100.000 (99.876)\n",
      "Epoch: [7][300/1515]\t\\Time 0.514 (0.542)\tData 0.404 (0.440)\tLoss 0.0048 (0.0236)\tPrec@1 100.000 (99.460)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [7][400/1515]\t\\Time 0.554 (0.541)\tData 0.444 (0.439)\tLoss 0.1525 (0.0213)\tPrec@1 93.750 (99.486)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [7][500/1515]\t\\Time 0.549 (0.543)\tData 0.443 (0.440)\tLoss 0.0030 (0.0218)\tPrec@1 100.000 (99.513)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [7][600/1515]\t\\Time 0.583 (0.544)\tData 0.455 (0.442)\tLoss 0.0012 (0.0212)\tPrec@1 100.000 (99.522)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [7][700/1515]\t\\Time 0.549 (0.543)\tData 0.446 (0.441)\tLoss 0.0017 (0.0209)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [7][800/1515]\t\\Time 0.436 (0.543)\tData 0.366 (0.441)\tLoss 0.0027 (0.0201)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [7][900/1515]\t\\Time 0.496 (0.543)\tData 0.425 (0.441)\tLoss 0.0022 (0.0212)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (99.945)\n",
      "Epoch: [7][1000/1515]\t\\Time 0.560 (0.544)\tData 0.490 (0.442)\tLoss 0.0009 (0.0214)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (99.950)\n",
      "Epoch: [7][1100/1515]\t\\Time 0.589 (0.545)\tData 0.481 (0.443)\tLoss 0.0028 (0.0210)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (99.949)\n",
      "Epoch: [7][1200/1515]\t\\Time 0.559 (0.546)\tData 0.488 (0.443)\tLoss 0.0034 (0.0210)\tPrec@1 100.000 (99.578)\tPrec@5 100.000 (99.948)\n",
      "Epoch: [7][1300/1515]\t\\Time 0.550 (0.545)\tData 0.440 (0.443)\tLoss 0.0060 (0.0204)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (99.952)\n",
      "Epoch: [7][1400/1515]\t\\Time 0.544 (0.544)\tData 0.433 (0.442)\tLoss 0.0028 (0.0198)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (99.955)\n",
      "Epoch: [7][1500/1515]\t\\Time 0.594 (0.545)\tData 0.480 (0.442)\tLoss 0.0020 (0.0196)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (99.958)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.461 (0.461)\n",
      "\n",
      "Loss 0.3492 (0.3492)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 89.062 Prec@5 92.188\n",
      " * Prec@1 91.250 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 89.286 Prec@5 92.857\n",
      " * Prec@1 89.844 Prec@5 92.969\n",
      " * Prec@1 88.889 Prec@5 91.667\n",
      " * Prec@1 88.125 Prec@5 90.625\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.530 (0.528)\n",
      "\n",
      "Loss 0.5981 (0.7177)\n",
      "\n",
      "Prec@1 81.250 (87.500)\n",
      "\n",
      "Prec@5 100.000 (91.477)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 91.477\n",
      " * Prec@1 88.021 Prec@5 92.188\n",
      " * Prec@1 88.942 Prec@5 92.788\n",
      " * Prec@1 88.393 Prec@5 91.964\n",
      " * Prec@1 87.500 Prec@5 91.250\n",
      " * Prec@1 87.109 Prec@5 91.406\n",
      " * Prec@1 86.029 Prec@5 90.441\n",
      " * Prec@1 84.722 Prec@5 89.583\n",
      " * Prec@1 84.539 Prec@5 89.145\n",
      " * Prec@1 84.375 Prec@5 89.062\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.560 (0.542)\n",
      "\n",
      "Loss 0.7375 (0.9069)\n",
      "\n",
      "Prec@1 93.750 (84.821)\n",
      "\n",
      "Prec@5 93.750 (89.286)\n",
      "\n",
      " * Prec@1 84.821 Prec@5 89.286\n",
      " * Prec@1 84.375 Prec@5 88.636\n",
      " * Prec@1 84.511 Prec@5 89.130\n",
      " * Prec@1 84.115 Prec@5 89.323\n",
      " * Prec@1 84.000 Prec@5 89.500\n",
      " * Prec@1 84.375 Prec@5 89.904\n",
      " * Prec@1 84.722 Prec@5 90.278\n",
      " * Prec@1 84.598 Prec@5 90.179\n",
      " * Prec@1 84.483 Prec@5 90.517\n",
      " * Prec@1 84.375 Prec@5 90.208\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.520 (0.537)\n",
      "\n",
      "Loss 0.5801 (0.8786)\n",
      "\n",
      "Prec@1 87.500 (84.476)\n",
      "\n",
      "Prec@5 93.750 (90.323)\n",
      "\n",
      " * Prec@1 84.476 Prec@5 90.323\n",
      " * Prec@1 84.570 Prec@5 90.430\n",
      " * Prec@1 84.091 Prec@5 90.152\n",
      " * Prec@1 83.456 Prec@5 89.706\n",
      " * Prec@1 83.393 Prec@5 89.821\n",
      " * Prec@1 83.333 Prec@5 89.757\n",
      " * Prec@1 83.277 Prec@5 89.865\n",
      " * Prec@1 83.388 Prec@5 90.132\n",
      " * Prec@1 83.013 Prec@5 90.224\n",
      " * Prec@1 82.969 Prec@5 90.312\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.533 (0.535)\n",
      "\n",
      "Loss 0.7382 (0.9169)\n",
      "\n",
      "Prec@1 87.500 (83.079)\n",
      "\n",
      "Prec@5 93.750 (90.396)\n",
      "\n",
      " * Prec@1 83.079 Prec@5 90.396\n",
      " * Prec@1 82.738 Prec@5 90.327\n",
      " * Prec@1 82.849 Prec@5 90.407\n",
      " * Prec@1 82.812 Prec@5 90.341\n",
      " * Prec@1 82.917 Prec@5 90.417\n",
      " * Prec@1 82.880 Prec@5 90.353\n",
      " * Prec@1 83.245 Prec@5 90.559\n",
      " * Prec@1 83.203 Prec@5 90.495\n",
      " * Prec@1 83.418 Prec@5 90.561\n",
      " * Prec@1 83.375 Prec@5 90.625\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.496 (0.534)\n",
      "\n",
      "Loss 1.4535 (0.9089)\n",
      "\n",
      "Prec@1 75.000 (83.211)\n",
      "\n",
      "Prec@5 81.250 (90.441)\n",
      "\n",
      " * Prec@1 83.211 Prec@5 90.441\n",
      " * Prec@1 83.053 Prec@5 90.385\n",
      " * Prec@1 83.255 Prec@5 90.566\n",
      " * Prec@1 83.102 Prec@5 90.509\n",
      " * Prec@1 82.841 Prec@5 90.455\n",
      " * Prec@1 82.812 Prec@5 90.513\n",
      " * Prec@1 82.785 Prec@5 90.461\n",
      " * Prec@1 82.759 Prec@5 90.517\n",
      " * Prec@1 82.733 Prec@5 90.572\n",
      " * Prec@1 82.604 Prec@5 90.625\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.551 (0.536)\n",
      "\n",
      "Loss 1.8162 (0.9233)\n",
      "\n",
      "Prec@1 62.500 (82.275)\n",
      "\n",
      "Prec@5 75.000 (90.369)\n",
      "\n",
      " * Prec@1 82.275 Prec@5 90.369\n",
      " * Prec@1 82.157 Prec@5 90.323\n",
      " * Prec@1 81.944 Prec@5 90.377\n",
      " * Prec@1 81.934 Prec@5 90.332\n",
      " * Prec@1 81.635 Prec@5 89.904\n",
      " * Prec@1 81.818 Prec@5 89.962\n",
      " * Prec@1 81.996 Prec@5 90.019\n",
      " * Prec@1 81.985 Prec@5 90.074\n",
      " * Prec@1 82.065 Prec@5 90.127\n",
      " * Prec@1 82.054 Prec@5 90.000\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.528 (0.534)\n",
      "\n",
      "Loss 0.1361 (0.9384)\n",
      "\n",
      "Prec@1 93.750 (82.218)\n",
      "\n",
      "Prec@5 100.000 (90.141)\n",
      "\n",
      " * Prec@1 82.218 Prec@5 90.141\n",
      " * Prec@1 82.292 Prec@5 90.191\n",
      " * Prec@1 82.363 Prec@5 90.325\n",
      " * Prec@1 82.432 Prec@5 90.456\n",
      " * Prec@1 82.500 Prec@5 90.417\n",
      " * Prec@1 82.566 Prec@5 90.378\n",
      " * Prec@1 82.711 Prec@5 90.503\n",
      " * Prec@1 82.772 Prec@5 90.545\n",
      " * Prec@1 82.674 Prec@5 90.348\n",
      " * Prec@1 82.578 Prec@5 90.312\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.473 (0.535)\n",
      "\n",
      "Loss 2.2365 (0.9475)\n",
      "\n",
      "Prec@1 68.750 (82.407)\n",
      "\n",
      "Prec@5 75.000 (90.123)\n",
      "\n",
      " * Prec@1 82.407 Prec@5 90.123\n",
      " * Prec@1 82.317 Prec@5 90.168\n",
      " * Prec@1 82.229 Prec@5 90.286\n",
      " * Prec@1 82.217 Prec@5 90.327\n",
      " * Prec@1 82.206 Prec@5 90.294\n",
      " * Prec@1 82.267 Prec@5 90.334\n",
      " * Prec@1 82.328 Prec@5 90.374\n",
      " * Prec@1 82.244 Prec@5 90.270\n",
      " * Prec@1 82.303 Prec@5 90.309\n",
      " * Prec@1 82.431 Prec@5 90.417\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.448 (0.531)\n",
      "\n",
      "Loss 0.0069 (0.9123)\n",
      "\n",
      "Prec@1 100.000 (82.624)\n",
      "\n",
      "Prec@5 100.000 (90.522)\n",
      "\n",
      " * Prec@1 82.624 Prec@5 90.522\n",
      " * Prec@1 82.677 Prec@5 90.557\n",
      " * Prec@1 82.796 Prec@5 90.659\n",
      " * Prec@1 82.846 Prec@5 90.691\n",
      " * Prec@1 82.895 Prec@5 90.789\n",
      " * Prec@1 82.747 Prec@5 90.690\n",
      " * Prec@1 82.668 Prec@5 90.657\n",
      " * Prec@1 82.589 Prec@5 90.497\n",
      " * Prec@1 82.576 Prec@5 90.530\n",
      " * Prec@1 82.750 Prec@5 90.625\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.549 (0.530)\n",
      "\n",
      "Loss 1.2531 (0.9201)\n",
      "\n",
      "Prec@1 75.000 (82.673)\n",
      "\n",
      "Prec@5 87.500 (90.594)\n",
      "\n",
      " * Prec@1 82.673 Prec@5 90.594\n",
      " * Prec@1 82.843 Prec@5 90.686\n",
      " * Prec@1 82.706 Prec@5 90.655\n",
      " * Prec@1 82.692 Prec@5 90.685\n",
      " * Prec@1 82.679 Prec@5 90.655\n",
      " * Prec@1 82.724 Prec@5 90.625\n",
      " * Prec@1 82.886 Prec@5 90.713\n",
      " * Prec@1 82.986 Prec@5 90.799\n",
      " * Prec@1 83.142 Prec@5 90.883\n",
      " * Prec@1 83.011 Prec@5 90.966\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.492 (0.531)\n",
      "\n",
      "Loss 0.6418 (0.8945)\n",
      "\n",
      "Prec@1 87.500 (83.052)\n",
      "\n",
      "Prec@5 93.750 (90.991)\n",
      "\n",
      " * Prec@1 83.052 Prec@5 90.991\n",
      " * Prec@1 82.924 Prec@5 90.960\n",
      " * Prec@1 82.909 Prec@5 91.040\n",
      " * Prec@1 82.840 Prec@5 91.009\n",
      " * Prec@1 82.935 Prec@5 91.033\n",
      " * Prec@1 82.920 Prec@5 91.110\n",
      " * Prec@1 82.906 Prec@5 91.132\n",
      " * Prec@1 82.786 Prec@5 91.049\n",
      " * Prec@1 82.931 Prec@5 91.124\n",
      " * Prec@1 82.865 Prec@5 91.094\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.553 (0.531)\n",
      "\n",
      "Loss 0.4747 (0.8855)\n",
      "\n",
      "Prec@1 93.750 (82.955)\n",
      "\n",
      "Prec@5 93.750 (91.116)\n",
      "\n",
      " * Prec@1 82.955 Prec@5 91.116\n",
      " * Prec@1 82.992 Prec@5 91.086\n",
      " * Prec@1 83.079 Prec@5 91.159\n",
      " * Prec@1 83.115 Prec@5 91.179\n",
      " * Prec@1 83.200 Prec@5 91.250\n",
      " * Prec@1 83.185 Prec@5 91.319\n",
      " * Prec@1 83.169 Prec@5 91.388\n",
      " * Prec@1 83.252 Prec@5 91.455\n",
      " * Prec@1 83.333 Prec@5 91.473\n",
      " * Prec@1 83.413 Prec@5 91.538\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.579 (0.531)\n",
      "\n",
      "Loss 1.2718 (0.8601)\n",
      "\n",
      "Prec@1 68.750 (83.302)\n",
      "\n",
      "Prec@5 93.750 (91.555)\n",
      "\n",
      " * Prec@1 83.302 Prec@5 91.555\n",
      " * Prec@1 83.381 Prec@5 91.572\n",
      " * Prec@1 83.506 Prec@5 91.635\n",
      " * Prec@1 83.396 Prec@5 91.651\n",
      " * Prec@1 83.426 Prec@5 91.620\n",
      " * Prec@1 83.272 Prec@5 91.498\n",
      " * Prec@1 83.257 Prec@5 91.423\n",
      " * Prec@1 83.243 Prec@5 91.350\n",
      " * Prec@1 83.273 Prec@5 91.412\n",
      " * Prec@1 83.214 Prec@5 91.339\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.526 (0.531)\n",
      "\n",
      "Loss 1.2943 (0.8728)\n",
      "\n",
      "Prec@1 81.250 (83.200)\n",
      "\n",
      "Prec@5 87.500 (91.312)\n",
      "\n",
      " * Prec@1 83.200 Prec@5 91.312\n",
      " * Prec@1 83.055 Prec@5 91.153\n",
      " * Prec@1 82.955 Prec@5 91.128\n",
      " * Prec@1 82.943 Prec@5 91.146\n",
      " * Prec@1 82.974 Prec@5 91.164\n",
      " * Prec@1 82.705 Prec@5 90.839\n",
      " * Prec@1 82.738 Prec@5 90.816\n",
      " * Prec@1 82.770 Prec@5 90.836\n",
      " * Prec@1 82.760 Prec@5 90.772\n",
      " * Prec@1 82.792 Prec@5 90.792\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.514 (0.532)\n",
      "\n",
      "Loss 1.6559 (0.9149)\n",
      "\n",
      "Prec@1 75.000 (82.740)\n",
      "\n",
      "Prec@5 81.250 (90.728)\n",
      "\n",
      " * Prec@1 82.740 Prec@5 90.728\n",
      " * Prec@1 82.854 Prec@5 90.789\n",
      " * Prec@1 82.925 Prec@5 90.850\n",
      " * Prec@1 82.995 Prec@5 90.909\n",
      " * Prec@1 83.105 Prec@5 90.968\n",
      " * Prec@1 83.053 Prec@5 90.865\n",
      " * Prec@1 82.962 Prec@5 90.804\n",
      " * Prec@1 83.070 Prec@5 90.862\n",
      " * Prec@1 82.980 Prec@5 90.841\n",
      " * Prec@1 82.969 Prec@5 90.898\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.518 (0.533)\n",
      "\n",
      "Loss 0.4374 (0.8943)\n",
      "\n",
      "Prec@1 87.500 (82.997)\n",
      "\n",
      "Prec@5 100.000 (90.955)\n",
      "\n",
      " * Prec@1 82.997 Prec@5 90.955\n",
      " * Prec@1 83.063 Prec@5 90.972\n",
      " * Prec@1 83.014 Prec@5 90.913\n",
      " * Prec@1 83.079 Prec@5 90.930\n",
      " * Prec@1 83.106 Prec@5 90.947\n",
      " * Prec@1 83.133 Prec@5 90.964\n",
      " * Prec@1 83.046 Prec@5 90.981\n",
      " * Prec@1 83.036 Prec@5 90.923\n",
      " * Prec@1 83.030 Prec@5 90.939\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1515]\t\\Time 0.622 (0.622)\tData 0.475 (0.475)\tLoss 0.0014 (0.0014)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/1515]\t\\Time 0.502 (0.532)\tData 0.432 (0.429)\tLoss 0.1017 (0.0129)\tPrec@1 93.750 (99.691)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][200/1515]\t\\Time 0.533 (0.531)\tData 0.431 (0.429)\tLoss 0.0022 (0.0092)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][300/1515]\t\\Time 0.542 (0.535)\tData 0.462 (0.432)\tLoss 0.0022 (0.0145)\tPrec@1 100.000 (99.647)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][400/1515]\t\\Time 0.542 (0.537)\tData 0.442 (0.434)\tLoss 0.0028 (0.0155)\tPrec@1 100.000 (99.610)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [8][500/1515]\t\\Time 0.499 (0.538)\tData 0.422 (0.435)\tLoss 0.0027 (0.0146)\tPrec@1 100.000 (99.638)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [8][600/1515]\t\\Time 0.551 (0.538)\tData 0.441 (0.436)\tLoss 0.0040 (0.0151)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [8][700/1515]\t\\Time 0.562 (0.540)\tData 0.451 (0.438)\tLoss 0.0021 (0.0154)\tPrec@1 100.000 (99.643)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [8][800/1515]\t\\Time 0.532 (0.541)\tData 0.422 (0.438)\tLoss 0.0384 (0.0151)\tPrec@1 100.000 (99.641)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [8][900/1515]\t\\Time 0.534 (0.542)\tData 0.462 (0.440)\tLoss 0.0022 (0.0144)\tPrec@1 100.000 (99.660)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [8][1000/1515]\t\\Time 0.562 (0.544)\tData 0.451 (0.441)\tLoss 0.0027 (0.0148)\tPrec@1 100.000 (99.650)\tPrec@5 100.000 (99.994)\n",
      "Epoch: [8][1100/1515]\t\\Time 0.551 (0.544)\tData 0.431 (0.441)\tLoss 0.0024 (0.0149)\tPrec@1 100.000 (99.659)\tPrec@5 100.000 (99.994)\n",
      "Epoch: [8][1200/1515]\t\\Time 0.600 (0.544)\tData 0.489 (0.441)\tLoss 0.0020 (0.0147)\tPrec@1 100.000 (99.651)\tPrec@5 100.000 (99.995)\n",
      "Epoch: [8][1300/1515]\t\\Time 0.561 (0.544)\tData 0.453 (0.441)\tLoss 0.0040 (0.0157)\tPrec@1 100.000 (99.635)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [8][1400/1515]\t\\Time 0.571 (0.545)\tData 0.471 (0.442)\tLoss 0.0022 (0.0159)\tPrec@1 100.000 (99.634)\tPrec@5 100.000 (99.987)\n",
      "Epoch: [8][1500/1515]\t\\Time 0.522 (0.545)\tData 0.422 (0.442)\tLoss 0.0030 (0.0163)\tPrec@1 100.000 (99.621)\tPrec@5 100.000 (99.988)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.453 (0.453)\n",
      "\n",
      "Loss 0.2846 (0.2846)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 89.062 Prec@5 93.750\n",
      " * Prec@1 90.000 Prec@5 95.000\n",
      " * Prec@1 87.500 Prec@5 93.750\n",
      " * Prec@1 86.607 Prec@5 92.857\n",
      " * Prec@1 87.500 Prec@5 92.969\n",
      " * Prec@1 86.806 Prec@5 92.361\n",
      " * Prec@1 86.250 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.515 (0.532)\n",
      "\n",
      "Loss 0.6008 (0.7345)\n",
      "\n",
      "Prec@1 81.250 (85.795)\n",
      "\n",
      "Prec@5 100.000 (92.045)\n",
      "\n",
      " * Prec@1 85.795 Prec@5 92.045\n",
      " * Prec@1 85.938 Prec@5 92.708\n",
      " * Prec@1 86.538 Prec@5 93.269\n",
      " * Prec@1 86.161 Prec@5 92.411\n",
      " * Prec@1 85.417 Prec@5 91.667\n",
      " * Prec@1 85.547 Prec@5 91.797\n",
      " * Prec@1 84.191 Prec@5 90.441\n",
      " * Prec@1 83.333 Prec@5 89.931\n",
      " * Prec@1 82.566 Prec@5 89.474\n",
      " * Prec@1 82.500 Prec@5 89.375\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.540 (0.521)\n",
      "\n",
      "Loss 0.8247 (0.9134)\n",
      "\n",
      "Prec@1 93.750 (83.036)\n",
      "\n",
      "Prec@5 93.750 (89.583)\n",
      "\n",
      " * Prec@1 83.036 Prec@5 89.583\n",
      " * Prec@1 82.670 Prec@5 88.920\n",
      " * Prec@1 82.880 Prec@5 89.402\n",
      " * Prec@1 82.812 Prec@5 89.583\n",
      " * Prec@1 82.750 Prec@5 89.750\n",
      " * Prec@1 83.173 Prec@5 90.144\n",
      " * Prec@1 83.565 Prec@5 90.509\n",
      " * Prec@1 83.482 Prec@5 90.402\n",
      " * Prec@1 83.405 Prec@5 90.733\n",
      " * Prec@1 83.125 Prec@5 90.417\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.493 (0.526)\n",
      "\n",
      "Loss 0.5458 (0.8664)\n",
      "\n",
      "Prec@1 87.500 (83.266)\n",
      "\n",
      "Prec@5 93.750 (90.524)\n",
      "\n",
      " * Prec@1 83.266 Prec@5 90.524\n",
      " * Prec@1 83.398 Prec@5 90.625\n",
      " * Prec@1 82.955 Prec@5 90.341\n",
      " * Prec@1 82.353 Prec@5 89.706\n",
      " * Prec@1 82.321 Prec@5 89.821\n",
      " * Prec@1 82.292 Prec@5 89.757\n",
      " * Prec@1 82.264 Prec@5 90.034\n",
      " * Prec@1 82.237 Prec@5 90.296\n",
      " * Prec@1 82.051 Prec@5 90.385\n",
      " * Prec@1 82.031 Prec@5 90.469\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.507 (0.526)\n",
      "\n",
      "Loss 0.9116 (0.9117)\n",
      "\n",
      "Prec@1 87.500 (82.165)\n",
      "\n",
      "Prec@5 93.750 (90.549)\n",
      "\n",
      " * Prec@1 82.165 Prec@5 90.549\n",
      " * Prec@1 81.845 Prec@5 90.476\n",
      " * Prec@1 81.977 Prec@5 90.698\n",
      " * Prec@1 81.960 Prec@5 90.767\n",
      " * Prec@1 82.083 Prec@5 90.833\n",
      " * Prec@1 81.929 Prec@5 90.761\n",
      " * Prec@1 82.314 Prec@5 90.957\n",
      " * Prec@1 82.292 Prec@5 90.885\n",
      " * Prec@1 82.526 Prec@5 90.944\n",
      " * Prec@1 82.375 Prec@5 90.875\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.525 (0.525)\n",
      "\n",
      "Loss 1.4563 (0.9029)\n",
      "\n",
      "Prec@1 75.000 (82.230)\n",
      "\n",
      "Prec@5 81.250 (90.686)\n",
      "\n",
      " * Prec@1 82.230 Prec@5 90.686\n",
      " * Prec@1 82.091 Prec@5 90.625\n",
      " * Prec@1 82.193 Prec@5 90.802\n",
      " * Prec@1 82.060 Prec@5 90.741\n",
      " * Prec@1 81.705 Prec@5 90.795\n",
      " * Prec@1 81.696 Prec@5 90.848\n",
      " * Prec@1 81.689 Prec@5 90.789\n",
      " * Prec@1 81.681 Prec@5 90.841\n",
      " * Prec@1 81.568 Prec@5 90.890\n",
      " * Prec@1 81.458 Prec@5 90.938\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.522 (0.526)\n",
      "\n",
      "Loss 1.7970 (0.9146)\n",
      "\n",
      "Prec@1 68.750 (81.250)\n",
      "\n",
      "Prec@5 75.000 (90.676)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.676\n",
      " * Prec@1 81.149 Prec@5 90.625\n",
      " * Prec@1 81.052 Prec@5 90.675\n",
      " * Prec@1 81.055 Prec@5 90.625\n",
      " * Prec@1 80.769 Prec@5 90.192\n",
      " * Prec@1 80.966 Prec@5 90.246\n",
      " * Prec@1 81.157 Prec@5 90.299\n",
      " * Prec@1 81.158 Prec@5 90.349\n",
      " * Prec@1 81.250 Prec@5 90.399\n",
      " * Prec@1 81.250 Prec@5 90.268\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.501 (0.525)\n",
      "\n",
      "Loss 0.2727 (0.9177)\n",
      "\n",
      "Prec@1 93.750 (81.426)\n",
      "\n",
      "Prec@5 100.000 (90.405)\n",
      "\n",
      " * Prec@1 81.426 Prec@5 90.405\n",
      " * Prec@1 81.424 Prec@5 90.451\n",
      " * Prec@1 81.507 Prec@5 90.582\n",
      " * Prec@1 81.588 Prec@5 90.625\n",
      " * Prec@1 81.667 Prec@5 90.583\n",
      " * Prec@1 81.743 Prec@5 90.543\n",
      " * Prec@1 81.899 Prec@5 90.666\n",
      " * Prec@1 81.971 Prec@5 90.705\n",
      " * Prec@1 81.883 Prec@5 90.585\n",
      " * Prec@1 81.797 Prec@5 90.547\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.478 (0.524)\n",
      "\n",
      "Loss 1.9604 (0.9296)\n",
      "\n",
      "Prec@1 68.750 (81.636)\n",
      "\n",
      "Prec@5 75.000 (90.355)\n",
      "\n",
      " * Prec@1 81.636 Prec@5 90.355\n",
      " * Prec@1 81.631 Prec@5 90.396\n",
      " * Prec@1 81.476 Prec@5 90.286\n",
      " * Prec@1 81.473 Prec@5 90.327\n",
      " * Prec@1 81.544 Prec@5 90.294\n",
      " * Prec@1 81.613 Prec@5 90.407\n",
      " * Prec@1 81.681 Prec@5 90.445\n",
      " * Prec@1 81.676 Prec@5 90.341\n",
      " * Prec@1 81.742 Prec@5 90.379\n",
      " * Prec@1 81.806 Prec@5 90.417\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.429 (0.521)\n",
      "\n",
      "Loss 0.0033 (0.8999)\n",
      "\n",
      "Prec@1 100.000 (82.005)\n",
      "\n",
      "Prec@5 100.000 (90.522)\n",
      "\n",
      " * Prec@1 82.005 Prec@5 90.522\n",
      " * Prec@1 82.133 Prec@5 90.557\n",
      " * Prec@1 82.258 Prec@5 90.591\n",
      " * Prec@1 82.314 Prec@5 90.559\n",
      " * Prec@1 82.368 Prec@5 90.592\n",
      " * Prec@1 82.227 Prec@5 90.495\n",
      " * Prec@1 82.152 Prec@5 90.464\n",
      " * Prec@1 82.015 Prec@5 90.306\n",
      " * Prec@1 81.944 Prec@5 90.341\n",
      " * Prec@1 82.125 Prec@5 90.438\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.562 (0.524)\n",
      "\n",
      "Loss 1.1807 (0.9047)\n",
      "\n",
      "Prec@1 81.250 (82.116)\n",
      "\n",
      "Prec@5 87.500 (90.408)\n",
      "\n",
      " * Prec@1 82.116 Prec@5 90.408\n",
      " * Prec@1 82.230 Prec@5 90.502\n",
      " * Prec@1 82.100 Prec@5 90.473\n",
      " * Prec@1 82.151 Prec@5 90.445\n",
      " * Prec@1 82.143 Prec@5 90.417\n",
      " * Prec@1 82.193 Prec@5 90.389\n",
      " * Prec@1 82.360 Prec@5 90.479\n",
      " * Prec@1 82.465 Prec@5 90.567\n",
      " * Prec@1 82.511 Prec@5 90.654\n",
      " * Prec@1 82.386 Prec@5 90.739\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.522 (0.526)\n",
      "\n",
      "Loss 0.7483 (0.8834)\n",
      "\n",
      "Prec@1 87.500 (82.432)\n",
      "\n",
      "Prec@5 93.750 (90.766)\n",
      "\n",
      " * Prec@1 82.432 Prec@5 90.766\n",
      " * Prec@1 82.254 Prec@5 90.737\n",
      " * Prec@1 82.301 Prec@5 90.819\n",
      " * Prec@1 82.237 Prec@5 90.789\n",
      " * Prec@1 82.337 Prec@5 90.815\n",
      " * Prec@1 82.328 Prec@5 90.894\n",
      " * Prec@1 82.318 Prec@5 90.919\n",
      " * Prec@1 82.203 Prec@5 90.890\n",
      " * Prec@1 82.353 Prec@5 90.966\n",
      " * Prec@1 82.344 Prec@5 90.938\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.526 (0.528)\n",
      "\n",
      "Loss 0.4152 (0.8722)\n",
      "\n",
      "Prec@1 93.750 (82.438)\n",
      "\n",
      "Prec@5 100.000 (91.012)\n",
      "\n",
      " * Prec@1 82.438 Prec@5 91.012\n",
      " * Prec@1 82.428 Prec@5 91.035\n",
      " * Prec@1 82.520 Prec@5 91.057\n",
      " * Prec@1 82.560 Prec@5 91.079\n",
      " * Prec@1 82.650 Prec@5 91.150\n",
      " * Prec@1 82.639 Prec@5 91.220\n",
      " * Prec@1 82.628 Prec@5 91.289\n",
      " * Prec@1 82.715 Prec@5 91.357\n",
      " * Prec@1 82.800 Prec@5 91.376\n",
      " * Prec@1 82.837 Prec@5 91.394\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.547 (0.528)\n",
      "\n",
      "Loss 1.1642 (0.8468)\n",
      "\n",
      "Prec@1 68.750 (82.729)\n",
      "\n",
      "Prec@5 87.500 (91.365)\n",
      "\n",
      " * Prec@1 82.729 Prec@5 91.365\n",
      " * Prec@1 82.812 Prec@5 91.383\n",
      " * Prec@1 82.942 Prec@5 91.447\n",
      " * Prec@1 82.882 Prec@5 91.465\n",
      " * Prec@1 82.917 Prec@5 91.528\n",
      " * Prec@1 82.767 Prec@5 91.406\n",
      " * Prec@1 82.755 Prec@5 91.332\n",
      " * Prec@1 82.745 Prec@5 91.259\n",
      " * Prec@1 82.779 Prec@5 91.322\n",
      " * Prec@1 82.723 Prec@5 91.250\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.516 (0.527)\n",
      "\n",
      "Loss 1.2691 (0.8560)\n",
      "\n",
      "Prec@1 81.250 (82.713)\n",
      "\n",
      "Prec@5 87.500 (91.223)\n",
      "\n",
      " * Prec@1 82.713 Prec@5 91.223\n",
      " * Prec@1 82.570 Prec@5 91.065\n",
      " * Prec@1 82.474 Prec@5 90.997\n",
      " * Prec@1 82.465 Prec@5 91.059\n",
      " * Prec@1 82.500 Prec@5 91.078\n",
      " * Prec@1 82.235 Prec@5 90.839\n",
      " * Prec@1 82.228 Prec@5 90.816\n",
      " * Prec@1 82.264 Prec@5 90.794\n",
      " * Prec@1 82.257 Prec@5 90.730\n",
      " * Prec@1 82.292 Prec@5 90.750\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.506 (0.528)\n",
      "\n",
      "Loss 1.4772 (0.8916)\n",
      "\n",
      "Prec@1 75.000 (82.243)\n",
      "\n",
      "Prec@5 87.500 (90.728)\n",
      "\n",
      " * Prec@1 82.243 Prec@5 90.728\n",
      " * Prec@1 82.360 Prec@5 90.789\n",
      " * Prec@1 82.435 Prec@5 90.850\n",
      " * Prec@1 82.508 Prec@5 90.909\n",
      " * Prec@1 82.621 Prec@5 90.968\n",
      " * Prec@1 82.572 Prec@5 90.865\n",
      " * Prec@1 82.484 Prec@5 90.764\n",
      " * Prec@1 82.595 Prec@5 90.823\n",
      " * Prec@1 82.508 Prec@5 90.802\n",
      " * Prec@1 82.500 Prec@5 90.859\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.508 (0.528)\n",
      "\n",
      "Loss 0.4668 (0.8748)\n",
      "\n",
      "Prec@1 81.250 (82.492)\n",
      "\n",
      "Prec@5 100.000 (90.916)\n",
      "\n",
      " * Prec@1 82.492 Prec@5 90.916\n",
      " * Prec@1 82.523 Prec@5 90.934\n",
      " * Prec@1 82.515 Prec@5 90.874\n",
      " * Prec@1 82.584 Prec@5 90.892\n",
      " * Prec@1 82.576 Prec@5 90.909\n",
      " * Prec@1 82.605 Prec@5 90.926\n",
      " * Prec@1 82.522 Prec@5 90.906\n",
      " * Prec@1 82.478 Prec@5 90.848\n",
      " * Prec@1 82.436 Prec@5 90.865\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1515]\t\\Time 0.615 (0.615)\tData 0.504 (0.504)\tLoss 0.0017 (0.0017)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/1515]\t\\Time 0.563 (0.526)\tData 0.441 (0.422)\tLoss 0.0022 (0.0219)\tPrec@1 100.000 (99.134)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][200/1515]\t\\Time 0.572 (0.528)\tData 0.464 (0.425)\tLoss 0.0018 (0.0163)\tPrec@1 100.000 (99.409)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][300/1515]\t\\Time 0.498 (0.526)\tData 0.388 (0.422)\tLoss 0.0015 (0.0173)\tPrec@1 100.000 (99.398)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][400/1515]\t\\Time 0.535 (0.527)\tData 0.425 (0.423)\tLoss 0.0030 (0.0170)\tPrec@1 100.000 (99.423)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][500/1515]\t\\Time 0.550 (0.529)\tData 0.435 (0.425)\tLoss 0.0022 (0.0158)\tPrec@1 100.000 (99.489)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][600/1515]\t\\Time 0.493 (0.531)\tData 0.397 (0.428)\tLoss 0.0032 (0.0176)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [9][700/1515]\t\\Time 0.546 (0.532)\tData 0.443 (0.429)\tLoss 0.0012 (0.0172)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [9][800/1515]\t\\Time 0.580 (0.533)\tData 0.470 (0.430)\tLoss 0.0018 (0.0164)\tPrec@1 100.000 (99.532)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [9][900/1515]\t\\Time 0.431 (0.534)\tData 0.361 (0.431)\tLoss 0.0016 (0.0164)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [9][1000/1515]\t\\Time 0.580 (0.536)\tData 0.461 (0.432)\tLoss 0.0050 (0.0161)\tPrec@1 100.000 (99.538)\tPrec@5 100.000 (99.994)\n",
      "Epoch: [9][1100/1515]\t\\Time 0.554 (0.537)\tData 0.453 (0.434)\tLoss 0.0022 (0.0157)\tPrec@1 100.000 (99.535)\tPrec@5 100.000 (99.994)\n",
      "Epoch: [9][1200/1515]\t\\Time 0.540 (0.538)\tData 0.430 (0.435)\tLoss 0.0052 (0.0152)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (99.995)\n",
      "Epoch: [9][1300/1515]\t\\Time 0.532 (0.538)\tData 0.430 (0.435)\tLoss 0.0023 (0.0161)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (99.995)\n",
      "Epoch: [9][1400/1515]\t\\Time 0.542 (0.539)\tData 0.424 (0.435)\tLoss 0.0017 (0.0154)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (99.996)\n",
      "Epoch: [9][1500/1515]\t\\Time 0.490 (0.539)\tData 0.409 (0.436)\tLoss 0.0025 (0.0148)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (99.996)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.491 (0.491)\n",
      "\n",
      "Loss 0.2786 (0.2786)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 95.000 Prec@5 95.000\n",
      " * Prec@1 91.667 Prec@5 94.792\n",
      " * Prec@1 90.179 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 88.889 Prec@5 92.361\n",
      " * Prec@1 88.125 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.551 (0.550)\n",
      "\n",
      "Loss 0.5089 (0.7050)\n",
      "\n",
      "Prec@1 81.250 (87.500)\n",
      "\n",
      "Prec@5 100.000 (92.045)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 92.045\n",
      " * Prec@1 86.979 Prec@5 92.708\n",
      " * Prec@1 87.500 Prec@5 93.269\n",
      " * Prec@1 87.054 Prec@5 92.411\n",
      " * Prec@1 86.250 Prec@5 92.083\n",
      " * Prec@1 86.328 Prec@5 92.188\n",
      " * Prec@1 84.926 Prec@5 91.176\n",
      " * Prec@1 84.028 Prec@5 90.625\n",
      " * Prec@1 83.224 Prec@5 90.132\n",
      " * Prec@1 83.125 Prec@5 90.000\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.577 (0.551)\n",
      "\n",
      "Loss 0.8179 (0.8720)\n",
      "\n",
      "Prec@1 93.750 (83.631)\n",
      "\n",
      "Prec@5 93.750 (90.179)\n",
      "\n",
      " * Prec@1 83.631 Prec@5 90.179\n",
      " * Prec@1 83.239 Prec@5 89.489\n",
      " * Prec@1 83.424 Prec@5 89.946\n",
      " * Prec@1 83.073 Prec@5 90.104\n",
      " * Prec@1 83.000 Prec@5 90.250\n",
      " * Prec@1 83.413 Prec@5 90.625\n",
      " * Prec@1 83.565 Prec@5 90.972\n",
      " * Prec@1 83.482 Prec@5 90.848\n",
      " * Prec@1 83.621 Prec@5 91.164\n",
      " * Prec@1 83.333 Prec@5 91.042\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.530 (0.548)\n",
      "\n",
      "Loss 0.5156 (0.8401)\n",
      "\n",
      "Prec@1 87.500 (83.468)\n",
      "\n",
      "Prec@5 93.750 (91.129)\n",
      "\n",
      " * Prec@1 83.468 Prec@5 91.129\n",
      " * Prec@1 83.594 Prec@5 91.211\n",
      " * Prec@1 83.144 Prec@5 90.909\n",
      " * Prec@1 82.537 Prec@5 90.441\n",
      " * Prec@1 82.321 Prec@5 90.536\n",
      " * Prec@1 82.292 Prec@5 90.451\n",
      " * Prec@1 82.264 Prec@5 90.541\n",
      " * Prec@1 82.237 Prec@5 90.789\n",
      " * Prec@1 81.891 Prec@5 90.865\n",
      " * Prec@1 81.875 Prec@5 90.938\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.545 (0.547)\n",
      "\n",
      "Loss 0.7858 (0.8780)\n",
      "\n",
      "Prec@1 87.500 (82.012)\n",
      "\n",
      "Prec@5 93.750 (91.006)\n",
      "\n",
      " * Prec@1 82.012 Prec@5 91.006\n",
      " * Prec@1 81.696 Prec@5 90.923\n",
      " * Prec@1 81.831 Prec@5 91.134\n",
      " * Prec@1 81.818 Prec@5 91.193\n",
      " * Prec@1 81.944 Prec@5 91.250\n",
      " * Prec@1 81.793 Prec@5 91.168\n",
      " * Prec@1 82.048 Prec@5 91.356\n",
      " * Prec@1 82.031 Prec@5 91.276\n",
      " * Prec@1 82.270 Prec@5 91.327\n",
      " * Prec@1 82.125 Prec@5 91.375\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.520 (0.548)\n",
      "\n",
      "Loss 1.4954 (0.8714)\n",
      "\n",
      "Prec@1 68.750 (81.863)\n",
      "\n",
      "Prec@5 81.250 (91.176)\n",
      "\n",
      " * Prec@1 81.863 Prec@5 91.176\n",
      " * Prec@1 81.731 Prec@5 91.106\n",
      " * Prec@1 81.840 Prec@5 91.274\n",
      " * Prec@1 81.713 Prec@5 91.204\n",
      " * Prec@1 81.364 Prec@5 91.136\n",
      " * Prec@1 81.362 Prec@5 91.183\n",
      " * Prec@1 81.469 Prec@5 91.118\n",
      " * Prec@1 81.466 Prec@5 91.164\n",
      " * Prec@1 81.462 Prec@5 91.208\n",
      " * Prec@1 81.458 Prec@5 91.250\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.535 (0.549)\n",
      "\n",
      "Loss 1.9631 (0.8881)\n",
      "\n",
      "Prec@1 62.500 (81.148)\n",
      "\n",
      "Prec@5 75.000 (90.984)\n",
      "\n",
      " * Prec@1 81.148 Prec@5 90.984\n",
      " * Prec@1 81.048 Prec@5 90.927\n",
      " * Prec@1 80.952 Prec@5 90.972\n",
      " * Prec@1 80.957 Prec@5 90.918\n",
      " * Prec@1 80.673 Prec@5 90.481\n",
      " * Prec@1 80.871 Prec@5 90.530\n",
      " * Prec@1 81.063 Prec@5 90.578\n",
      " * Prec@1 81.066 Prec@5 90.625\n",
      " * Prec@1 81.069 Prec@5 90.670\n",
      " * Prec@1 81.071 Prec@5 90.536\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.494 (0.543)\n",
      "\n",
      "Loss 0.1612 (0.8967)\n",
      "\n",
      "Prec@1 93.750 (81.250)\n",
      "\n",
      "Prec@5 100.000 (90.669)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 90.669\n",
      " * Prec@1 81.250 Prec@5 90.712\n",
      " * Prec@1 81.336 Prec@5 90.839\n",
      " * Prec@1 81.419 Prec@5 90.963\n",
      " * Prec@1 81.417 Prec@5 90.917\n",
      " * Prec@1 81.497 Prec@5 90.872\n",
      " * Prec@1 81.656 Prec@5 90.990\n",
      " * Prec@1 81.731 Prec@5 91.026\n",
      " * Prec@1 81.646 Prec@5 90.902\n",
      " * Prec@1 81.562 Prec@5 90.859\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.475 (0.541)\n",
      "\n",
      "Loss 2.1763 (0.9092)\n",
      "\n",
      "Prec@1 68.750 (81.404)\n",
      "\n",
      "Prec@5 75.000 (90.664)\n",
      "\n",
      " * Prec@1 81.404 Prec@5 90.664\n",
      " * Prec@1 81.402 Prec@5 90.701\n",
      " * Prec@1 81.250 Prec@5 90.738\n",
      " * Prec@1 81.176 Prec@5 90.774\n",
      " * Prec@1 81.250 Prec@5 90.735\n",
      " * Prec@1 81.323 Prec@5 90.770\n",
      " * Prec@1 81.394 Prec@5 90.805\n",
      " * Prec@1 81.321 Prec@5 90.696\n",
      " * Prec@1 81.390 Prec@5 90.730\n",
      " * Prec@1 81.458 Prec@5 90.764\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.472 (0.536)\n",
      "\n",
      "Loss 0.0037 (0.8819)\n",
      "\n",
      "Prec@1 100.000 (81.662)\n",
      "\n",
      "Prec@5 100.000 (90.865)\n",
      "\n",
      " * Prec@1 81.662 Prec@5 90.865\n",
      " * Prec@1 81.726 Prec@5 90.897\n",
      " * Prec@1 81.855 Prec@5 90.927\n",
      " * Prec@1 81.981 Prec@5 90.957\n",
      " * Prec@1 82.039 Prec@5 91.053\n",
      " * Prec@1 81.966 Prec@5 90.951\n",
      " * Prec@1 81.894 Prec@5 90.915\n",
      " * Prec@1 81.760 Prec@5 90.753\n",
      " * Prec@1 81.692 Prec@5 90.783\n",
      " * Prec@1 81.875 Prec@5 90.875\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.567 (0.535)\n",
      "\n",
      "Loss 1.2401 (0.8908)\n",
      "\n",
      "Prec@1 75.000 (81.807)\n",
      "\n",
      "Prec@5 87.500 (90.842)\n",
      "\n",
      " * Prec@1 81.807 Prec@5 90.842\n",
      " * Prec@1 81.985 Prec@5 90.931\n",
      " * Prec@1 81.917 Prec@5 90.898\n",
      " * Prec@1 81.911 Prec@5 90.925\n",
      " * Prec@1 81.905 Prec@5 90.893\n",
      " * Prec@1 81.958 Prec@5 90.920\n",
      " * Prec@1 82.126 Prec@5 91.005\n",
      " * Prec@1 82.234 Prec@5 91.088\n",
      " * Prec@1 82.339 Prec@5 91.170\n",
      " * Prec@1 82.216 Prec@5 91.193\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.493 (0.534)\n",
      "\n",
      "Loss 0.7237 (0.8661)\n",
      "\n",
      "Prec@1 87.500 (82.264)\n",
      "\n",
      "Prec@5 93.750 (91.216)\n",
      "\n",
      " * Prec@1 82.264 Prec@5 91.216\n",
      " * Prec@1 82.087 Prec@5 91.127\n",
      " * Prec@1 82.080 Prec@5 91.206\n",
      " * Prec@1 82.018 Prec@5 91.173\n",
      " * Prec@1 82.120 Prec@5 91.196\n",
      " * Prec@1 82.166 Prec@5 91.272\n",
      " * Prec@1 82.158 Prec@5 91.293\n",
      " * Prec@1 82.044 Prec@5 91.208\n",
      " * Prec@1 82.195 Prec@5 91.282\n",
      " * Prec@1 82.188 Prec@5 91.250\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.543 (0.533)\n",
      "\n",
      "Loss 0.3882 (0.8611)\n",
      "\n",
      "Prec@1 93.750 (82.283)\n",
      "\n",
      "Prec@5 100.000 (91.322)\n",
      "\n",
      " * Prec@1 82.283 Prec@5 91.322\n",
      " * Prec@1 82.326 Prec@5 91.291\n",
      " * Prec@1 82.419 Prec@5 91.311\n",
      " * Prec@1 82.460 Prec@5 91.331\n",
      " * Prec@1 82.550 Prec@5 91.350\n",
      " * Prec@1 82.540 Prec@5 91.419\n",
      " * Prec@1 82.628 Prec@5 91.486\n",
      " * Prec@1 82.715 Prec@5 91.553\n",
      " * Prec@1 82.800 Prec@5 91.570\n",
      " * Prec@1 82.885 Prec@5 91.587\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.607 (0.532)\n",
      "\n",
      "Loss 1.0648 (0.8353)\n",
      "\n",
      "Prec@1 75.000 (82.824)\n",
      "\n",
      "Prec@5 87.500 (91.555)\n",
      "\n",
      " * Prec@1 82.824 Prec@5 91.555\n",
      " * Prec@1 82.907 Prec@5 91.572\n",
      " * Prec@1 83.036 Prec@5 91.635\n",
      " * Prec@1 82.929 Prec@5 91.604\n",
      " * Prec@1 82.963 Prec@5 91.667\n",
      " * Prec@1 82.858 Prec@5 91.544\n",
      " * Prec@1 82.847 Prec@5 91.469\n",
      " * Prec@1 82.835 Prec@5 91.395\n",
      " * Prec@1 82.959 Prec@5 91.457\n",
      " * Prec@1 82.857 Prec@5 91.384\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.559 (0.533)\n",
      "\n",
      "Loss 1.2414 (0.8465)\n",
      "\n",
      "Prec@1 81.250 (82.846)\n",
      "\n",
      "Prec@5 87.500 (91.356)\n",
      "\n",
      " * Prec@1 82.846 Prec@5 91.356\n",
      " * Prec@1 82.746 Prec@5 91.197\n",
      " * Prec@1 82.649 Prec@5 91.171\n",
      " * Prec@1 82.639 Prec@5 91.233\n",
      " * Prec@1 82.672 Prec@5 91.250\n",
      " * Prec@1 82.406 Prec@5 91.010\n",
      " * Prec@1 82.398 Prec@5 90.986\n",
      " * Prec@1 82.432 Prec@5 90.963\n",
      " * Prec@1 82.424 Prec@5 90.898\n",
      " * Prec@1 82.458 Prec@5 90.917\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.540 (0.534)\n",
      "\n",
      "Loss 1.5644 (0.8828)\n",
      "\n",
      "Prec@1 75.000 (82.409)\n",
      "\n",
      "Prec@5 81.250 (90.853)\n",
      "\n",
      " * Prec@1 82.409 Prec@5 90.853\n",
      " * Prec@1 82.525 Prec@5 90.913\n",
      " * Prec@1 82.639 Prec@5 90.972\n",
      " * Prec@1 82.711 Prec@5 91.031\n",
      " * Prec@1 82.823 Prec@5 91.089\n",
      " * Prec@1 82.772 Prec@5 90.986\n",
      " * Prec@1 82.683 Prec@5 90.924\n",
      " * Prec@1 82.793 Prec@5 90.981\n",
      " * Prec@1 82.704 Prec@5 90.959\n",
      " * Prec@1 82.734 Prec@5 91.016\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.531 (0.535)\n",
      "\n",
      "Loss 0.3881 (0.8662)\n",
      "\n",
      "Prec@1 81.250 (82.725)\n",
      "\n",
      "Prec@5 100.000 (91.071)\n",
      "\n",
      " * Prec@1 82.725 Prec@5 91.071\n",
      " * Prec@1 82.755 Prec@5 91.088\n",
      " * Prec@1 82.745 Prec@5 91.028\n",
      " * Prec@1 82.812 Prec@5 91.044\n",
      " * Prec@1 82.803 Prec@5 91.061\n",
      " * Prec@1 82.869 Prec@5 91.077\n",
      " * Prec@1 82.784 Prec@5 91.018\n",
      " * Prec@1 82.738 Prec@5 90.960\n",
      " * Prec@1 82.696 Prec@5 90.977\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [10][0/1515]\t\\Time 0.537 (0.537)\tData 0.425 (0.425)\tLoss 0.0009 (0.0009)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/1515]\t\\Time 0.491 (0.547)\tData 0.421 (0.442)\tLoss 0.0014 (0.0154)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][200/1515]\t\\Time 0.600 (0.547)\tData 0.495 (0.442)\tLoss 0.0020 (0.0135)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][300/1515]\t\\Time 0.593 (0.545)\tData 0.483 (0.440)\tLoss 0.0017 (0.0133)\tPrec@1 100.000 (99.585)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][400/1515]\t\\Time 0.507 (0.543)\tData 0.423 (0.439)\tLoss 0.0038 (0.0132)\tPrec@1 100.000 (99.610)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][500/1515]\t\\Time 0.546 (0.541)\tData 0.472 (0.437)\tLoss 0.0023 (0.0128)\tPrec@1 100.000 (99.638)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][600/1515]\t\\Time 0.562 (0.541)\tData 0.428 (0.438)\tLoss 0.0023 (0.0127)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][700/1515]\t\\Time 0.520 (0.540)\tData 0.409 (0.437)\tLoss 0.0027 (0.0123)\tPrec@1 100.000 (99.652)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][800/1515]\t\\Time 0.472 (0.540)\tData 0.362 (0.437)\tLoss 0.0033 (0.0129)\tPrec@1 100.000 (99.618)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][900/1515]\t\\Time 0.564 (0.542)\tData 0.490 (0.438)\tLoss 0.0022 (0.0132)\tPrec@1 100.000 (99.612)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][1000/1515]\t\\Time 0.534 (0.543)\tData 0.416 (0.439)\tLoss 0.0016 (0.0136)\tPrec@1 100.000 (99.600)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][1100/1515]\t\\Time 0.549 (0.542)\tData 0.439 (0.439)\tLoss 0.0036 (0.0129)\tPrec@1 100.000 (99.620)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][1200/1515]\t\\Time 0.557 (0.542)\tData 0.437 (0.438)\tLoss 0.0032 (0.0126)\tPrec@1 100.000 (99.636)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][1300/1515]\t\\Time 0.544 (0.542)\tData 0.458 (0.439)\tLoss 0.0029 (0.0132)\tPrec@1 100.000 (99.630)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][1400/1515]\t\\Time 0.557 (0.543)\tData 0.440 (0.440)\tLoss 0.0018 (0.0129)\tPrec@1 100.000 (99.639)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][1500/1515]\t\\Time 0.557 (0.543)\tData 0.437 (0.440)\tLoss 0.0248 (0.0128)\tPrec@1 100.000 (99.654)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.499 (0.499)\n",
      "\n",
      "Loss 0.2498 (0.2498)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 90.625 Prec@5 94.792\n",
      " * Prec@1 89.286 Prec@5 93.750\n",
      " * Prec@1 89.844 Prec@5 94.531\n",
      " * Prec@1 88.889 Prec@5 93.750\n",
      " * Prec@1 88.125 Prec@5 92.500\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.559 (0.553)\n",
      "\n",
      "Loss 0.5403 (0.6981)\n",
      "\n",
      "Prec@1 81.250 (87.500)\n",
      "\n",
      "Prec@5 100.000 (93.182)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 93.182\n",
      " * Prec@1 88.021 Prec@5 93.750\n",
      " * Prec@1 88.942 Prec@5 94.231\n",
      " * Prec@1 88.393 Prec@5 93.304\n",
      " * Prec@1 87.500 Prec@5 92.500\n",
      " * Prec@1 87.109 Prec@5 92.969\n",
      " * Prec@1 85.662 Prec@5 92.279\n",
      " * Prec@1 84.722 Prec@5 91.319\n",
      " * Prec@1 83.882 Prec@5 91.118\n",
      " * Prec@1 83.750 Prec@5 90.938\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.563 (0.549)\n",
      "\n",
      "Loss 0.7321 (0.8752)\n",
      "\n",
      "Prec@1 93.750 (84.226)\n",
      "\n",
      "Prec@5 93.750 (91.071)\n",
      "\n",
      " * Prec@1 84.226 Prec@5 91.071\n",
      " * Prec@1 83.807 Prec@5 90.341\n",
      " * Prec@1 83.967 Prec@5 90.489\n",
      " * Prec@1 83.854 Prec@5 90.885\n",
      " * Prec@1 83.750 Prec@5 91.000\n",
      " * Prec@1 84.135 Prec@5 91.346\n",
      " * Prec@1 84.491 Prec@5 91.667\n",
      " * Prec@1 84.375 Prec@5 91.741\n",
      " * Prec@1 84.483 Prec@5 91.810\n",
      " * Prec@1 84.167 Prec@5 91.667\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.505 (0.543)\n",
      "\n",
      "Loss 0.5437 (0.8208)\n",
      "\n",
      "Prec@1 87.500 (84.274)\n",
      "\n",
      "Prec@5 93.750 (91.734)\n",
      "\n",
      " * Prec@1 84.274 Prec@5 91.734\n",
      " * Prec@1 84.375 Prec@5 91.797\n",
      " * Prec@1 84.091 Prec@5 91.477\n",
      " * Prec@1 83.640 Prec@5 90.809\n",
      " * Prec@1 83.393 Prec@5 90.893\n",
      " * Prec@1 83.333 Prec@5 90.799\n",
      " * Prec@1 83.277 Prec@5 90.878\n",
      " * Prec@1 83.224 Prec@5 91.118\n",
      " * Prec@1 82.853 Prec@5 91.186\n",
      " * Prec@1 82.812 Prec@5 91.250\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.505 (0.538)\n",
      "\n",
      "Loss 0.7708 (0.8562)\n",
      "\n",
      "Prec@1 87.500 (82.927)\n",
      "\n",
      "Prec@5 93.750 (91.311)\n",
      "\n",
      " * Prec@1 82.927 Prec@5 91.311\n",
      " * Prec@1 82.589 Prec@5 91.220\n",
      " * Prec@1 82.703 Prec@5 91.424\n",
      " * Prec@1 82.670 Prec@5 91.477\n",
      " * Prec@1 82.778 Prec@5 91.528\n",
      " * Prec@1 82.745 Prec@5 91.440\n",
      " * Prec@1 83.112 Prec@5 91.622\n",
      " * Prec@1 83.073 Prec@5 91.536\n",
      " * Prec@1 83.291 Prec@5 91.582\n",
      " * Prec@1 83.125 Prec@5 91.500\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.457 (0.535)\n",
      "\n",
      "Loss 1.5198 (0.8485)\n",
      "\n",
      "Prec@1 68.750 (82.843)\n",
      "\n",
      "Prec@5 81.250 (91.299)\n",
      "\n",
      " * Prec@1 82.843 Prec@5 91.299\n",
      " * Prec@1 82.692 Prec@5 91.346\n",
      " * Prec@1 82.783 Prec@5 91.509\n",
      " * Prec@1 82.639 Prec@5 91.435\n",
      " * Prec@1 82.386 Prec@5 91.477\n",
      " * Prec@1 82.366 Prec@5 91.518\n",
      " * Prec@1 82.346 Prec@5 91.447\n",
      " * Prec@1 82.328 Prec@5 91.487\n",
      " * Prec@1 82.203 Prec@5 91.525\n",
      " * Prec@1 82.083 Prec@5 91.562\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.547 (0.535)\n",
      "\n",
      "Loss 1.9358 (0.8711)\n",
      "\n",
      "Prec@1 68.750 (81.865)\n",
      "\n",
      "Prec@5 75.000 (91.291)\n",
      "\n",
      " * Prec@1 81.865 Prec@5 91.291\n",
      " * Prec@1 81.754 Prec@5 91.230\n",
      " * Prec@1 81.647 Prec@5 91.270\n",
      " * Prec@1 81.641 Prec@5 91.211\n",
      " * Prec@1 81.346 Prec@5 90.769\n",
      " * Prec@1 81.534 Prec@5 90.814\n",
      " * Prec@1 81.716 Prec@5 90.858\n",
      " * Prec@1 81.710 Prec@5 90.901\n",
      " * Prec@1 81.793 Prec@5 90.942\n",
      " * Prec@1 81.786 Prec@5 90.982\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.501 (0.532)\n",
      "\n",
      "Loss 0.2390 (0.8785)\n",
      "\n",
      "Prec@1 93.750 (81.954)\n",
      "\n",
      "Prec@5 93.750 (91.021)\n",
      "\n",
      " * Prec@1 81.954 Prec@5 91.021\n",
      " * Prec@1 81.944 Prec@5 91.059\n",
      " * Prec@1 82.021 Prec@5 91.182\n",
      " * Prec@1 82.095 Prec@5 91.216\n",
      " * Prec@1 82.167 Prec@5 91.167\n",
      " * Prec@1 82.237 Prec@5 91.118\n",
      " * Prec@1 82.386 Prec@5 91.234\n",
      " * Prec@1 82.452 Prec@5 91.266\n",
      " * Prec@1 82.358 Prec@5 91.139\n",
      " * Prec@1 82.266 Prec@5 91.094\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.490 (0.531)\n",
      "\n",
      "Loss 2.0160 (0.8921)\n",
      "\n",
      "Prec@1 68.750 (82.099)\n",
      "\n",
      "Prec@5 75.000 (90.895)\n",
      "\n",
      " * Prec@1 82.099 Prec@5 90.895\n",
      " * Prec@1 82.088 Prec@5 90.930\n",
      " * Prec@1 82.003 Prec@5 90.964\n",
      " * Prec@1 81.994 Prec@5 90.997\n",
      " * Prec@1 82.059 Prec@5 90.956\n",
      " * Prec@1 82.122 Prec@5 90.988\n",
      " * Prec@1 82.184 Prec@5 91.020\n",
      " * Prec@1 82.173 Prec@5 90.909\n",
      " * Prec@1 82.163 Prec@5 90.941\n",
      " * Prec@1 82.222 Prec@5 90.972\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.480 (0.530)\n",
      "\n",
      "Loss 0.0036 (0.8646)\n",
      "\n",
      "Prec@1 100.000 (82.418)\n",
      "\n",
      "Prec@5 100.000 (91.071)\n",
      "\n",
      " * Prec@1 82.418 Prec@5 91.071\n",
      " * Prec@1 82.541 Prec@5 91.101\n",
      " * Prec@1 82.661 Prec@5 91.129\n",
      " * Prec@1 82.713 Prec@5 91.090\n",
      " * Prec@1 82.763 Prec@5 91.184\n",
      " * Prec@1 82.682 Prec@5 91.081\n",
      " * Prec@1 82.668 Prec@5 90.979\n",
      " * Prec@1 82.526 Prec@5 90.816\n",
      " * Prec@1 82.513 Prec@5 90.846\n",
      " * Prec@1 82.688 Prec@5 90.938\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.538 (0.530)\n",
      "\n",
      "Loss 1.1022 (0.8669)\n",
      "\n",
      "Prec@1 81.250 (82.673)\n",
      "\n",
      "Prec@5 87.500 (90.903)\n",
      "\n",
      " * Prec@1 82.673 Prec@5 90.903\n",
      " * Prec@1 82.843 Prec@5 90.993\n",
      " * Prec@1 82.767 Prec@5 90.959\n",
      " * Prec@1 82.812 Prec@5 90.925\n",
      " * Prec@1 82.798 Prec@5 90.893\n",
      " * Prec@1 82.842 Prec@5 90.861\n",
      " * Prec@1 83.002 Prec@5 90.946\n",
      " * Prec@1 83.102 Prec@5 91.030\n",
      " * Prec@1 83.142 Prec@5 91.055\n",
      " * Prec@1 83.011 Prec@5 91.136\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.490 (0.529)\n",
      "\n",
      "Loss 0.9604 (0.8486)\n",
      "\n",
      "Prec@1 81.250 (82.995)\n",
      "\n",
      "Prec@5 93.750 (91.160)\n",
      "\n",
      " * Prec@1 82.995 Prec@5 91.160\n",
      " * Prec@1 82.812 Prec@5 91.127\n",
      " * Prec@1 82.799 Prec@5 91.206\n",
      " * Prec@1 82.730 Prec@5 91.173\n",
      " * Prec@1 82.826 Prec@5 91.196\n",
      " * Prec@1 82.812 Prec@5 91.272\n",
      " * Prec@1 82.799 Prec@5 91.293\n",
      " * Prec@1 82.680 Prec@5 91.261\n",
      " * Prec@1 82.826 Prec@5 91.334\n",
      " * Prec@1 82.812 Prec@5 91.302\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.526 (0.528)\n",
      "\n",
      "Loss 0.3815 (0.8451)\n",
      "\n",
      "Prec@1 93.750 (82.903)\n",
      "\n",
      "Prec@5 100.000 (91.374)\n",
      "\n",
      " * Prec@1 82.903 Prec@5 91.374\n",
      " * Prec@1 82.941 Prec@5 91.342\n",
      " * Prec@1 83.028 Prec@5 91.362\n",
      " * Prec@1 83.065 Prec@5 91.331\n",
      " * Prec@1 83.150 Prec@5 91.350\n",
      " * Prec@1 83.135 Prec@5 91.369\n",
      " * Prec@1 83.120 Prec@5 91.437\n",
      " * Prec@1 83.203 Prec@5 91.504\n",
      " * Prec@1 83.285 Prec@5 91.521\n",
      " * Prec@1 83.365 Prec@5 91.587\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.581 (0.528)\n",
      "\n",
      "Loss 1.1087 (0.8222)\n",
      "\n",
      "Prec@1 75.000 (83.302)\n",
      "\n",
      "Prec@5 93.750 (91.603)\n",
      "\n",
      " * Prec@1 83.302 Prec@5 91.603\n",
      " * Prec@1 83.381 Prec@5 91.619\n",
      " * Prec@1 83.506 Prec@5 91.682\n",
      " * Prec@1 83.442 Prec@5 91.698\n",
      " * Prec@1 83.472 Prec@5 91.759\n",
      " * Prec@1 83.364 Prec@5 91.636\n",
      " * Prec@1 83.349 Prec@5 91.606\n",
      " * Prec@1 83.333 Prec@5 91.531\n",
      " * Prec@1 83.408 Prec@5 91.592\n",
      " * Prec@1 83.304 Prec@5 91.518\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.531 (0.528)\n",
      "\n",
      "Loss 1.3086 (0.8348)\n",
      "\n",
      "Prec@1 81.250 (83.289)\n",
      "\n",
      "Prec@5 87.500 (91.489)\n",
      "\n",
      " * Prec@1 83.289 Prec@5 91.489\n",
      " * Prec@1 83.143 Prec@5 91.329\n",
      " * Prec@1 83.042 Prec@5 91.259\n",
      " * Prec@1 83.030 Prec@5 91.276\n",
      " * Prec@1 83.060 Prec@5 91.293\n",
      " * Prec@1 82.791 Prec@5 91.010\n",
      " * Prec@1 82.738 Prec@5 90.986\n",
      " * Prec@1 82.770 Prec@5 91.005\n",
      " * Prec@1 82.760 Prec@5 90.982\n",
      " * Prec@1 82.792 Prec@5 91.042\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.536 (0.529)\n",
      "\n",
      "Loss 1.4528 (0.8711)\n",
      "\n",
      "Prec@1 75.000 (82.740)\n",
      "\n",
      "Prec@5 87.500 (91.018)\n",
      "\n",
      " * Prec@1 82.740 Prec@5 91.018\n",
      " * Prec@1 82.854 Prec@5 91.077\n",
      " * Prec@1 82.966 Prec@5 91.136\n",
      " * Prec@1 83.036 Prec@5 91.193\n",
      " * Prec@1 83.145 Prec@5 91.250\n",
      " * Prec@1 83.053 Prec@5 91.146\n",
      " * Prec@1 82.962 Prec@5 91.043\n",
      " * Prec@1 83.070 Prec@5 91.100\n",
      " * Prec@1 82.980 Prec@5 91.077\n",
      " * Prec@1 82.969 Prec@5 91.133\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.539 (0.530)\n",
      "\n",
      "Loss 0.3997 (0.8540)\n",
      "\n",
      "Prec@1 81.250 (82.958)\n",
      "\n",
      "Prec@5 100.000 (91.188)\n",
      "\n",
      " * Prec@1 82.958 Prec@5 91.188\n",
      " * Prec@1 83.025 Prec@5 91.204\n",
      " * Prec@1 83.014 Prec@5 91.143\n",
      " * Prec@1 83.079 Prec@5 91.159\n",
      " * Prec@1 83.106 Prec@5 91.174\n",
      " * Prec@1 83.170 Prec@5 91.190\n",
      " * Prec@1 83.084 Prec@5 91.205\n",
      " * Prec@1 83.036 Prec@5 91.146\n",
      " * Prec@1 82.993 Prec@5 91.162\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [11][0/1515]\t\\Time 0.498 (0.498)\tData 0.398 (0.398)\tLoss 0.0014 (0.0014)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1515]\t\\Time 0.544 (0.522)\tData 0.443 (0.420)\tLoss 0.0029 (0.0133)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [11][200/1515]\t\\Time 0.607 (0.529)\tData 0.496 (0.426)\tLoss 0.0021 (0.0107)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [11][300/1515]\t\\Time 0.584 (0.528)\tData 0.474 (0.426)\tLoss 0.0022 (0.0099)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [11][400/1515]\t\\Time 0.532 (0.534)\tData 0.412 (0.431)\tLoss 0.0173 (0.0102)\tPrec@1 100.000 (99.735)\tPrec@5 100.000 (99.984)\n",
      "Epoch: [11][500/1515]\t\\Time 0.537 (0.535)\tData 0.427 (0.432)\tLoss 0.0027 (0.0117)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [11][600/1515]\t\\Time 0.545 (0.536)\tData 0.445 (0.432)\tLoss 0.1477 (0.0126)\tPrec@1 93.750 (99.626)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [11][700/1515]\t\\Time 0.538 (0.536)\tData 0.418 (0.433)\tLoss 0.0011 (0.0122)\tPrec@1 100.000 (99.634)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [11][800/1515]\t\\Time 0.602 (0.536)\tData 0.494 (0.433)\tLoss 0.0031 (0.0117)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [11][900/1515]\t\\Time 0.571 (0.538)\tData 0.454 (0.435)\tLoss 0.0023 (0.0117)\tPrec@1 100.000 (99.653)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [11][1000/1515]\t\\Time 0.610 (0.539)\tData 0.490 (0.436)\tLoss 0.0023 (0.0121)\tPrec@1 100.000 (99.644)\tPrec@5 100.000 (99.994)\n",
      "Epoch: [11][1100/1515]\t\\Time 0.550 (0.540)\tData 0.440 (0.437)\tLoss 0.0345 (0.0118)\tPrec@1 100.000 (99.654)\tPrec@5 100.000 (99.994)\n",
      "Epoch: [11][1200/1515]\t\\Time 0.494 (0.540)\tData 0.371 (0.436)\tLoss 0.0033 (0.0118)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (99.995)\n",
      "Epoch: [11][1300/1515]\t\\Time 0.539 (0.541)\tData 0.439 (0.438)\tLoss 0.0033 (0.0127)\tPrec@1 100.000 (99.649)\tPrec@5 100.000 (99.995)\n",
      "Epoch: [11][1400/1515]\t\\Time 0.539 (0.541)\tData 0.412 (0.438)\tLoss 0.0027 (0.0129)\tPrec@1 100.000 (99.643)\tPrec@5 100.000 (99.996)\n",
      "Epoch: [11][1500/1515]\t\\Time 0.534 (0.541)\tData 0.453 (0.438)\tLoss 0.0061 (0.0135)\tPrec@1 100.000 (99.634)\tPrec@5 100.000 (99.996)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.471 (0.471)\n",
      "\n",
      "Loss 0.2723 (0.2723)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 92.188 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 95.000\n",
      " * Prec@1 91.667 Prec@5 94.792\n",
      " * Prec@1 90.179 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 94.531\n",
      " * Prec@1 89.583 Prec@5 93.750\n",
      " * Prec@1 88.750 Prec@5 92.500\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.514 (0.518)\n",
      "\n",
      "Loss 0.4568 (0.7070)\n",
      "\n",
      "Prec@1 81.250 (88.068)\n",
      "\n",
      "Prec@5 100.000 (93.182)\n",
      "\n",
      " * Prec@1 88.068 Prec@5 93.182\n",
      " * Prec@1 89.062 Prec@5 93.750\n",
      " * Prec@1 89.423 Prec@5 94.231\n",
      " * Prec@1 88.393 Prec@5 93.304\n",
      " * Prec@1 87.500 Prec@5 92.917\n",
      " * Prec@1 87.500 Prec@5 92.969\n",
      " * Prec@1 86.029 Prec@5 92.279\n",
      " * Prec@1 85.069 Prec@5 91.667\n",
      " * Prec@1 84.539 Prec@5 91.447\n",
      " * Prec@1 84.375 Prec@5 91.250\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.566 (0.517)\n",
      "\n",
      "Loss 0.7641 (0.8563)\n",
      "\n",
      "Prec@1 93.750 (84.821)\n",
      "\n",
      "Prec@5 93.750 (91.369)\n",
      "\n",
      " * Prec@1 84.821 Prec@5 91.369\n",
      " * Prec@1 84.375 Prec@5 90.625\n",
      " * Prec@1 84.511 Prec@5 90.761\n",
      " * Prec@1 84.115 Prec@5 91.146\n",
      " * Prec@1 84.000 Prec@5 91.250\n",
      " * Prec@1 84.375 Prec@5 91.587\n",
      " * Prec@1 84.722 Prec@5 91.898\n",
      " * Prec@1 84.598 Prec@5 91.741\n",
      " * Prec@1 84.698 Prec@5 92.026\n",
      " * Prec@1 84.583 Prec@5 91.875\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.518 (0.518)\n",
      "\n",
      "Loss 0.5609 (0.8225)\n",
      "\n",
      "Prec@1 87.500 (84.677)\n",
      "\n",
      "Prec@5 93.750 (91.935)\n",
      "\n",
      " * Prec@1 84.677 Prec@5 91.935\n",
      " * Prec@1 84.766 Prec@5 91.992\n",
      " * Prec@1 84.280 Prec@5 91.667\n",
      " * Prec@1 83.640 Prec@5 90.993\n",
      " * Prec@1 83.571 Prec@5 91.071\n",
      " * Prec@1 83.507 Prec@5 90.972\n",
      " * Prec@1 83.446 Prec@5 91.047\n",
      " * Prec@1 83.553 Prec@5 91.283\n",
      " * Prec@1 83.333 Prec@5 91.346\n",
      " * Prec@1 83.125 Prec@5 91.406\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.520 (0.517)\n",
      "\n",
      "Loss 0.8207 (0.8650)\n",
      "\n",
      "Prec@1 87.500 (83.232)\n",
      "\n",
      "Prec@5 93.750 (91.463)\n",
      "\n",
      " * Prec@1 83.232 Prec@5 91.463\n",
      " * Prec@1 82.887 Prec@5 91.369\n",
      " * Prec@1 82.994 Prec@5 91.570\n",
      " * Prec@1 82.955 Prec@5 91.619\n",
      " * Prec@1 83.194 Prec@5 91.667\n",
      " * Prec@1 83.016 Prec@5 91.576\n",
      " * Prec@1 83.245 Prec@5 91.755\n",
      " * Prec@1 83.203 Prec@5 91.667\n",
      " * Prec@1 83.418 Prec@5 91.709\n",
      " * Prec@1 83.375 Prec@5 91.625\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.537 (0.522)\n",
      "\n",
      "Loss 1.4982 (0.8541)\n",
      "\n",
      "Prec@1 75.000 (83.211)\n",
      "\n",
      "Prec@5 81.250 (91.422)\n",
      "\n",
      " * Prec@1 83.211 Prec@5 91.422\n",
      " * Prec@1 83.053 Prec@5 91.466\n",
      " * Prec@1 83.137 Prec@5 91.627\n",
      " * Prec@1 82.986 Prec@5 91.551\n",
      " * Prec@1 82.614 Prec@5 91.591\n",
      " * Prec@1 82.589 Prec@5 91.629\n",
      " * Prec@1 82.566 Prec@5 91.557\n",
      " * Prec@1 82.543 Prec@5 91.595\n",
      " * Prec@1 82.521 Prec@5 91.631\n",
      " * Prec@1 82.500 Prec@5 91.667\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.520 (0.525)\n",
      "\n",
      "Loss 1.8351 (0.8724)\n",
      "\n",
      "Prec@1 68.750 (82.275)\n",
      "\n",
      "Prec@5 75.000 (91.393)\n",
      "\n",
      " * Prec@1 82.275 Prec@5 91.393\n",
      " * Prec@1 82.157 Prec@5 91.331\n",
      " * Prec@1 82.044 Prec@5 91.369\n",
      " * Prec@1 82.129 Prec@5 91.309\n",
      " * Prec@1 81.827 Prec@5 90.962\n",
      " * Prec@1 81.913 Prec@5 91.004\n",
      " * Prec@1 82.090 Prec@5 91.045\n",
      " * Prec@1 82.077 Prec@5 91.085\n",
      " * Prec@1 82.065 Prec@5 91.123\n",
      " * Prec@1 82.054 Prec@5 90.982\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.510 (0.522)\n",
      "\n",
      "Loss 0.2192 (0.8822)\n",
      "\n",
      "Prec@1 93.750 (82.218)\n",
      "\n",
      "Prec@5 100.000 (91.109)\n",
      "\n",
      " * Prec@1 82.218 Prec@5 91.109\n",
      " * Prec@1 82.292 Prec@5 91.146\n",
      " * Prec@1 82.363 Prec@5 91.267\n",
      " * Prec@1 82.432 Prec@5 91.301\n",
      " * Prec@1 82.500 Prec@5 91.250\n",
      " * Prec@1 82.566 Prec@5 91.201\n",
      " * Prec@1 82.711 Prec@5 91.315\n",
      " * Prec@1 82.772 Prec@5 91.346\n",
      " * Prec@1 82.674 Prec@5 91.218\n",
      " * Prec@1 82.578 Prec@5 91.094\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.534 (0.524)\n",
      "\n",
      "Loss 2.1048 (0.8916)\n",
      "\n",
      "Prec@1 68.750 (82.407)\n",
      "\n",
      "Prec@5 75.000 (90.895)\n",
      "\n",
      " * Prec@1 82.407 Prec@5 90.895\n",
      " * Prec@1 82.393 Prec@5 90.930\n",
      " * Prec@1 82.304 Prec@5 91.039\n",
      " * Prec@1 82.292 Prec@5 91.071\n",
      " * Prec@1 82.279 Prec@5 91.029\n",
      " * Prec@1 82.340 Prec@5 91.061\n",
      " * Prec@1 82.399 Prec@5 91.092\n",
      " * Prec@1 82.315 Prec@5 90.980\n",
      " * Prec@1 82.303 Prec@5 91.011\n",
      " * Prec@1 82.361 Prec@5 91.042\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.437 (0.523)\n",
      "\n",
      "Loss 0.0033 (0.8639)\n",
      "\n",
      "Prec@1 100.000 (82.555)\n",
      "\n",
      "Prec@5 100.000 (91.140)\n",
      "\n",
      " * Prec@1 82.555 Prec@5 91.140\n",
      " * Prec@1 82.677 Prec@5 91.168\n",
      " * Prec@1 82.796 Prec@5 91.196\n",
      " * Prec@1 82.846 Prec@5 91.157\n",
      " * Prec@1 82.895 Prec@5 91.184\n",
      " * Prec@1 82.747 Prec@5 91.081\n",
      " * Prec@1 82.732 Prec@5 91.044\n",
      " * Prec@1 82.589 Prec@5 90.880\n",
      " * Prec@1 82.513 Prec@5 90.909\n",
      " * Prec@1 82.625 Prec@5 91.000\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.573 (0.523)\n",
      "\n",
      "Loss 1.1309 (0.8720)\n",
      "\n",
      "Prec@1 81.250 (82.611)\n",
      "\n",
      "Prec@5 87.500 (90.965)\n",
      "\n",
      " * Prec@1 82.611 Prec@5 90.965\n",
      " * Prec@1 82.782 Prec@5 91.054\n",
      " * Prec@1 82.706 Prec@5 91.019\n",
      " * Prec@1 82.752 Prec@5 90.986\n",
      " * Prec@1 82.738 Prec@5 90.952\n",
      " * Prec@1 82.783 Prec@5 90.979\n",
      " * Prec@1 82.944 Prec@5 91.063\n",
      " * Prec@1 83.044 Prec@5 91.146\n",
      " * Prec@1 83.085 Prec@5 91.170\n",
      " * Prec@1 82.955 Prec@5 91.250\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.489 (0.524)\n",
      "\n",
      "Loss 1.0411 (0.8538)\n",
      "\n",
      "Prec@1 81.250 (82.939)\n",
      "\n",
      "Prec@5 93.750 (91.273)\n",
      "\n",
      " * Prec@1 82.939 Prec@5 91.273\n",
      " * Prec@1 82.757 Prec@5 91.183\n",
      " * Prec@1 82.799 Prec@5 91.261\n",
      " * Prec@1 82.730 Prec@5 91.228\n",
      " * Prec@1 82.826 Prec@5 91.250\n",
      " * Prec@1 82.866 Prec@5 91.325\n",
      " * Prec@1 82.853 Prec@5 91.346\n",
      " * Prec@1 82.733 Prec@5 91.314\n",
      " * Prec@1 82.878 Prec@5 91.387\n",
      " * Prec@1 82.812 Prec@5 91.406\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.511 (0.524)\n",
      "\n",
      "Loss 0.2505 (0.8492)\n",
      "\n",
      "Prec@1 93.750 (82.903)\n",
      "\n",
      "Prec@5 100.000 (91.477)\n",
      "\n",
      " * Prec@1 82.903 Prec@5 91.477\n",
      " * Prec@1 82.941 Prec@5 91.445\n",
      " * Prec@1 83.028 Prec@5 91.463\n",
      " * Prec@1 83.065 Prec@5 91.431\n",
      " * Prec@1 83.100 Prec@5 91.450\n",
      " * Prec@1 83.135 Prec@5 91.518\n",
      " * Prec@1 83.169 Prec@5 91.585\n",
      " * Prec@1 83.252 Prec@5 91.650\n",
      " * Prec@1 83.333 Prec@5 91.667\n",
      " * Prec@1 83.413 Prec@5 91.731\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.568 (0.523)\n",
      "\n",
      "Loss 1.1024 (0.8242)\n",
      "\n",
      "Prec@1 75.000 (83.349)\n",
      "\n",
      "Prec@5 87.500 (91.698)\n",
      "\n",
      " * Prec@1 83.349 Prec@5 91.698\n",
      " * Prec@1 83.428 Prec@5 91.714\n",
      " * Prec@1 83.553 Prec@5 91.776\n",
      " * Prec@1 83.442 Prec@5 91.791\n",
      " * Prec@1 83.472 Prec@5 91.852\n",
      " * Prec@1 83.364 Prec@5 91.682\n",
      " * Prec@1 83.349 Prec@5 91.606\n",
      " * Prec@1 83.333 Prec@5 91.531\n",
      " * Prec@1 83.408 Prec@5 91.592\n",
      " * Prec@1 83.348 Prec@5 91.562\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.531 (0.523)\n",
      "\n",
      "Loss 1.2137 (0.8367)\n",
      "\n",
      "Prec@1 81.250 (83.333)\n",
      "\n",
      "Prec@5 87.500 (91.534)\n",
      "\n",
      " * Prec@1 83.333 Prec@5 91.534\n",
      " * Prec@1 83.187 Prec@5 91.373\n",
      " * Prec@1 83.086 Prec@5 91.346\n",
      " * Prec@1 83.073 Prec@5 91.406\n",
      " * Prec@1 83.103 Prec@5 91.422\n",
      " * Prec@1 82.834 Prec@5 91.182\n",
      " * Prec@1 82.781 Prec@5 91.156\n",
      " * Prec@1 82.812 Prec@5 91.174\n",
      " * Prec@1 82.802 Prec@5 91.149\n",
      " * Prec@1 82.833 Prec@5 91.167\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.512 (0.525)\n",
      "\n",
      "Loss 1.4513 (0.8709)\n",
      "\n",
      "Prec@1 75.000 (82.781)\n",
      "\n",
      "Prec@5 87.500 (91.142)\n",
      "\n",
      " * Prec@1 82.781 Prec@5 91.142\n",
      " * Prec@1 82.895 Prec@5 91.201\n",
      " * Prec@1 82.925 Prec@5 91.258\n",
      " * Prec@1 82.995 Prec@5 91.315\n",
      " * Prec@1 83.105 Prec@5 91.371\n",
      " * Prec@1 83.053 Prec@5 91.266\n",
      " * Prec@1 82.962 Prec@5 91.202\n",
      " * Prec@1 83.070 Prec@5 91.258\n",
      " * Prec@1 82.980 Prec@5 91.234\n",
      " * Prec@1 82.969 Prec@5 91.250\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.517 (0.525)\n",
      "\n",
      "Loss 0.3780 (0.8546)\n",
      "\n",
      "Prec@1 87.500 (82.997)\n",
      "\n",
      "Prec@5 100.000 (91.304)\n",
      "\n",
      " * Prec@1 82.997 Prec@5 91.304\n",
      " * Prec@1 83.063 Prec@5 91.319\n",
      " * Prec@1 83.014 Prec@5 91.258\n",
      " * Prec@1 83.079 Prec@5 91.273\n",
      " * Prec@1 83.106 Prec@5 91.326\n",
      " * Prec@1 83.170 Prec@5 91.340\n",
      " * Prec@1 83.084 Prec@5 91.355\n",
      " * Prec@1 83.036 Prec@5 91.295\n",
      " * Prec@1 82.993 Prec@5 91.311\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [12][0/1515]\t\\Time 0.530 (0.530)\tData 0.430 (0.430)\tLoss 0.0022 (0.0022)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1515]\t\\Time 0.560 (0.527)\tData 0.430 (0.425)\tLoss 0.0029 (0.0185)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][200/1515]\t\\Time 0.520 (0.527)\tData 0.420 (0.424)\tLoss 0.0024 (0.0134)\tPrec@1 100.000 (99.658)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][300/1515]\t\\Time 0.484 (0.526)\tData 0.380 (0.424)\tLoss 0.0016 (0.0128)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][400/1515]\t\\Time 0.548 (0.531)\tData 0.438 (0.428)\tLoss 0.0273 (0.0125)\tPrec@1 100.000 (99.642)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][500/1515]\t\\Time 0.440 (0.530)\tData 0.370 (0.428)\tLoss 0.0048 (0.0142)\tPrec@1 100.000 (99.601)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][600/1515]\t\\Time 0.510 (0.531)\tData 0.400 (0.429)\tLoss 0.0020 (0.0146)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][700/1515]\t\\Time 0.530 (0.534)\tData 0.420 (0.432)\tLoss 0.0044 (0.0136)\tPrec@1 100.000 (99.634)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][800/1515]\t\\Time 0.525 (0.534)\tData 0.405 (0.432)\tLoss 0.0047 (0.0138)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][900/1515]\t\\Time 0.500 (0.536)\tData 0.380 (0.434)\tLoss 0.0025 (0.0131)\tPrec@1 100.000 (99.653)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1000/1515]\t\\Time 0.450 (0.538)\tData 0.360 (0.436)\tLoss 0.0018 (0.0127)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1100/1515]\t\\Time 0.570 (0.540)\tData 0.451 (0.437)\tLoss 0.0019 (0.0132)\tPrec@1 100.000 (99.631)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1200/1515]\t\\Time 0.560 (0.541)\tData 0.490 (0.439)\tLoss 0.0027 (0.0135)\tPrec@1 100.000 (99.636)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1300/1515]\t\\Time 0.579 (0.541)\tData 0.509 (0.439)\tLoss 0.0027 (0.0135)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1400/1515]\t\\Time 0.591 (0.541)\tData 0.491 (0.439)\tLoss 0.2276 (0.0132)\tPrec@1 93.750 (99.634)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1500/1515]\t\\Time 0.490 (0.542)\tData 0.390 (0.440)\tLoss 0.0013 (0.0135)\tPrec@1 100.000 (99.621)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.480 (0.480)\n",
      "\n",
      "Loss 0.2777 (0.2777)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 89.583 Prec@5 93.750\n",
      " * Prec@1 88.393 Prec@5 92.857\n",
      " * Prec@1 89.062 Prec@5 93.750\n",
      " * Prec@1 88.194 Prec@5 92.361\n",
      " * Prec@1 87.500 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.520 (0.544)\n",
      "\n",
      "Loss 0.5289 (0.6930)\n",
      "\n",
      "Prec@1 81.250 (86.932)\n",
      "\n",
      "Prec@5 100.000 (92.045)\n",
      "\n",
      " * Prec@1 86.932 Prec@5 92.045\n",
      " * Prec@1 87.500 Prec@5 92.708\n",
      " * Prec@1 88.462 Prec@5 93.269\n",
      " * Prec@1 87.946 Prec@5 92.411\n",
      " * Prec@1 87.083 Prec@5 91.667\n",
      " * Prec@1 86.719 Prec@5 92.188\n",
      " * Prec@1 85.294 Prec@5 91.176\n",
      " * Prec@1 84.375 Prec@5 90.278\n",
      " * Prec@1 83.882 Prec@5 89.803\n",
      " * Prec@1 83.750 Prec@5 89.688\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.530 (0.544)\n",
      "\n",
      "Loss 0.6800 (0.8402)\n",
      "\n",
      "Prec@1 93.750 (84.226)\n",
      "\n",
      "Prec@5 93.750 (89.881)\n",
      "\n",
      " * Prec@1 84.226 Prec@5 89.881\n",
      " * Prec@1 83.807 Prec@5 89.205\n",
      " * Prec@1 83.696 Prec@5 89.402\n",
      " * Prec@1 83.333 Prec@5 89.844\n",
      " * Prec@1 83.000 Prec@5 90.000\n",
      " * Prec@1 83.413 Prec@5 90.385\n",
      " * Prec@1 83.796 Prec@5 90.741\n",
      " * Prec@1 83.705 Prec@5 90.625\n",
      " * Prec@1 83.621 Prec@5 90.948\n",
      " * Prec@1 83.333 Prec@5 90.833\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.530 (0.547)\n",
      "\n",
      "Loss 0.5418 (0.8129)\n",
      "\n",
      "Prec@1 93.750 (83.669)\n",
      "\n",
      "Prec@5 93.750 (90.927)\n",
      "\n",
      " * Prec@1 83.669 Prec@5 90.927\n",
      " * Prec@1 83.789 Prec@5 91.016\n",
      " * Prec@1 83.523 Prec@5 90.720\n",
      " * Prec@1 82.904 Prec@5 90.074\n",
      " * Prec@1 82.857 Prec@5 90.179\n",
      " * Prec@1 82.812 Prec@5 90.104\n",
      " * Prec@1 82.939 Prec@5 90.203\n",
      " * Prec@1 83.059 Prec@5 90.461\n",
      " * Prec@1 82.853 Prec@5 90.545\n",
      " * Prec@1 82.812 Prec@5 90.625\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.510 (0.544)\n",
      "\n",
      "Loss 0.8102 (0.8490)\n",
      "\n",
      "Prec@1 81.250 (82.774)\n",
      "\n",
      "Prec@5 93.750 (90.701)\n",
      "\n",
      " * Prec@1 82.774 Prec@5 90.701\n",
      " * Prec@1 82.440 Prec@5 90.625\n",
      " * Prec@1 82.558 Prec@5 90.843\n",
      " * Prec@1 82.670 Prec@5 90.909\n",
      " * Prec@1 82.639 Prec@5 90.972\n",
      " * Prec@1 82.609 Prec@5 90.897\n",
      " * Prec@1 82.979 Prec@5 91.090\n",
      " * Prec@1 82.943 Prec@5 91.016\n",
      " * Prec@1 83.163 Prec@5 91.071\n",
      " * Prec@1 83.125 Prec@5 91.125\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.500 (0.540)\n",
      "\n",
      "Loss 1.5459 (0.8372)\n",
      "\n",
      "Prec@1 75.000 (82.966)\n",
      "\n",
      "Prec@5 81.250 (90.931)\n",
      "\n",
      " * Prec@1 82.966 Prec@5 90.931\n",
      " * Prec@1 82.812 Prec@5 90.865\n",
      " * Prec@1 82.901 Prec@5 91.038\n",
      " * Prec@1 82.755 Prec@5 90.972\n",
      " * Prec@1 82.500 Prec@5 91.023\n",
      " * Prec@1 82.478 Prec@5 91.071\n",
      " * Prec@1 82.566 Prec@5 91.009\n",
      " * Prec@1 82.543 Prec@5 91.056\n",
      " * Prec@1 82.521 Prec@5 91.102\n",
      " * Prec@1 82.500 Prec@5 91.146\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.530 (0.542)\n",
      "\n",
      "Loss 1.9811 (0.8538)\n",
      "\n",
      "Prec@1 62.500 (82.172)\n",
      "\n",
      "Prec@5 75.000 (90.881)\n",
      "\n",
      " * Prec@1 82.172 Prec@5 90.881\n",
      " * Prec@1 82.056 Prec@5 90.827\n",
      " * Prec@1 82.044 Prec@5 90.873\n",
      " * Prec@1 82.031 Prec@5 90.820\n",
      " * Prec@1 81.731 Prec@5 90.481\n",
      " * Prec@1 81.913 Prec@5 90.530\n",
      " * Prec@1 82.090 Prec@5 90.578\n",
      " * Prec@1 82.077 Prec@5 90.625\n",
      " * Prec@1 82.156 Prec@5 90.670\n",
      " * Prec@1 82.143 Prec@5 90.714\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.501 (0.536)\n",
      "\n",
      "Loss 0.2525 (0.8641)\n",
      "\n",
      "Prec@1 93.750 (82.306)\n",
      "\n",
      "Prec@5 93.750 (90.757)\n",
      "\n",
      " * Prec@1 82.306 Prec@5 90.757\n",
      " * Prec@1 82.378 Prec@5 90.799\n",
      " * Prec@1 82.449 Prec@5 90.925\n",
      " * Prec@1 82.517 Prec@5 91.047\n",
      " * Prec@1 82.583 Prec@5 91.000\n",
      " * Prec@1 82.648 Prec@5 90.954\n",
      " * Prec@1 82.792 Prec@5 91.071\n",
      " * Prec@1 82.853 Prec@5 91.026\n",
      " * Prec@1 82.753 Prec@5 90.902\n",
      " * Prec@1 82.656 Prec@5 90.859\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.450 (0.534)\n",
      "\n",
      "Loss 1.8611 (0.8735)\n",
      "\n",
      "Prec@1 68.750 (82.485)\n",
      "\n",
      "Prec@5 81.250 (90.741)\n",
      "\n",
      " * Prec@1 82.485 Prec@5 90.741\n",
      " * Prec@1 82.470 Prec@5 90.777\n",
      " * Prec@1 82.455 Prec@5 90.813\n",
      " * Prec@1 82.440 Prec@5 90.848\n",
      " * Prec@1 82.500 Prec@5 90.809\n",
      " * Prec@1 82.558 Prec@5 90.770\n",
      " * Prec@1 82.615 Prec@5 90.805\n",
      " * Prec@1 82.599 Prec@5 90.696\n",
      " * Prec@1 82.654 Prec@5 90.730\n",
      " * Prec@1 82.708 Prec@5 90.764\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.454 (0.531)\n",
      "\n",
      "Loss 0.0036 (0.8451)\n",
      "\n",
      "Prec@1 100.000 (82.898)\n",
      "\n",
      "Prec@5 100.000 (90.865)\n",
      "\n",
      " * Prec@1 82.898 Prec@5 90.865\n",
      " * Prec@1 83.016 Prec@5 90.897\n",
      " * Prec@1 83.132 Prec@5 90.927\n",
      " * Prec@1 83.178 Prec@5 90.957\n",
      " * Prec@1 83.224 Prec@5 90.987\n",
      " * Prec@1 83.073 Prec@5 90.885\n",
      " * Prec@1 83.054 Prec@5 90.786\n",
      " * Prec@1 82.908 Prec@5 90.625\n",
      " * Prec@1 82.891 Prec@5 90.657\n",
      " * Prec@1 83.062 Prec@5 90.750\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.581 (0.532)\n",
      "\n",
      "Loss 1.0794 (0.8462)\n",
      "\n",
      "Prec@1 81.250 (83.045)\n",
      "\n",
      "Prec@5 87.500 (90.718)\n",
      "\n",
      " * Prec@1 83.045 Prec@5 90.718\n",
      " * Prec@1 83.150 Prec@5 90.809\n",
      " * Prec@1 83.070 Prec@5 90.777\n",
      " * Prec@1 83.053 Prec@5 90.805\n",
      " * Prec@1 83.036 Prec@5 90.774\n",
      " * Prec@1 83.078 Prec@5 90.802\n",
      " * Prec@1 83.236 Prec@5 90.888\n",
      " * Prec@1 83.333 Prec@5 90.972\n",
      " * Prec@1 83.372 Prec@5 90.998\n",
      " * Prec@1 83.239 Prec@5 91.023\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.490 (0.531)\n",
      "\n",
      "Loss 1.0350 (0.8300)\n",
      "\n",
      "Prec@1 81.250 (83.221)\n",
      "\n",
      "Prec@5 93.750 (91.047)\n",
      "\n",
      " * Prec@1 83.221 Prec@5 91.047\n",
      " * Prec@1 83.036 Prec@5 91.016\n",
      " * Prec@1 83.020 Prec@5 91.095\n",
      " * Prec@1 82.950 Prec@5 91.064\n",
      " * Prec@1 83.043 Prec@5 91.087\n",
      " * Prec@1 83.028 Prec@5 91.164\n",
      " * Prec@1 83.013 Prec@5 91.186\n",
      " * Prec@1 82.892 Prec@5 91.155\n",
      " * Prec@1 83.036 Prec@5 91.229\n",
      " * Prec@1 83.021 Prec@5 91.250\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.521 (0.530)\n",
      "\n",
      "Loss 0.3225 (0.8270)\n",
      "\n",
      "Prec@1 93.750 (83.110)\n",
      "\n",
      "Prec@5 100.000 (91.322)\n",
      "\n",
      " * Prec@1 83.110 Prec@5 91.322\n",
      " * Prec@1 83.145 Prec@5 91.291\n",
      " * Prec@1 83.232 Prec@5 91.311\n",
      " * Prec@1 83.266 Prec@5 91.331\n",
      " * Prec@1 83.350 Prec@5 91.350\n",
      " * Prec@1 83.383 Prec@5 91.369\n",
      " * Prec@1 83.415 Prec@5 91.437\n",
      " * Prec@1 83.496 Prec@5 91.504\n",
      " * Prec@1 83.576 Prec@5 91.521\n",
      " * Prec@1 83.654 Prec@5 91.587\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.560 (0.529)\n",
      "\n",
      "Loss 1.0312 (0.8038)\n",
      "\n",
      "Prec@1 75.000 (83.588)\n",
      "\n",
      "Prec@5 87.500 (91.555)\n",
      "\n",
      " * Prec@1 83.588 Prec@5 91.555\n",
      " * Prec@1 83.665 Prec@5 91.572\n",
      " * Prec@1 83.741 Prec@5 91.635\n",
      " * Prec@1 83.675 Prec@5 91.651\n",
      " * Prec@1 83.704 Prec@5 91.713\n",
      " * Prec@1 83.594 Prec@5 91.544\n",
      " * Prec@1 83.577 Prec@5 91.515\n",
      " * Prec@1 83.560 Prec@5 91.440\n",
      " * Prec@1 83.633 Prec@5 91.502\n",
      " * Prec@1 83.527 Prec@5 91.429\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.528 (0.529)\n",
      "\n",
      "Loss 1.1461 (0.8138)\n",
      "\n",
      "Prec@1 87.500 (83.555)\n",
      "\n",
      "Prec@5 87.500 (91.401)\n",
      "\n",
      " * Prec@1 83.555 Prec@5 91.401\n",
      " * Prec@1 83.407 Prec@5 91.241\n",
      " * Prec@1 83.304 Prec@5 91.215\n",
      " * Prec@1 83.290 Prec@5 91.276\n",
      " * Prec@1 83.319 Prec@5 91.293\n",
      " * Prec@1 83.048 Prec@5 91.053\n",
      " * Prec@1 82.993 Prec@5 91.029\n",
      " * Prec@1 83.024 Prec@5 91.005\n",
      " * Prec@1 83.012 Prec@5 90.982\n",
      " * Prec@1 83.042 Prec@5 91.042\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.520 (0.530)\n",
      "\n",
      "Loss 1.4169 (0.8493)\n",
      "\n",
      "Prec@1 75.000 (82.988)\n",
      "\n",
      "Prec@5 87.500 (91.018)\n",
      "\n",
      " * Prec@1 82.988 Prec@5 91.018\n",
      " * Prec@1 83.100 Prec@5 91.077\n",
      " * Prec@1 83.129 Prec@5 91.136\n",
      " * Prec@1 83.198 Prec@5 91.193\n",
      " * Prec@1 83.306 Prec@5 91.250\n",
      " * Prec@1 83.213 Prec@5 91.146\n",
      " * Prec@1 83.121 Prec@5 91.083\n",
      " * Prec@1 83.228 Prec@5 91.139\n",
      " * Prec@1 83.137 Prec@5 91.116\n",
      " * Prec@1 83.125 Prec@5 91.172\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.490 (0.529)\n",
      "\n",
      "Loss 0.4114 (0.8332)\n",
      "\n",
      "Prec@1 87.500 (83.152)\n",
      "\n",
      "Prec@5 100.000 (91.227)\n",
      "\n",
      " * Prec@1 83.152 Prec@5 91.227\n",
      " * Prec@1 83.218 Prec@5 91.242\n",
      " * Prec@1 83.206 Prec@5 91.181\n",
      " * Prec@1 83.270 Prec@5 91.197\n",
      " * Prec@1 83.295 Prec@5 91.212\n",
      " * Prec@1 83.321 Prec@5 91.227\n",
      " * Prec@1 83.234 Prec@5 91.243\n",
      " * Prec@1 83.185 Prec@5 91.183\n",
      " * Prec@1 83.179 Prec@5 91.199\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [13][0/1515]\t\\Time 0.519 (0.519)\tData 0.409 (0.409)\tLoss 0.0027 (0.0027)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1515]\t\\Time 0.540 (0.536)\tData 0.420 (0.431)\tLoss 0.0035 (0.0095)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][200/1515]\t\\Time 0.500 (0.532)\tData 0.390 (0.429)\tLoss 0.0019 (0.0093)\tPrec@1 100.000 (99.782)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][300/1515]\t\\Time 0.510 (0.534)\tData 0.400 (0.430)\tLoss 0.0031 (0.0112)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][400/1515]\t\\Time 0.540 (0.536)\tData 0.430 (0.431)\tLoss 0.0026 (0.0117)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][500/1515]\t\\Time 0.560 (0.538)\tData 0.460 (0.433)\tLoss 0.0030 (0.0123)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][600/1515]\t\\Time 0.533 (0.539)\tData 0.432 (0.436)\tLoss 0.0036 (0.0126)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][700/1515]\t\\Time 0.550 (0.542)\tData 0.450 (0.438)\tLoss 0.0026 (0.0131)\tPrec@1 100.000 (99.599)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][800/1515]\t\\Time 0.641 (0.543)\tData 0.531 (0.439)\tLoss 0.0021 (0.0124)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][900/1515]\t\\Time 0.561 (0.544)\tData 0.441 (0.441)\tLoss 0.0021 (0.0128)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1000/1515]\t\\Time 0.560 (0.545)\tData 0.450 (0.441)\tLoss 0.0041 (0.0132)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1100/1515]\t\\Time 0.503 (0.544)\tData 0.433 (0.440)\tLoss 0.0059 (0.0127)\tPrec@1 100.000 (99.637)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1200/1515]\t\\Time 0.480 (0.543)\tData 0.370 (0.439)\tLoss 0.0022 (0.0127)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1300/1515]\t\\Time 0.551 (0.542)\tData 0.441 (0.439)\tLoss 0.0027 (0.0125)\tPrec@1 100.000 (99.630)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1400/1515]\t\\Time 0.550 (0.543)\tData 0.440 (0.439)\tLoss 0.0036 (0.0128)\tPrec@1 100.000 (99.612)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1500/1515]\t\\Time 0.540 (0.543)\tData 0.472 (0.439)\tLoss 0.0040 (0.0128)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.491 (0.491)\n",
      "\n",
      "Loss 0.2925 (0.2925)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 89.583 Prec@5 93.750\n",
      " * Prec@1 88.393 Prec@5 92.857\n",
      " * Prec@1 89.062 Prec@5 93.750\n",
      " * Prec@1 88.194 Prec@5 93.056\n",
      " * Prec@1 87.500 Prec@5 91.875\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.510 (0.541)\n",
      "\n",
      "Loss 0.5399 (0.6642)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 100.000 (92.614)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 92.614\n",
      " * Prec@1 87.500 Prec@5 93.229\n",
      " * Prec@1 88.462 Prec@5 93.750\n",
      " * Prec@1 87.946 Prec@5 92.857\n",
      " * Prec@1 87.083 Prec@5 92.083\n",
      " * Prec@1 87.109 Prec@5 92.188\n",
      " * Prec@1 86.029 Prec@5 91.176\n",
      " * Prec@1 85.069 Prec@5 90.625\n",
      " * Prec@1 84.539 Prec@5 90.461\n",
      " * Prec@1 84.375 Prec@5 90.312\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.540 (0.529)\n",
      "\n",
      "Loss 0.6903 (0.8122)\n",
      "\n",
      "Prec@1 93.750 (84.821)\n",
      "\n",
      "Prec@5 93.750 (90.476)\n",
      "\n",
      " * Prec@1 84.821 Prec@5 90.476\n",
      " * Prec@1 84.375 Prec@5 89.773\n",
      " * Prec@1 84.511 Prec@5 90.217\n",
      " * Prec@1 84.115 Prec@5 90.625\n",
      " * Prec@1 84.000 Prec@5 90.750\n",
      " * Prec@1 84.375 Prec@5 91.106\n",
      " * Prec@1 84.722 Prec@5 91.435\n",
      " * Prec@1 84.598 Prec@5 91.071\n",
      " * Prec@1 84.483 Prec@5 91.379\n",
      " * Prec@1 84.167 Prec@5 91.250\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.500 (0.527)\n",
      "\n",
      "Loss 0.4961 (0.7801)\n",
      "\n",
      "Prec@1 87.500 (84.274)\n",
      "\n",
      "Prec@5 93.750 (91.331)\n",
      "\n",
      " * Prec@1 84.274 Prec@5 91.331\n",
      " * Prec@1 84.570 Prec@5 91.406\n",
      " * Prec@1 84.280 Prec@5 91.098\n",
      " * Prec@1 83.640 Prec@5 90.441\n",
      " * Prec@1 83.571 Prec@5 90.536\n",
      " * Prec@1 83.507 Prec@5 90.451\n",
      " * Prec@1 83.446 Prec@5 90.541\n",
      " * Prec@1 83.553 Prec@5 90.789\n",
      " * Prec@1 83.333 Prec@5 90.865\n",
      " * Prec@1 83.125 Prec@5 90.938\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.509 (0.526)\n",
      "\n",
      "Loss 0.7561 (0.8204)\n",
      "\n",
      "Prec@1 87.500 (83.232)\n",
      "\n",
      "Prec@5 93.750 (91.006)\n",
      "\n",
      " * Prec@1 83.232 Prec@5 91.006\n",
      " * Prec@1 82.887 Prec@5 91.071\n",
      " * Prec@1 82.994 Prec@5 91.279\n",
      " * Prec@1 83.097 Prec@5 91.335\n",
      " * Prec@1 83.194 Prec@5 91.389\n",
      " * Prec@1 83.016 Prec@5 91.304\n",
      " * Prec@1 83.378 Prec@5 91.489\n",
      " * Prec@1 83.333 Prec@5 91.406\n",
      " * Prec@1 83.546 Prec@5 91.454\n",
      " * Prec@1 83.500 Prec@5 91.500\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.501 (0.525)\n",
      "\n",
      "Loss 1.3861 (0.8152)\n",
      "\n",
      "Prec@1 75.000 (83.333)\n",
      "\n",
      "Prec@5 81.250 (91.299)\n",
      "\n",
      " * Prec@1 83.333 Prec@5 91.299\n",
      " * Prec@1 83.173 Prec@5 91.346\n",
      " * Prec@1 83.373 Prec@5 91.509\n",
      " * Prec@1 83.218 Prec@5 91.435\n",
      " * Prec@1 83.068 Prec@5 91.477\n",
      " * Prec@1 83.036 Prec@5 91.406\n",
      " * Prec@1 83.004 Prec@5 91.338\n",
      " * Prec@1 82.974 Prec@5 91.379\n",
      " * Prec@1 82.945 Prec@5 91.419\n",
      " * Prec@1 82.917 Prec@5 91.458\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.531 (0.527)\n",
      "\n",
      "Loss 2.0663 (0.8357)\n",
      "\n",
      "Prec@1 68.750 (82.684)\n",
      "\n",
      "Prec@5 75.000 (91.189)\n",
      "\n",
      " * Prec@1 82.684 Prec@5 91.189\n",
      " * Prec@1 82.560 Prec@5 91.129\n",
      " * Prec@1 82.540 Prec@5 91.171\n",
      " * Prec@1 82.617 Prec@5 91.113\n",
      " * Prec@1 82.308 Prec@5 90.769\n",
      " * Prec@1 82.386 Prec@5 90.814\n",
      " * Prec@1 82.556 Prec@5 90.858\n",
      " * Prec@1 82.537 Prec@5 90.901\n",
      " * Prec@1 82.518 Prec@5 90.942\n",
      " * Prec@1 82.500 Prec@5 90.893\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.490 (0.523)\n",
      "\n",
      "Loss 0.1825 (0.8456)\n",
      "\n",
      "Prec@1 93.750 (82.658)\n",
      "\n",
      "Prec@5 100.000 (91.021)\n",
      "\n",
      " * Prec@1 82.658 Prec@5 91.021\n",
      " * Prec@1 82.639 Prec@5 91.059\n",
      " * Prec@1 82.705 Prec@5 91.182\n",
      " * Prec@1 82.770 Prec@5 91.301\n",
      " * Prec@1 82.833 Prec@5 91.250\n",
      " * Prec@1 82.895 Prec@5 91.201\n",
      " * Prec@1 83.036 Prec@5 91.315\n",
      " * Prec@1 83.093 Prec@5 91.266\n",
      " * Prec@1 82.991 Prec@5 91.139\n",
      " * Prec@1 82.891 Prec@5 91.094\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.499 (0.525)\n",
      "\n",
      "Loss 1.8717 (0.8562)\n",
      "\n",
      "Prec@1 68.750 (82.716)\n",
      "\n",
      "Prec@5 75.000 (90.895)\n",
      "\n",
      " * Prec@1 82.716 Prec@5 90.895\n",
      " * Prec@1 82.698 Prec@5 90.930\n",
      " * Prec@1 82.605 Prec@5 90.964\n",
      " * Prec@1 82.664 Prec@5 90.997\n",
      " * Prec@1 82.721 Prec@5 90.956\n",
      " * Prec@1 82.776 Prec@5 90.988\n",
      " * Prec@1 82.830 Prec@5 91.020\n",
      " * Prec@1 82.812 Prec@5 90.980\n",
      " * Prec@1 82.865 Prec@5 91.011\n",
      " * Prec@1 82.917 Prec@5 91.042\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.461 (0.524)\n",
      "\n",
      "Loss 0.0041 (0.8282)\n",
      "\n",
      "Prec@1 100.000 (83.104)\n",
      "\n",
      "Prec@5 100.000 (91.140)\n",
      "\n",
      " * Prec@1 83.104 Prec@5 91.140\n",
      " * Prec@1 83.152 Prec@5 91.168\n",
      " * Prec@1 83.266 Prec@5 91.263\n",
      " * Prec@1 83.311 Prec@5 91.290\n",
      " * Prec@1 83.355 Prec@5 91.316\n",
      " * Prec@1 83.333 Prec@5 91.211\n",
      " * Prec@1 83.247 Prec@5 91.108\n",
      " * Prec@1 83.099 Prec@5 90.944\n",
      " * Prec@1 83.081 Prec@5 90.972\n",
      " * Prec@1 83.250 Prec@5 91.062\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.530 (0.525)\n",
      "\n",
      "Loss 1.0030 (0.8352)\n",
      "\n",
      "Prec@1 81.250 (83.230)\n",
      "\n",
      "Prec@5 87.500 (91.027)\n",
      "\n",
      " * Prec@1 83.230 Prec@5 91.027\n",
      " * Prec@1 83.333 Prec@5 91.115\n",
      " * Prec@1 83.252 Prec@5 91.080\n",
      " * Prec@1 83.233 Prec@5 91.106\n",
      " * Prec@1 83.214 Prec@5 91.071\n",
      " * Prec@1 83.255 Prec@5 91.097\n",
      " * Prec@1 83.411 Prec@5 91.180\n",
      " * Prec@1 83.507 Prec@5 91.262\n",
      " * Prec@1 83.601 Prec@5 91.342\n",
      " * Prec@1 83.466 Prec@5 91.364\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.520 (0.526)\n",
      "\n",
      "Loss 1.0581 (0.8170)\n",
      "\n",
      "Prec@1 81.250 (83.446)\n",
      "\n",
      "Prec@5 93.750 (91.385)\n",
      "\n",
      " * Prec@1 83.446 Prec@5 91.385\n",
      " * Prec@1 83.259 Prec@5 91.295\n",
      " * Prec@1 83.241 Prec@5 91.372\n",
      " * Prec@1 83.169 Prec@5 91.338\n",
      " * Prec@1 83.261 Prec@5 91.359\n",
      " * Prec@1 83.244 Prec@5 91.433\n",
      " * Prec@1 83.226 Prec@5 91.453\n",
      " * Prec@1 83.157 Prec@5 91.419\n",
      " * Prec@1 83.298 Prec@5 91.492\n",
      " * Prec@1 83.281 Prec@5 91.510\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.501 (0.527)\n",
      "\n",
      "Loss 0.2961 (0.8123)\n",
      "\n",
      "Prec@1 93.750 (83.368)\n",
      "\n",
      "Prec@5 100.000 (91.581)\n",
      "\n",
      " * Prec@1 83.368 Prec@5 91.581\n",
      " * Prec@1 83.402 Prec@5 91.547\n",
      " * Prec@1 83.486 Prec@5 91.565\n",
      " * Prec@1 83.518 Prec@5 91.583\n",
      " * Prec@1 83.550 Prec@5 91.600\n",
      " * Prec@1 83.532 Prec@5 91.617\n",
      " * Prec@1 83.514 Prec@5 91.683\n",
      " * Prec@1 83.594 Prec@5 91.748\n",
      " * Prec@1 83.672 Prec@5 91.764\n",
      " * Prec@1 83.750 Prec@5 91.827\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.556 (0.526)\n",
      "\n",
      "Loss 1.0376 (0.7902)\n",
      "\n",
      "Prec@1 75.000 (83.683)\n",
      "\n",
      "Prec@5 87.500 (91.794)\n",
      "\n",
      " * Prec@1 83.683 Prec@5 91.794\n",
      " * Prec@1 83.759 Prec@5 91.809\n",
      " * Prec@1 83.882 Prec@5 91.870\n",
      " * Prec@1 83.769 Prec@5 91.884\n",
      " * Prec@1 83.796 Prec@5 91.944\n",
      " * Prec@1 83.686 Prec@5 91.820\n",
      " * Prec@1 83.622 Prec@5 91.788\n",
      " * Prec@1 83.605 Prec@5 91.712\n",
      " * Prec@1 83.678 Prec@5 91.772\n",
      " * Prec@1 83.616 Prec@5 91.696\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.530 (0.526)\n",
      "\n",
      "Loss 1.2124 (0.8016)\n",
      "\n",
      "Prec@1 87.500 (83.644)\n",
      "\n",
      "Prec@5 87.500 (91.667)\n",
      "\n",
      " * Prec@1 83.644 Prec@5 91.667\n",
      " * Prec@1 83.495 Prec@5 91.505\n",
      " * Prec@1 83.392 Prec@5 91.477\n",
      " * Prec@1 83.377 Prec@5 91.536\n",
      " * Prec@1 83.405 Prec@5 91.552\n",
      " * Prec@1 83.134 Prec@5 91.267\n",
      " * Prec@1 83.078 Prec@5 91.241\n",
      " * Prec@1 83.108 Prec@5 91.258\n",
      " * Prec@1 83.096 Prec@5 91.191\n",
      " * Prec@1 83.125 Prec@5 91.250\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.488 (0.527)\n",
      "\n",
      "Loss 1.3949 (0.8352)\n",
      "\n",
      "Prec@1 75.000 (83.071)\n",
      "\n",
      "Prec@5 87.500 (91.225)\n",
      "\n",
      " * Prec@1 83.071 Prec@5 91.225\n",
      " * Prec@1 83.183 Prec@5 91.283\n",
      " * Prec@1 83.292 Prec@5 91.340\n",
      " * Prec@1 83.360 Prec@5 91.396\n",
      " * Prec@1 83.468 Prec@5 91.452\n",
      " * Prec@1 83.413 Prec@5 91.346\n",
      " * Prec@1 83.320 Prec@5 91.322\n",
      " * Prec@1 83.426 Prec@5 91.377\n",
      " * Prec@1 83.333 Prec@5 91.352\n",
      " * Prec@1 83.320 Prec@5 91.406\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.500 (0.527)\n",
      "\n",
      "Loss 0.3916 (0.8182)\n",
      "\n",
      "Prec@1 87.500 (83.346)\n",
      "\n",
      "Prec@5 100.000 (91.460)\n",
      "\n",
      " * Prec@1 83.346 Prec@5 91.460\n",
      " * Prec@1 83.410 Prec@5 91.474\n",
      " * Prec@1 83.397 Prec@5 91.411\n",
      " * Prec@1 83.460 Prec@5 91.425\n",
      " * Prec@1 83.485 Prec@5 91.439\n",
      " * Prec@1 83.509 Prec@5 91.453\n",
      " * Prec@1 83.421 Prec@5 91.467\n",
      " * Prec@1 83.408 Prec@5 91.406\n",
      " * Prec@1 83.364 Prec@5 91.422\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [14][0/1515]\t\\Time 0.547 (0.547)\tData 0.437 (0.437)\tLoss 0.0437 (0.0437)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1515]\t\\Time 0.502 (0.536)\tData 0.370 (0.434)\tLoss 0.0024 (0.0109)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/1515]\t\\Time 0.580 (0.534)\tData 0.470 (0.431)\tLoss 0.0026 (0.0119)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][300/1515]\t\\Time 0.582 (0.538)\tData 0.472 (0.436)\tLoss 0.0022 (0.0131)\tPrec@1 100.000 (99.460)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][400/1515]\t\\Time 0.577 (0.542)\tData 0.462 (0.439)\tLoss 0.0032 (0.0134)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][500/1515]\t\\Time 0.524 (0.541)\tData 0.402 (0.439)\tLoss 0.0024 (0.0135)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][600/1515]\t\\Time 0.499 (0.541)\tData 0.427 (0.439)\tLoss 0.0016 (0.0122)\tPrec@1 100.000 (99.553)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][700/1515]\t\\Time 0.561 (0.542)\tData 0.461 (0.439)\tLoss 0.0028 (0.0132)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][800/1515]\t\\Time 0.490 (0.542)\tData 0.390 (0.439)\tLoss 0.0023 (0.0133)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][900/1515]\t\\Time 0.574 (0.543)\tData 0.465 (0.441)\tLoss 0.0029 (0.0130)\tPrec@1 100.000 (99.556)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1000/1515]\t\\Time 0.560 (0.544)\tData 0.460 (0.441)\tLoss 0.0037 (0.0124)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1100/1515]\t\\Time 0.508 (0.545)\tData 0.397 (0.442)\tLoss 0.0024 (0.0116)\tPrec@1 100.000 (99.620)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1200/1515]\t\\Time 0.564 (0.546)\tData 0.486 (0.443)\tLoss 0.0034 (0.0118)\tPrec@1 100.000 (99.610)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1300/1515]\t\\Time 0.461 (0.547)\tData 0.381 (0.444)\tLoss 0.0027 (0.0119)\tPrec@1 100.000 (99.620)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1400/1515]\t\\Time 0.591 (0.547)\tData 0.481 (0.444)\tLoss 0.0038 (0.0124)\tPrec@1 100.000 (99.612)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1500/1515]\t\\Time 0.523 (0.547)\tData 0.443 (0.444)\tLoss 0.0032 (0.0127)\tPrec@1 100.000 (99.609)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.490 (0.490)\n",
      "\n",
      "Loss 0.2984 (0.2984)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 92.188 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 90.625 Prec@5 94.792\n",
      " * Prec@1 89.286 Prec@5 93.750\n",
      " * Prec@1 89.062 Prec@5 94.531\n",
      " * Prec@1 88.194 Prec@5 93.750\n",
      " * Prec@1 87.500 Prec@5 92.500\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.496 (0.544)\n",
      "\n",
      "Loss 0.5195 (0.6628)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 100.000 (93.182)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 93.182\n",
      " * Prec@1 87.500 Prec@5 93.750\n",
      " * Prec@1 88.462 Prec@5 94.231\n",
      " * Prec@1 87.946 Prec@5 93.304\n",
      " * Prec@1 87.083 Prec@5 92.500\n",
      " * Prec@1 86.719 Prec@5 92.969\n",
      " * Prec@1 85.294 Prec@5 91.912\n",
      " * Prec@1 84.375 Prec@5 90.972\n",
      " * Prec@1 83.882 Prec@5 90.789\n",
      " * Prec@1 83.750 Prec@5 90.625\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.523 (0.533)\n",
      "\n",
      "Loss 0.6765 (0.8209)\n",
      "\n",
      "Prec@1 93.750 (84.226)\n",
      "\n",
      "Prec@5 93.750 (90.774)\n",
      "\n",
      " * Prec@1 84.226 Prec@5 90.774\n",
      " * Prec@1 83.807 Prec@5 90.057\n",
      " * Prec@1 83.696 Prec@5 90.489\n",
      " * Prec@1 83.333 Prec@5 90.885\n",
      " * Prec@1 83.250 Prec@5 90.750\n",
      " * Prec@1 83.654 Prec@5 91.106\n",
      " * Prec@1 84.028 Prec@5 91.435\n",
      " * Prec@1 83.929 Prec@5 91.295\n",
      " * Prec@1 83.836 Prec@5 91.595\n",
      " * Prec@1 83.750 Prec@5 91.458\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.514 (0.528)\n",
      "\n",
      "Loss 0.5393 (0.7841)\n",
      "\n",
      "Prec@1 87.500 (83.871)\n",
      "\n",
      "Prec@5 93.750 (91.532)\n",
      "\n",
      " * Prec@1 83.871 Prec@5 91.532\n",
      " * Prec@1 83.984 Prec@5 91.602\n",
      " * Prec@1 83.712 Prec@5 91.098\n",
      " * Prec@1 83.088 Prec@5 90.441\n",
      " * Prec@1 83.036 Prec@5 90.536\n",
      " * Prec@1 82.986 Prec@5 90.451\n",
      " * Prec@1 82.939 Prec@5 90.709\n",
      " * Prec@1 83.059 Prec@5 90.954\n",
      " * Prec@1 82.853 Prec@5 91.026\n",
      " * Prec@1 82.656 Prec@5 91.094\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.539 (0.527)\n",
      "\n",
      "Loss 0.7590 (0.8271)\n",
      "\n",
      "Prec@1 87.500 (82.774)\n",
      "\n",
      "Prec@5 93.750 (91.159)\n",
      "\n",
      " * Prec@1 82.774 Prec@5 91.159\n",
      " * Prec@1 82.440 Prec@5 91.071\n",
      " * Prec@1 82.558 Prec@5 91.279\n",
      " * Prec@1 82.670 Prec@5 91.335\n",
      " * Prec@1 82.778 Prec@5 91.389\n",
      " * Prec@1 82.745 Prec@5 91.304\n",
      " * Prec@1 83.112 Prec@5 91.489\n",
      " * Prec@1 83.073 Prec@5 91.406\n",
      " * Prec@1 83.291 Prec@5 91.454\n",
      " * Prec@1 83.125 Prec@5 91.375\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.502 (0.529)\n",
      "\n",
      "Loss 1.4577 (0.8192)\n",
      "\n",
      "Prec@1 75.000 (82.966)\n",
      "\n",
      "Prec@5 81.250 (91.176)\n",
      "\n",
      " * Prec@1 82.966 Prec@5 91.176\n",
      " * Prec@1 82.812 Prec@5 91.226\n",
      " * Prec@1 82.901 Prec@5 91.392\n",
      " * Prec@1 82.755 Prec@5 91.319\n",
      " * Prec@1 82.500 Prec@5 91.364\n",
      " * Prec@1 82.478 Prec@5 91.406\n",
      " * Prec@1 82.456 Prec@5 91.338\n",
      " * Prec@1 82.435 Prec@5 91.379\n",
      " * Prec@1 82.415 Prec@5 91.314\n",
      " * Prec@1 82.292 Prec@5 91.458\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.514 (0.530)\n",
      "\n",
      "Loss 2.1438 (0.8470)\n",
      "\n",
      "Prec@1 62.500 (81.967)\n",
      "\n",
      "Prec@5 75.000 (91.189)\n",
      "\n",
      " * Prec@1 81.967 Prec@5 91.189\n",
      " * Prec@1 81.855 Prec@5 91.129\n",
      " * Prec@1 81.944 Prec@5 91.171\n",
      " * Prec@1 81.934 Prec@5 91.113\n",
      " * Prec@1 81.635 Prec@5 90.865\n",
      " * Prec@1 81.818 Prec@5 90.909\n",
      " * Prec@1 81.996 Prec@5 90.951\n",
      " * Prec@1 82.077 Prec@5 90.993\n",
      " * Prec@1 82.065 Prec@5 91.033\n",
      " * Prec@1 82.054 Prec@5 91.071\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.509 (0.527)\n",
      "\n",
      "Loss 0.2220 (0.8527)\n",
      "\n",
      "Prec@1 93.750 (82.218)\n",
      "\n",
      "Prec@5 100.000 (91.197)\n",
      "\n",
      " * Prec@1 82.218 Prec@5 91.197\n",
      " * Prec@1 82.205 Prec@5 91.233\n",
      " * Prec@1 82.277 Prec@5 91.353\n",
      " * Prec@1 82.348 Prec@5 91.385\n",
      " * Prec@1 82.417 Prec@5 91.333\n",
      " * Prec@1 82.484 Prec@5 91.283\n",
      " * Prec@1 82.630 Prec@5 91.396\n",
      " * Prec@1 82.692 Prec@5 91.346\n",
      " * Prec@1 82.595 Prec@5 91.218\n",
      " * Prec@1 82.500 Prec@5 91.172\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.503 (0.528)\n",
      "\n",
      "Loss 1.8132 (0.8610)\n",
      "\n",
      "Prec@1 68.750 (82.330)\n",
      "\n",
      "Prec@5 75.000 (90.972)\n",
      "\n",
      " * Prec@1 82.330 Prec@5 90.972\n",
      " * Prec@1 82.393 Prec@5 91.006\n",
      " * Prec@1 82.380 Prec@5 91.114\n",
      " * Prec@1 82.440 Prec@5 91.146\n",
      " * Prec@1 82.500 Prec@5 91.103\n",
      " * Prec@1 82.558 Prec@5 91.061\n",
      " * Prec@1 82.543 Prec@5 91.092\n",
      " * Prec@1 82.528 Prec@5 90.980\n",
      " * Prec@1 82.584 Prec@5 91.011\n",
      " * Prec@1 82.639 Prec@5 91.042\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.440 (0.524)\n",
      "\n",
      "Loss 0.0049 (0.8335)\n",
      "\n",
      "Prec@1 100.000 (82.830)\n",
      "\n",
      "Prec@5 100.000 (91.140)\n",
      "\n",
      " * Prec@1 82.830 Prec@5 91.140\n",
      " * Prec@1 82.880 Prec@5 91.168\n",
      " * Prec@1 82.997 Prec@5 91.263\n",
      " * Prec@1 83.045 Prec@5 91.223\n",
      " * Prec@1 83.092 Prec@5 91.184\n",
      " * Prec@1 83.073 Prec@5 91.081\n",
      " * Prec@1 82.990 Prec@5 90.979\n",
      " * Prec@1 82.844 Prec@5 90.816\n",
      " * Prec@1 82.828 Prec@5 90.846\n",
      " * Prec@1 83.000 Prec@5 90.938\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.544 (0.525)\n",
      "\n",
      "Loss 1.0122 (0.8408)\n",
      "\n",
      "Prec@1 81.250 (82.983)\n",
      "\n",
      "Prec@5 87.500 (90.903)\n",
      "\n",
      " * Prec@1 82.983 Prec@5 90.903\n",
      " * Prec@1 83.088 Prec@5 90.993\n",
      " * Prec@1 83.010 Prec@5 90.959\n",
      " * Prec@1 83.053 Prec@5 90.925\n",
      " * Prec@1 83.036 Prec@5 90.893\n",
      " * Prec@1 83.078 Prec@5 90.920\n",
      " * Prec@1 83.236 Prec@5 91.005\n",
      " * Prec@1 83.333 Prec@5 91.088\n",
      " * Prec@1 83.429 Prec@5 91.170\n",
      " * Prec@1 83.295 Prec@5 91.250\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.493 (0.525)\n",
      "\n",
      "Loss 1.0072 (0.8207)\n",
      "\n",
      "Prec@1 81.250 (83.277)\n",
      "\n",
      "Prec@5 93.750 (91.273)\n",
      "\n",
      " * Prec@1 83.277 Prec@5 91.273\n",
      " * Prec@1 83.092 Prec@5 91.127\n",
      " * Prec@1 83.075 Prec@5 91.206\n",
      " * Prec@1 83.004 Prec@5 91.173\n",
      " * Prec@1 83.098 Prec@5 91.196\n",
      " * Prec@1 83.082 Prec@5 91.272\n",
      " * Prec@1 83.066 Prec@5 91.293\n",
      " * Prec@1 82.945 Prec@5 91.261\n",
      " * Prec@1 83.088 Prec@5 91.334\n",
      " * Prec@1 83.073 Prec@5 91.354\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.539 (0.526)\n",
      "\n",
      "Loss 0.2283 (0.8154)\n",
      "\n",
      "Prec@1 93.750 (83.161)\n",
      "\n",
      "Prec@5 100.000 (91.426)\n",
      "\n",
      " * Prec@1 83.161 Prec@5 91.426\n",
      " * Prec@1 83.197 Prec@5 91.393\n",
      " * Prec@1 83.283 Prec@5 91.413\n",
      " * Prec@1 83.317 Prec@5 91.381\n",
      " * Prec@1 83.350 Prec@5 91.400\n",
      " * Prec@1 83.333 Prec@5 91.419\n",
      " * Prec@1 83.317 Prec@5 91.486\n",
      " * Prec@1 83.398 Prec@5 91.553\n",
      " * Prec@1 83.479 Prec@5 91.570\n",
      " * Prec@1 83.558 Prec@5 91.635\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.591 (0.527)\n",
      "\n",
      "Loss 1.0148 (0.7924)\n",
      "\n",
      "Prec@1 75.000 (83.492)\n",
      "\n",
      "Prec@5 93.750 (91.651)\n",
      "\n",
      " * Prec@1 83.492 Prec@5 91.651\n",
      " * Prec@1 83.570 Prec@5 91.667\n",
      " * Prec@1 83.694 Prec@5 91.729\n",
      " * Prec@1 83.629 Prec@5 91.744\n",
      " * Prec@1 83.657 Prec@5 91.806\n",
      " * Prec@1 83.548 Prec@5 91.682\n",
      " * Prec@1 83.485 Prec@5 91.651\n",
      " * Prec@1 83.469 Prec@5 91.576\n",
      " * Prec@1 83.588 Prec@5 91.637\n",
      " * Prec@1 83.482 Prec@5 91.562\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.535 (0.528)\n",
      "\n",
      "Loss 1.1199 (0.8041)\n",
      "\n",
      "Prec@1 81.250 (83.466)\n",
      "\n",
      "Prec@5 87.500 (91.534)\n",
      "\n",
      " * Prec@1 83.466 Prec@5 91.534\n",
      " * Prec@1 83.319 Prec@5 91.373\n",
      " * Prec@1 83.217 Prec@5 91.302\n",
      " * Prec@1 83.203 Prec@5 91.319\n",
      " * Prec@1 83.233 Prec@5 91.336\n",
      " * Prec@1 82.962 Prec@5 91.139\n",
      " * Prec@1 82.908 Prec@5 91.114\n",
      " * Prec@1 82.939 Prec@5 91.132\n",
      " * Prec@1 82.928 Prec@5 91.107\n",
      " * Prec@1 82.958 Prec@5 91.167\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.556 (0.531)\n",
      "\n",
      "Loss 1.3178 (0.8366)\n",
      "\n",
      "Prec@1 75.000 (82.906)\n",
      "\n",
      "Prec@5 87.500 (91.142)\n",
      "\n",
      " * Prec@1 82.906 Prec@5 91.142\n",
      " * Prec@1 83.018 Prec@5 91.201\n",
      " * Prec@1 83.088 Prec@5 91.258\n",
      " * Prec@1 83.157 Prec@5 91.315\n",
      " * Prec@1 83.266 Prec@5 91.371\n",
      " * Prec@1 83.173 Prec@5 91.266\n",
      " * Prec@1 83.081 Prec@5 91.162\n",
      " * Prec@1 83.188 Prec@5 91.218\n",
      " * Prec@1 83.137 Prec@5 91.195\n",
      " * Prec@1 83.125 Prec@5 91.250\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.547 (0.532)\n",
      "\n",
      "Loss 0.4726 (0.8211)\n",
      "\n",
      "Prec@1 81.250 (83.113)\n",
      "\n",
      "Prec@5 100.000 (91.304)\n",
      "\n",
      " * Prec@1 83.113 Prec@5 91.304\n",
      " * Prec@1 83.179 Prec@5 91.319\n",
      " * Prec@1 83.167 Prec@5 91.258\n",
      " * Prec@1 83.232 Prec@5 91.273\n",
      " * Prec@1 83.258 Prec@5 91.288\n",
      " * Prec@1 83.321 Prec@5 91.303\n",
      " * Prec@1 83.234 Prec@5 91.317\n",
      " * Prec@1 83.222 Prec@5 91.257\n",
      " * Prec@1 83.216 Prec@5 91.274\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [15][0/1515]\t\\Time 0.601 (0.601)\tData 0.495 (0.495)\tLoss 0.0783 (0.0783)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1515]\t\\Time 0.512 (0.528)\tData 0.412 (0.426)\tLoss 0.0029 (0.0108)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/1515]\t\\Time 0.579 (0.528)\tData 0.448 (0.424)\tLoss 0.0023 (0.0127)\tPrec@1 100.000 (99.596)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/1515]\t\\Time 0.564 (0.529)\tData 0.464 (0.425)\tLoss 0.0042 (0.0121)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][400/1515]\t\\Time 0.510 (0.529)\tData 0.432 (0.427)\tLoss 0.1871 (0.0118)\tPrec@1 93.750 (99.610)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][500/1515]\t\\Time 0.541 (0.529)\tData 0.431 (0.427)\tLoss 0.0023 (0.0123)\tPrec@1 100.000 (99.588)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][600/1515]\t\\Time 0.562 (0.532)\tData 0.492 (0.429)\tLoss 0.0019 (0.0123)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][700/1515]\t\\Time 0.546 (0.533)\tData 0.444 (0.430)\tLoss 0.0027 (0.0122)\tPrec@1 100.000 (99.590)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][800/1515]\t\\Time 0.575 (0.534)\tData 0.456 (0.431)\tLoss 0.0034 (0.0115)\tPrec@1 100.000 (99.618)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][900/1515]\t\\Time 0.554 (0.535)\tData 0.474 (0.433)\tLoss 0.0040 (0.0114)\tPrec@1 100.000 (99.612)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1000/1515]\t\\Time 0.543 (0.537)\tData 0.430 (0.434)\tLoss 0.0025 (0.0119)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1100/1515]\t\\Time 0.560 (0.537)\tData 0.440 (0.434)\tLoss 0.0029 (0.0117)\tPrec@1 100.000 (99.603)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1200/1515]\t\\Time 0.582 (0.537)\tData 0.462 (0.434)\tLoss 0.1410 (0.0123)\tPrec@1 93.750 (99.573)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1300/1515]\t\\Time 0.491 (0.539)\tData 0.421 (0.436)\tLoss 0.0844 (0.0125)\tPrec@1 93.750 (99.558)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1400/1515]\t\\Time 0.550 (0.540)\tData 0.480 (0.437)\tLoss 0.0032 (0.0125)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1500/1515]\t\\Time 0.493 (0.540)\tData 0.413 (0.437)\tLoss 0.0045 (0.0127)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.471 (0.471)\n",
      "\n",
      "Loss 0.3467 (0.3467)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 92.188 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 89.583 Prec@5 93.750\n",
      " * Prec@1 88.393 Prec@5 92.857\n",
      " * Prec@1 89.062 Prec@5 93.750\n",
      " * Prec@1 88.194 Prec@5 92.361\n",
      " * Prec@1 87.500 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.502 (0.526)\n",
      "\n",
      "Loss 0.5121 (0.6645)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 100.000 (92.045)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 92.045\n",
      " * Prec@1 87.500 Prec@5 92.708\n",
      " * Prec@1 88.462 Prec@5 93.269\n",
      " * Prec@1 87.500 Prec@5 92.411\n",
      " * Prec@1 86.667 Prec@5 91.667\n",
      " * Prec@1 86.328 Prec@5 91.797\n",
      " * Prec@1 84.926 Prec@5 90.809\n",
      " * Prec@1 84.028 Prec@5 90.278\n",
      " * Prec@1 83.553 Prec@5 90.132\n",
      " * Prec@1 83.438 Prec@5 90.312\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.564 (0.523)\n",
      "\n",
      "Loss 0.7177 (0.8231)\n",
      "\n",
      "Prec@1 93.750 (83.929)\n",
      "\n",
      "Prec@5 93.750 (90.476)\n",
      "\n",
      " * Prec@1 83.929 Prec@5 90.476\n",
      " * Prec@1 83.523 Prec@5 89.773\n",
      " * Prec@1 83.696 Prec@5 90.217\n",
      " * Prec@1 83.594 Prec@5 90.625\n",
      " * Prec@1 83.500 Prec@5 90.500\n",
      " * Prec@1 83.894 Prec@5 90.865\n",
      " * Prec@1 84.259 Prec@5 91.204\n",
      " * Prec@1 84.152 Prec@5 91.071\n",
      " * Prec@1 84.052 Prec@5 91.164\n",
      " * Prec@1 83.750 Prec@5 91.042\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.519 (0.528)\n",
      "\n",
      "Loss 0.5391 (0.7802)\n",
      "\n",
      "Prec@1 87.500 (83.871)\n",
      "\n",
      "Prec@5 93.750 (91.129)\n",
      "\n",
      " * Prec@1 83.871 Prec@5 91.129\n",
      " * Prec@1 84.180 Prec@5 91.211\n",
      " * Prec@1 83.902 Prec@5 90.720\n",
      " * Prec@1 83.456 Prec@5 90.257\n",
      " * Prec@1 83.393 Prec@5 90.357\n",
      " * Prec@1 83.333 Prec@5 90.278\n",
      " * Prec@1 83.277 Prec@5 90.541\n",
      " * Prec@1 83.388 Prec@5 90.789\n",
      " * Prec@1 83.173 Prec@5 90.865\n",
      " * Prec@1 82.969 Prec@5 90.938\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.520 (0.525)\n",
      "\n",
      "Loss 0.6936 (0.8126)\n",
      "\n",
      "Prec@1 87.500 (83.079)\n",
      "\n",
      "Prec@5 93.750 (91.006)\n",
      "\n",
      " * Prec@1 83.079 Prec@5 91.006\n",
      " * Prec@1 82.738 Prec@5 90.923\n",
      " * Prec@1 82.849 Prec@5 91.134\n",
      " * Prec@1 82.955 Prec@5 91.193\n",
      " * Prec@1 83.056 Prec@5 91.250\n",
      " * Prec@1 83.016 Prec@5 91.168\n",
      " * Prec@1 83.378 Prec@5 91.356\n",
      " * Prec@1 83.333 Prec@5 91.276\n",
      " * Prec@1 83.546 Prec@5 91.327\n",
      " * Prec@1 83.500 Prec@5 91.375\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.501 (0.525)\n",
      "\n",
      "Loss 1.4056 (0.8048)\n",
      "\n",
      "Prec@1 75.000 (83.333)\n",
      "\n",
      "Prec@5 81.250 (91.176)\n",
      "\n",
      " * Prec@1 83.333 Prec@5 91.176\n",
      " * Prec@1 83.173 Prec@5 91.226\n",
      " * Prec@1 83.373 Prec@5 91.392\n",
      " * Prec@1 83.218 Prec@5 91.319\n",
      " * Prec@1 82.955 Prec@5 91.364\n",
      " * Prec@1 82.924 Prec@5 91.406\n",
      " * Prec@1 82.895 Prec@5 91.338\n",
      " * Prec@1 82.866 Prec@5 91.379\n",
      " * Prec@1 82.839 Prec@5 91.419\n",
      " * Prec@1 82.812 Prec@5 91.562\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.510 (0.527)\n",
      "\n",
      "Loss 1.9936 (0.8271)\n",
      "\n",
      "Prec@1 68.750 (82.582)\n",
      "\n",
      "Prec@5 75.000 (91.291)\n",
      "\n",
      " * Prec@1 82.582 Prec@5 91.291\n",
      " * Prec@1 82.460 Prec@5 91.230\n",
      " * Prec@1 82.440 Prec@5 91.270\n",
      " * Prec@1 82.520 Prec@5 91.211\n",
      " * Prec@1 82.212 Prec@5 90.865\n",
      " * Prec@1 82.292 Prec@5 90.909\n",
      " * Prec@1 82.463 Prec@5 90.951\n",
      " * Prec@1 82.445 Prec@5 90.993\n",
      " * Prec@1 82.518 Prec@5 91.033\n",
      " * Prec@1 82.500 Prec@5 90.982\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.490 (0.524)\n",
      "\n",
      "Loss 0.2069 (0.8370)\n",
      "\n",
      "Prec@1 93.750 (82.658)\n",
      "\n",
      "Prec@5 100.000 (91.109)\n",
      "\n",
      " * Prec@1 82.658 Prec@5 91.109\n",
      " * Prec@1 82.639 Prec@5 91.146\n",
      " * Prec@1 82.705 Prec@5 91.267\n",
      " * Prec@1 82.770 Prec@5 91.301\n",
      " * Prec@1 82.833 Prec@5 91.250\n",
      " * Prec@1 82.895 Prec@5 91.201\n",
      " * Prec@1 83.036 Prec@5 91.315\n",
      " * Prec@1 83.093 Prec@5 91.266\n",
      " * Prec@1 82.991 Prec@5 91.139\n",
      " * Prec@1 82.891 Prec@5 91.094\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.488 (0.524)\n",
      "\n",
      "Loss 1.8376 (0.8470)\n",
      "\n",
      "Prec@1 68.750 (82.716)\n",
      "\n",
      "Prec@5 75.000 (90.895)\n",
      "\n",
      " * Prec@1 82.716 Prec@5 90.895\n",
      " * Prec@1 82.774 Prec@5 90.930\n",
      " * Prec@1 82.756 Prec@5 91.039\n",
      " * Prec@1 82.738 Prec@5 91.071\n",
      " * Prec@1 82.794 Prec@5 91.029\n",
      " * Prec@1 82.849 Prec@5 91.061\n",
      " * Prec@1 82.902 Prec@5 91.092\n",
      " * Prec@1 82.884 Prec@5 90.980\n",
      " * Prec@1 82.935 Prec@5 91.011\n",
      " * Prec@1 82.986 Prec@5 91.042\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.453 (0.522)\n",
      "\n",
      "Loss 0.0046 (0.8189)\n",
      "\n",
      "Prec@1 100.000 (83.173)\n",
      "\n",
      "Prec@5 100.000 (91.140)\n",
      "\n",
      " * Prec@1 83.173 Prec@5 91.140\n",
      " * Prec@1 83.220 Prec@5 91.168\n",
      " * Prec@1 83.333 Prec@5 91.263\n",
      " * Prec@1 83.378 Prec@5 91.223\n",
      " * Prec@1 83.421 Prec@5 91.184\n",
      " * Prec@1 83.333 Prec@5 91.081\n",
      " * Prec@1 83.247 Prec@5 90.979\n",
      " * Prec@1 83.099 Prec@5 90.816\n",
      " * Prec@1 83.144 Prec@5 90.846\n",
      " * Prec@1 83.312 Prec@5 90.938\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.573 (0.523)\n",
      "\n",
      "Loss 0.9352 (0.8254)\n",
      "\n",
      "Prec@1 81.250 (83.292)\n",
      "\n",
      "Prec@5 87.500 (90.903)\n",
      "\n",
      " * Prec@1 83.292 Prec@5 90.903\n",
      " * Prec@1 83.395 Prec@5 90.993\n",
      " * Prec@1 83.313 Prec@5 90.959\n",
      " * Prec@1 83.353 Prec@5 90.986\n",
      " * Prec@1 83.333 Prec@5 90.952\n",
      " * Prec@1 83.373 Prec@5 90.920\n",
      " * Prec@1 83.528 Prec@5 91.005\n",
      " * Prec@1 83.623 Prec@5 91.088\n",
      " * Prec@1 83.658 Prec@5 91.170\n",
      " * Prec@1 83.523 Prec@5 91.250\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.494 (0.523)\n",
      "\n",
      "Loss 0.7141 (0.8061)\n",
      "\n",
      "Prec@1 87.500 (83.559)\n",
      "\n",
      "Prec@5 93.750 (91.273)\n",
      "\n",
      " * Prec@1 83.559 Prec@5 91.273\n",
      " * Prec@1 83.371 Prec@5 91.183\n",
      " * Prec@1 83.352 Prec@5 91.261\n",
      " * Prec@1 83.279 Prec@5 91.228\n",
      " * Prec@1 83.370 Prec@5 91.250\n",
      " * Prec@1 83.351 Prec@5 91.325\n",
      " * Prec@1 83.387 Prec@5 91.346\n",
      " * Prec@1 83.316 Prec@5 91.261\n",
      " * Prec@1 83.456 Prec@5 91.334\n",
      " * Prec@1 83.385 Prec@5 91.354\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.512 (0.525)\n",
      "\n",
      "Loss 0.3363 (0.8009)\n",
      "\n",
      "Prec@1 93.750 (83.471)\n",
      "\n",
      "Prec@5 100.000 (91.426)\n",
      "\n",
      " * Prec@1 83.471 Prec@5 91.426\n",
      " * Prec@1 83.453 Prec@5 91.393\n",
      " * Prec@1 83.537 Prec@5 91.413\n",
      " * Prec@1 83.569 Prec@5 91.381\n",
      " * Prec@1 83.600 Prec@5 91.450\n",
      " * Prec@1 83.631 Prec@5 91.518\n",
      " * Prec@1 83.661 Prec@5 91.585\n",
      " * Prec@1 83.740 Prec@5 91.650\n",
      " * Prec@1 83.818 Prec@5 91.667\n",
      " * Prec@1 83.894 Prec@5 91.731\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.557 (0.524)\n",
      "\n",
      "Loss 1.0043 (0.7788)\n",
      "\n",
      "Prec@1 75.000 (83.826)\n",
      "\n",
      "Prec@5 87.500 (91.698)\n",
      "\n",
      " * Prec@1 83.826 Prec@5 91.698\n",
      " * Prec@1 83.902 Prec@5 91.714\n",
      " * Prec@1 84.023 Prec@5 91.776\n",
      " * Prec@1 83.955 Prec@5 91.791\n",
      " * Prec@1 83.981 Prec@5 91.852\n",
      " * Prec@1 83.869 Prec@5 91.728\n",
      " * Prec@1 83.805 Prec@5 91.697\n",
      " * Prec@1 83.786 Prec@5 91.621\n",
      " * Prec@1 83.903 Prec@5 91.682\n",
      " * Prec@1 83.795 Prec@5 91.607\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.532 (0.523)\n",
      "\n",
      "Loss 1.1624 (0.7902)\n",
      "\n",
      "Prec@1 87.500 (83.821)\n",
      "\n",
      "Prec@5 87.500 (91.578)\n",
      "\n",
      " * Prec@1 83.821 Prec@5 91.578\n",
      " * Prec@1 83.671 Prec@5 91.417\n",
      " * Prec@1 83.566 Prec@5 91.390\n",
      " * Prec@1 83.550 Prec@5 91.450\n",
      " * Prec@1 83.578 Prec@5 91.466\n",
      " * Prec@1 83.305 Prec@5 91.267\n",
      " * Prec@1 83.248 Prec@5 91.241\n",
      " * Prec@1 83.277 Prec@5 91.258\n",
      " * Prec@1 83.263 Prec@5 91.233\n",
      " * Prec@1 83.292 Prec@5 91.292\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.510 (0.525)\n",
      "\n",
      "Loss 1.3152 (0.8236)\n",
      "\n",
      "Prec@1 75.000 (83.237)\n",
      "\n",
      "Prec@5 87.500 (91.267)\n",
      "\n",
      " * Prec@1 83.237 Prec@5 91.267\n",
      " * Prec@1 83.347 Prec@5 91.324\n",
      " * Prec@1 83.456 Prec@5 91.381\n",
      " * Prec@1 83.523 Prec@5 91.437\n",
      " * Prec@1 83.629 Prec@5 91.492\n",
      " * Prec@1 83.574 Prec@5 91.386\n",
      " * Prec@1 83.479 Prec@5 91.282\n",
      " * Prec@1 83.584 Prec@5 91.337\n",
      " * Prec@1 83.530 Prec@5 91.313\n",
      " * Prec@1 83.516 Prec@5 91.367\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.530 (0.526)\n",
      "\n",
      "Loss 0.3876 (0.8079)\n",
      "\n",
      "Prec@1 87.500 (83.540)\n",
      "\n",
      "Prec@5 100.000 (91.421)\n",
      "\n",
      " * Prec@1 83.540 Prec@5 91.421\n",
      " * Prec@1 83.603 Prec@5 91.435\n",
      " * Prec@1 83.589 Prec@5 91.373\n",
      " * Prec@1 83.651 Prec@5 91.387\n",
      " * Prec@1 83.636 Prec@5 91.402\n",
      " * Prec@1 83.697 Prec@5 91.416\n",
      " * Prec@1 83.608 Prec@5 91.430\n",
      " * Prec@1 83.594 Prec@5 91.369\n",
      " * Prec@1 83.587 Prec@5 91.385\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [16][0/1515]\t\\Time 0.584 (0.584)\tData 0.474 (0.474)\tLoss 0.0023 (0.0023)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1515]\t\\Time 0.570 (0.542)\tData 0.480 (0.440)\tLoss 0.0257 (0.0148)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/1515]\t\\Time 0.543 (0.543)\tData 0.441 (0.439)\tLoss 0.1631 (0.0172)\tPrec@1 93.750 (99.471)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][300/1515]\t\\Time 0.500 (0.539)\tData 0.429 (0.437)\tLoss 0.0013 (0.0160)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][400/1515]\t\\Time 0.565 (0.541)\tData 0.442 (0.439)\tLoss 0.0036 (0.0140)\tPrec@1 100.000 (99.595)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][500/1515]\t\\Time 0.539 (0.542)\tData 0.469 (0.440)\tLoss 0.0034 (0.0129)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][600/1515]\t\\Time 0.509 (0.544)\tData 0.389 (0.441)\tLoss 0.0041 (0.0139)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][700/1515]\t\\Time 0.481 (0.542)\tData 0.391 (0.440)\tLoss 0.0046 (0.0138)\tPrec@1 100.000 (99.599)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][800/1515]\t\\Time 0.570 (0.542)\tData 0.454 (0.440)\tLoss 0.0030 (0.0141)\tPrec@1 100.000 (99.571)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][900/1515]\t\\Time 0.556 (0.543)\tData 0.437 (0.440)\tLoss 0.0037 (0.0141)\tPrec@1 100.000 (99.577)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1000/1515]\t\\Time 0.501 (0.543)\tData 0.392 (0.441)\tLoss 0.0024 (0.0133)\tPrec@1 100.000 (99.607)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1100/1515]\t\\Time 0.593 (0.544)\tData 0.492 (0.442)\tLoss 0.0025 (0.0129)\tPrec@1 100.000 (99.614)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1200/1515]\t\\Time 0.542 (0.544)\tData 0.431 (0.441)\tLoss 0.0028 (0.0127)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1300/1515]\t\\Time 0.571 (0.544)\tData 0.471 (0.441)\tLoss 0.0037 (0.0130)\tPrec@1 100.000 (99.616)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1400/1515]\t\\Time 0.523 (0.542)\tData 0.412 (0.440)\tLoss 0.0049 (0.0128)\tPrec@1 100.000 (99.630)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1500/1515]\t\\Time 0.523 (0.542)\tData 0.422 (0.440)\tLoss 0.0058 (0.0128)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.420 (0.420)\n",
      "\n",
      "Loss 0.3605 (0.3605)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 95.000\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 89.286 Prec@5 92.857\n",
      " * Prec@1 89.844 Prec@5 93.750\n",
      " * Prec@1 88.889 Prec@5 92.361\n",
      " * Prec@1 88.125 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.542 (0.532)\n",
      "\n",
      "Loss 0.5103 (0.6519)\n",
      "\n",
      "Prec@1 87.500 (88.068)\n",
      "\n",
      "Prec@5 100.000 (92.045)\n",
      "\n",
      " * Prec@1 88.068 Prec@5 92.045\n",
      " * Prec@1 88.021 Prec@5 92.708\n",
      " * Prec@1 88.942 Prec@5 93.269\n",
      " * Prec@1 87.946 Prec@5 92.411\n",
      " * Prec@1 87.083 Prec@5 91.667\n",
      " * Prec@1 87.109 Prec@5 91.797\n",
      " * Prec@1 86.029 Prec@5 91.176\n",
      " * Prec@1 85.069 Prec@5 90.625\n",
      " * Prec@1 84.868 Prec@5 90.461\n",
      " * Prec@1 84.688 Prec@5 90.312\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.593 (0.532)\n",
      "\n",
      "Loss 0.7179 (0.8013)\n",
      "\n",
      "Prec@1 93.750 (85.119)\n",
      "\n",
      "Prec@5 93.750 (90.476)\n",
      "\n",
      " * Prec@1 85.119 Prec@5 90.476\n",
      " * Prec@1 84.659 Prec@5 89.773\n",
      " * Prec@1 84.783 Prec@5 90.217\n",
      " * Prec@1 84.635 Prec@5 90.625\n",
      " * Prec@1 84.500 Prec@5 90.500\n",
      " * Prec@1 84.856 Prec@5 90.865\n",
      " * Prec@1 85.185 Prec@5 91.204\n",
      " * Prec@1 85.045 Prec@5 90.848\n",
      " * Prec@1 85.129 Prec@5 91.164\n",
      " * Prec@1 85.000 Prec@5 91.042\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.523 (0.534)\n",
      "\n",
      "Loss 0.5805 (0.7735)\n",
      "\n",
      "Prec@1 87.500 (85.081)\n",
      "\n",
      "Prec@5 93.750 (91.129)\n",
      "\n",
      " * Prec@1 85.081 Prec@5 91.129\n",
      " * Prec@1 85.352 Prec@5 91.211\n",
      " * Prec@1 85.038 Prec@5 90.720\n",
      " * Prec@1 84.375 Prec@5 90.074\n",
      " * Prec@1 84.286 Prec@5 90.179\n",
      " * Prec@1 84.201 Prec@5 90.104\n",
      " * Prec@1 84.291 Prec@5 90.034\n",
      " * Prec@1 84.375 Prec@5 90.296\n",
      " * Prec@1 84.135 Prec@5 90.385\n",
      " * Prec@1 83.906 Prec@5 90.469\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.504 (0.529)\n",
      "\n",
      "Loss 0.7333 (0.8120)\n",
      "\n",
      "Prec@1 87.500 (83.994)\n",
      "\n",
      "Prec@5 93.750 (90.549)\n",
      "\n",
      " * Prec@1 83.994 Prec@5 90.549\n",
      " * Prec@1 83.631 Prec@5 90.476\n",
      " * Prec@1 83.721 Prec@5 90.698\n",
      " * Prec@1 83.807 Prec@5 90.909\n",
      " * Prec@1 83.889 Prec@5 90.972\n",
      " * Prec@1 83.832 Prec@5 91.033\n",
      " * Prec@1 84.176 Prec@5 91.223\n",
      " * Prec@1 84.115 Prec@5 91.146\n",
      " * Prec@1 84.311 Prec@5 91.199\n",
      " * Prec@1 84.250 Prec@5 91.250\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.502 (0.527)\n",
      "\n",
      "Loss 1.4415 (0.8069)\n",
      "\n",
      "Prec@1 75.000 (84.069)\n",
      "\n",
      "Prec@5 81.250 (91.054)\n",
      "\n",
      " * Prec@1 84.069 Prec@5 91.054\n",
      " * Prec@1 84.014 Prec@5 91.106\n",
      " * Prec@1 84.198 Prec@5 91.274\n",
      " * Prec@1 84.028 Prec@5 91.204\n",
      " * Prec@1 83.636 Prec@5 91.250\n",
      " * Prec@1 83.594 Prec@5 91.295\n",
      " * Prec@1 83.553 Prec@5 91.338\n",
      " * Prec@1 83.513 Prec@5 91.379\n",
      " * Prec@1 83.475 Prec@5 91.314\n",
      " * Prec@1 83.333 Prec@5 91.354\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.523 (0.529)\n",
      "\n",
      "Loss 2.1448 (0.8283)\n",
      "\n",
      "Prec@1 62.500 (82.992)\n",
      "\n",
      "Prec@5 75.000 (91.086)\n",
      "\n",
      " * Prec@1 82.992 Prec@5 91.086\n",
      " * Prec@1 82.863 Prec@5 91.028\n",
      " * Prec@1 82.837 Prec@5 91.071\n",
      " * Prec@1 82.910 Prec@5 91.016\n",
      " * Prec@1 82.596 Prec@5 90.865\n",
      " * Prec@1 82.765 Prec@5 90.909\n",
      " * Prec@1 82.929 Prec@5 90.951\n",
      " * Prec@1 82.904 Prec@5 90.993\n",
      " * Prec@1 82.971 Prec@5 91.033\n",
      " * Prec@1 82.946 Prec@5 90.982\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.491 (0.525)\n",
      "\n",
      "Loss 0.1370 (0.8321)\n",
      "\n",
      "Prec@1 93.750 (83.099)\n",
      "\n",
      "Prec@5 100.000 (91.109)\n",
      "\n",
      " * Prec@1 83.099 Prec@5 91.109\n",
      " * Prec@1 83.073 Prec@5 91.146\n",
      " * Prec@1 83.134 Prec@5 91.267\n",
      " * Prec@1 83.193 Prec@5 91.301\n",
      " * Prec@1 83.250 Prec@5 91.250\n",
      " * Prec@1 83.306 Prec@5 91.201\n",
      " * Prec@1 83.442 Prec@5 91.315\n",
      " * Prec@1 83.494 Prec@5 91.346\n",
      " * Prec@1 83.386 Prec@5 91.218\n",
      " * Prec@1 83.281 Prec@5 91.172\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.503 (0.526)\n",
      "\n",
      "Loss 1.8682 (0.8403)\n",
      "\n",
      "Prec@1 68.750 (83.102)\n",
      "\n",
      "Prec@5 75.000 (90.972)\n",
      "\n",
      " * Prec@1 83.102 Prec@5 90.972\n",
      " * Prec@1 83.155 Prec@5 91.006\n",
      " * Prec@1 83.057 Prec@5 91.039\n",
      " * Prec@1 83.110 Prec@5 90.997\n",
      " * Prec@1 83.162 Prec@5 90.956\n",
      " * Prec@1 83.212 Prec@5 90.916\n",
      " * Prec@1 83.261 Prec@5 90.948\n",
      " * Prec@1 83.239 Prec@5 90.838\n",
      " * Prec@1 83.287 Prec@5 90.871\n",
      " * Prec@1 83.333 Prec@5 90.903\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.485 (0.527)\n",
      "\n",
      "Loss 0.0047 (0.8161)\n",
      "\n",
      "Prec@1 100.000 (83.516)\n",
      "\n",
      "Prec@5 100.000 (91.003)\n",
      "\n",
      " * Prec@1 83.516 Prec@5 91.003\n",
      " * Prec@1 83.560 Prec@5 91.033\n",
      " * Prec@1 83.669 Prec@5 91.129\n",
      " * Prec@1 83.777 Prec@5 91.157\n",
      " * Prec@1 83.816 Prec@5 91.118\n",
      " * Prec@1 83.724 Prec@5 91.016\n",
      " * Prec@1 83.634 Prec@5 90.915\n",
      " * Prec@1 83.482 Prec@5 90.753\n",
      " * Prec@1 83.396 Prec@5 90.783\n",
      " * Prec@1 83.562 Prec@5 90.875\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.549 (0.528)\n",
      "\n",
      "Loss 0.9782 (0.8225)\n",
      "\n",
      "Prec@1 81.250 (83.540)\n",
      "\n",
      "Prec@5 87.500 (90.842)\n",
      "\n",
      " * Prec@1 83.540 Prec@5 90.842\n",
      " * Prec@1 83.640 Prec@5 90.931\n",
      " * Prec@1 83.556 Prec@5 90.898\n",
      " * Prec@1 83.534 Prec@5 90.925\n",
      " * Prec@1 83.512 Prec@5 90.893\n",
      " * Prec@1 83.550 Prec@5 90.861\n",
      " * Prec@1 83.703 Prec@5 90.946\n",
      " * Prec@1 83.796 Prec@5 91.030\n",
      " * Prec@1 83.888 Prec@5 91.112\n",
      " * Prec@1 83.807 Prec@5 91.136\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.491 (0.528)\n",
      "\n",
      "Loss 0.7831 (0.7998)\n",
      "\n",
      "Prec@1 87.500 (83.840)\n",
      "\n",
      "Prec@5 93.750 (91.160)\n",
      "\n",
      " * Prec@1 83.840 Prec@5 91.160\n",
      " * Prec@1 83.594 Prec@5 91.071\n",
      " * Prec@1 83.573 Prec@5 91.150\n",
      " * Prec@1 83.498 Prec@5 91.118\n",
      " * Prec@1 83.587 Prec@5 91.141\n",
      " * Prec@1 83.621 Prec@5 91.218\n",
      " * Prec@1 83.600 Prec@5 91.239\n",
      " * Prec@1 83.475 Prec@5 91.155\n",
      " * Prec@1 83.613 Prec@5 91.229\n",
      " * Prec@1 83.594 Prec@5 91.250\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.509 (0.529)\n",
      "\n",
      "Loss 0.2386 (0.7945)\n",
      "\n",
      "Prec@1 93.750 (83.678)\n",
      "\n",
      "Prec@5 100.000 (91.322)\n",
      "\n",
      " * Prec@1 83.678 Prec@5 91.322\n",
      " * Prec@1 83.709 Prec@5 91.291\n",
      " * Prec@1 83.791 Prec@5 91.311\n",
      " * Prec@1 83.821 Prec@5 91.331\n",
      " * Prec@1 83.900 Prec@5 91.350\n",
      " * Prec@1 83.879 Prec@5 91.369\n",
      " * Prec@1 83.858 Prec@5 91.437\n",
      " * Prec@1 83.936 Prec@5 91.504\n",
      " * Prec@1 84.012 Prec@5 91.521\n",
      " * Prec@1 84.087 Prec@5 91.587\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.569 (0.528)\n",
      "\n",
      "Loss 1.0447 (0.7718)\n",
      "\n",
      "Prec@1 75.000 (84.017)\n",
      "\n",
      "Prec@5 87.500 (91.555)\n",
      "\n",
      " * Prec@1 84.017 Prec@5 91.555\n",
      " * Prec@1 84.091 Prec@5 91.572\n",
      " * Prec@1 84.211 Prec@5 91.635\n",
      " * Prec@1 84.142 Prec@5 91.651\n",
      " * Prec@1 84.167 Prec@5 91.713\n",
      " * Prec@1 84.053 Prec@5 91.544\n",
      " * Prec@1 83.987 Prec@5 91.515\n",
      " * Prec@1 83.967 Prec@5 91.440\n",
      " * Prec@1 84.083 Prec@5 91.502\n",
      " * Prec@1 84.018 Prec@5 91.429\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.544 (0.528)\n",
      "\n",
      "Loss 1.1952 (0.7834)\n",
      "\n",
      "Prec@1 87.500 (84.043)\n",
      "\n",
      "Prec@5 87.500 (91.401)\n",
      "\n",
      " * Prec@1 84.043 Prec@5 91.401\n",
      " * Prec@1 83.935 Prec@5 91.241\n",
      " * Prec@1 83.829 Prec@5 91.215\n",
      " * Prec@1 83.811 Prec@5 91.276\n",
      " * Prec@1 83.836 Prec@5 91.293\n",
      " * Prec@1 83.562 Prec@5 91.096\n",
      " * Prec@1 83.503 Prec@5 91.071\n",
      " * Prec@1 83.530 Prec@5 91.047\n",
      " * Prec@1 83.515 Prec@5 90.982\n",
      " * Prec@1 83.542 Prec@5 91.042\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.507 (0.530)\n",
      "\n",
      "Loss 1.3272 (0.8144)\n",
      "\n",
      "Prec@1 75.000 (83.485)\n",
      "\n",
      "Prec@5 87.500 (91.018)\n",
      "\n",
      " * Prec@1 83.485 Prec@5 91.018\n",
      " * Prec@1 83.594 Prec@5 91.077\n",
      " * Prec@1 83.660 Prec@5 91.136\n",
      " * Prec@1 83.726 Prec@5 91.193\n",
      " * Prec@1 83.831 Prec@5 91.250\n",
      " * Prec@1 83.774 Prec@5 91.146\n",
      " * Prec@1 83.678 Prec@5 91.043\n",
      " * Prec@1 83.782 Prec@5 91.100\n",
      " * Prec@1 83.687 Prec@5 91.077\n",
      " * Prec@1 83.672 Prec@5 91.133\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.510 (0.529)\n",
      "\n",
      "Loss 0.4099 (0.7994)\n",
      "\n",
      "Prec@1 87.500 (83.696)\n",
      "\n",
      "Prec@5 100.000 (91.188)\n",
      "\n",
      " * Prec@1 83.696 Prec@5 91.188\n",
      " * Prec@1 83.758 Prec@5 91.204\n",
      " * Prec@1 83.742 Prec@5 91.181\n",
      " * Prec@1 83.803 Prec@5 91.197\n",
      " * Prec@1 83.826 Prec@5 91.212\n",
      " * Prec@1 83.886 Prec@5 91.227\n",
      " * Prec@1 83.795 Prec@5 91.243\n",
      " * Prec@1 83.743 Prec@5 91.183\n",
      " * Prec@1 83.736 Prec@5 91.199\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [17][0/1515]\t\\Time 0.603 (0.603)\tData 0.492 (0.492)\tLoss 0.0802 (0.0802)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/1515]\t\\Time 0.420 (0.532)\tData 0.340 (0.428)\tLoss 0.0037 (0.0143)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][200/1515]\t\\Time 0.541 (0.532)\tData 0.422 (0.430)\tLoss 0.0024 (0.0094)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][300/1515]\t\\Time 0.560 (0.534)\tData 0.481 (0.432)\tLoss 0.0030 (0.0114)\tPrec@1 100.000 (99.605)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][400/1515]\t\\Time 0.559 (0.535)\tData 0.478 (0.433)\tLoss 0.0036 (0.0118)\tPrec@1 100.000 (99.626)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][500/1515]\t\\Time 0.581 (0.538)\tData 0.501 (0.436)\tLoss 0.0049 (0.0108)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][600/1515]\t\\Time 0.603 (0.540)\tData 0.493 (0.438)\tLoss 0.0039 (0.0100)\tPrec@1 100.000 (99.698)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][700/1515]\t\\Time 0.551 (0.540)\tData 0.481 (0.438)\tLoss 0.0583 (0.0104)\tPrec@1 93.750 (99.679)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][800/1515]\t\\Time 0.624 (0.546)\tData 0.516 (0.443)\tLoss 0.0043 (0.0104)\tPrec@1 100.000 (99.680)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][900/1515]\t\\Time 0.613 (0.548)\tData 0.506 (0.446)\tLoss 0.0034 (0.0109)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1000/1515]\t\\Time 0.531 (0.549)\tData 0.421 (0.447)\tLoss 0.0027 (0.0107)\tPrec@1 100.000 (99.675)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1100/1515]\t\\Time 0.565 (0.549)\tData 0.455 (0.447)\tLoss 0.0726 (0.0110)\tPrec@1 93.750 (99.665)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1200/1515]\t\\Time 0.574 (0.549)\tData 0.450 (0.447)\tLoss 0.0098 (0.0113)\tPrec@1 100.000 (99.657)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1300/1515]\t\\Time 0.601 (0.549)\tData 0.491 (0.446)\tLoss 0.0044 (0.0119)\tPrec@1 100.000 (99.635)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1400/1515]\t\\Time 0.521 (0.549)\tData 0.401 (0.447)\tLoss 0.0056 (0.0121)\tPrec@1 100.000 (99.639)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][1500/1515]\t\\Time 0.552 (0.550)\tData 0.442 (0.447)\tLoss 0.0028 (0.0124)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.479 (0.479)\n",
      "\n",
      "Loss 0.2822 (0.2822)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 91.667 Prec@5 93.750\n",
      " * Prec@1 92.188 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 89.583 Prec@5 93.750\n",
      " * Prec@1 88.393 Prec@5 92.857\n",
      " * Prec@1 89.062 Prec@5 92.969\n",
      " * Prec@1 88.194 Prec@5 92.361\n",
      " * Prec@1 87.500 Prec@5 91.250\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.530 (0.559)\n",
      "\n",
      "Loss 0.4890 (0.6376)\n",
      "\n",
      "Prec@1 87.500 (87.500)\n",
      "\n",
      "Prec@5 93.750 (91.477)\n",
      "\n",
      " * Prec@1 87.500 Prec@5 91.477\n",
      " * Prec@1 87.500 Prec@5 92.188\n",
      " * Prec@1 88.462 Prec@5 92.788\n",
      " * Prec@1 87.500 Prec@5 91.964\n",
      " * Prec@1 86.667 Prec@5 91.250\n",
      " * Prec@1 86.719 Prec@5 91.797\n",
      " * Prec@1 85.294 Prec@5 90.809\n",
      " * Prec@1 84.375 Prec@5 90.278\n",
      " * Prec@1 83.882 Prec@5 89.803\n",
      " * Prec@1 83.750 Prec@5 89.688\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.581 (0.550)\n",
      "\n",
      "Loss 0.6509 (0.8037)\n",
      "\n",
      "Prec@1 93.750 (84.226)\n",
      "\n",
      "Prec@5 93.750 (89.881)\n",
      "\n",
      " * Prec@1 84.226 Prec@5 89.881\n",
      " * Prec@1 83.807 Prec@5 89.489\n",
      " * Prec@1 83.967 Prec@5 89.946\n",
      " * Prec@1 83.854 Prec@5 90.365\n",
      " * Prec@1 83.750 Prec@5 90.250\n",
      " * Prec@1 84.135 Prec@5 90.625\n",
      " * Prec@1 84.491 Prec@5 90.972\n",
      " * Prec@1 84.375 Prec@5 90.848\n",
      " * Prec@1 84.267 Prec@5 91.164\n",
      " * Prec@1 83.958 Prec@5 90.833\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.523 (0.550)\n",
      "\n",
      "Loss 0.5113 (0.7681)\n",
      "\n",
      "Prec@1 93.750 (84.274)\n",
      "\n",
      "Prec@5 93.750 (90.927)\n",
      "\n",
      " * Prec@1 84.274 Prec@5 90.927\n",
      " * Prec@1 84.570 Prec@5 91.016\n",
      " * Prec@1 84.091 Prec@5 90.530\n",
      " * Prec@1 83.456 Prec@5 89.890\n",
      " * Prec@1 83.393 Prec@5 90.000\n",
      " * Prec@1 83.333 Prec@5 89.931\n",
      " * Prec@1 83.277 Prec@5 90.034\n",
      " * Prec@1 83.388 Prec@5 90.296\n",
      " * Prec@1 83.173 Prec@5 90.224\n",
      " * Prec@1 82.969 Prec@5 90.312\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.510 (0.546)\n",
      "\n",
      "Loss 0.7401 (0.8123)\n",
      "\n",
      "Prec@1 87.500 (83.079)\n",
      "\n",
      "Prec@5 93.750 (90.396)\n",
      "\n",
      " * Prec@1 83.079 Prec@5 90.396\n",
      " * Prec@1 82.738 Prec@5 90.327\n",
      " * Prec@1 82.849 Prec@5 90.407\n",
      " * Prec@1 82.955 Prec@5 90.483\n",
      " * Prec@1 83.194 Prec@5 90.556\n",
      " * Prec@1 83.016 Prec@5 90.625\n",
      " * Prec@1 83.378 Prec@5 90.824\n",
      " * Prec@1 83.333 Prec@5 90.755\n",
      " * Prec@1 83.546 Prec@5 90.816\n",
      " * Prec@1 83.500 Prec@5 90.875\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.496 (0.541)\n",
      "\n",
      "Loss 1.4155 (0.8008)\n",
      "\n",
      "Prec@1 75.000 (83.333)\n",
      "\n",
      "Prec@5 81.250 (90.686)\n",
      "\n",
      " * Prec@1 83.333 Prec@5 90.686\n",
      " * Prec@1 83.173 Prec@5 90.745\n",
      " * Prec@1 83.255 Prec@5 90.920\n",
      " * Prec@1 83.102 Prec@5 90.856\n",
      " * Prec@1 82.841 Prec@5 90.909\n",
      " * Prec@1 82.812 Prec@5 90.960\n",
      " * Prec@1 82.785 Prec@5 91.009\n",
      " * Prec@1 82.759 Prec@5 91.056\n",
      " * Prec@1 82.733 Prec@5 91.102\n",
      " * Prec@1 82.708 Prec@5 91.250\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.539 (0.542)\n",
      "\n",
      "Loss 2.1100 (0.8220)\n",
      "\n",
      "Prec@1 62.500 (82.377)\n",
      "\n",
      "Prec@5 75.000 (90.984)\n",
      "\n",
      " * Prec@1 82.377 Prec@5 90.984\n",
      " * Prec@1 82.258 Prec@5 91.028\n",
      " * Prec@1 82.242 Prec@5 91.071\n",
      " * Prec@1 82.227 Prec@5 91.016\n",
      " * Prec@1 81.923 Prec@5 90.769\n",
      " * Prec@1 82.102 Prec@5 90.814\n",
      " * Prec@1 82.276 Prec@5 90.858\n",
      " * Prec@1 82.261 Prec@5 90.901\n",
      " * Prec@1 82.337 Prec@5 90.942\n",
      " * Prec@1 82.321 Prec@5 90.982\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.499 (0.539)\n",
      "\n",
      "Loss 0.2510 (0.8298)\n",
      "\n",
      "Prec@1 93.750 (82.482)\n",
      "\n",
      "Prec@5 93.750 (91.021)\n",
      "\n",
      " * Prec@1 82.482 Prec@5 91.021\n",
      " * Prec@1 82.552 Prec@5 90.972\n",
      " * Prec@1 82.620 Prec@5 91.010\n",
      " * Prec@1 82.686 Prec@5 91.047\n",
      " * Prec@1 82.750 Prec@5 91.000\n",
      " * Prec@1 82.812 Prec@5 90.954\n",
      " * Prec@1 82.955 Prec@5 91.071\n",
      " * Prec@1 83.013 Prec@5 91.026\n",
      " * Prec@1 82.911 Prec@5 90.902\n",
      " * Prec@1 82.812 Prec@5 90.859\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.521 (0.540)\n",
      "\n",
      "Loss 1.8011 (0.8436)\n",
      "\n",
      "Prec@1 68.750 (82.639)\n",
      "\n",
      "Prec@5 75.000 (90.664)\n",
      "\n",
      " * Prec@1 82.639 Prec@5 90.664\n",
      " * Prec@1 82.622 Prec@5 90.701\n",
      " * Prec@1 82.605 Prec@5 90.738\n",
      " * Prec@1 82.589 Prec@5 90.774\n",
      " * Prec@1 82.647 Prec@5 90.735\n",
      " * Prec@1 82.703 Prec@5 90.698\n",
      " * Prec@1 82.759 Prec@5 90.733\n",
      " * Prec@1 82.741 Prec@5 90.625\n",
      " * Prec@1 82.865 Prec@5 90.660\n",
      " * Prec@1 82.917 Prec@5 90.694\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.462 (0.537)\n",
      "\n",
      "Loss 0.0043 (0.8184)\n",
      "\n",
      "Prec@1 100.000 (83.104)\n",
      "\n",
      "Prec@5 100.000 (90.797)\n",
      "\n",
      " * Prec@1 83.104 Prec@5 90.797\n",
      " * Prec@1 83.152 Prec@5 90.829\n",
      " * Prec@1 83.266 Prec@5 90.927\n",
      " * Prec@1 83.311 Prec@5 90.957\n",
      " * Prec@1 83.355 Prec@5 90.987\n",
      " * Prec@1 83.333 Prec@5 90.885\n",
      " * Prec@1 83.247 Prec@5 90.786\n",
      " * Prec@1 83.099 Prec@5 90.625\n",
      " * Prec@1 83.144 Prec@5 90.657\n",
      " * Prec@1 83.312 Prec@5 90.750\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.551 (0.539)\n",
      "\n",
      "Loss 0.9281 (0.8208)\n",
      "\n",
      "Prec@1 81.250 (83.292)\n",
      "\n",
      "Prec@5 87.500 (90.718)\n",
      "\n",
      " * Prec@1 83.292 Prec@5 90.718\n",
      " * Prec@1 83.395 Prec@5 90.809\n",
      " * Prec@1 83.313 Prec@5 90.777\n",
      " * Prec@1 83.353 Prec@5 90.805\n",
      " * Prec@1 83.333 Prec@5 90.774\n",
      " * Prec@1 83.373 Prec@5 90.743\n",
      " * Prec@1 83.528 Prec@5 90.829\n",
      " * Prec@1 83.623 Prec@5 90.914\n",
      " * Prec@1 83.716 Prec@5 90.940\n",
      " * Prec@1 83.636 Prec@5 91.023\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.481 (0.537)\n",
      "\n",
      "Loss 0.7046 (0.8004)\n",
      "\n",
      "Prec@1 87.500 (83.671)\n",
      "\n",
      "Prec@5 93.750 (91.047)\n",
      "\n",
      " * Prec@1 83.671 Prec@5 91.047\n",
      " * Prec@1 83.482 Prec@5 90.904\n",
      " * Prec@1 83.518 Prec@5 90.985\n",
      " * Prec@1 83.443 Prec@5 90.954\n",
      " * Prec@1 83.533 Prec@5 90.978\n",
      " * Prec@1 83.513 Prec@5 91.056\n",
      " * Prec@1 83.547 Prec@5 91.079\n",
      " * Prec@1 83.475 Prec@5 90.996\n",
      " * Prec@1 83.613 Prec@5 91.071\n",
      " * Prec@1 83.542 Prec@5 91.094\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.522 (0.536)\n",
      "\n",
      "Loss 0.3024 (0.7971)\n",
      "\n",
      "Prec@1 93.750 (83.626)\n",
      "\n",
      "Prec@5 100.000 (91.167)\n",
      "\n",
      " * Prec@1 83.626 Prec@5 91.167\n",
      " * Prec@1 83.658 Prec@5 91.137\n",
      " * Prec@1 83.740 Prec@5 91.159\n",
      " * Prec@1 83.770 Prec@5 91.129\n",
      " * Prec@1 83.850 Prec@5 91.200\n",
      " * Prec@1 83.829 Prec@5 91.220\n",
      " * Prec@1 83.907 Prec@5 91.289\n",
      " * Prec@1 83.984 Prec@5 91.357\n",
      " * Prec@1 84.060 Prec@5 91.376\n",
      " * Prec@1 84.087 Prec@5 91.442\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.564 (0.535)\n",
      "\n",
      "Loss 1.0380 (0.7747)\n",
      "\n",
      "Prec@1 75.000 (84.017)\n",
      "\n",
      "Prec@5 87.500 (91.412)\n",
      "\n",
      " * Prec@1 84.017 Prec@5 91.412\n",
      " * Prec@1 84.091 Prec@5 91.430\n",
      " * Prec@1 84.211 Prec@5 91.494\n",
      " * Prec@1 84.095 Prec@5 91.511\n",
      " * Prec@1 84.120 Prec@5 91.574\n",
      " * Prec@1 84.007 Prec@5 91.406\n",
      " * Prec@1 83.942 Prec@5 91.378\n",
      " * Prec@1 83.922 Prec@5 91.304\n",
      " * Prec@1 84.038 Prec@5 91.367\n",
      " * Prec@1 83.929 Prec@5 91.295\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.520 (0.533)\n",
      "\n",
      "Loss 1.1744 (0.7857)\n",
      "\n",
      "Prec@1 81.250 (83.910)\n",
      "\n",
      "Prec@5 87.500 (91.268)\n",
      "\n",
      " * Prec@1 83.910 Prec@5 91.268\n",
      " * Prec@1 83.759 Prec@5 91.109\n",
      " * Prec@1 83.654 Prec@5 91.084\n",
      " * Prec@1 83.637 Prec@5 91.102\n",
      " * Prec@1 83.664 Prec@5 91.121\n",
      " * Prec@1 83.390 Prec@5 90.925\n",
      " * Prec@1 83.333 Prec@5 90.901\n",
      " * Prec@1 83.361 Prec@5 90.878\n",
      " * Prec@1 83.347 Prec@5 90.814\n",
      " * Prec@1 83.375 Prec@5 90.833\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.523 (0.534)\n",
      "\n",
      "Loss 1.3043 (0.8182)\n",
      "\n",
      "Prec@1 75.000 (83.320)\n",
      "\n",
      "Prec@5 87.500 (90.811)\n",
      "\n",
      " * Prec@1 83.320 Prec@5 90.811\n",
      " * Prec@1 83.429 Prec@5 90.872\n",
      " * Prec@1 83.497 Prec@5 90.931\n",
      " * Prec@1 83.563 Prec@5 90.990\n",
      " * Prec@1 83.669 Prec@5 91.048\n",
      " * Prec@1 83.574 Prec@5 90.946\n",
      " * Prec@1 83.479 Prec@5 90.844\n",
      " * Prec@1 83.584 Prec@5 90.902\n",
      " * Prec@1 83.491 Prec@5 90.881\n",
      " * Prec@1 83.477 Prec@5 90.938\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.500 (0.534)\n",
      "\n",
      "Loss 0.4019 (0.8036)\n",
      "\n",
      "Prec@1 87.500 (83.502)\n",
      "\n",
      "Prec@5 100.000 (90.994)\n",
      "\n",
      " * Prec@1 83.502 Prec@5 90.994\n",
      " * Prec@1 83.565 Prec@5 91.011\n",
      " * Prec@1 83.551 Prec@5 90.989\n",
      " * Prec@1 83.613 Prec@5 91.006\n",
      " * Prec@1 83.636 Prec@5 91.023\n",
      " * Prec@1 83.697 Prec@5 91.039\n",
      " * Prec@1 83.608 Prec@5 91.055\n",
      " * Prec@1 83.557 Prec@5 90.997\n",
      " * Prec@1 83.550 Prec@5 91.014\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [18][0/1515]\t\\Time 0.561 (0.561)\tData 0.452 (0.452)\tLoss 0.0021 (0.0021)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/1515]\t\\Time 0.482 (0.528)\tData 0.371 (0.426)\tLoss 0.0028 (0.0041)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][200/1515]\t\\Time 0.491 (0.539)\tData 0.371 (0.437)\tLoss 0.0047 (0.0047)\tPrec@1 100.000 (99.969)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][300/1515]\t\\Time 0.512 (0.543)\tData 0.402 (0.440)\tLoss 0.0030 (0.0062)\tPrec@1 100.000 (99.917)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][400/1515]\t\\Time 0.686 (0.558)\tData 0.570 (0.455)\tLoss 0.0047 (0.0075)\tPrec@1 100.000 (99.844)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][500/1515]\t\\Time 0.604 (0.571)\tData 0.523 (0.468)\tLoss 0.0049 (0.0097)\tPrec@1 100.000 (99.763)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][600/1515]\t\\Time 0.563 (0.569)\tData 0.468 (0.466)\tLoss 0.0662 (0.0098)\tPrec@1 93.750 (99.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][700/1515]\t\\Time 0.527 (0.573)\tData 0.427 (0.469)\tLoss 0.0154 (0.0100)\tPrec@1 100.000 (99.741)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][800/1515]\t\\Time 0.650 (0.571)\tData 0.530 (0.468)\tLoss 0.0022 (0.0108)\tPrec@1 100.000 (99.719)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][900/1515]\t\\Time 0.541 (0.570)\tData 0.421 (0.466)\tLoss 0.0043 (0.0107)\tPrec@1 100.000 (99.729)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1000/1515]\t\\Time 0.554 (0.569)\tData 0.474 (0.465)\tLoss 0.0073 (0.0110)\tPrec@1 100.000 (99.725)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1100/1515]\t\\Time 0.580 (0.568)\tData 0.470 (0.465)\tLoss 0.0028 (0.0113)\tPrec@1 100.000 (99.710)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1200/1515]\t\\Time 0.552 (0.568)\tData 0.442 (0.464)\tLoss 0.0027 (0.0114)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1300/1515]\t\\Time 0.533 (0.567)\tData 0.424 (0.463)\tLoss 0.0044 (0.0116)\tPrec@1 100.000 (99.678)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1400/1515]\t\\Time 0.610 (0.567)\tData 0.511 (0.463)\tLoss 0.0041 (0.0120)\tPrec@1 100.000 (99.661)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][1500/1515]\t\\Time 0.501 (0.565)\tData 0.381 (0.461)\tLoss 0.0048 (0.0120)\tPrec@1 100.000 (99.663)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.465 (0.465)\n",
      "\n",
      "Loss 0.2959 (0.2959)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 95.000\n",
      " * Prec@1 90.625 Prec@5 93.750\n",
      " * Prec@1 89.286 Prec@5 92.857\n",
      " * Prec@1 89.844 Prec@5 93.750\n",
      " * Prec@1 88.889 Prec@5 93.056\n",
      " * Prec@1 88.125 Prec@5 91.875\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.572 (0.552)\n",
      "\n",
      "Loss 0.4783 (0.6424)\n",
      "\n",
      "Prec@1 87.500 (88.068)\n",
      "\n",
      "Prec@5 100.000 (92.614)\n",
      "\n",
      " * Prec@1 88.068 Prec@5 92.614\n",
      " * Prec@1 88.021 Prec@5 93.229\n",
      " * Prec@1 88.942 Prec@5 93.750\n",
      " * Prec@1 87.946 Prec@5 92.857\n",
      " * Prec@1 87.083 Prec@5 92.500\n",
      " * Prec@1 87.109 Prec@5 92.578\n",
      " * Prec@1 86.029 Prec@5 91.912\n",
      " * Prec@1 85.069 Prec@5 91.319\n",
      " * Prec@1 84.539 Prec@5 91.118\n",
      " * Prec@1 84.375 Prec@5 91.250\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.553 (0.539)\n",
      "\n",
      "Loss 0.6114 (0.7818)\n",
      "\n",
      "Prec@1 93.750 (84.821)\n",
      "\n",
      "Prec@5 93.750 (91.369)\n",
      "\n",
      " * Prec@1 84.821 Prec@5 91.369\n",
      " * Prec@1 84.375 Prec@5 90.909\n",
      " * Prec@1 84.239 Prec@5 91.304\n",
      " * Prec@1 84.115 Prec@5 91.667\n",
      " * Prec@1 84.000 Prec@5 91.500\n",
      " * Prec@1 84.375 Prec@5 91.827\n",
      " * Prec@1 84.491 Prec@5 92.130\n",
      " * Prec@1 84.375 Prec@5 91.964\n",
      " * Prec@1 84.483 Prec@5 92.026\n",
      " * Prec@1 84.167 Prec@5 91.875\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.531 (0.534)\n",
      "\n",
      "Loss 0.5454 (0.7652)\n",
      "\n",
      "Prec@1 87.500 (84.274)\n",
      "\n",
      "Prec@5 93.750 (91.935)\n",
      "\n",
      " * Prec@1 84.274 Prec@5 91.935\n",
      " * Prec@1 84.570 Prec@5 91.992\n",
      " * Prec@1 84.280 Prec@5 91.667\n",
      " * Prec@1 83.640 Prec@5 91.176\n",
      " * Prec@1 83.393 Prec@5 91.071\n",
      " * Prec@1 83.333 Prec@5 90.972\n",
      " * Prec@1 83.446 Prec@5 91.047\n",
      " * Prec@1 83.553 Prec@5 91.283\n",
      " * Prec@1 83.333 Prec@5 91.186\n",
      " * Prec@1 83.125 Prec@5 91.250\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.490 (0.532)\n",
      "\n",
      "Loss 0.7270 (0.8063)\n",
      "\n",
      "Prec@1 87.500 (83.232)\n",
      "\n",
      "Prec@5 93.750 (91.311)\n",
      "\n",
      " * Prec@1 83.232 Prec@5 91.311\n",
      " * Prec@1 82.887 Prec@5 91.220\n",
      " * Prec@1 82.994 Prec@5 91.424\n",
      " * Prec@1 83.097 Prec@5 91.477\n",
      " * Prec@1 83.194 Prec@5 91.528\n",
      " * Prec@1 83.016 Prec@5 91.576\n",
      " * Prec@1 83.378 Prec@5 91.755\n",
      " * Prec@1 83.333 Prec@5 91.667\n",
      " * Prec@1 83.546 Prec@5 91.709\n",
      " * Prec@1 83.500 Prec@5 91.625\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.501 (0.531)\n",
      "\n",
      "Loss 1.3948 (0.7971)\n",
      "\n",
      "Prec@1 68.750 (83.211)\n",
      "\n",
      "Prec@5 87.500 (91.544)\n",
      "\n",
      " * Prec@1 83.211 Prec@5 91.544\n",
      " * Prec@1 83.053 Prec@5 91.466\n",
      " * Prec@1 83.137 Prec@5 91.627\n",
      " * Prec@1 83.102 Prec@5 91.551\n",
      " * Prec@1 82.841 Prec@5 91.591\n",
      " * Prec@1 82.812 Prec@5 91.629\n",
      " * Prec@1 82.785 Prec@5 91.667\n",
      " * Prec@1 82.759 Prec@5 91.703\n",
      " * Prec@1 82.733 Prec@5 91.737\n",
      " * Prec@1 82.604 Prec@5 91.875\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.539 (0.535)\n",
      "\n",
      "Loss 2.2277 (0.8233)\n",
      "\n",
      "Prec@1 68.750 (82.377)\n",
      "\n",
      "Prec@5 75.000 (91.598)\n",
      "\n",
      " * Prec@1 82.377 Prec@5 91.598\n",
      " * Prec@1 82.258 Prec@5 91.633\n",
      " * Prec@1 82.242 Prec@5 91.667\n",
      " * Prec@1 82.324 Prec@5 91.602\n",
      " * Prec@1 82.019 Prec@5 91.442\n",
      " * Prec@1 82.102 Prec@5 91.477\n",
      " * Prec@1 82.276 Prec@5 91.511\n",
      " * Prec@1 82.261 Prec@5 91.544\n",
      " * Prec@1 82.246 Prec@5 91.576\n",
      " * Prec@1 82.232 Prec@5 91.518\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.481 (0.533)\n",
      "\n",
      "Loss 0.2005 (0.8312)\n",
      "\n",
      "Prec@1 93.750 (82.394)\n",
      "\n",
      "Prec@5 100.000 (91.637)\n",
      "\n",
      " * Prec@1 82.394 Prec@5 91.637\n",
      " * Prec@1 82.465 Prec@5 91.667\n",
      " * Prec@1 82.534 Prec@5 91.781\n",
      " * Prec@1 82.601 Prec@5 91.807\n",
      " * Prec@1 82.667 Prec@5 91.833\n",
      " * Prec@1 82.730 Prec@5 91.776\n",
      " * Prec@1 82.873 Prec@5 91.802\n",
      " * Prec@1 82.933 Prec@5 91.747\n",
      " * Prec@1 82.753 Prec@5 91.693\n",
      " * Prec@1 82.656 Prec@5 91.641\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.482 (0.532)\n",
      "\n",
      "Loss 1.7886 (0.8395)\n",
      "\n",
      "Prec@1 68.750 (82.485)\n",
      "\n",
      "Prec@5 75.000 (91.435)\n",
      "\n",
      " * Prec@1 82.485 Prec@5 91.435\n",
      " * Prec@1 82.470 Prec@5 91.463\n",
      " * Prec@1 82.530 Prec@5 91.491\n",
      " * Prec@1 82.589 Prec@5 91.518\n",
      " * Prec@1 82.574 Prec@5 91.471\n",
      " * Prec@1 82.631 Prec@5 91.424\n",
      " * Prec@1 82.687 Prec@5 91.451\n",
      " * Prec@1 82.670 Prec@5 91.335\n",
      " * Prec@1 82.725 Prec@5 91.362\n",
      " * Prec@1 82.778 Prec@5 91.389\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.457 (0.531)\n",
      "\n",
      "Loss 0.0046 (0.8145)\n",
      "\n",
      "Prec@1 100.000 (82.967)\n",
      "\n",
      "Prec@5 100.000 (91.484)\n",
      "\n",
      " * Prec@1 82.967 Prec@5 91.484\n",
      " * Prec@1 83.084 Prec@5 91.508\n",
      " * Prec@1 83.199 Prec@5 91.599\n",
      " * Prec@1 83.245 Prec@5 91.622\n",
      " * Prec@1 83.289 Prec@5 91.579\n",
      " * Prec@1 83.268 Prec@5 91.471\n",
      " * Prec@1 83.247 Prec@5 91.366\n",
      " * Prec@1 83.163 Prec@5 91.199\n",
      " * Prec@1 83.207 Prec@5 91.225\n",
      " * Prec@1 83.375 Prec@5 91.312\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.592 (0.534)\n",
      "\n",
      "Loss 0.9977 (0.8172)\n",
      "\n",
      "Prec@1 81.250 (83.354)\n",
      "\n",
      "Prec@5 87.500 (91.275)\n",
      "\n",
      " * Prec@1 83.354 Prec@5 91.275\n",
      " * Prec@1 83.456 Prec@5 91.360\n",
      " * Prec@1 83.374 Prec@5 91.323\n",
      " * Prec@1 83.413 Prec@5 91.286\n",
      " * Prec@1 83.393 Prec@5 91.250\n",
      " * Prec@1 83.432 Prec@5 91.215\n",
      " * Prec@1 83.586 Prec@5 91.297\n",
      " * Prec@1 83.681 Prec@5 91.377\n",
      " * Prec@1 83.716 Prec@5 91.456\n",
      " * Prec@1 83.636 Prec@5 91.534\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.512 (0.534)\n",
      "\n",
      "Loss 0.9285 (0.7964)\n",
      "\n",
      "Prec@1 81.250 (83.615)\n",
      "\n",
      "Prec@5 93.750 (91.554)\n",
      "\n",
      " * Prec@1 83.615 Prec@5 91.554\n",
      " * Prec@1 83.371 Prec@5 91.406\n",
      " * Prec@1 83.352 Prec@5 91.482\n",
      " * Prec@1 83.279 Prec@5 91.447\n",
      " * Prec@1 83.370 Prec@5 91.467\n",
      " * Prec@1 83.405 Prec@5 91.541\n",
      " * Prec@1 83.387 Prec@5 91.560\n",
      " * Prec@1 83.316 Prec@5 91.472\n",
      " * Prec@1 83.456 Prec@5 91.544\n",
      " * Prec@1 83.385 Prec@5 91.562\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.511 (0.535)\n",
      "\n",
      "Loss 0.0721 (0.7930)\n",
      "\n",
      "Prec@1 100.000 (83.523)\n",
      "\n",
      "Prec@5 100.000 (91.632)\n",
      "\n",
      " * Prec@1 83.523 Prec@5 91.632\n",
      " * Prec@1 83.555 Prec@5 91.598\n",
      " * Prec@1 83.638 Prec@5 91.616\n",
      " * Prec@1 83.669 Prec@5 91.633\n",
      " * Prec@1 83.650 Prec@5 91.650\n",
      " * Prec@1 83.631 Prec@5 91.667\n",
      " * Prec@1 83.612 Prec@5 91.732\n",
      " * Prec@1 83.691 Prec@5 91.797\n",
      " * Prec@1 83.769 Prec@5 91.812\n",
      " * Prec@1 83.846 Prec@5 91.875\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.560 (0.534)\n",
      "\n",
      "Loss 0.8661 (0.7702)\n",
      "\n",
      "Prec@1 75.000 (83.779)\n",
      "\n",
      "Prec@5 87.500 (91.842)\n",
      "\n",
      " * Prec@1 83.779 Prec@5 91.842\n",
      " * Prec@1 83.854 Prec@5 91.856\n",
      " * Prec@1 83.976 Prec@5 91.917\n",
      " * Prec@1 83.862 Prec@5 91.931\n",
      " * Prec@1 83.889 Prec@5 91.991\n",
      " * Prec@1 83.778 Prec@5 91.820\n",
      " * Prec@1 83.714 Prec@5 91.788\n",
      " * Prec@1 83.696 Prec@5 91.712\n",
      " * Prec@1 83.768 Prec@5 91.772\n",
      " * Prec@1 83.661 Prec@5 91.696\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.534 (0.532)\n",
      "\n",
      "Loss 1.1146 (0.7809)\n",
      "\n",
      "Prec@1 87.500 (83.688)\n",
      "\n",
      "Prec@5 87.500 (91.667)\n",
      "\n",
      " * Prec@1 83.688 Prec@5 91.667\n",
      " * Prec@1 83.539 Prec@5 91.505\n",
      " * Prec@1 83.435 Prec@5 91.477\n",
      " * Prec@1 83.420 Prec@5 91.493\n",
      " * Prec@1 83.448 Prec@5 91.509\n",
      " * Prec@1 83.176 Prec@5 91.353\n",
      " * Prec@1 83.121 Prec@5 91.327\n",
      " * Prec@1 83.150 Prec@5 91.343\n",
      " * Prec@1 83.138 Prec@5 91.317\n",
      " * Prec@1 83.167 Prec@5 91.375\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.554 (0.534)\n",
      "\n",
      "Loss 1.3636 (0.8135)\n",
      "\n",
      "Prec@1 75.000 (83.113)\n",
      "\n",
      "Prec@5 87.500 (91.349)\n",
      "\n",
      " * Prec@1 83.113 Prec@5 91.349\n",
      " * Prec@1 83.224 Prec@5 91.406\n",
      " * Prec@1 83.292 Prec@5 91.462\n",
      " * Prec@1 83.360 Prec@5 91.518\n",
      " * Prec@1 83.468 Prec@5 91.573\n",
      " * Prec@1 83.413 Prec@5 91.466\n",
      " * Prec@1 83.320 Prec@5 91.361\n",
      " * Prec@1 83.426 Prec@5 91.416\n",
      " * Prec@1 83.333 Prec@5 91.392\n",
      " * Prec@1 83.320 Prec@5 91.445\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.582 (0.535)\n",
      "\n",
      "Loss 0.4812 (0.7993)\n",
      "\n",
      "Prec@1 81.250 (83.307)\n",
      "\n",
      "Prec@5 93.750 (91.460)\n",
      "\n",
      " * Prec@1 83.307 Prec@5 91.460\n",
      " * Prec@1 83.372 Prec@5 91.474\n",
      " * Prec@1 83.359 Prec@5 91.449\n",
      " * Prec@1 83.422 Prec@5 91.463\n",
      " * Prec@1 83.447 Prec@5 91.477\n",
      " * Prec@1 83.471 Prec@5 91.491\n",
      " * Prec@1 83.383 Prec@5 91.504\n",
      " * Prec@1 83.371 Prec@5 91.443\n",
      " * Prec@1 83.364 Prec@5 91.459\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [19][0/1515]\t\\Time 0.531 (0.531)\tData 0.421 (0.421)\tLoss 0.0025 (0.0025)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][100/1515]\t\\Time 0.560 (0.531)\tData 0.450 (0.428)\tLoss 0.0024 (0.0168)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][200/1515]\t\\Time 0.528 (0.533)\tData 0.418 (0.430)\tLoss 0.0026 (0.0126)\tPrec@1 100.000 (99.658)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][300/1515]\t\\Time 0.550 (0.535)\tData 0.450 (0.432)\tLoss 0.0038 (0.0127)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][400/1515]\t\\Time 0.541 (0.534)\tData 0.430 (0.432)\tLoss 0.0024 (0.0125)\tPrec@1 100.000 (99.673)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][500/1515]\t\\Time 0.511 (0.537)\tData 0.410 (0.435)\tLoss 0.0039 (0.0123)\tPrec@1 100.000 (99.676)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][600/1515]\t\\Time 0.551 (0.539)\tData 0.441 (0.437)\tLoss 0.0042 (0.0118)\tPrec@1 100.000 (99.698)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][700/1515]\t\\Time 0.543 (0.542)\tData 0.431 (0.439)\tLoss 0.0034 (0.0118)\tPrec@1 100.000 (99.697)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][800/1515]\t\\Time 0.480 (0.543)\tData 0.410 (0.440)\tLoss 0.0032 (0.0119)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][900/1515]\t\\Time 0.611 (0.543)\tData 0.491 (0.440)\tLoss 0.0062 (0.0119)\tPrec@1 100.000 (99.681)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1000/1515]\t\\Time 0.480 (0.543)\tData 0.410 (0.440)\tLoss 0.0055 (0.0129)\tPrec@1 100.000 (99.644)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1100/1515]\t\\Time 0.491 (0.543)\tData 0.421 (0.440)\tLoss 0.0035 (0.0127)\tPrec@1 100.000 (99.648)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1200/1515]\t\\Time 0.501 (0.544)\tData 0.391 (0.441)\tLoss 0.0058 (0.0128)\tPrec@1 100.000 (99.641)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1300/1515]\t\\Time 0.553 (0.545)\tData 0.443 (0.442)\tLoss 0.0041 (0.0127)\tPrec@1 100.000 (99.640)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1400/1515]\t\\Time 0.597 (0.545)\tData 0.477 (0.442)\tLoss 0.0096 (0.0127)\tPrec@1 100.000 (99.639)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][1500/1515]\t\\Time 0.630 (0.545)\tData 0.520 (0.442)\tLoss 0.0041 (0.0130)\tPrec@1 100.000 (99.617)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/169]\n",
      "\n",
      "Time 0.481 (0.481)\n",
      "\n",
      "Loss 0.3169 (0.3169)\n",
      "\n",
      "Prec@1 93.750 (93.750)\n",
      "\n",
      "Prec@5 93.750 (93.750)\n",
      "\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 93.750 Prec@5 93.750\n",
      " * Prec@1 92.188 Prec@5 93.750\n",
      " * Prec@1 92.500 Prec@5 95.000\n",
      " * Prec@1 89.583 Prec@5 93.750\n",
      " * Prec@1 88.393 Prec@5 92.857\n",
      " * Prec@1 88.281 Prec@5 93.750\n",
      " * Prec@1 87.500 Prec@5 93.056\n",
      " * Prec@1 86.875 Prec@5 91.875\n",
      "Test: [10/169]\n",
      "\n",
      "Time 0.552 (0.541)\n",
      "\n",
      "Loss 0.4517 (0.6397)\n",
      "\n",
      "Prec@1 87.500 (86.932)\n",
      "\n",
      "Prec@5 93.750 (92.045)\n",
      "\n",
      " * Prec@1 86.932 Prec@5 92.045\n",
      " * Prec@1 86.979 Prec@5 92.708\n",
      " * Prec@1 87.981 Prec@5 93.269\n",
      " * Prec@1 87.500 Prec@5 92.411\n",
      " * Prec@1 86.667 Prec@5 92.083\n",
      " * Prec@1 86.719 Prec@5 92.188\n",
      " * Prec@1 85.294 Prec@5 91.176\n",
      " * Prec@1 84.375 Prec@5 90.972\n",
      " * Prec@1 83.882 Prec@5 90.789\n",
      " * Prec@1 83.750 Prec@5 90.625\n",
      "Test: [20/169]\n",
      "\n",
      "Time 0.555 (0.536)\n",
      "\n",
      "Loss 0.6517 (0.7914)\n",
      "\n",
      "Prec@1 93.750 (84.226)\n",
      "\n",
      "Prec@5 93.750 (90.774)\n",
      "\n",
      " * Prec@1 84.226 Prec@5 90.774\n",
      " * Prec@1 83.807 Prec@5 90.057\n",
      " * Prec@1 83.696 Prec@5 90.489\n",
      " * Prec@1 83.073 Prec@5 90.885\n",
      " * Prec@1 83.000 Prec@5 90.750\n",
      " * Prec@1 83.413 Prec@5 91.106\n",
      " * Prec@1 83.796 Prec@5 91.435\n",
      " * Prec@1 83.482 Prec@5 91.071\n",
      " * Prec@1 83.621 Prec@5 91.379\n",
      " * Prec@1 83.333 Prec@5 91.042\n",
      "Test: [30/169]\n",
      "\n",
      "Time 0.519 (0.538)\n",
      "\n",
      "Loss 0.5330 (0.7727)\n",
      "\n",
      "Prec@1 87.500 (83.468)\n",
      "\n",
      "Prec@5 93.750 (91.129)\n",
      "\n",
      " * Prec@1 83.468 Prec@5 91.129\n",
      " * Prec@1 83.594 Prec@5 91.211\n",
      " * Prec@1 83.144 Prec@5 90.909\n",
      " * Prec@1 82.537 Prec@5 90.257\n",
      " * Prec@1 82.500 Prec@5 90.357\n",
      " * Prec@1 82.465 Prec@5 90.278\n",
      " * Prec@1 82.432 Prec@5 90.203\n",
      " * Prec@1 82.566 Prec@5 90.461\n",
      " * Prec@1 82.372 Prec@5 90.385\n",
      " * Prec@1 82.031 Prec@5 90.469\n",
      "Test: [40/169]\n",
      "\n",
      "Time 0.520 (0.535)\n",
      "\n",
      "Loss 0.7670 (0.8188)\n",
      "\n",
      "Prec@1 87.500 (82.165)\n",
      "\n",
      "Prec@5 93.750 (90.549)\n",
      "\n",
      " * Prec@1 82.165 Prec@5 90.549\n",
      " * Prec@1 81.845 Prec@5 90.476\n",
      " * Prec@1 81.977 Prec@5 90.698\n",
      " * Prec@1 82.102 Prec@5 90.767\n",
      " * Prec@1 82.361 Prec@5 90.833\n",
      " * Prec@1 82.201 Prec@5 90.897\n",
      " * Prec@1 82.580 Prec@5 91.090\n",
      " * Prec@1 82.552 Prec@5 91.016\n",
      " * Prec@1 82.781 Prec@5 91.071\n",
      " * Prec@1 82.750 Prec@5 91.125\n",
      "Test: [50/169]\n",
      "\n",
      "Time 0.514 (0.534)\n",
      "\n",
      "Loss 1.4168 (0.8053)\n",
      "\n",
      "Prec@1 75.000 (82.598)\n",
      "\n",
      "Prec@5 81.250 (90.931)\n",
      "\n",
      " * Prec@1 82.598 Prec@5 90.931\n",
      " * Prec@1 82.452 Prec@5 90.986\n",
      " * Prec@1 82.547 Prec@5 91.156\n",
      " * Prec@1 82.407 Prec@5 91.088\n",
      " * Prec@1 82.159 Prec@5 91.136\n",
      " * Prec@1 82.143 Prec@5 91.183\n",
      " * Prec@1 82.127 Prec@5 91.228\n",
      " * Prec@1 82.112 Prec@5 91.272\n",
      " * Prec@1 81.992 Prec@5 91.208\n",
      " * Prec@1 81.979 Prec@5 91.354\n",
      "Test: [60/169]\n",
      "\n",
      "Time 0.543 (0.537)\n",
      "\n",
      "Loss 2.0128 (0.8289)\n",
      "\n",
      "Prec@1 62.500 (81.660)\n",
      "\n",
      "Prec@5 75.000 (91.086)\n",
      "\n",
      " * Prec@1 81.660 Prec@5 91.086\n",
      " * Prec@1 81.552 Prec@5 90.927\n",
      " * Prec@1 81.548 Prec@5 90.972\n",
      " * Prec@1 81.543 Prec@5 90.918\n",
      " * Prec@1 81.250 Prec@5 90.577\n",
      " * Prec@1 81.439 Prec@5 90.625\n",
      " * Prec@1 81.623 Prec@5 90.672\n",
      " * Prec@1 81.618 Prec@5 90.717\n",
      " * Prec@1 81.703 Prec@5 90.761\n",
      " * Prec@1 81.696 Prec@5 90.625\n",
      "Test: [70/169]\n",
      "\n",
      "Time 0.508 (0.532)\n",
      "\n",
      "Loss 0.2785 (0.8379)\n",
      "\n",
      "Prec@1 93.750 (81.866)\n",
      "\n",
      "Prec@5 93.750 (90.669)\n",
      "\n",
      " * Prec@1 81.866 Prec@5 90.669\n",
      " * Prec@1 81.944 Prec@5 90.625\n",
      " * Prec@1 82.021 Prec@5 90.753\n",
      " * Prec@1 82.095 Prec@5 90.794\n",
      " * Prec@1 82.167 Prec@5 90.833\n",
      " * Prec@1 82.237 Prec@5 90.789\n",
      " * Prec@1 82.386 Prec@5 90.828\n",
      " * Prec@1 82.452 Prec@5 90.785\n",
      " * Prec@1 82.358 Prec@5 90.665\n",
      " * Prec@1 82.266 Prec@5 90.625\n",
      "Test: [80/169]\n",
      "\n",
      "Time 0.476 (0.533)\n",
      "\n",
      "Loss 1.7681 (0.8496)\n",
      "\n",
      "Prec@1 68.750 (82.099)\n",
      "\n",
      "Prec@5 75.000 (90.432)\n",
      "\n",
      " * Prec@1 82.099 Prec@5 90.432\n",
      " * Prec@1 82.165 Prec@5 90.473\n",
      " * Prec@1 82.154 Prec@5 90.512\n",
      " * Prec@1 82.217 Prec@5 90.551\n",
      " * Prec@1 82.206 Prec@5 90.515\n",
      " * Prec@1 82.267 Prec@5 90.552\n",
      " * Prec@1 82.328 Prec@5 90.661\n",
      " * Prec@1 82.315 Prec@5 90.554\n",
      " * Prec@1 82.374 Prec@5 90.590\n",
      " * Prec@1 82.431 Prec@5 90.625\n",
      "Test: [90/169]\n",
      "\n",
      "Time 0.461 (0.532)\n",
      "\n",
      "Loss 0.0055 (0.8212)\n",
      "\n",
      "Prec@1 100.000 (82.624)\n",
      "\n",
      "Prec@5 100.000 (90.728)\n",
      "\n",
      " * Prec@1 82.624 Prec@5 90.728\n",
      " * Prec@1 82.677 Prec@5 90.761\n",
      " * Prec@1 82.796 Prec@5 90.860\n",
      " * Prec@1 82.846 Prec@5 90.891\n",
      " * Prec@1 82.895 Prec@5 90.855\n",
      " * Prec@1 82.878 Prec@5 90.755\n",
      " * Prec@1 82.796 Prec@5 90.657\n",
      " * Prec@1 82.717 Prec@5 90.497\n",
      " * Prec@1 82.702 Prec@5 90.530\n",
      " * Prec@1 82.875 Prec@5 90.625\n",
      "Test: [100/169]\n",
      "\n",
      "Time 0.526 (0.532)\n",
      "\n",
      "Loss 0.8900 (0.8234)\n",
      "\n",
      "Prec@1 81.250 (82.859)\n",
      "\n",
      "Prec@5 87.500 (90.594)\n",
      "\n",
      " * Prec@1 82.859 Prec@5 90.594\n",
      " * Prec@1 82.966 Prec@5 90.686\n",
      " * Prec@1 82.888 Prec@5 90.655\n",
      " * Prec@1 82.933 Prec@5 90.685\n",
      " * Prec@1 82.917 Prec@5 90.655\n",
      " * Prec@1 82.960 Prec@5 90.625\n",
      " * Prec@1 83.119 Prec@5 90.713\n",
      " * Prec@1 83.218 Prec@5 90.799\n",
      " * Prec@1 83.314 Prec@5 90.826\n",
      " * Prec@1 83.239 Prec@5 90.852\n",
      "Test: [110/169]\n",
      "\n",
      "Time 0.490 (0.533)\n",
      "\n",
      "Loss 0.7356 (0.8043)\n",
      "\n",
      "Prec@1 87.500 (83.277)\n",
      "\n",
      "Prec@5 93.750 (90.878)\n",
      "\n",
      " * Prec@1 83.277 Prec@5 90.878\n",
      " * Prec@1 83.036 Prec@5 90.848\n",
      " * Prec@1 83.075 Prec@5 90.929\n",
      " * Prec@1 83.004 Prec@5 90.899\n",
      " * Prec@1 83.098 Prec@5 90.924\n",
      " * Prec@1 83.082 Prec@5 91.002\n",
      " * Prec@1 83.066 Prec@5 91.026\n",
      " * Prec@1 82.998 Prec@5 90.943\n",
      " * Prec@1 83.141 Prec@5 91.019\n",
      " * Prec@1 83.125 Prec@5 91.042\n",
      "Test: [120/169]\n",
      "\n",
      "Time 0.513 (0.533)\n",
      "\n",
      "Loss 0.4081 (0.7988)\n",
      "\n",
      "Prec@1 93.750 (83.213)\n",
      "\n",
      "Prec@5 100.000 (91.116)\n",
      "\n",
      " * Prec@1 83.213 Prec@5 91.116\n",
      " * Prec@1 83.248 Prec@5 91.086\n",
      " * Prec@1 83.333 Prec@5 91.108\n",
      " * Prec@1 83.367 Prec@5 91.129\n",
      " * Prec@1 83.400 Prec@5 91.150\n",
      " * Prec@1 83.383 Prec@5 91.220\n",
      " * Prec@1 83.415 Prec@5 91.289\n",
      " * Prec@1 83.496 Prec@5 91.357\n",
      " * Prec@1 83.576 Prec@5 91.376\n",
      " * Prec@1 83.606 Prec@5 91.442\n",
      "Test: [130/169]\n",
      "\n",
      "Time 0.542 (0.532)\n",
      "\n",
      "Loss 0.9282 (0.7758)\n",
      "\n",
      "Prec@1 75.000 (83.540)\n",
      "\n",
      "Prec@5 87.500 (91.412)\n",
      "\n",
      " * Prec@1 83.540 Prec@5 91.412\n",
      " * Prec@1 83.617 Prec@5 91.430\n",
      " * Prec@1 83.741 Prec@5 91.494\n",
      " * Prec@1 83.629 Prec@5 91.511\n",
      " * Prec@1 83.657 Prec@5 91.574\n",
      " * Prec@1 83.548 Prec@5 91.452\n",
      " * Prec@1 83.531 Prec@5 91.423\n",
      " * Prec@1 83.514 Prec@5 91.350\n",
      " * Prec@1 83.588 Prec@5 91.412\n",
      " * Prec@1 83.438 Prec@5 91.339\n",
      "Test: [140/169]\n",
      "\n",
      "Time 0.530 (0.531)\n",
      "\n",
      "Loss 1.2418 (0.7878)\n",
      "\n",
      "Prec@1 75.000 (83.378)\n",
      "\n",
      "Prec@5 87.500 (91.312)\n",
      "\n",
      " * Prec@1 83.378 Prec@5 91.312\n",
      " * Prec@1 83.231 Prec@5 91.153\n",
      " * Prec@1 83.129 Prec@5 91.128\n",
      " * Prec@1 83.116 Prec@5 91.146\n",
      " * Prec@1 83.147 Prec@5 91.164\n",
      " * Prec@1 82.877 Prec@5 91.010\n",
      " * Prec@1 82.908 Prec@5 91.029\n",
      " * Prec@1 82.939 Prec@5 91.047\n",
      " * Prec@1 82.928 Prec@5 91.023\n",
      " * Prec@1 82.958 Prec@5 91.083\n",
      "Test: [150/169]\n",
      "\n",
      "Time 0.518 (0.532)\n",
      "\n",
      "Loss 1.2976 (0.8166)\n",
      "\n",
      "Prec@1 75.000 (82.906)\n",
      "\n",
      "Prec@5 87.500 (91.060)\n",
      "\n",
      " * Prec@1 82.906 Prec@5 91.060\n",
      " * Prec@1 83.018 Prec@5 91.118\n",
      " * Prec@1 83.088 Prec@5 91.176\n",
      " * Prec@1 83.157 Prec@5 91.234\n",
      " * Prec@1 83.266 Prec@5 91.290\n",
      " * Prec@1 83.173 Prec@5 91.186\n",
      " * Prec@1 83.081 Prec@5 91.123\n",
      " * Prec@1 83.188 Prec@5 91.179\n",
      " * Prec@1 83.097 Prec@5 91.156\n",
      " * Prec@1 83.086 Prec@5 91.211\n",
      "Test: [160/169]\n",
      "\n",
      "Time 0.521 (0.532)\n",
      "\n",
      "Loss 0.4933 (0.8015)\n",
      "\n",
      "Prec@1 81.250 (83.075)\n",
      "\n",
      "Prec@5 100.000 (91.266)\n",
      "\n",
      " * Prec@1 83.075 Prec@5 91.266\n",
      " * Prec@1 83.102 Prec@5 91.281\n",
      " * Prec@1 83.090 Prec@5 91.258\n",
      " * Prec@1 83.155 Prec@5 91.273\n",
      " * Prec@1 83.182 Prec@5 91.288\n",
      " * Prec@1 83.208 Prec@5 91.303\n",
      " * Prec@1 83.121 Prec@5 91.317\n",
      " * Prec@1 83.073 Prec@5 91.257\n",
      " * Prec@1 83.067 Prec@5 91.274\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 400, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_400targets_weights_Noneseed'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_400_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8630b5fe-646f-429e-943f-9ad6d841f58c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_19992\\3414169806.py:13: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.location_dataframe = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/vit_b_16_artsobservasjoner224_300targets_weights_none_seed_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1276]\t\\Time 0.695 (0.695)\tData 0.472 (0.472)\tLoss 5.9771 (5.9771)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/1276]\t\\Time 0.522 (0.521)\tData 0.409 (0.420)\tLoss 6.2706 (6.5476)\tPrec@1 0.000 (0.371)\tPrec@5 0.000 (1.918)\n",
      "Epoch: [0][200/1276]\t\\Time 0.512 (0.514)\tData 0.430 (0.415)\tLoss 6.0646 (6.4451)\tPrec@1 0.000 (0.498)\tPrec@5 0.000 (2.799)\n",
      "Epoch: [0][300/1276]\t\\Time 0.520 (0.513)\tData 0.400 (0.414)\tLoss 5.7486 (6.2182)\tPrec@1 0.000 (0.706)\tPrec@5 0.000 (3.135)\n",
      "Epoch: [0][400/1276]\t\\Time 0.575 (0.513)\tData 0.440 (0.413)\tLoss 5.5703 (6.0892)\tPrec@1 0.000 (0.810)\tPrec@5 12.500 (3.382)\n",
      "Epoch: [0][500/1276]\t\\Time 0.550 (0.515)\tData 0.440 (0.415)\tLoss 5.9576 (6.0054)\tPrec@1 0.000 (0.823)\tPrec@5 0.000 (3.468)\n",
      "Epoch: [0][600/1276]\t\\Time 0.531 (0.515)\tData 0.412 (0.415)\tLoss 5.9811 (5.9495)\tPrec@1 0.000 (0.915)\tPrec@5 0.000 (3.785)\n",
      "Epoch: [0][700/1276]\t\\Time 0.551 (0.514)\tData 0.441 (0.414)\tLoss 5.6349 (5.9081)\tPrec@1 0.000 (0.981)\tPrec@5 0.000 (4.048)\n",
      "Epoch: [0][800/1276]\t\\Time 0.446 (0.514)\tData 0.352 (0.414)\tLoss 5.7581 (5.8781)\tPrec@1 0.000 (1.046)\tPrec@5 0.000 (4.260)\n",
      "Epoch: [0][900/1276]\t\\Time 0.530 (0.513)\tData 0.423 (0.414)\tLoss 5.4802 (5.8524)\tPrec@1 0.000 (1.131)\tPrec@5 6.250 (4.433)\n",
      "Epoch: [0][1000/1276]\t\\Time 0.522 (0.513)\tData 0.423 (0.414)\tLoss 5.6632 (5.8329)\tPrec@1 0.000 (1.174)\tPrec@5 12.500 (4.558)\n",
      "Epoch: [0][1100/1276]\t\\Time 0.512 (0.513)\tData 0.411 (0.413)\tLoss 5.7889 (5.8154)\tPrec@1 0.000 (1.232)\tPrec@5 6.250 (4.672)\n",
      "Epoch: [0][1200/1276]\t\\Time 0.500 (0.513)\tData 0.390 (0.413)\tLoss 5.6774 (5.8003)\tPrec@1 0.000 (1.291)\tPrec@5 0.000 (4.746)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.476 (0.476)\n",
      "\n",
      "Loss 5.8229 (5.8229)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 0.000 (0.000)\n",
      "\n",
      " * Prec@1 0.000 Prec@5 0.000\n",
      " * Prec@1 3.125 Prec@5 6.250\n",
      " * Prec@1 2.083 Prec@5 6.250\n",
      " * Prec@1 1.562 Prec@5 4.688\n",
      " * Prec@1 1.250 Prec@5 3.750\n",
      " * Prec@1 1.042 Prec@5 4.167\n",
      " * Prec@1 0.893 Prec@5 4.464\n",
      " * Prec@1 0.781 Prec@5 4.688\n",
      " * Prec@1 0.694 Prec@5 4.167\n",
      " * Prec@1 0.625 Prec@5 4.375\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.481 (0.501)\n",
      "\n",
      "Loss 5.7313 (5.6470)\n",
      "\n",
      "Prec@1 6.250 (1.136)\n",
      "\n",
      "Prec@5 6.250 (4.545)\n",
      "\n",
      " * Prec@1 1.136 Prec@5 4.545\n",
      " * Prec@1 1.042 Prec@5 4.167\n",
      " * Prec@1 0.962 Prec@5 4.327\n",
      " * Prec@1 0.893 Prec@5 4.464\n",
      " * Prec@1 0.833 Prec@5 4.583\n",
      " * Prec@1 1.172 Prec@5 5.078\n",
      " * Prec@1 1.103 Prec@5 4.779\n",
      " * Prec@1 1.389 Prec@5 4.861\n",
      " * Prec@1 1.316 Prec@5 4.605\n",
      " * Prec@1 1.250 Prec@5 4.688\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.515 (0.499)\n",
      "\n",
      "Loss 5.7847 (5.6402)\n",
      "\n",
      "Prec@1 0.000 (1.190)\n",
      "\n",
      "Prec@5 6.250 (4.762)\n",
      "\n",
      " * Prec@1 1.190 Prec@5 4.762\n",
      " * Prec@1 1.136 Prec@5 4.545\n",
      " * Prec@1 1.087 Prec@5 4.891\n",
      " * Prec@1 1.302 Prec@5 4.948\n",
      " * Prec@1 1.250 Prec@5 5.000\n",
      " * Prec@1 1.442 Prec@5 5.288\n",
      " * Prec@1 1.389 Prec@5 5.324\n",
      " * Prec@1 1.339 Prec@5 5.134\n",
      " * Prec@1 1.509 Prec@5 5.172\n",
      " * Prec@1 1.458 Prec@5 5.208\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.510 (0.500)\n",
      "\n",
      "Loss 5.5570 (5.6332)\n",
      "\n",
      "Prec@1 0.000 (1.411)\n",
      "\n",
      "Prec@5 0.000 (5.040)\n",
      "\n",
      " * Prec@1 1.411 Prec@5 5.040\n",
      " * Prec@1 1.562 Prec@5 5.078\n",
      " * Prec@1 1.515 Prec@5 4.924\n",
      " * Prec@1 1.471 Prec@5 4.963\n",
      " * Prec@1 1.429 Prec@5 5.000\n",
      " * Prec@1 1.389 Prec@5 4.861\n",
      " * Prec@1 1.351 Prec@5 4.730\n",
      " * Prec@1 1.316 Prec@5 4.605\n",
      " * Prec@1 1.282 Prec@5 4.487\n",
      " * Prec@1 1.250 Prec@5 4.375\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.451 (0.503)\n",
      "\n",
      "Loss 5.4497 (5.6408)\n",
      "\n",
      "Prec@1 0.000 (1.220)\n",
      "\n",
      "Prec@5 6.250 (4.421)\n",
      "\n",
      " * Prec@1 1.220 Prec@5 4.421\n",
      " * Prec@1 1.339 Prec@5 4.613\n",
      " * Prec@1 1.308 Prec@5 4.651\n",
      " * Prec@1 1.278 Prec@5 4.972\n",
      " * Prec@1 1.250 Prec@5 5.000\n",
      " * Prec@1 1.223 Prec@5 5.027\n",
      " * Prec@1 1.197 Prec@5 5.186\n",
      " * Prec@1 1.172 Prec@5 5.078\n",
      " * Prec@1 1.148 Prec@5 5.102\n",
      " * Prec@1 1.125 Prec@5 5.125\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.489 (0.502)\n",
      "\n",
      "Loss 5.7439 (5.6335)\n",
      "\n",
      "Prec@1 0.000 (1.103)\n",
      "\n",
      "Prec@5 6.250 (5.147)\n",
      "\n",
      " * Prec@1 1.103 Prec@5 5.147\n",
      " * Prec@1 1.202 Prec@5 5.168\n",
      " * Prec@1 1.179 Prec@5 5.189\n",
      " * Prec@1 1.273 Prec@5 5.208\n",
      " * Prec@1 1.250 Prec@5 5.114\n",
      " * Prec@1 1.228 Prec@5 5.246\n",
      " * Prec@1 1.206 Prec@5 5.263\n",
      " * Prec@1 1.185 Prec@5 5.280\n",
      " * Prec@1 1.165 Prec@5 5.191\n",
      " * Prec@1 1.146 Prec@5 5.208\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.456 (0.504)\n",
      "\n",
      "Loss 5.5908 (5.6362)\n",
      "\n",
      "Prec@1 0.000 (1.127)\n",
      "\n",
      "Prec@5 6.250 (5.225)\n",
      "\n",
      " * Prec@1 1.127 Prec@5 5.225\n",
      " * Prec@1 1.109 Prec@5 5.242\n",
      " * Prec@1 1.091 Prec@5 5.159\n",
      " * Prec@1 1.074 Prec@5 5.078\n",
      " * Prec@1 1.154 Prec@5 5.288\n",
      " * Prec@1 1.136 Prec@5 5.208\n",
      " * Prec@1 1.119 Prec@5 5.317\n",
      " * Prec@1 1.103 Prec@5 5.331\n",
      " * Prec@1 1.087 Prec@5 5.254\n",
      " * Prec@1 1.161 Prec@5 5.357\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.463 (0.508)\n",
      "\n",
      "Loss 5.8157 (5.6377)\n",
      "\n",
      "Prec@1 0.000 (1.144)\n",
      "\n",
      "Prec@5 6.250 (5.370)\n",
      "\n",
      " * Prec@1 1.144 Prec@5 5.370\n",
      " * Prec@1 1.128 Prec@5 5.382\n",
      " * Prec@1 1.113 Prec@5 5.308\n",
      " * Prec@1 1.182 Prec@5 5.405\n",
      " * Prec@1 1.167 Prec@5 5.417\n",
      " * Prec@1 1.151 Prec@5 5.345\n",
      " * Prec@1 1.218 Prec@5 5.357\n",
      " * Prec@1 1.202 Prec@5 5.288\n",
      " * Prec@1 1.187 Prec@5 5.222\n",
      " * Prec@1 1.172 Prec@5 5.312\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.541 (0.508)\n",
      "\n",
      "Loss 5.6539 (5.6307)\n",
      "\n",
      "Prec@1 0.000 (1.157)\n",
      "\n",
      "Prec@5 6.250 (5.324)\n",
      "\n",
      " * Prec@1 1.157 Prec@5 5.324\n",
      " * Prec@1 1.296 Prec@5 5.412\n",
      " * Prec@1 1.280 Prec@5 5.346\n",
      " * Prec@1 1.265 Prec@5 5.357\n",
      " * Prec@1 1.250 Prec@5 5.294\n",
      " * Prec@1 1.308 Prec@5 5.305\n",
      " * Prec@1 1.293 Prec@5 5.316\n",
      " * Prec@1 1.278 Prec@5 5.327\n",
      " * Prec@1 1.264 Prec@5 5.478\n",
      " * Prec@1 1.319 Prec@5 5.625\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.471 (0.509)\n",
      "\n",
      "Loss 5.8299 (5.6293)\n",
      "\n",
      "Prec@1 0.000 (1.305)\n",
      "\n",
      "Prec@5 0.000 (5.563)\n",
      "\n",
      " * Prec@1 1.305 Prec@5 5.563\n",
      " * Prec@1 1.291 Prec@5 5.503\n",
      " * Prec@1 1.277 Prec@5 5.444\n",
      " * Prec@1 1.330 Prec@5 5.452\n",
      " * Prec@1 1.382 Prec@5 5.461\n",
      " * Prec@1 1.432 Prec@5 5.469\n",
      " * Prec@1 1.418 Prec@5 5.477\n",
      " * Prec@1 1.403 Prec@5 5.421\n",
      " * Prec@1 1.389 Prec@5 5.492\n",
      " * Prec@1 1.375 Prec@5 5.500\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.521 (0.509)\n",
      "\n",
      "Loss 5.4555 (5.6280)\n",
      "\n",
      "Prec@1 12.500 (1.485)\n",
      "\n",
      "Prec@5 18.750 (5.631)\n",
      "\n",
      " * Prec@1 1.485 Prec@5 5.631\n",
      " * Prec@1 1.471 Prec@5 5.576\n",
      " * Prec@1 1.517 Prec@5 5.643\n",
      " * Prec@1 1.562 Prec@5 5.709\n",
      " * Prec@1 1.548 Prec@5 5.774\n",
      " * Prec@1 1.533 Prec@5 5.719\n",
      " * Prec@1 1.577 Prec@5 5.783\n",
      " * Prec@1 1.562 Prec@5 5.729\n",
      " * Prec@1 1.606 Prec@5 5.791\n",
      " * Prec@1 1.591 Prec@5 5.852\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.541 (0.508)\n",
      "\n",
      "Loss 5.8328 (5.6254)\n",
      "\n",
      "Prec@1 0.000 (1.577)\n",
      "\n",
      "Prec@5 0.000 (5.800)\n",
      "\n",
      " * Prec@1 1.577 Prec@5 5.800\n",
      " * Prec@1 1.562 Prec@5 5.804\n",
      " * Prec@1 1.549 Prec@5 5.808\n",
      " * Prec@1 1.535 Prec@5 5.757\n",
      " * Prec@1 1.522 Prec@5 5.815\n",
      " * Prec@1 1.509 Prec@5 5.819\n",
      " * Prec@1 1.496 Prec@5 5.769\n",
      " * Prec@1 1.483 Prec@5 5.826\n",
      " * Prec@1 1.523 Prec@5 5.882\n",
      " * Prec@1 1.510 Prec@5 5.885\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.470 (0.507)\n",
      "\n",
      "Loss 5.7051 (5.6231)\n",
      "\n",
      "Prec@1 0.000 (1.498)\n",
      "\n",
      "Prec@5 0.000 (5.837)\n",
      "\n",
      " * Prec@1 1.498 Prec@5 5.837\n",
      " * Prec@1 1.588 Prec@5 5.943\n",
      " * Prec@1 1.626 Prec@5 5.996\n",
      " * Prec@1 1.613 Prec@5 5.948\n",
      " * Prec@1 1.600 Prec@5 5.950\n",
      " * Prec@1 1.687 Prec@5 6.002\n",
      " * Prec@1 1.673 Prec@5 5.955\n",
      " * Prec@1 1.660 Prec@5 5.908\n",
      " * Prec@1 1.647 Prec@5 5.959\n",
      " * Prec@1 1.635 Prec@5 5.962\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.567 (0.508)\n",
      "\n",
      "Loss 5.4852 (5.6162)\n",
      "\n",
      "Prec@1 0.000 (1.622)\n",
      "\n",
      "Prec@5 6.250 (5.964)\n",
      "\n",
      " * Prec@1 1.622 Prec@5 5.964\n",
      " * Prec@1 1.610 Prec@5 5.919\n",
      " * Prec@1 1.598 Prec@5 5.874\n",
      " * Prec@1 1.586 Prec@5 5.877\n",
      " * Prec@1 1.574 Prec@5 5.833\n",
      " * Prec@1 1.562 Prec@5 5.882\n",
      " * Prec@1 1.551 Prec@5 5.839\n",
      " * Prec@1 1.540 Prec@5 5.842\n",
      " * Prec@1 1.529 Prec@5 5.845\n",
      " * Prec@1 1.518 Prec@5 5.848\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.501 (0.506)\n",
      "\n",
      "Loss 5.7120 (5.6199)\n",
      "\n",
      "Prec@1 0.000 (1.507)\n",
      "\n",
      "Prec@5 6.250 (5.851)\n",
      "\n",
      " * Prec@1 1.507 Prec@5 5.851\n",
      " * Prec@1 1.498 Prec@5 5.818\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/1276]\t\\Time 0.473 (0.473)\tData 0.363 (0.363)\tLoss 5.7503 (5.7503)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [1][100/1276]\t\\Time 0.522 (0.498)\tData 0.403 (0.399)\tLoss 5.5800 (5.6282)\tPrec@1 0.000 (0.866)\tPrec@5 6.250 (4.827)\n",
      "Epoch: [1][200/1276]\t\\Time 0.500 (0.499)\tData 0.376 (0.399)\tLoss 5.7841 (5.5923)\tPrec@1 0.000 (1.368)\tPrec@5 0.000 (5.970)\n",
      "Epoch: [1][300/1276]\t\\Time 0.538 (0.499)\tData 0.431 (0.399)\tLoss 5.4395 (5.5740)\tPrec@1 0.000 (1.557)\tPrec@5 6.250 (6.084)\n",
      "Epoch: [1][400/1276]\t\\Time 0.480 (0.500)\tData 0.390 (0.400)\tLoss 5.7205 (5.5619)\tPrec@1 0.000 (1.652)\tPrec@5 6.250 (6.608)\n",
      "Epoch: [1][500/1276]\t\\Time 0.530 (0.500)\tData 0.421 (0.401)\tLoss 5.5863 (5.5448)\tPrec@1 0.000 (1.684)\tPrec@5 6.250 (6.749)\n",
      "Epoch: [1][600/1276]\t\\Time 0.520 (0.500)\tData 0.420 (0.401)\tLoss 5.5462 (5.5324)\tPrec@1 0.000 (1.726)\tPrec@5 0.000 (6.957)\n",
      "Epoch: [1][700/1276]\t\\Time 0.499 (0.500)\tData 0.390 (0.401)\tLoss 5.1192 (5.5172)\tPrec@1 6.250 (1.810)\tPrec@5 18.750 (7.266)\n",
      "Epoch: [1][800/1276]\t\\Time 0.460 (0.501)\tData 0.390 (0.401)\tLoss 5.4334 (5.4962)\tPrec@1 0.000 (1.888)\tPrec@5 6.250 (7.654)\n",
      "Epoch: [1][900/1276]\t\\Time 0.552 (0.501)\tData 0.442 (0.401)\tLoss 5.3427 (5.4858)\tPrec@1 0.000 (1.942)\tPrec@5 0.000 (7.845)\n",
      "Epoch: [1][1000/1276]\t\\Time 0.550 (0.501)\tData 0.430 (0.402)\tLoss 5.3085 (5.4689)\tPrec@1 0.000 (2.004)\tPrec@5 12.500 (8.061)\n",
      "Epoch: [1][1100/1276]\t\\Time 0.441 (0.502)\tData 0.351 (0.402)\tLoss 5.6301 (5.4580)\tPrec@1 0.000 (2.089)\tPrec@5 12.500 (8.163)\n",
      "Epoch: [1][1200/1276]\t\\Time 0.531 (0.502)\tData 0.421 (0.402)\tLoss 4.6293 (5.4451)\tPrec@1 18.750 (2.196)\tPrec@5 31.250 (8.347)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.441 (0.441)\n",
      "\n",
      "Loss 5.4174 (5.4174)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 6.250 (6.250)\n",
      "\n",
      " * Prec@1 0.000 Prec@5 6.250\n",
      " * Prec@1 3.125 Prec@5 12.500\n",
      " * Prec@1 4.167 Prec@5 14.583\n",
      " * Prec@1 3.125 Prec@5 15.625\n",
      " * Prec@1 5.000 Prec@5 17.500\n",
      " * Prec@1 4.167 Prec@5 16.667\n",
      " * Prec@1 3.571 Prec@5 15.179\n",
      " * Prec@1 4.688 Prec@5 15.625\n",
      " * Prec@1 5.556 Prec@5 15.972\n",
      " * Prec@1 5.000 Prec@5 15.625\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.491 (0.490)\n",
      "\n",
      "Loss 5.4610 (5.1787)\n",
      "\n",
      "Prec@1 0.000 (4.545)\n",
      "\n",
      "Prec@5 6.250 (14.773)\n",
      "\n",
      " * Prec@1 4.545 Prec@5 14.773\n",
      " * Prec@1 4.688 Prec@5 14.583\n",
      " * Prec@1 4.808 Prec@5 14.904\n",
      " * Prec@1 4.464 Prec@5 14.732\n",
      " * Prec@1 4.167 Prec@5 14.167\n",
      " * Prec@1 3.906 Prec@5 13.281\n",
      " * Prec@1 4.044 Prec@5 13.235\n",
      " * Prec@1 4.167 Prec@5 13.889\n",
      " * Prec@1 4.276 Prec@5 14.145\n",
      " * Prec@1 4.062 Prec@5 13.750\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.534 (0.492)\n",
      "\n",
      "Loss 5.5997 (5.2231)\n",
      "\n",
      "Prec@1 0.000 (3.869)\n",
      "\n",
      "Prec@5 0.000 (13.095)\n",
      "\n",
      " * Prec@1 3.869 Prec@5 13.095\n",
      " * Prec@1 3.977 Prec@5 12.784\n",
      " * Prec@1 3.804 Prec@5 12.500\n",
      " * Prec@1 3.646 Prec@5 12.240\n",
      " * Prec@1 3.500 Prec@5 11.750\n",
      " * Prec@1 3.365 Prec@5 11.538\n",
      " * Prec@1 3.241 Prec@5 11.343\n",
      " * Prec@1 3.125 Prec@5 11.161\n",
      " * Prec@1 3.017 Prec@5 10.776\n",
      " * Prec@1 2.917 Prec@5 10.417\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.511 (0.495)\n",
      "\n",
      "Loss 5.4960 (5.2836)\n",
      "\n",
      "Prec@1 0.000 (2.823)\n",
      "\n",
      "Prec@5 6.250 (10.282)\n",
      "\n",
      " * Prec@1 2.823 Prec@5 10.282\n",
      " * Prec@1 2.734 Prec@5 10.156\n",
      " * Prec@1 2.841 Prec@5 10.227\n",
      " * Prec@1 2.757 Prec@5 10.294\n",
      " * Prec@1 2.679 Prec@5 10.714\n",
      " * Prec@1 2.778 Prec@5 10.764\n",
      " * Prec@1 2.703 Prec@5 10.642\n",
      " * Prec@1 2.632 Prec@5 10.362\n",
      " * Prec@1 2.564 Prec@5 10.417\n",
      " * Prec@1 2.500 Prec@5 10.312\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.441 (0.494)\n",
      "\n",
      "Loss 4.5509 (5.2539)\n",
      "\n",
      "Prec@1 12.500 (2.744)\n",
      "\n",
      "Prec@5 37.500 (10.976)\n",
      "\n",
      " * Prec@1 2.744 Prec@5 10.976\n",
      " * Prec@1 2.827 Prec@5 11.161\n",
      " * Prec@1 2.762 Prec@5 11.047\n",
      " * Prec@1 2.841 Prec@5 11.222\n",
      " * Prec@1 3.056 Prec@5 11.250\n",
      " * Prec@1 3.125 Prec@5 11.549\n",
      " * Prec@1 3.059 Prec@5 11.436\n",
      " * Prec@1 3.125 Prec@5 11.328\n",
      " * Prec@1 3.061 Prec@5 11.224\n",
      " * Prec@1 3.000 Prec@5 11.125\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.492 (0.493)\n",
      "\n",
      "Loss 5.2395 (5.2578)\n",
      "\n",
      "Prec@1 6.250 (3.064)\n",
      "\n",
      "Prec@5 6.250 (11.029)\n",
      "\n",
      " * Prec@1 3.064 Prec@5 11.029\n",
      " * Prec@1 3.005 Prec@5 11.058\n",
      " * Prec@1 3.066 Prec@5 10.967\n",
      " * Prec@1 3.009 Prec@5 11.111\n",
      " * Prec@1 3.068 Prec@5 11.136\n",
      " * Prec@1 3.013 Prec@5 11.049\n",
      " * Prec@1 3.070 Prec@5 11.294\n",
      " * Prec@1 3.125 Prec@5 11.422\n",
      " * Prec@1 3.178 Prec@5 11.653\n",
      " * Prec@1 3.333 Prec@5 12.083\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.454 (0.496)\n",
      "\n",
      "Loss 5.2267 (5.2399)\n",
      "\n",
      "Prec@1 12.500 (3.484)\n",
      "\n",
      "Prec@5 18.750 (12.193)\n",
      "\n",
      " * Prec@1 3.484 Prec@5 12.193\n",
      " * Prec@1 3.427 Prec@5 11.996\n",
      " * Prec@1 3.373 Prec@5 11.806\n",
      " * Prec@1 3.418 Prec@5 11.914\n",
      " * Prec@1 3.365 Prec@5 12.212\n",
      " * Prec@1 3.409 Prec@5 12.216\n",
      " * Prec@1 3.545 Prec@5 12.220\n",
      " * Prec@1 3.493 Prec@5 12.224\n",
      " * Prec@1 3.533 Prec@5 12.138\n",
      " * Prec@1 3.482 Prec@5 12.143\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.483 (0.499)\n",
      "\n",
      "Loss 5.4610 (5.2451)\n",
      "\n",
      "Prec@1 0.000 (3.433)\n",
      "\n",
      "Prec@5 6.250 (12.060)\n",
      "\n",
      " * Prec@1 3.433 Prec@5 12.060\n",
      " * Prec@1 3.472 Prec@5 12.066\n",
      " * Prec@1 3.510 Prec@5 12.072\n",
      " * Prec@1 3.547 Prec@5 12.162\n",
      " * Prec@1 3.583 Prec@5 12.417\n",
      " * Prec@1 3.618 Prec@5 12.418\n",
      " * Prec@1 3.653 Prec@5 12.419\n",
      " * Prec@1 3.766 Prec@5 12.420\n",
      " * Prec@1 3.718 Prec@5 12.421\n",
      " * Prec@1 3.750 Prec@5 12.500\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.540 (0.499)\n",
      "\n",
      "Loss 5.4280 (5.2464)\n",
      "\n",
      "Prec@1 6.250 (3.781)\n",
      "\n",
      "Prec@5 12.500 (12.500)\n",
      "\n",
      " * Prec@1 3.781 Prec@5 12.500\n",
      " * Prec@1 3.735 Prec@5 12.348\n",
      " * Prec@1 3.690 Prec@5 12.349\n",
      " * Prec@1 3.646 Prec@5 12.351\n",
      " * Prec@1 3.676 Prec@5 12.353\n",
      " * Prec@1 3.706 Prec@5 12.282\n",
      " * Prec@1 3.664 Prec@5 12.141\n",
      " * Prec@1 3.764 Prec@5 12.145\n",
      " * Prec@1 3.862 Prec@5 12.289\n",
      " * Prec@1 4.028 Prec@5 12.361\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.451 (0.500)\n",
      "\n",
      "Loss 5.5573 (5.2483)\n",
      "\n",
      "Prec@1 0.000 (3.984)\n",
      "\n",
      "Prec@5 6.250 (12.294)\n",
      "\n",
      " * Prec@1 3.984 Prec@5 12.294\n",
      " * Prec@1 3.940 Prec@5 12.160\n",
      " * Prec@1 3.965 Prec@5 12.164\n",
      " * Prec@1 3.923 Prec@5 12.367\n",
      " * Prec@1 3.882 Prec@5 12.303\n",
      " * Prec@1 3.841 Prec@5 12.305\n",
      " * Prec@1 3.866 Prec@5 12.242\n",
      " * Prec@1 3.890 Prec@5 12.245\n",
      " * Prec@1 3.914 Prec@5 12.374\n",
      " * Prec@1 3.938 Prec@5 12.375\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.520 (0.499)\n",
      "\n",
      "Loss 4.7167 (5.2485)\n",
      "\n",
      "Prec@1 6.250 (3.960)\n",
      "\n",
      "Prec@5 25.000 (12.500)\n",
      "\n",
      " * Prec@1 3.960 Prec@5 12.500\n",
      " * Prec@1 3.922 Prec@5 12.561\n",
      " * Prec@1 3.883 Prec@5 12.621\n",
      " * Prec@1 3.906 Prec@5 12.680\n",
      " * Prec@1 3.929 Prec@5 12.857\n",
      " * Prec@1 3.950 Prec@5 12.854\n",
      " * Prec@1 3.914 Prec@5 12.850\n",
      " * Prec@1 3.935 Prec@5 12.847\n",
      " * Prec@1 3.899 Prec@5 12.844\n",
      " * Prec@1 3.920 Prec@5 12.955\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.529 (0.499)\n",
      "\n",
      "Loss 5.0846 (5.2316)\n",
      "\n",
      "Prec@1 0.000 (3.885)\n",
      "\n",
      "Prec@5 6.250 (12.894)\n",
      "\n",
      " * Prec@1 3.885 Prec@5 12.894\n",
      " * Prec@1 3.906 Prec@5 12.891\n",
      " * Prec@1 3.872 Prec@5 12.777\n",
      " * Prec@1 3.838 Prec@5 12.664\n",
      " * Prec@1 3.859 Prec@5 12.772\n",
      " * Prec@1 3.825 Prec@5 12.769\n",
      " * Prec@1 3.793 Prec@5 12.660\n",
      " * Prec@1 3.814 Prec@5 12.712\n",
      " * Prec@1 3.834 Prec@5 12.815\n",
      " * Prec@1 3.802 Prec@5 12.865\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.503 (0.499)\n",
      "\n",
      "Loss 5.5488 (5.2331)\n",
      "\n",
      "Prec@1 0.000 (3.771)\n",
      "\n",
      "Prec@5 6.250 (12.810)\n",
      "\n",
      " * Prec@1 3.771 Prec@5 12.810\n",
      " * Prec@1 3.740 Prec@5 12.756\n",
      " * Prec@1 3.709 Prec@5 12.754\n",
      " * Prec@1 3.679 Prec@5 12.702\n",
      " * Prec@1 3.700 Prec@5 12.750\n",
      " * Prec@1 3.671 Prec@5 12.748\n",
      " * Prec@1 3.642 Prec@5 12.648\n",
      " * Prec@1 3.662 Prec@5 12.695\n",
      " * Prec@1 3.731 Prec@5 12.791\n",
      " * Prec@1 3.702 Prec@5 12.740\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.540 (0.499)\n",
      "\n",
      "Loss 4.9618 (5.2272)\n",
      "\n",
      "Prec@1 6.250 (3.721)\n",
      "\n",
      "Prec@5 18.750 (12.786)\n",
      "\n",
      " * Prec@1 3.721 Prec@5 12.786\n",
      " * Prec@1 3.693 Prec@5 12.784\n",
      " * Prec@1 3.712 Prec@5 12.782\n",
      " * Prec@1 3.685 Prec@5 12.733\n",
      " * Prec@1 3.657 Prec@5 12.685\n",
      " * Prec@1 3.676 Prec@5 12.776\n",
      " * Prec@1 3.650 Prec@5 12.819\n",
      " * Prec@1 3.623 Prec@5 12.817\n",
      " * Prec@1 3.597 Prec@5 12.815\n",
      " * Prec@1 3.571 Prec@5 12.812\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.511 (0.498)\n",
      "\n",
      "Loss 5.3340 (5.2271)\n",
      "\n",
      "Prec@1 6.250 (3.590)\n",
      "\n",
      "Prec@5 12.500 (12.810)\n",
      "\n",
      " * Prec@1 3.590 Prec@5 12.810\n",
      " * Prec@1 3.614 Prec@5 12.869\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1276]\t\\Time 0.512 (0.512)\tData 0.401 (0.401)\tLoss 5.5895 (5.5895)\tPrec@1 6.250 (6.250)\tPrec@5 6.250 (6.250)\n",
      "Epoch: [2][100/1276]\t\\Time 0.513 (0.496)\tData 0.414 (0.398)\tLoss 5.3727 (5.2366)\tPrec@1 6.250 (3.032)\tPrec@5 12.500 (11.015)\n",
      "Epoch: [2][200/1276]\t\\Time 0.471 (0.498)\tData 0.401 (0.401)\tLoss 5.4166 (5.2204)\tPrec@1 0.000 (3.545)\tPrec@5 6.250 (11.287)\n",
      "Epoch: [2][300/1276]\t\\Time 0.510 (0.497)\tData 0.400 (0.400)\tLoss 5.4420 (5.2011)\tPrec@1 0.000 (3.530)\tPrec@5 12.500 (11.836)\n",
      "Epoch: [2][400/1276]\t\\Time 0.531 (0.498)\tData 0.421 (0.400)\tLoss 5.2831 (5.1735)\tPrec@1 0.000 (3.787)\tPrec@5 12.500 (12.438)\n",
      "Epoch: [2][500/1276]\t\\Time 0.501 (0.498)\tData 0.381 (0.400)\tLoss 5.0629 (5.1546)\tPrec@1 6.250 (4.029)\tPrec@5 18.750 (13.024)\n",
      "Epoch: [2][600/1276]\t\\Time 0.530 (0.497)\tData 0.430 (0.399)\tLoss 4.9440 (5.1361)\tPrec@1 12.500 (4.170)\tPrec@5 18.750 (13.301)\n",
      "Epoch: [2][700/1276]\t\\Time 0.484 (0.497)\tData 0.375 (0.399)\tLoss 5.0634 (5.1195)\tPrec@1 6.250 (4.208)\tPrec@5 12.500 (13.490)\n",
      "Epoch: [2][800/1276]\t\\Time 0.491 (0.498)\tData 0.390 (0.399)\tLoss 5.3902 (5.1006)\tPrec@1 0.000 (4.276)\tPrec@5 6.250 (13.616)\n",
      "Epoch: [2][900/1276]\t\\Time 0.450 (0.498)\tData 0.340 (0.399)\tLoss 5.2122 (5.0804)\tPrec@1 0.000 (4.481)\tPrec@5 0.000 (13.978)\n",
      "Epoch: [2][1000/1276]\t\\Time 0.535 (0.498)\tData 0.427 (0.399)\tLoss 4.1095 (5.0544)\tPrec@1 25.000 (4.577)\tPrec@5 43.750 (14.467)\n",
      "Epoch: [2][1100/1276]\t\\Time 0.521 (0.497)\tData 0.410 (0.399)\tLoss 3.9084 (5.0377)\tPrec@1 12.500 (4.700)\tPrec@5 43.750 (14.799)\n",
      "Epoch: [2][1200/1276]\t\\Time 0.512 (0.497)\tData 0.411 (0.398)\tLoss 4.7992 (5.0183)\tPrec@1 12.500 (4.819)\tPrec@5 25.000 (15.112)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.470 (0.470)\n",
      "\n",
      "Loss 4.9488 (4.9488)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 18.750 (18.750)\n",
      "\n",
      " * Prec@1 0.000 Prec@5 18.750\n",
      " * Prec@1 15.625 Prec@5 28.125\n",
      " * Prec@1 12.500 Prec@5 22.917\n",
      " * Prec@1 12.500 Prec@5 21.875\n",
      " * Prec@1 10.000 Prec@5 20.000\n",
      " * Prec@1 8.333 Prec@5 17.708\n",
      " * Prec@1 8.036 Prec@5 17.857\n",
      " * Prec@1 9.375 Prec@5 18.750\n",
      " * Prec@1 9.028 Prec@5 18.750\n",
      " * Prec@1 9.375 Prec@5 20.000\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.481 (0.491)\n",
      "\n",
      "Loss 4.9358 (4.7977)\n",
      "\n",
      "Prec@1 6.250 (9.091)\n",
      "\n",
      "Prec@5 25.000 (20.455)\n",
      "\n",
      " * Prec@1 9.091 Prec@5 20.455\n",
      " * Prec@1 8.854 Prec@5 21.875\n",
      " * Prec@1 9.135 Prec@5 22.115\n",
      " * Prec@1 8.929 Prec@5 22.321\n",
      " * Prec@1 9.583 Prec@5 23.750\n",
      " * Prec@1 9.375 Prec@5 22.656\n",
      " * Prec@1 9.191 Prec@5 23.162\n",
      " * Prec@1 9.028 Prec@5 22.917\n",
      " * Prec@1 9.211 Prec@5 22.368\n",
      " * Prec@1 9.062 Prec@5 21.875\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.501 (0.501)\n",
      "\n",
      "Loss 5.2473 (4.7730)\n",
      "\n",
      "Prec@1 0.000 (8.631)\n",
      "\n",
      "Prec@5 0.000 (20.833)\n",
      "\n",
      " * Prec@1 8.631 Prec@5 20.833\n",
      " * Prec@1 8.239 Prec@5 20.455\n",
      " * Prec@1 7.880 Prec@5 20.109\n",
      " * Prec@1 7.552 Prec@5 19.792\n",
      " * Prec@1 7.250 Prec@5 19.000\n",
      " * Prec@1 7.212 Prec@5 18.750\n",
      " * Prec@1 7.176 Prec@5 18.981\n",
      " * Prec@1 7.143 Prec@5 19.420\n",
      " * Prec@1 7.112 Prec@5 19.397\n",
      " * Prec@1 7.083 Prec@5 19.167\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.501 (0.500)\n",
      "\n",
      "Loss 4.9411 (4.7948)\n",
      "\n",
      "Prec@1 0.000 (6.855)\n",
      "\n",
      "Prec@5 12.500 (18.952)\n",
      "\n",
      " * Prec@1 6.855 Prec@5 18.952\n",
      " * Prec@1 6.836 Prec@5 18.555\n",
      " * Prec@1 6.629 Prec@5 18.561\n",
      " * Prec@1 6.618 Prec@5 18.750\n",
      " * Prec@1 6.786 Prec@5 18.750\n",
      " * Prec@1 6.771 Prec@5 18.576\n",
      " * Prec@1 6.757 Prec@5 18.412\n",
      " * Prec@1 6.579 Prec@5 18.257\n",
      " * Prec@1 6.731 Prec@5 18.910\n",
      " * Prec@1 6.562 Prec@5 18.750\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.440 (0.499)\n",
      "\n",
      "Loss 4.3800 (4.7655)\n",
      "\n",
      "Prec@1 6.250 (6.555)\n",
      "\n",
      "Prec@5 25.000 (18.902)\n",
      "\n",
      " * Prec@1 6.555 Prec@5 18.902\n",
      " * Prec@1 6.845 Prec@5 19.048\n",
      " * Prec@1 6.977 Prec@5 18.895\n",
      " * Prec@1 7.386 Prec@5 19.034\n",
      " * Prec@1 7.222 Prec@5 18.889\n",
      " * Prec@1 7.201 Prec@5 18.750\n",
      " * Prec@1 7.314 Prec@5 19.016\n",
      " * Prec@1 7.292 Prec@5 18.880\n",
      " * Prec@1 7.398 Prec@5 18.750\n",
      " * Prec@1 7.375 Prec@5 18.875\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.472 (0.496)\n",
      "\n",
      "Loss 4.1022 (4.7650)\n",
      "\n",
      "Prec@1 12.500 (7.475)\n",
      "\n",
      "Prec@5 37.500 (19.240)\n",
      "\n",
      " * Prec@1 7.475 Prec@5 19.240\n",
      " * Prec@1 7.452 Prec@5 19.231\n",
      " * Prec@1 7.429 Prec@5 19.340\n",
      " * Prec@1 7.523 Prec@5 19.792\n",
      " * Prec@1 7.386 Prec@5 19.659\n",
      " * Prec@1 7.366 Prec@5 19.531\n",
      " * Prec@1 7.675 Prec@5 19.737\n",
      " * Prec@1 7.651 Prec@5 19.828\n",
      " * Prec@1 7.627 Prec@5 20.021\n",
      " * Prec@1 7.500 Prec@5 19.896\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.493 (0.497)\n",
      "\n",
      "Loss 4.9769 (4.7409)\n",
      "\n",
      "Prec@1 12.500 (7.582)\n",
      "\n",
      "Prec@5 31.250 (20.082)\n",
      "\n",
      " * Prec@1 7.582 Prec@5 20.082\n",
      " * Prec@1 7.560 Prec@5 20.060\n",
      " * Prec@1 7.440 Prec@5 19.841\n",
      " * Prec@1 7.422 Prec@5 19.824\n",
      " * Prec@1 7.596 Prec@5 20.096\n",
      " * Prec@1 7.481 Prec@5 19.981\n",
      " * Prec@1 7.556 Prec@5 20.056\n",
      " * Prec@1 7.537 Prec@5 20.037\n",
      " * Prec@1 7.428 Prec@5 19.837\n",
      " * Prec@1 7.500 Prec@5 19.732\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.483 (0.499)\n",
      "\n",
      "Loss 5.0650 (4.7606)\n",
      "\n",
      "Prec@1 6.250 (7.482)\n",
      "\n",
      "Prec@5 12.500 (19.630)\n",
      "\n",
      " * Prec@1 7.482 Prec@5 19.630\n",
      " * Prec@1 7.378 Prec@5 19.531\n",
      " * Prec@1 7.277 Prec@5 19.521\n",
      " * Prec@1 7.432 Prec@5 19.510\n",
      " * Prec@1 7.333 Prec@5 19.583\n",
      " * Prec@1 7.319 Prec@5 19.655\n",
      " * Prec@1 7.305 Prec@5 19.643\n",
      " * Prec@1 7.212 Prec@5 19.551\n",
      " * Prec@1 7.199 Prec@5 19.620\n",
      " * Prec@1 7.344 Prec@5 19.609\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.573 (0.500)\n",
      "\n",
      "Loss 5.0584 (4.7758)\n",
      "\n",
      "Prec@1 12.500 (7.407)\n",
      "\n",
      "Prec@5 12.500 (19.522)\n",
      "\n",
      " * Prec@1 7.407 Prec@5 19.522\n",
      " * Prec@1 7.317 Prec@5 19.360\n",
      " * Prec@1 7.229 Prec@5 19.277\n",
      " * Prec@1 7.217 Prec@5 19.271\n",
      " * Prec@1 7.206 Prec@5 19.265\n",
      " * Prec@1 7.195 Prec@5 19.331\n",
      " * Prec@1 7.184 Prec@5 19.181\n",
      " * Prec@1 7.244 Prec@5 19.318\n",
      " * Prec@1 7.444 Prec@5 19.593\n",
      " * Prec@1 7.569 Prec@5 19.792\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.471 (0.500)\n",
      "\n",
      "Loss 4.8186 (4.7812)\n",
      "\n",
      "Prec@1 0.000 (7.486)\n",
      "\n",
      "Prec@5 12.500 (19.712)\n",
      "\n",
      " * Prec@1 7.486 Prec@5 19.712\n",
      " * Prec@1 7.405 Prec@5 19.565\n",
      " * Prec@1 7.392 Prec@5 19.489\n",
      " * Prec@1 7.380 Prec@5 19.481\n",
      " * Prec@1 7.368 Prec@5 19.539\n",
      " * Prec@1 7.357 Prec@5 19.531\n",
      " * Prec@1 7.410 Prec@5 19.588\n",
      " * Prec@1 7.398 Prec@5 19.515\n",
      " * Prec@1 7.449 Prec@5 19.697\n",
      " * Prec@1 7.375 Prec@5 19.500\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.531 (0.500)\n",
      "\n",
      "Loss 4.5357 (4.7922)\n",
      "\n",
      "Prec@1 0.000 (7.302)\n",
      "\n",
      "Prec@5 18.750 (19.493)\n",
      "\n",
      " * Prec@1 7.302 Prec@5 19.493\n",
      " * Prec@1 7.353 Prec@5 19.485\n",
      " * Prec@1 7.342 Prec@5 19.417\n",
      " * Prec@1 7.392 Prec@5 19.411\n",
      " * Prec@1 7.500 Prec@5 19.464\n",
      " * Prec@1 7.547 Prec@5 19.752\n",
      " * Prec@1 7.535 Prec@5 19.743\n",
      " * Prec@1 7.523 Prec@5 19.734\n",
      " * Prec@1 7.454 Prec@5 19.725\n",
      " * Prec@1 7.557 Prec@5 19.886\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.534 (0.499)\n",
      "\n",
      "Loss 4.6082 (4.7681)\n",
      "\n",
      "Prec@1 6.250 (7.545)\n",
      "\n",
      "Prec@5 25.000 (19.932)\n",
      "\n",
      " * Prec@1 7.545 Prec@5 19.932\n",
      " * Prec@1 7.589 Prec@5 20.033\n",
      " * Prec@1 7.577 Prec@5 19.912\n",
      " * Prec@1 7.511 Prec@5 19.901\n",
      " * Prec@1 7.554 Prec@5 20.000\n",
      " * Prec@1 7.543 Prec@5 20.097\n",
      " * Prec@1 7.479 Prec@5 20.032\n",
      " * Prec@1 7.468 Prec@5 20.021\n",
      " * Prec@1 7.511 Prec@5 20.116\n",
      " * Prec@1 7.500 Prec@5 20.052\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.520 (0.499)\n",
      "\n",
      "Loss 4.9708 (4.7750)\n",
      "\n",
      "Prec@1 0.000 (7.438)\n",
      "\n",
      "Prec@5 6.250 (19.938)\n",
      "\n",
      " * Prec@1 7.438 Prec@5 19.938\n",
      " * Prec@1 7.480 Prec@5 19.980\n",
      " * Prec@1 7.520 Prec@5 20.224\n",
      " * Prec@1 7.510 Prec@5 20.212\n",
      " * Prec@1 7.450 Prec@5 20.200\n",
      " * Prec@1 7.440 Prec@5 20.188\n",
      " * Prec@1 7.382 Prec@5 20.030\n",
      " * Prec@1 7.324 Prec@5 19.971\n",
      " * Prec@1 7.267 Prec@5 20.010\n",
      " * Prec@1 7.212 Prec@5 20.000\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.503 (0.500)\n",
      "\n",
      "Loss 4.6914 (4.7762)\n",
      "\n",
      "Prec@1 6.250 (7.204)\n",
      "\n",
      "Prec@5 18.750 (19.990)\n",
      "\n",
      " * Prec@1 7.204 Prec@5 19.990\n",
      " * Prec@1 7.197 Prec@5 19.981\n",
      " * Prec@1 7.143 Prec@5 19.878\n",
      " * Prec@1 7.136 Prec@5 19.916\n",
      " * Prec@1 7.083 Prec@5 19.907\n",
      " * Prec@1 7.077 Prec@5 19.945\n",
      " * Prec@1 7.071 Prec@5 19.891\n",
      " * Prec@1 7.020 Prec@5 19.837\n",
      " * Prec@1 6.969 Prec@5 19.739\n",
      " * Prec@1 6.964 Prec@5 19.688\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.490 (0.498)\n",
      "\n",
      "Loss 5.2693 (4.7829)\n",
      "\n",
      "Prec@1 0.000 (6.915)\n",
      "\n",
      "Prec@5 6.250 (19.592)\n",
      "\n",
      " * Prec@1 6.915 Prec@5 19.592\n",
      " * Prec@1 7.007 Prec@5 19.744\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1276]\t\\Time 0.502 (0.502)\tData 0.391 (0.391)\tLoss 4.5355 (4.5355)\tPrec@1 6.250 (6.250)\tPrec@5 18.750 (18.750)\n",
      "Epoch: [3][100/1276]\t\\Time 0.451 (0.499)\tData 0.361 (0.396)\tLoss 4.6265 (4.7809)\tPrec@1 0.000 (6.993)\tPrec@5 18.750 (19.926)\n",
      "Epoch: [3][200/1276]\t\\Time 0.491 (0.496)\tData 0.381 (0.395)\tLoss 4.7559 (4.7290)\tPrec@1 6.250 (7.276)\tPrec@5 18.750 (20.522)\n",
      "Epoch: [3][300/1276]\t\\Time 0.481 (0.499)\tData 0.391 (0.397)\tLoss 4.7294 (4.7231)\tPrec@1 0.000 (7.122)\tPrec@5 18.750 (20.660)\n",
      "Epoch: [3][400/1276]\t\\Time 0.505 (0.498)\tData 0.394 (0.397)\tLoss 5.4176 (4.7198)\tPrec@1 0.000 (7.060)\tPrec@5 0.000 (20.620)\n",
      "Epoch: [3][500/1276]\t\\Time 0.521 (0.499)\tData 0.434 (0.398)\tLoss 4.6588 (4.7056)\tPrec@1 6.250 (7.161)\tPrec@5 18.750 (21.307)\n",
      "Epoch: [3][600/1276]\t\\Time 0.560 (0.498)\tData 0.450 (0.398)\tLoss 5.0427 (4.6879)\tPrec@1 0.000 (7.176)\tPrec@5 0.000 (21.537)\n",
      "Epoch: [3][700/1276]\t\\Time 0.536 (0.498)\tData 0.411 (0.398)\tLoss 3.9744 (4.6731)\tPrec@1 12.500 (7.284)\tPrec@5 37.500 (21.826)\n",
      "Epoch: [3][800/1276]\t\\Time 0.461 (0.497)\tData 0.391 (0.398)\tLoss 3.9917 (4.6560)\tPrec@1 18.750 (7.561)\tPrec@5 56.250 (22.129)\n",
      "Epoch: [3][900/1276]\t\\Time 0.522 (0.497)\tData 0.422 (0.398)\tLoss 4.6227 (4.6484)\tPrec@1 6.250 (7.617)\tPrec@5 18.750 (22.218)\n",
      "Epoch: [3][1000/1276]\t\\Time 0.521 (0.498)\tData 0.411 (0.398)\tLoss 4.3296 (4.6367)\tPrec@1 12.500 (7.730)\tPrec@5 12.500 (22.396)\n",
      "Epoch: [3][1100/1276]\t\\Time 0.546 (0.498)\tData 0.426 (0.398)\tLoss 5.0459 (4.6229)\tPrec@1 0.000 (7.811)\tPrec@5 18.750 (22.729)\n",
      "Epoch: [3][1200/1276]\t\\Time 0.501 (0.498)\tData 0.431 (0.398)\tLoss 4.3115 (4.6116)\tPrec@1 0.000 (7.931)\tPrec@5 37.500 (23.012)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.431 (0.431)\n",
      "\n",
      "Loss 4.5583 (4.5583)\n",
      "\n",
      "Prec@1 18.750 (18.750)\n",
      "\n",
      "Prec@5 18.750 (18.750)\n",
      "\n",
      " * Prec@1 18.750 Prec@5 18.750\n",
      " * Prec@1 9.375 Prec@5 18.750\n",
      " * Prec@1 8.333 Prec@5 20.833\n",
      " * Prec@1 6.250 Prec@5 17.188\n",
      " * Prec@1 7.500 Prec@5 18.750\n",
      " * Prec@1 8.333 Prec@5 20.833\n",
      " * Prec@1 8.929 Prec@5 20.536\n",
      " * Prec@1 8.594 Prec@5 22.656\n",
      " * Prec@1 8.333 Prec@5 23.611\n",
      " * Prec@1 8.125 Prec@5 23.750\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.503 (0.489)\n",
      "\n",
      "Loss 4.7145 (4.4792)\n",
      "\n",
      "Prec@1 6.250 (7.955)\n",
      "\n",
      "Prec@5 31.250 (24.432)\n",
      "\n",
      " * Prec@1 7.955 Prec@5 24.432\n",
      " * Prec@1 8.854 Prec@5 26.042\n",
      " * Prec@1 9.135 Prec@5 26.923\n",
      " * Prec@1 9.375 Prec@5 26.786\n",
      " * Prec@1 8.750 Prec@5 26.667\n",
      " * Prec@1 8.594 Prec@5 26.172\n",
      " * Prec@1 8.456 Prec@5 25.735\n",
      " * Prec@1 9.722 Prec@5 26.736\n",
      " * Prec@1 10.197 Prec@5 27.303\n",
      " * Prec@1 10.000 Prec@5 26.875\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.532 (0.493)\n",
      "\n",
      "Loss 5.0795 (4.4921)\n",
      "\n",
      "Prec@1 0.000 (9.524)\n",
      "\n",
      "Prec@5 0.000 (25.595)\n",
      "\n",
      " * Prec@1 9.524 Prec@5 25.595\n",
      " * Prec@1 9.375 Prec@5 25.000\n",
      " * Prec@1 9.239 Prec@5 24.457\n",
      " * Prec@1 8.854 Prec@5 24.479\n",
      " * Prec@1 8.750 Prec@5 25.250\n",
      " * Prec@1 8.654 Prec@5 25.000\n",
      " * Prec@1 8.565 Prec@5 25.231\n",
      " * Prec@1 8.482 Prec@5 25.000\n",
      " * Prec@1 8.621 Prec@5 25.000\n",
      " * Prec@1 8.750 Prec@5 25.000\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.515 (0.495)\n",
      "\n",
      "Loss 4.5371 (4.4942)\n",
      "\n",
      "Prec@1 12.500 (8.871)\n",
      "\n",
      "Prec@5 25.000 (25.000)\n",
      "\n",
      " * Prec@1 8.871 Prec@5 25.000\n",
      " * Prec@1 8.789 Prec@5 25.000\n",
      " * Prec@1 9.091 Prec@5 25.379\n",
      " * Prec@1 9.007 Prec@5 25.735\n",
      " * Prec@1 9.107 Prec@5 25.714\n",
      " * Prec@1 8.854 Prec@5 25.868\n",
      " * Prec@1 8.784 Prec@5 25.845\n",
      " * Prec@1 9.211 Prec@5 26.151\n",
      " * Prec@1 9.615 Prec@5 26.442\n",
      " * Prec@1 9.688 Prec@5 26.406\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.430 (0.494)\n",
      "\n",
      "Loss 3.9940 (4.4471)\n",
      "\n",
      "Prec@1 12.500 (9.756)\n",
      "\n",
      "Prec@5 43.750 (26.829)\n",
      "\n",
      " * Prec@1 9.756 Prec@5 26.829\n",
      " * Prec@1 10.119 Prec@5 27.083\n",
      " * Prec@1 10.174 Prec@5 27.180\n",
      " * Prec@1 10.369 Prec@5 27.415\n",
      " * Prec@1 10.139 Prec@5 27.500\n",
      " * Prec@1 10.190 Prec@5 27.582\n",
      " * Prec@1 10.372 Prec@5 27.394\n",
      " * Prec@1 10.156 Prec@5 27.083\n",
      " * Prec@1 10.077 Prec@5 26.658\n",
      " * Prec@1 10.125 Prec@5 26.750\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.461 (0.495)\n",
      "\n",
      "Loss 3.8655 (4.4698)\n",
      "\n",
      "Prec@1 6.250 (10.049)\n",
      "\n",
      "Prec@5 43.750 (27.083)\n",
      "\n",
      " * Prec@1 10.049 Prec@5 27.083\n",
      " * Prec@1 9.976 Prec@5 26.803\n",
      " * Prec@1 10.024 Prec@5 26.651\n",
      " * Prec@1 9.954 Prec@5 26.852\n",
      " * Prec@1 9.773 Prec@5 26.705\n",
      " * Prec@1 9.710 Prec@5 26.674\n",
      " * Prec@1 9.649 Prec@5 26.754\n",
      " * Prec@1 9.914 Prec@5 27.047\n",
      " * Prec@1 10.064 Prec@5 27.225\n",
      " * Prec@1 10.104 Prec@5 27.292\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.460 (0.495)\n",
      "\n",
      "Loss 4.8311 (4.4571)\n",
      "\n",
      "Prec@1 0.000 (9.939)\n",
      "\n",
      "Prec@5 12.500 (27.049)\n",
      "\n",
      " * Prec@1 9.939 Prec@5 27.049\n",
      " * Prec@1 9.879 Prec@5 27.117\n",
      " * Prec@1 9.722 Prec@5 26.786\n",
      " * Prec@1 9.766 Prec@5 26.660\n",
      " * Prec@1 9.904 Prec@5 26.731\n",
      " * Prec@1 9.848 Prec@5 26.610\n",
      " * Prec@1 9.888 Prec@5 26.399\n",
      " * Prec@1 9.926 Prec@5 26.287\n",
      " * Prec@1 9.783 Prec@5 25.996\n",
      " * Prec@1 9.732 Prec@5 25.893\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.491 (0.498)\n",
      "\n",
      "Loss 4.8106 (4.4810)\n",
      "\n",
      "Prec@1 6.250 (9.683)\n",
      "\n",
      "Prec@5 6.250 (25.616)\n",
      "\n",
      " * Prec@1 9.683 Prec@5 25.616\n",
      " * Prec@1 9.635 Prec@5 25.521\n",
      " * Prec@1 9.589 Prec@5 25.514\n",
      " * Prec@1 9.544 Prec@5 25.591\n",
      " * Prec@1 9.667 Prec@5 25.833\n",
      " * Prec@1 9.622 Prec@5 25.740\n",
      " * Prec@1 9.578 Prec@5 25.731\n",
      " * Prec@1 9.455 Prec@5 25.561\n",
      " * Prec@1 9.415 Prec@5 25.554\n",
      " * Prec@1 9.453 Prec@5 25.547\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.501 (0.499)\n",
      "\n",
      "Loss 4.7757 (4.4952)\n",
      "\n",
      "Prec@1 6.250 (9.414)\n",
      "\n",
      "Prec@5 18.750 (25.463)\n",
      "\n",
      " * Prec@1 9.414 Prec@5 25.463\n",
      " * Prec@1 9.375 Prec@5 25.381\n",
      " * Prec@1 9.262 Prec@5 25.377\n",
      " * Prec@1 9.226 Prec@5 25.372\n",
      " * Prec@1 9.191 Prec@5 25.221\n",
      " * Prec@1 9.084 Prec@5 25.073\n",
      " * Prec@1 9.052 Prec@5 24.856\n",
      " * Prec@1 9.020 Prec@5 24.858\n",
      " * Prec@1 9.129 Prec@5 25.000\n",
      " * Prec@1 9.167 Prec@5 25.347\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.460 (0.499)\n",
      "\n",
      "Loss 4.5379 (4.5039)\n",
      "\n",
      "Prec@1 6.250 (9.135)\n",
      "\n",
      "Prec@5 18.750 (25.275)\n",
      "\n",
      " * Prec@1 9.135 Prec@5 25.275\n",
      " * Prec@1 9.171 Prec@5 25.340\n",
      " * Prec@1 9.140 Prec@5 25.269\n",
      " * Prec@1 9.043 Prec@5 25.399\n",
      " * Prec@1 9.013 Prec@5 25.197\n",
      " * Prec@1 9.115 Prec@5 25.521\n",
      " * Prec@1 9.149 Prec@5 25.580\n",
      " * Prec@1 9.184 Prec@5 25.574\n",
      " * Prec@1 9.280 Prec@5 25.568\n",
      " * Prec@1 9.188 Prec@5 25.500\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.532 (0.498)\n",
      "\n",
      "Loss 4.2490 (4.5059)\n",
      "\n",
      "Prec@1 0.000 (9.097)\n",
      "\n",
      "Prec@5 31.250 (25.557)\n",
      "\n",
      " * Prec@1 9.097 Prec@5 25.557\n",
      " * Prec@1 9.069 Prec@5 25.429\n",
      " * Prec@1 9.041 Prec@5 25.546\n",
      " * Prec@1 9.135 Prec@5 25.661\n",
      " * Prec@1 9.226 Prec@5 25.774\n",
      " * Prec@1 9.198 Prec@5 25.825\n",
      " * Prec@1 9.229 Prec@5 25.935\n",
      " * Prec@1 9.144 Prec@5 26.100\n",
      " * Prec@1 9.174 Prec@5 26.089\n",
      " * Prec@1 9.432 Prec@5 26.477\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.554 (0.499)\n",
      "\n",
      "Loss 3.9727 (4.4792)\n",
      "\n",
      "Prec@1 12.500 (9.459)\n",
      "\n",
      "Prec@5 31.250 (26.520)\n",
      "\n",
      " * Prec@1 9.459 Prec@5 26.520\n",
      " * Prec@1 9.542 Prec@5 26.618\n",
      " * Prec@1 9.513 Prec@5 26.604\n",
      " * Prec@1 9.594 Prec@5 26.535\n",
      " * Prec@1 9.674 Prec@5 26.685\n",
      " * Prec@1 9.698 Prec@5 26.724\n",
      " * Prec@1 9.615 Prec@5 26.763\n",
      " * Prec@1 9.640 Prec@5 26.695\n",
      " * Prec@1 9.611 Prec@5 26.628\n",
      " * Prec@1 9.583 Prec@5 26.562\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.491 (0.499)\n",
      "\n",
      "Loss 4.4857 (4.4783)\n",
      "\n",
      "Prec@1 0.000 (9.504)\n",
      "\n",
      "Prec@5 25.000 (26.550)\n",
      "\n",
      " * Prec@1 9.504 Prec@5 26.550\n",
      " * Prec@1 9.631 Prec@5 26.691\n",
      " * Prec@1 9.705 Prec@5 26.829\n",
      " * Prec@1 9.627 Prec@5 26.764\n",
      " * Prec@1 9.550 Prec@5 26.650\n",
      " * Prec@1 9.623 Prec@5 26.736\n",
      " * Prec@1 9.596 Prec@5 26.722\n",
      " * Prec@1 9.570 Prec@5 26.855\n",
      " * Prec@1 9.641 Prec@5 27.035\n",
      " * Prec@1 9.615 Prec@5 26.923\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.550 (0.499)\n",
      "\n",
      "Loss 4.6166 (4.4735)\n",
      "\n",
      "Prec@1 6.250 (9.590)\n",
      "\n",
      "Prec@5 18.750 (26.861)\n",
      "\n",
      " * Prec@1 9.590 Prec@5 26.861\n",
      " * Prec@1 9.517 Prec@5 26.752\n",
      " * Prec@1 9.492 Prec@5 26.692\n",
      " * Prec@1 9.562 Prec@5 26.679\n",
      " * Prec@1 9.537 Prec@5 26.759\n",
      " * Prec@1 9.651 Prec@5 26.884\n",
      " * Prec@1 9.626 Prec@5 27.053\n",
      " * Prec@1 9.601 Prec@5 27.083\n",
      " * Prec@1 9.577 Prec@5 26.933\n",
      " * Prec@1 9.554 Prec@5 26.920\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.511 (0.499)\n",
      "\n",
      "Loss 4.7969 (4.4797)\n",
      "\n",
      "Prec@1 6.250 (9.530)\n",
      "\n",
      "Prec@5 12.500 (26.817)\n",
      "\n",
      " * Prec@1 9.530 Prec@5 26.817\n",
      " * Prec@1 9.608 Prec@5 26.884\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1276]\t\\Time 0.575 (0.575)\tData 0.430 (0.430)\tLoss 4.8564 (4.8564)\tPrec@1 12.500 (12.500)\tPrec@5 18.750 (18.750)\n",
      "Epoch: [4][100/1276]\t\\Time 0.468 (0.500)\tData 0.384 (0.396)\tLoss 3.9607 (4.3286)\tPrec@1 25.000 (9.901)\tPrec@5 43.750 (28.342)\n",
      "Epoch: [4][200/1276]\t\\Time 0.485 (0.499)\tData 0.383 (0.398)\tLoss 4.2861 (4.3533)\tPrec@1 12.500 (10.261)\tPrec@5 31.250 (28.141)\n",
      "Epoch: [4][300/1276]\t\\Time 0.505 (0.498)\tData 0.383 (0.397)\tLoss 4.3981 (4.3699)\tPrec@1 12.500 (10.361)\tPrec@5 31.250 (27.554)\n",
      "Epoch: [4][400/1276]\t\\Time 0.482 (0.499)\tData 0.378 (0.398)\tLoss 4.7313 (4.3686)\tPrec@1 6.250 (10.536)\tPrec@5 25.000 (27.494)\n",
      "Epoch: [4][500/1276]\t\\Time 0.499 (0.498)\tData 0.378 (0.397)\tLoss 4.2394 (4.3705)\tPrec@1 6.250 (10.479)\tPrec@5 31.250 (27.520)\n",
      "Epoch: [4][600/1276]\t\\Time 0.501 (0.498)\tData 0.391 (0.397)\tLoss 4.6286 (4.3614)\tPrec@1 6.250 (10.347)\tPrec@5 12.500 (27.797)\n",
      "Epoch: [4][700/1276]\t\\Time 0.498 (0.498)\tData 0.389 (0.397)\tLoss 4.4855 (4.3496)\tPrec@1 6.250 (10.449)\tPrec@5 37.500 (28.272)\n",
      "Epoch: [4][800/1276]\t\\Time 0.501 (0.498)\tData 0.391 (0.398)\tLoss 3.8471 (4.3418)\tPrec@1 12.500 (10.573)\tPrec@5 37.500 (28.605)\n",
      "Epoch: [4][900/1276]\t\\Time 0.472 (0.499)\tData 0.379 (0.398)\tLoss 4.6781 (4.3323)\tPrec@1 6.250 (10.627)\tPrec@5 18.750 (28.725)\n",
      "Epoch: [4][1000/1276]\t\\Time 0.532 (0.499)\tData 0.428 (0.398)\tLoss 4.7048 (4.3273)\tPrec@1 0.000 (10.602)\tPrec@5 6.250 (28.871)\n",
      "Epoch: [4][1100/1276]\t\\Time 0.451 (0.499)\tData 0.381 (0.398)\tLoss 4.2231 (4.3203)\tPrec@1 6.250 (10.638)\tPrec@5 18.750 (29.116)\n",
      "Epoch: [4][1200/1276]\t\\Time 0.521 (0.499)\tData 0.411 (0.398)\tLoss 4.6036 (4.3169)\tPrec@1 12.500 (10.736)\tPrec@5 31.250 (29.304)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.466 (0.466)\n",
      "\n",
      "Loss 4.7117 (4.7117)\n",
      "\n",
      "Prec@1 6.250 (6.250)\n",
      "\n",
      "Prec@5 12.500 (12.500)\n",
      "\n",
      " * Prec@1 6.250 Prec@5 12.500\n",
      " * Prec@1 9.375 Prec@5 25.000\n",
      " * Prec@1 8.333 Prec@5 27.083\n",
      " * Prec@1 7.812 Prec@5 25.000\n",
      " * Prec@1 7.500 Prec@5 28.750\n",
      " * Prec@1 7.292 Prec@5 29.167\n",
      " * Prec@1 8.036 Prec@5 29.464\n",
      " * Prec@1 9.375 Prec@5 31.250\n",
      " * Prec@1 9.722 Prec@5 32.639\n",
      " * Prec@1 9.375 Prec@5 33.750\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.501 (0.495)\n",
      "\n",
      "Loss 4.4622 (4.1646)\n",
      "\n",
      "Prec@1 6.250 (9.091)\n",
      "\n",
      "Prec@5 31.250 (33.523)\n",
      "\n",
      " * Prec@1 9.091 Prec@5 33.523\n",
      " * Prec@1 9.896 Prec@5 35.417\n",
      " * Prec@1 11.058 Prec@5 35.577\n",
      " * Prec@1 11.607 Prec@5 36.161\n",
      " * Prec@1 12.500 Prec@5 36.250\n",
      " * Prec@1 12.109 Prec@5 35.156\n",
      " * Prec@1 11.397 Prec@5 34.926\n",
      " * Prec@1 12.153 Prec@5 35.069\n",
      " * Prec@1 12.171 Prec@5 34.868\n",
      " * Prec@1 11.875 Prec@5 34.688\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.540 (0.500)\n",
      "\n",
      "Loss 4.9393 (4.1738)\n",
      "\n",
      "Prec@1 0.000 (11.310)\n",
      "\n",
      "Prec@5 12.500 (33.631)\n",
      "\n",
      " * Prec@1 11.310 Prec@5 33.631\n",
      " * Prec@1 11.080 Prec@5 34.091\n",
      " * Prec@1 11.141 Prec@5 33.967\n",
      " * Prec@1 11.198 Prec@5 34.115\n",
      " * Prec@1 11.000 Prec@5 34.000\n",
      " * Prec@1 10.817 Prec@5 33.413\n",
      " * Prec@1 10.648 Prec@5 33.102\n",
      " * Prec@1 10.268 Prec@5 33.036\n",
      " * Prec@1 10.560 Prec@5 33.190\n",
      " * Prec@1 10.625 Prec@5 32.917\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.481 (0.497)\n",
      "\n",
      "Loss 4.8559 (4.1837)\n",
      "\n",
      "Prec@1 12.500 (10.685)\n",
      "\n",
      "Prec@5 25.000 (32.661)\n",
      "\n",
      " * Prec@1 10.685 Prec@5 32.661\n",
      " * Prec@1 10.547 Prec@5 32.227\n",
      " * Prec@1 10.606 Prec@5 32.008\n",
      " * Prec@1 10.662 Prec@5 32.353\n",
      " * Prec@1 10.714 Prec@5 32.143\n",
      " * Prec@1 10.938 Prec@5 32.118\n",
      " * Prec@1 11.149 Prec@5 31.926\n",
      " * Prec@1 11.184 Prec@5 32.237\n",
      " * Prec@1 11.538 Prec@5 32.532\n",
      " * Prec@1 11.562 Prec@5 32.656\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.472 (0.500)\n",
      "\n",
      "Loss 4.0276 (4.1858)\n",
      "\n",
      "Prec@1 12.500 (11.585)\n",
      "\n",
      "Prec@5 43.750 (32.927)\n",
      "\n",
      " * Prec@1 11.585 Prec@5 32.927\n",
      " * Prec@1 11.756 Prec@5 32.738\n",
      " * Prec@1 11.773 Prec@5 32.558\n",
      " * Prec@1 12.074 Prec@5 32.812\n",
      " * Prec@1 11.944 Prec@5 32.639\n",
      " * Prec@1 11.957 Prec@5 32.473\n",
      " * Prec@1 12.101 Prec@5 32.447\n",
      " * Prec@1 12.109 Prec@5 32.031\n",
      " * Prec@1 12.117 Prec@5 31.888\n",
      " * Prec@1 12.000 Prec@5 31.500\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.453 (0.498)\n",
      "\n",
      "Loss 3.4083 (4.2264)\n",
      "\n",
      "Prec@1 18.750 (12.132)\n",
      "\n",
      "Prec@5 56.250 (31.985)\n",
      "\n",
      " * Prec@1 12.132 Prec@5 31.985\n",
      " * Prec@1 11.899 Prec@5 31.611\n",
      " * Prec@1 11.910 Prec@5 31.368\n",
      " * Prec@1 11.921 Prec@5 31.481\n",
      " * Prec@1 11.932 Prec@5 31.250\n",
      " * Prec@1 12.054 Prec@5 31.250\n",
      " * Prec@1 12.171 Prec@5 31.031\n",
      " * Prec@1 12.716 Prec@5 31.466\n",
      " * Prec@1 12.924 Prec@5 31.462\n",
      " * Prec@1 12.708 Prec@5 31.354\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.481 (0.498)\n",
      "\n",
      "Loss 4.1454 (4.2227)\n",
      "\n",
      "Prec@1 18.750 (12.807)\n",
      "\n",
      "Prec@5 37.500 (31.455)\n",
      "\n",
      " * Prec@1 12.807 Prec@5 31.455\n",
      " * Prec@1 12.903 Prec@5 31.351\n",
      " * Prec@1 12.798 Prec@5 31.349\n",
      " * Prec@1 12.793 Prec@5 31.250\n",
      " * Prec@1 12.981 Prec@5 31.346\n",
      " * Prec@1 12.879 Prec@5 31.155\n",
      " * Prec@1 13.060 Prec@5 31.343\n",
      " * Prec@1 12.960 Prec@5 31.250\n",
      " * Prec@1 12.772 Prec@5 30.888\n",
      " * Prec@1 12.768 Prec@5 30.714\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.503 (0.501)\n",
      "\n",
      "Loss 4.5759 (4.2526)\n",
      "\n",
      "Prec@1 12.500 (12.764)\n",
      "\n",
      "Prec@5 25.000 (30.634)\n",
      "\n",
      " * Prec@1 12.764 Prec@5 30.634\n",
      " * Prec@1 12.674 Prec@5 30.556\n",
      " * Prec@1 12.757 Prec@5 30.651\n",
      " * Prec@1 12.753 Prec@5 30.659\n",
      " * Prec@1 12.750 Prec@5 30.833\n",
      " * Prec@1 12.664 Prec@5 30.757\n",
      " * Prec@1 12.744 Prec@5 30.844\n",
      " * Prec@1 12.660 Prec@5 30.689\n",
      " * Prec@1 12.658 Prec@5 30.617\n",
      " * Prec@1 12.578 Prec@5 30.547\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.541 (0.502)\n",
      "\n",
      "Loss 4.4981 (4.2701)\n",
      "\n",
      "Prec@1 6.250 (12.500)\n",
      "\n",
      "Prec@5 25.000 (30.478)\n",
      "\n",
      " * Prec@1 12.500 Prec@5 30.478\n",
      " * Prec@1 12.348 Prec@5 30.259\n",
      " * Prec@1 12.274 Prec@5 30.196\n",
      " * Prec@1 12.277 Prec@5 30.134\n",
      " * Prec@1 12.279 Prec@5 29.926\n",
      " * Prec@1 12.209 Prec@5 29.797\n",
      " * Prec@1 12.213 Prec@5 29.598\n",
      " * Prec@1 12.145 Prec@5 29.403\n",
      " * Prec@1 12.360 Prec@5 29.775\n",
      " * Prec@1 12.431 Prec@5 30.000\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.458 (0.502)\n",
      "\n",
      "Loss 4.0045 (4.2801)\n",
      "\n",
      "Prec@1 18.750 (12.500)\n",
      "\n",
      "Prec@5 37.500 (30.082)\n",
      "\n",
      " * Prec@1 12.500 Prec@5 30.082\n",
      " * Prec@1 12.432 Prec@5 30.095\n",
      " * Prec@1 12.366 Prec@5 30.040\n",
      " * Prec@1 12.301 Prec@5 29.987\n",
      " * Prec@1 12.171 Prec@5 29.803\n",
      " * Prec@1 12.240 Prec@5 30.013\n",
      " * Prec@1 12.242 Prec@5 30.090\n",
      " * Prec@1 12.245 Prec@5 29.974\n",
      " * Prec@1 12.437 Prec@5 30.051\n",
      " * Prec@1 12.375 Prec@5 30.062\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.542 (0.501)\n",
      "\n",
      "Loss 4.0581 (4.2798)\n",
      "\n",
      "Prec@1 12.500 (12.376)\n",
      "\n",
      "Prec@5 31.250 (30.074)\n",
      "\n",
      " * Prec@1 12.376 Prec@5 30.074\n",
      " * Prec@1 12.255 Prec@5 29.963\n",
      " * Prec@1 12.257 Prec@5 29.976\n",
      " * Prec@1 12.200 Prec@5 29.988\n",
      " * Prec@1 12.262 Prec@5 30.060\n",
      " * Prec@1 12.205 Prec@5 30.071\n",
      " * Prec@1 12.208 Prec@5 30.023\n",
      " * Prec@1 12.153 Prec@5 30.093\n",
      " * Prec@1 12.213 Prec@5 30.103\n",
      " * Prec@1 12.443 Prec@5 30.511\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.534 (0.501)\n",
      "\n",
      "Loss 3.5695 (4.2575)\n",
      "\n",
      "Prec@1 37.500 (12.669)\n",
      "\n",
      "Prec@5 43.750 (30.631)\n",
      "\n",
      " * Prec@1 12.669 Prec@5 30.631\n",
      " * Prec@1 12.723 Prec@5 30.748\n",
      " * Prec@1 12.832 Prec@5 30.808\n",
      " * Prec@1 12.939 Prec@5 30.866\n",
      " * Prec@1 12.989 Prec@5 30.870\n",
      " * Prec@1 13.039 Prec@5 30.927\n",
      " * Prec@1 13.141 Prec@5 31.197\n",
      " * Prec@1 13.136 Prec@5 31.197\n",
      " * Prec@1 13.078 Prec@5 31.092\n",
      " * Prec@1 12.969 Prec@5 31.042\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.506 (0.501)\n",
      "\n",
      "Loss 4.0311 (4.2475)\n",
      "\n",
      "Prec@1 6.250 (12.913)\n",
      "\n",
      "Prec@5 37.500 (31.095)\n",
      "\n",
      " * Prec@1 12.913 Prec@5 31.095\n",
      " * Prec@1 12.910 Prec@5 31.352\n",
      " * Prec@1 13.110 Prec@5 31.555\n",
      " * Prec@1 13.054 Prec@5 31.452\n",
      " * Prec@1 12.950 Prec@5 31.350\n",
      " * Prec@1 12.996 Prec@5 31.399\n",
      " * Prec@1 12.943 Prec@5 31.447\n",
      " * Prec@1 12.988 Prec@5 31.592\n",
      " * Prec@1 12.984 Prec@5 31.783\n",
      " * Prec@1 12.981 Prec@5 31.779\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.563 (0.501)\n",
      "\n",
      "Loss 4.3257 (4.2294)\n",
      "\n",
      "Prec@1 6.250 (12.929)\n",
      "\n",
      "Prec@5 25.000 (31.727)\n",
      "\n",
      " * Prec@1 12.929 Prec@5 31.727\n",
      " * Prec@1 12.926 Prec@5 31.723\n",
      " * Prec@1 12.923 Prec@5 31.673\n",
      " * Prec@1 12.966 Prec@5 31.716\n",
      " * Prec@1 13.056 Prec@5 31.806\n",
      " * Prec@1 13.051 Prec@5 31.847\n",
      " * Prec@1 13.047 Prec@5 31.889\n",
      " * Prec@1 13.089 Prec@5 31.884\n",
      " * Prec@1 13.085 Prec@5 31.879\n",
      " * Prec@1 13.036 Prec@5 31.830\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.480 (0.499)\n",
      "\n",
      "Loss 4.8096 (4.2321)\n",
      "\n",
      "Prec@1 6.250 (12.988)\n",
      "\n",
      "Prec@5 12.500 (31.693)\n",
      "\n",
      " * Prec@1 12.988 Prec@5 31.693\n",
      " * Prec@1 13.045 Prec@5 31.776\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1276]\t\\Time 0.499 (0.499)\tData 0.346 (0.346)\tLoss 3.9335 (3.9335)\tPrec@1 12.500 (12.500)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [5][100/1276]\t\\Time 0.533 (0.498)\tData 0.428 (0.400)\tLoss 3.5678 (4.0127)\tPrec@1 25.000 (13.552)\tPrec@5 43.750 (37.252)\n",
      "Epoch: [5][200/1276]\t\\Time 0.541 (0.502)\tData 0.431 (0.402)\tLoss 4.4215 (4.0492)\tPrec@1 12.500 (14.024)\tPrec@5 31.250 (35.852)\n",
      "Epoch: [5][300/1276]\t\\Time 0.488 (0.503)\tData 0.375 (0.401)\tLoss 3.8878 (4.0495)\tPrec@1 6.250 (13.663)\tPrec@5 37.500 (35.673)\n",
      "Epoch: [5][400/1276]\t\\Time 0.540 (0.503)\tData 0.433 (0.401)\tLoss 3.9262 (4.0478)\tPrec@1 12.500 (13.762)\tPrec@5 25.000 (35.443)\n",
      "Epoch: [5][500/1276]\t\\Time 0.491 (0.502)\tData 0.381 (0.400)\tLoss 4.2371 (4.0619)\tPrec@1 0.000 (13.448)\tPrec@5 18.750 (35.242)\n",
      "Epoch: [5][600/1276]\t\\Time 0.536 (0.502)\tData 0.419 (0.400)\tLoss 4.4250 (4.0693)\tPrec@1 18.750 (13.259)\tPrec@5 25.000 (34.983)\n",
      "Epoch: [5][700/1276]\t\\Time 0.530 (0.502)\tData 0.420 (0.400)\tLoss 3.8302 (4.0676)\tPrec@1 25.000 (13.392)\tPrec@5 43.750 (34.879)\n",
      "Epoch: [5][800/1276]\t\\Time 0.532 (0.502)\tData 0.426 (0.400)\tLoss 4.4640 (4.0642)\tPrec@1 6.250 (13.538)\tPrec@5 25.000 (34.956)\n",
      "Epoch: [5][900/1276]\t\\Time 0.482 (0.501)\tData 0.412 (0.400)\tLoss 4.3221 (4.0575)\tPrec@1 18.750 (13.686)\tPrec@5 43.750 (35.176)\n",
      "Epoch: [5][1000/1276]\t\\Time 0.480 (0.501)\tData 0.381 (0.400)\tLoss 4.4006 (4.0527)\tPrec@1 12.500 (13.774)\tPrec@5 25.000 (35.271)\n",
      "Epoch: [5][1100/1276]\t\\Time 0.454 (0.501)\tData 0.354 (0.400)\tLoss 4.6910 (4.0446)\tPrec@1 12.500 (13.970)\tPrec@5 12.500 (35.559)\n",
      "Epoch: [5][1200/1276]\t\\Time 0.535 (0.501)\tData 0.423 (0.400)\tLoss 4.0182 (4.0443)\tPrec@1 12.500 (14.025)\tPrec@5 37.500 (35.689)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.423 (0.423)\n",
      "\n",
      "Loss 3.9929 (3.9929)\n",
      "\n",
      "Prec@1 12.500 (12.500)\n",
      "\n",
      "Prec@5 37.500 (37.500)\n",
      "\n",
      " * Prec@1 12.500 Prec@5 37.500\n",
      " * Prec@1 18.750 Prec@5 40.625\n",
      " * Prec@1 14.583 Prec@5 37.500\n",
      " * Prec@1 12.500 Prec@5 35.938\n",
      " * Prec@1 11.250 Prec@5 33.750\n",
      " * Prec@1 12.500 Prec@5 31.250\n",
      " * Prec@1 12.500 Prec@5 33.036\n",
      " * Prec@1 14.844 Prec@5 33.594\n",
      " * Prec@1 14.583 Prec@5 34.722\n",
      " * Prec@1 15.000 Prec@5 35.625\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.488 (0.487)\n",
      "\n",
      "Loss 3.9076 (3.9290)\n",
      "\n",
      "Prec@1 12.500 (14.773)\n",
      "\n",
      "Prec@5 37.500 (35.795)\n",
      "\n",
      " * Prec@1 14.773 Prec@5 35.795\n",
      " * Prec@1 15.625 Prec@5 38.021\n",
      " * Prec@1 15.385 Prec@5 37.500\n",
      " * Prec@1 15.179 Prec@5 38.393\n",
      " * Prec@1 15.417 Prec@5 38.333\n",
      " * Prec@1 15.625 Prec@5 37.891\n",
      " * Prec@1 15.809 Prec@5 37.868\n",
      " * Prec@1 16.667 Prec@5 38.542\n",
      " * Prec@1 16.118 Prec@5 38.816\n",
      " * Prec@1 15.312 Prec@5 38.125\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.537 (0.494)\n",
      "\n",
      "Loss 4.8075 (3.9774)\n",
      "\n",
      "Prec@1 0.000 (14.583)\n",
      "\n",
      "Prec@5 18.750 (37.202)\n",
      "\n",
      " * Prec@1 14.583 Prec@5 37.202\n",
      " * Prec@1 15.057 Prec@5 37.784\n",
      " * Prec@1 14.946 Prec@5 37.228\n",
      " * Prec@1 14.323 Prec@5 36.979\n",
      " * Prec@1 14.250 Prec@5 37.000\n",
      " * Prec@1 14.183 Prec@5 37.019\n",
      " * Prec@1 14.120 Prec@5 36.806\n",
      " * Prec@1 14.286 Prec@5 36.607\n",
      " * Prec@1 14.440 Prec@5 36.638\n",
      " * Prec@1 15.000 Prec@5 36.875\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.524 (0.499)\n",
      "\n",
      "Loss 4.0605 (3.9763)\n",
      "\n",
      "Prec@1 12.500 (14.919)\n",
      "\n",
      "Prec@5 31.250 (36.694)\n",
      "\n",
      " * Prec@1 14.919 Prec@5 36.694\n",
      " * Prec@1 15.039 Prec@5 36.523\n",
      " * Prec@1 15.341 Prec@5 36.174\n",
      " * Prec@1 15.257 Prec@5 36.213\n",
      " * Prec@1 15.179 Prec@5 36.607\n",
      " * Prec@1 15.104 Prec@5 36.458\n",
      " * Prec@1 15.203 Prec@5 36.486\n",
      " * Prec@1 15.132 Prec@5 36.184\n",
      " * Prec@1 14.904 Prec@5 36.378\n",
      " * Prec@1 14.844 Prec@5 36.406\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.443 (0.500)\n",
      "\n",
      "Loss 3.3992 (3.9647)\n",
      "\n",
      "Prec@1 31.250 (15.244)\n",
      "\n",
      "Prec@5 50.000 (36.738)\n",
      "\n",
      " * Prec@1 15.244 Prec@5 36.738\n",
      " * Prec@1 15.179 Prec@5 36.756\n",
      " * Prec@1 15.262 Prec@5 37.064\n",
      " * Prec@1 15.341 Prec@5 37.358\n",
      " * Prec@1 15.278 Prec@5 37.361\n",
      " * Prec@1 15.353 Prec@5 37.092\n",
      " * Prec@1 15.559 Prec@5 37.101\n",
      " * Prec@1 15.365 Prec@5 36.719\n",
      " * Prec@1 15.434 Prec@5 36.607\n",
      " * Prec@1 15.375 Prec@5 36.375\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.540 (0.499)\n",
      "\n",
      "Loss 3.2216 (3.9830)\n",
      "\n",
      "Prec@1 25.000 (15.564)\n",
      "\n",
      "Prec@5 43.750 (36.520)\n",
      "\n",
      " * Prec@1 15.564 Prec@5 36.520\n",
      " * Prec@1 15.264 Prec@5 36.418\n",
      " * Prec@1 15.330 Prec@5 36.321\n",
      " * Prec@1 15.394 Prec@5 36.574\n",
      " * Prec@1 15.227 Prec@5 36.250\n",
      " * Prec@1 15.067 Prec@5 36.049\n",
      " * Prec@1 15.022 Prec@5 35.965\n",
      " * Prec@1 15.409 Prec@5 36.315\n",
      " * Prec@1 15.466 Prec@5 36.335\n",
      " * Prec@1 15.521 Prec@5 36.250\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.478 (0.499)\n",
      "\n",
      "Loss 4.1335 (3.9931)\n",
      "\n",
      "Prec@1 37.500 (15.881)\n",
      "\n",
      "Prec@5 37.500 (36.270)\n",
      "\n",
      " * Prec@1 15.881 Prec@5 36.270\n",
      " * Prec@1 15.927 Prec@5 36.391\n",
      " * Prec@1 15.774 Prec@5 36.409\n",
      " * Prec@1 15.820 Prec@5 36.426\n",
      " * Prec@1 15.769 Prec@5 36.442\n",
      " * Prec@1 15.625 Prec@5 36.364\n",
      " * Prec@1 15.765 Prec@5 36.567\n",
      " * Prec@1 15.717 Prec@5 36.397\n",
      " * Prec@1 15.489 Prec@5 36.232\n",
      " * Prec@1 15.268 Prec@5 36.250\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.483 (0.502)\n",
      "\n",
      "Loss 4.2429 (4.0170)\n",
      "\n",
      "Prec@1 18.750 (15.317)\n",
      "\n",
      "Prec@5 31.250 (36.180)\n",
      "\n",
      " * Prec@1 15.317 Prec@5 36.180\n",
      " * Prec@1 15.365 Prec@5 36.285\n",
      " * Prec@1 15.325 Prec@5 36.387\n",
      " * Prec@1 15.287 Prec@5 36.233\n",
      " * Prec@1 15.250 Prec@5 36.167\n",
      " * Prec@1 15.132 Prec@5 36.020\n",
      " * Prec@1 15.016 Prec@5 35.958\n",
      " * Prec@1 14.904 Prec@5 35.897\n",
      " * Prec@1 14.873 Prec@5 35.759\n",
      " * Prec@1 14.766 Prec@5 35.547\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.532 (0.504)\n",
      "\n",
      "Loss 4.4022 (4.0506)\n",
      "\n",
      "Prec@1 31.250 (14.969)\n",
      "\n",
      "Prec@5 31.250 (35.494)\n",
      "\n",
      " * Prec@1 14.969 Prec@5 35.494\n",
      " * Prec@1 14.787 Prec@5 35.290\n",
      " * Prec@1 14.759 Prec@5 35.166\n",
      " * Prec@1 14.881 Prec@5 35.268\n",
      " * Prec@1 14.779 Prec@5 35.074\n",
      " * Prec@1 14.680 Prec@5 34.956\n",
      " * Prec@1 14.655 Prec@5 34.914\n",
      " * Prec@1 14.631 Prec@5 34.872\n",
      " * Prec@1 14.747 Prec@5 35.112\n",
      " * Prec@1 14.861 Prec@5 35.208\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.477 (0.504)\n",
      "\n",
      "Loss 3.7275 (4.0528)\n",
      "\n",
      "Prec@1 31.250 (15.041)\n",
      "\n",
      "Prec@5 56.250 (35.440)\n",
      "\n",
      " * Prec@1 15.041 Prec@5 35.440\n",
      " * Prec@1 15.082 Prec@5 35.326\n",
      " * Prec@1 15.121 Prec@5 35.417\n",
      " * Prec@1 15.093 Prec@5 35.372\n",
      " * Prec@1 14.934 Prec@5 35.329\n",
      " * Prec@1 14.974 Prec@5 35.286\n",
      " * Prec@1 15.077 Prec@5 35.503\n",
      " * Prec@1 15.051 Prec@5 35.395\n",
      " * Prec@1 15.278 Prec@5 35.417\n",
      " * Prec@1 15.312 Prec@5 35.375\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.536 (0.504)\n",
      "\n",
      "Loss 4.1148 (4.0468)\n",
      "\n",
      "Prec@1 18.750 (15.347)\n",
      "\n",
      "Prec@5 43.750 (35.458)\n",
      "\n",
      " * Prec@1 15.347 Prec@5 35.458\n",
      " * Prec@1 15.319 Prec@5 35.355\n",
      " * Prec@1 15.291 Prec@5 35.437\n",
      " * Prec@1 15.325 Prec@5 35.577\n",
      " * Prec@1 15.298 Prec@5 35.655\n",
      " * Prec@1 15.153 Prec@5 35.613\n",
      " * Prec@1 15.245 Prec@5 35.514\n",
      " * Prec@1 15.394 Prec@5 35.648\n",
      " * Prec@1 15.424 Prec@5 35.665\n",
      " * Prec@1 15.739 Prec@5 36.023\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.546 (0.503)\n",
      "\n",
      "Loss 3.2069 (4.0117)\n",
      "\n",
      "Prec@1 12.500 (15.709)\n",
      "\n",
      "Prec@5 68.750 (36.318)\n",
      "\n",
      " * Prec@1 15.709 Prec@5 36.318\n",
      " * Prec@1 15.737 Prec@5 36.328\n",
      " * Prec@1 15.763 Prec@5 36.449\n",
      " * Prec@1 15.735 Prec@5 36.513\n",
      " * Prec@1 15.815 Prec@5 36.685\n",
      " * Prec@1 15.787 Prec@5 36.746\n",
      " * Prec@1 15.705 Prec@5 36.752\n",
      " * Prec@1 15.678 Prec@5 36.706\n",
      " * Prec@1 15.599 Prec@5 36.660\n",
      " * Prec@1 15.469 Prec@5 36.510\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.524 (0.504)\n",
      "\n",
      "Loss 3.5015 (4.0044)\n",
      "\n",
      "Prec@1 18.750 (15.496)\n",
      "\n",
      "Prec@5 62.500 (36.725)\n",
      "\n",
      " * Prec@1 15.496 Prec@5 36.725\n",
      " * Prec@1 15.625 Prec@5 36.834\n",
      " * Prec@1 15.701 Prec@5 37.043\n",
      " * Prec@1 15.625 Prec@5 36.895\n",
      " * Prec@1 15.500 Prec@5 36.800\n",
      " * Prec@1 15.625 Prec@5 36.905\n",
      " * Prec@1 15.600 Prec@5 36.811\n",
      " * Prec@1 15.576 Prec@5 36.914\n",
      " * Prec@1 15.795 Prec@5 37.355\n",
      " * Prec@1 15.769 Prec@5 37.308\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.524 (0.505)\n",
      "\n",
      "Loss 4.0853 (3.9842)\n",
      "\n",
      "Prec@1 0.000 (15.649)\n",
      "\n",
      "Prec@5 25.000 (37.214)\n",
      "\n",
      " * Prec@1 15.649 Prec@5 37.214\n",
      " * Prec@1 15.625 Prec@5 37.074\n",
      " * Prec@1 15.602 Prec@5 37.030\n",
      " * Prec@1 15.625 Prec@5 37.127\n",
      " * Prec@1 15.602 Prec@5 37.315\n",
      " * Prec@1 15.579 Prec@5 37.316\n",
      " * Prec@1 15.511 Prec@5 37.272\n",
      " * Prec@1 15.534 Prec@5 37.183\n",
      " * Prec@1 15.513 Prec@5 37.095\n",
      " * Prec@1 15.491 Prec@5 37.098\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.489 (0.503)\n",
      "\n",
      "Loss 4.2849 (3.9825)\n",
      "\n",
      "Prec@1 12.500 (15.470)\n",
      "\n",
      "Prec@5 18.750 (36.968)\n",
      "\n",
      " * Prec@1 15.470 Prec@5 36.968\n",
      " * Prec@1 15.513 Prec@5 37.021\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1276]\t\\Time 0.512 (0.512)\tData 0.364 (0.364)\tLoss 3.2146 (3.2146)\tPrec@1 25.000 (25.000)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [6][100/1276]\t\\Time 0.500 (0.500)\tData 0.391 (0.399)\tLoss 4.0007 (3.7959)\tPrec@1 18.750 (17.698)\tPrec@5 25.000 (40.161)\n",
      "Epoch: [6][200/1276]\t\\Time 0.411 (0.499)\tData 0.341 (0.398)\tLoss 3.6686 (3.7888)\tPrec@1 31.250 (17.910)\tPrec@5 43.750 (41.169)\n",
      "Epoch: [6][300/1276]\t\\Time 0.503 (0.499)\tData 0.393 (0.398)\tLoss 3.6209 (3.7941)\tPrec@1 18.750 (18.231)\tPrec@5 37.500 (41.424)\n",
      "Epoch: [6][400/1276]\t\\Time 0.492 (0.499)\tData 0.421 (0.398)\tLoss 3.6516 (3.7961)\tPrec@1 25.000 (18.080)\tPrec@5 37.500 (41.599)\n",
      "Epoch: [6][500/1276]\t\\Time 0.544 (0.501)\tData 0.433 (0.400)\tLoss 4.1456 (3.7926)\tPrec@1 12.500 (17.864)\tPrec@5 43.750 (41.629)\n",
      "Epoch: [6][600/1276]\t\\Time 0.554 (0.501)\tData 0.451 (0.399)\tLoss 3.9839 (3.7972)\tPrec@1 12.500 (17.689)\tPrec@5 25.000 (41.577)\n",
      "Epoch: [6][700/1276]\t\\Time 0.500 (0.501)\tData 0.401 (0.399)\tLoss 4.0140 (3.8085)\tPrec@1 6.250 (17.350)\tPrec@5 37.500 (41.298)\n",
      "Epoch: [6][800/1276]\t\\Time 0.488 (0.501)\tData 0.414 (0.399)\tLoss 3.3263 (3.8127)\tPrec@1 12.500 (17.322)\tPrec@5 56.250 (41.323)\n",
      "Epoch: [6][900/1276]\t\\Time 0.503 (0.501)\tData 0.384 (0.399)\tLoss 3.7462 (3.8102)\tPrec@1 12.500 (17.321)\tPrec@5 37.500 (41.329)\n",
      "Epoch: [6][1000/1276]\t\\Time 0.541 (0.501)\tData 0.431 (0.399)\tLoss 4.3636 (3.8045)\tPrec@1 6.250 (17.308)\tPrec@5 25.000 (41.496)\n",
      "Epoch: [6][1100/1276]\t\\Time 0.426 (0.501)\tData 0.350 (0.399)\tLoss 4.3744 (3.8036)\tPrec@1 18.750 (17.461)\tPrec@5 43.750 (41.627)\n",
      "Epoch: [6][1200/1276]\t\\Time 0.531 (0.502)\tData 0.420 (0.399)\tLoss 3.0682 (3.7980)\tPrec@1 31.250 (17.574)\tPrec@5 62.500 (41.684)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.436 (0.436)\n",
      "\n",
      "Loss 4.0306 (4.0306)\n",
      "\n",
      "Prec@1 12.500 (12.500)\n",
      "\n",
      "Prec@5 37.500 (37.500)\n",
      "\n",
      " * Prec@1 12.500 Prec@5 37.500\n",
      " * Prec@1 21.875 Prec@5 43.750\n",
      " * Prec@1 16.667 Prec@5 37.500\n",
      " * Prec@1 15.625 Prec@5 35.938\n",
      " * Prec@1 12.500 Prec@5 38.750\n",
      " * Prec@1 13.542 Prec@5 36.458\n",
      " * Prec@1 16.071 Prec@5 38.393\n",
      " * Prec@1 17.188 Prec@5 39.844\n",
      " * Prec@1 16.667 Prec@5 38.889\n",
      " * Prec@1 16.875 Prec@5 39.375\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.485 (0.496)\n",
      "\n",
      "Loss 4.0667 (3.7924)\n",
      "\n",
      "Prec@1 25.000 (17.614)\n",
      "\n",
      "Prec@5 43.750 (39.773)\n",
      "\n",
      " * Prec@1 17.614 Prec@5 39.773\n",
      " * Prec@1 17.188 Prec@5 40.104\n",
      " * Prec@1 17.308 Prec@5 39.423\n",
      " * Prec@1 18.304 Prec@5 40.179\n",
      " * Prec@1 18.333 Prec@5 40.000\n",
      " * Prec@1 17.969 Prec@5 39.453\n",
      " * Prec@1 17.647 Prec@5 40.441\n",
      " * Prec@1 18.056 Prec@5 40.625\n",
      " * Prec@1 19.079 Prec@5 41.776\n",
      " * Prec@1 18.438 Prec@5 40.938\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.506 (0.499)\n",
      "\n",
      "Loss 4.7057 (3.8185)\n",
      "\n",
      "Prec@1 6.250 (17.857)\n",
      "\n",
      "Prec@5 18.750 (39.881)\n",
      "\n",
      " * Prec@1 17.857 Prec@5 39.881\n",
      " * Prec@1 18.182 Prec@5 40.909\n",
      " * Prec@1 18.207 Prec@5 40.489\n",
      " * Prec@1 18.229 Prec@5 40.365\n",
      " * Prec@1 18.250 Prec@5 41.000\n",
      " * Prec@1 18.029 Prec@5 40.385\n",
      " * Prec@1 18.056 Prec@5 40.046\n",
      " * Prec@1 18.080 Prec@5 39.955\n",
      " * Prec@1 17.888 Prec@5 39.871\n",
      " * Prec@1 18.542 Prec@5 40.833\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.510 (0.499)\n",
      "\n",
      "Loss 4.4827 (3.8293)\n",
      "\n",
      "Prec@1 6.250 (18.145)\n",
      "\n",
      "Prec@5 18.750 (40.121)\n",
      "\n",
      " * Prec@1 18.145 Prec@5 40.121\n",
      " * Prec@1 18.359 Prec@5 39.648\n",
      " * Prec@1 18.371 Prec@5 39.394\n",
      " * Prec@1 18.015 Prec@5 39.522\n",
      " * Prec@1 18.036 Prec@5 39.286\n",
      " * Prec@1 17.708 Prec@5 39.062\n",
      " * Prec@1 17.230 Prec@5 39.020\n",
      " * Prec@1 17.105 Prec@5 39.474\n",
      " * Prec@1 17.308 Prec@5 39.904\n",
      " * Prec@1 17.188 Prec@5 39.688\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.461 (0.502)\n",
      "\n",
      "Loss 3.5223 (3.8479)\n",
      "\n",
      "Prec@1 25.000 (17.378)\n",
      "\n",
      "Prec@5 56.250 (40.091)\n",
      "\n",
      " * Prec@1 17.378 Prec@5 40.091\n",
      " * Prec@1 17.560 Prec@5 40.327\n",
      " * Prec@1 17.587 Prec@5 40.116\n",
      " * Prec@1 17.898 Prec@5 40.483\n",
      " * Prec@1 17.778 Prec@5 40.417\n",
      " * Prec@1 17.799 Prec@5 40.353\n",
      " * Prec@1 17.819 Prec@5 40.559\n",
      " * Prec@1 17.708 Prec@5 40.104\n",
      " * Prec@1 17.730 Prec@5 40.051\n",
      " * Prec@1 17.625 Prec@5 40.000\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.524 (0.501)\n",
      "\n",
      "Loss 2.8365 (3.8972)\n",
      "\n",
      "Prec@1 31.250 (17.892)\n",
      "\n",
      "Prec@5 75.000 (40.686)\n",
      "\n",
      " * Prec@1 17.892 Prec@5 40.686\n",
      " * Prec@1 17.668 Prec@5 40.505\n",
      " * Prec@1 17.689 Prec@5 40.330\n",
      " * Prec@1 17.824 Prec@5 40.741\n",
      " * Prec@1 17.727 Prec@5 40.568\n",
      " * Prec@1 17.522 Prec@5 40.402\n",
      " * Prec@1 17.434 Prec@5 40.351\n",
      " * Prec@1 17.780 Prec@5 40.625\n",
      " * Prec@1 17.797 Prec@5 40.784\n",
      " * Prec@1 17.604 Prec@5 40.521\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.452 (0.501)\n",
      "\n",
      "Loss 3.5942 (3.8928)\n",
      "\n",
      "Prec@1 37.500 (17.930)\n",
      "\n",
      "Prec@5 43.750 (40.574)\n",
      "\n",
      " * Prec@1 17.930 Prec@5 40.574\n",
      " * Prec@1 17.944 Prec@5 40.524\n",
      " * Prec@1 18.056 Prec@5 40.675\n",
      " * Prec@1 18.359 Prec@5 41.016\n",
      " * Prec@1 18.365 Prec@5 41.154\n",
      " * Prec@1 18.371 Prec@5 41.004\n",
      " * Prec@1 18.377 Prec@5 41.045\n",
      " * Prec@1 18.199 Prec@5 40.809\n",
      " * Prec@1 18.116 Prec@5 40.761\n",
      " * Prec@1 18.214 Prec@5 40.625\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.482 (0.504)\n",
      "\n",
      "Loss 4.4696 (3.9078)\n",
      "\n",
      "Prec@1 12.500 (18.134)\n",
      "\n",
      "Prec@5 31.250 (40.493)\n",
      "\n",
      " * Prec@1 18.134 Prec@5 40.493\n",
      " * Prec@1 18.316 Prec@5 40.451\n",
      " * Prec@1 18.408 Prec@5 40.582\n",
      " * Prec@1 18.243 Prec@5 40.372\n",
      " * Prec@1 18.333 Prec@5 40.500\n",
      " * Prec@1 18.174 Prec@5 40.461\n",
      " * Prec@1 18.182 Prec@5 40.422\n",
      " * Prec@1 18.029 Prec@5 40.304\n",
      " * Prec@1 18.117 Prec@5 40.269\n",
      " * Prec@1 18.125 Prec@5 40.312\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.500 (0.504)\n",
      "\n",
      "Loss 4.2961 (3.9234)\n",
      "\n",
      "Prec@1 25.000 (18.210)\n",
      "\n",
      "Prec@5 31.250 (40.201)\n",
      "\n",
      " * Prec@1 18.210 Prec@5 40.201\n",
      " * Prec@1 18.064 Prec@5 39.939\n",
      " * Prec@1 18.072 Prec@5 39.985\n",
      " * Prec@1 17.932 Prec@5 39.807\n",
      " * Prec@1 17.794 Prec@5 39.559\n",
      " * Prec@1 17.805 Prec@5 39.390\n",
      " * Prec@1 17.672 Prec@5 39.368\n",
      " * Prec@1 17.685 Prec@5 39.347\n",
      " * Prec@1 17.837 Prec@5 39.466\n",
      " * Prec@1 17.778 Prec@5 39.653\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.434 (0.503)\n",
      "\n",
      "Loss 3.4824 (3.9294)\n",
      "\n",
      "Prec@1 31.250 (17.926)\n",
      "\n",
      "Prec@5 68.750 (39.973)\n",
      "\n",
      " * Prec@1 17.926 Prec@5 39.973\n",
      " * Prec@1 17.799 Prec@5 39.742\n",
      " * Prec@1 17.742 Prec@5 39.718\n",
      " * Prec@1 17.686 Prec@5 39.761\n",
      " * Prec@1 17.566 Prec@5 39.737\n",
      " * Prec@1 17.578 Prec@5 39.779\n",
      " * Prec@1 17.655 Prec@5 39.948\n",
      " * Prec@1 17.666 Prec@5 39.923\n",
      " * Prec@1 17.677 Prec@5 39.962\n",
      " * Prec@1 17.625 Prec@5 39.750\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.517 (0.503)\n",
      "\n",
      "Loss 3.9615 (3.9390)\n",
      "\n",
      "Prec@1 25.000 (17.698)\n",
      "\n",
      "Prec@5 37.500 (39.728)\n",
      "\n",
      " * Prec@1 17.698 Prec@5 39.728\n",
      " * Prec@1 17.647 Prec@5 39.706\n",
      " * Prec@1 17.597 Prec@5 39.745\n",
      " * Prec@1 17.488 Prec@5 39.784\n",
      " * Prec@1 17.679 Prec@5 39.940\n",
      " * Prec@1 17.630 Prec@5 39.976\n",
      " * Prec@1 17.699 Prec@5 40.070\n",
      " * Prec@1 17.593 Prec@5 40.104\n",
      " * Prec@1 17.661 Prec@5 40.023\n",
      " * Prec@1 17.784 Prec@5 40.284\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.510 (0.503)\n",
      "\n",
      "Loss 2.7959 (3.8959)\n",
      "\n",
      "Prec@1 50.000 (18.074)\n",
      "\n",
      "Prec@5 68.750 (40.541)\n",
      "\n",
      " * Prec@1 18.074 Prec@5 40.541\n",
      " * Prec@1 18.248 Prec@5 40.625\n",
      " * Prec@1 18.142 Prec@5 40.763\n",
      " * Prec@1 18.147 Prec@5 40.789\n",
      " * Prec@1 18.370 Prec@5 40.978\n",
      " * Prec@1 18.481 Prec@5 41.110\n",
      " * Prec@1 18.536 Prec@5 41.079\n",
      " * Prec@1 18.591 Prec@5 41.102\n",
      " * Prec@1 18.487 Prec@5 41.019\n",
      " * Prec@1 18.333 Prec@5 40.833\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.490 (0.502)\n",
      "\n",
      "Loss 3.3063 (3.8769)\n",
      "\n",
      "Prec@1 18.750 (18.337)\n",
      "\n",
      "Prec@5 68.750 (41.064)\n",
      "\n",
      " * Prec@1 18.337 Prec@5 41.064\n",
      " * Prec@1 18.340 Prec@5 41.189\n",
      " * Prec@1 18.496 Prec@5 41.463\n",
      " * Prec@1 18.448 Prec@5 41.431\n",
      " * Prec@1 18.350 Prec@5 41.350\n",
      " * Prec@1 18.403 Prec@5 41.567\n",
      " * Prec@1 18.307 Prec@5 41.535\n",
      " * Prec@1 18.311 Prec@5 41.650\n",
      " * Prec@1 18.459 Prec@5 41.812\n",
      " * Prec@1 18.413 Prec@5 41.731\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.563 (0.502)\n",
      "\n",
      "Loss 4.2036 (3.8599)\n",
      "\n",
      "Prec@1 6.250 (18.321)\n",
      "\n",
      "Prec@5 37.500 (41.698)\n",
      "\n",
      " * Prec@1 18.321 Prec@5 41.698\n",
      " * Prec@1 18.277 Prec@5 41.667\n",
      " * Prec@1 18.186 Prec@5 41.635\n",
      " * Prec@1 18.144 Prec@5 41.744\n",
      " * Prec@1 18.102 Prec@5 41.713\n",
      " * Prec@1 18.061 Prec@5 41.820\n",
      " * Prec@1 17.974 Prec@5 41.834\n",
      " * Prec@1 17.980 Prec@5 41.803\n",
      " * Prec@1 17.986 Prec@5 41.772\n",
      " * Prec@1 17.946 Prec@5 41.652\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.507 (0.501)\n",
      "\n",
      "Loss 4.2131 (3.8635)\n",
      "\n",
      "Prec@1 25.000 (17.996)\n",
      "\n",
      "Prec@5 25.000 (41.534)\n",
      "\n",
      " * Prec@1 17.996 Prec@5 41.534\n",
      " * Prec@1 18.026 Prec@5 41.604\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1276]\t\\Time 0.460 (0.460)\tData 0.349 (0.349)\tLoss 3.6813 (3.6813)\tPrec@1 31.250 (31.250)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [7][100/1276]\t\\Time 0.483 (0.498)\tData 0.383 (0.397)\tLoss 3.5450 (3.5066)\tPrec@1 12.500 (22.463)\tPrec@5 43.750 (48.205)\n",
      "Epoch: [7][200/1276]\t\\Time 0.525 (0.496)\tData 0.403 (0.395)\tLoss 3.9953 (3.4798)\tPrec@1 12.500 (22.730)\tPrec@5 43.750 (48.632)\n",
      "Epoch: [7][300/1276]\t\\Time 0.494 (0.497)\tData 0.393 (0.396)\tLoss 3.7003 (3.4954)\tPrec@1 18.750 (22.778)\tPrec@5 50.000 (48.505)\n",
      "Epoch: [7][400/1276]\t\\Time 0.463 (0.499)\tData 0.381 (0.397)\tLoss 3.7365 (3.5126)\tPrec@1 12.500 (22.085)\tPrec@5 31.250 (47.974)\n",
      "Epoch: [7][500/1276]\t\\Time 0.506 (0.499)\tData 0.388 (0.398)\tLoss 4.3190 (3.5273)\tPrec@1 12.500 (22.206)\tPrec@5 37.500 (47.480)\n",
      "Epoch: [7][600/1276]\t\\Time 0.470 (0.500)\tData 0.392 (0.398)\tLoss 4.1120 (3.5401)\tPrec@1 18.750 (21.932)\tPrec@5 31.250 (47.327)\n",
      "Epoch: [7][700/1276]\t\\Time 0.519 (0.500)\tData 0.401 (0.399)\tLoss 3.0383 (3.5482)\tPrec@1 25.000 (21.969)\tPrec@5 50.000 (47.138)\n",
      "Epoch: [7][800/1276]\t\\Time 0.560 (0.500)\tData 0.451 (0.399)\tLoss 3.3509 (3.5543)\tPrec@1 12.500 (21.855)\tPrec@5 50.000 (47.058)\n",
      "Epoch: [7][900/1276]\t\\Time 0.461 (0.500)\tData 0.371 (0.399)\tLoss 3.5980 (3.5464)\tPrec@1 12.500 (21.996)\tPrec@5 43.750 (47.232)\n",
      "Epoch: [7][1000/1276]\t\\Time 0.523 (0.501)\tData 0.412 (0.399)\tLoss 2.7644 (3.5460)\tPrec@1 43.750 (21.991)\tPrec@5 75.000 (47.253)\n",
      "Epoch: [7][1100/1276]\t\\Time 0.481 (0.501)\tData 0.360 (0.399)\tLoss 3.7292 (3.5471)\tPrec@1 25.000 (22.048)\tPrec@5 37.500 (47.196)\n",
      "Epoch: [7][1200/1276]\t\\Time 0.483 (0.501)\tData 0.414 (0.399)\tLoss 4.0391 (3.5537)\tPrec@1 18.750 (22.018)\tPrec@5 31.250 (46.997)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.458 (0.458)\n",
      "\n",
      "Loss 4.0553 (4.0553)\n",
      "\n",
      "Prec@1 6.250 (6.250)\n",
      "\n",
      "Prec@5 43.750 (43.750)\n",
      "\n",
      " * Prec@1 6.250 Prec@5 43.750\n",
      " * Prec@1 18.750 Prec@5 50.000\n",
      " * Prec@1 20.833 Prec@5 47.917\n",
      " * Prec@1 21.875 Prec@5 50.000\n",
      " * Prec@1 20.000 Prec@5 50.000\n",
      " * Prec@1 19.792 Prec@5 47.917\n",
      " * Prec@1 21.429 Prec@5 48.214\n",
      " * Prec@1 21.094 Prec@5 46.094\n",
      " * Prec@1 20.139 Prec@5 46.528\n",
      " * Prec@1 18.125 Prec@5 46.875\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.463 (0.494)\n",
      "\n",
      "Loss 3.5392 (3.6687)\n",
      "\n",
      "Prec@1 25.000 (18.750)\n",
      "\n",
      "Prec@5 62.500 (48.295)\n",
      "\n",
      " * Prec@1 18.750 Prec@5 48.295\n",
      " * Prec@1 19.271 Prec@5 48.958\n",
      " * Prec@1 19.712 Prec@5 47.596\n",
      " * Prec@1 20.089 Prec@5 48.661\n",
      " * Prec@1 20.000 Prec@5 48.333\n",
      " * Prec@1 19.531 Prec@5 47.656\n",
      " * Prec@1 19.853 Prec@5 48.162\n",
      " * Prec@1 19.792 Prec@5 48.264\n",
      " * Prec@1 20.395 Prec@5 49.342\n",
      " * Prec@1 20.000 Prec@5 48.125\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.501 (0.493)\n",
      "\n",
      "Loss 4.5847 (3.6958)\n",
      "\n",
      "Prec@1 6.250 (19.345)\n",
      "\n",
      "Prec@5 37.500 (47.619)\n",
      "\n",
      " * Prec@1 19.345 Prec@5 47.619\n",
      " * Prec@1 19.034 Prec@5 48.580\n",
      " * Prec@1 19.565 Prec@5 48.370\n",
      " * Prec@1 20.052 Prec@5 48.177\n",
      " * Prec@1 20.500 Prec@5 48.750\n",
      " * Prec@1 19.952 Prec@5 48.317\n",
      " * Prec@1 19.907 Prec@5 48.148\n",
      " * Prec@1 20.089 Prec@5 47.991\n",
      " * Prec@1 20.043 Prec@5 47.629\n",
      " * Prec@1 20.000 Prec@5 48.125\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.522 (0.497)\n",
      "\n",
      "Loss 4.1430 (3.6792)\n",
      "\n",
      "Prec@1 12.500 (19.758)\n",
      "\n",
      "Prec@5 31.250 (47.581)\n",
      "\n",
      " * Prec@1 19.758 Prec@5 47.581\n",
      " * Prec@1 19.727 Prec@5 47.266\n",
      " * Prec@1 19.508 Prec@5 47.159\n",
      " * Prec@1 19.669 Prec@5 47.426\n",
      " * Prec@1 19.286 Prec@5 47.143\n",
      " * Prec@1 19.097 Prec@5 47.049\n",
      " * Prec@1 18.750 Prec@5 46.791\n",
      " * Prec@1 18.750 Prec@5 46.711\n",
      " * Prec@1 19.231 Prec@5 47.276\n",
      " * Prec@1 19.219 Prec@5 47.031\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.451 (0.497)\n",
      "\n",
      "Loss 3.5011 (3.7021)\n",
      "\n",
      "Prec@1 18.750 (19.207)\n",
      "\n",
      "Prec@5 43.750 (46.951)\n",
      "\n",
      " * Prec@1 19.207 Prec@5 46.951\n",
      " * Prec@1 19.048 Prec@5 47.024\n",
      " * Prec@1 19.041 Prec@5 46.657\n",
      " * Prec@1 19.176 Prec@5 46.591\n",
      " * Prec@1 18.750 Prec@5 45.972\n",
      " * Prec@1 18.750 Prec@5 45.516\n",
      " * Prec@1 19.282 Prec@5 46.011\n",
      " * Prec@1 19.010 Prec@5 45.443\n",
      " * Prec@1 19.133 Prec@5 45.536\n",
      " * Prec@1 19.250 Prec@5 45.500\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.487 (0.498)\n",
      "\n",
      "Loss 2.8694 (3.7229)\n",
      "\n",
      "Prec@1 43.750 (19.730)\n",
      "\n",
      "Prec@5 56.250 (45.711)\n",
      "\n",
      " * Prec@1 19.730 Prec@5 45.711\n",
      " * Prec@1 19.471 Prec@5 45.312\n",
      " * Prec@1 19.575 Prec@5 45.165\n",
      " * Prec@1 19.560 Prec@5 45.255\n",
      " * Prec@1 19.432 Prec@5 45.227\n",
      " * Prec@1 19.420 Prec@5 45.089\n",
      " * Prec@1 19.518 Prec@5 45.066\n",
      " * Prec@1 19.828 Prec@5 45.151\n",
      " * Prec@1 20.021 Prec@5 45.233\n",
      " * Prec@1 20.000 Prec@5 45.000\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.481 (0.499)\n",
      "\n",
      "Loss 3.4939 (3.7212)\n",
      "\n",
      "Prec@1 37.500 (20.287)\n",
      "\n",
      "Prec@5 56.250 (45.184)\n",
      "\n",
      " * Prec@1 20.287 Prec@5 45.184\n",
      " * Prec@1 20.565 Prec@5 45.262\n",
      " * Prec@1 20.437 Prec@5 45.139\n",
      " * Prec@1 20.605 Prec@5 45.312\n",
      " * Prec@1 20.865 Prec@5 45.577\n",
      " * Prec@1 20.833 Prec@5 45.265\n",
      " * Prec@1 20.896 Prec@5 45.243\n",
      " * Prec@1 20.680 Prec@5 44.945\n",
      " * Prec@1 20.562 Prec@5 44.837\n",
      " * Prec@1 20.714 Prec@5 44.732\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.499 (0.502)\n",
      "\n",
      "Loss 4.2358 (3.7533)\n",
      "\n",
      "Prec@1 12.500 (20.599)\n",
      "\n",
      "Prec@5 37.500 (44.630)\n",
      "\n",
      " * Prec@1 20.599 Prec@5 44.630\n",
      " * Prec@1 20.573 Prec@5 44.618\n",
      " * Prec@1 20.634 Prec@5 44.606\n",
      " * Prec@1 20.524 Prec@5 44.426\n",
      " * Prec@1 20.333 Prec@5 44.333\n",
      " * Prec@1 20.148 Prec@5 43.997\n",
      " * Prec@1 20.292 Prec@5 43.912\n",
      " * Prec@1 20.112 Prec@5 43.750\n",
      " * Prec@1 20.174 Prec@5 43.829\n",
      " * Prec@1 20.078 Prec@5 43.516\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.524 (0.503)\n",
      "\n",
      "Loss 3.9959 (3.7871)\n",
      "\n",
      "Prec@1 12.500 (19.985)\n",
      "\n",
      "Prec@5 37.500 (43.441)\n",
      "\n",
      " * Prec@1 19.985 Prec@5 43.441\n",
      " * Prec@1 19.817 Prec@5 43.140\n",
      " * Prec@1 19.880 Prec@5 43.072\n",
      " * Prec@1 19.940 Prec@5 43.080\n",
      " * Prec@1 19.926 Prec@5 43.015\n",
      " * Prec@1 19.985 Prec@5 43.169\n",
      " * Prec@1 19.971 Prec@5 43.319\n",
      " * Prec@1 19.957 Prec@5 43.395\n",
      " * Prec@1 20.084 Prec@5 43.680\n",
      " * Prec@1 20.069 Prec@5 43.750\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.471 (0.503)\n",
      "\n",
      "Loss 3.6968 (3.7780)\n",
      "\n",
      "Prec@1 12.500 (19.986)\n",
      "\n",
      "Prec@5 37.500 (43.681)\n",
      "\n",
      " * Prec@1 19.986 Prec@5 43.681\n",
      " * Prec@1 19.905 Prec@5 43.614\n",
      " * Prec@1 19.960 Prec@5 43.548\n",
      " * Prec@1 19.947 Prec@5 43.750\n",
      " * Prec@1 20.000 Prec@5 43.750\n",
      " * Prec@1 20.052 Prec@5 43.750\n",
      " * Prec@1 20.039 Prec@5 43.879\n",
      " * Prec@1 20.089 Prec@5 43.814\n",
      " * Prec@1 20.076 Prec@5 43.876\n",
      " * Prec@1 20.000 Prec@5 43.812\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.522 (0.503)\n",
      "\n",
      "Loss 4.1088 (3.7815)\n",
      "\n",
      "Prec@1 6.250 (19.864)\n",
      "\n",
      "Prec@5 43.750 (43.812)\n",
      "\n",
      " * Prec@1 19.864 Prec@5 43.812\n",
      " * Prec@1 19.730 Prec@5 43.934\n",
      " * Prec@1 19.782 Prec@5 44.053\n",
      " * Prec@1 19.952 Prec@5 44.171\n",
      " * Prec@1 20.000 Prec@5 44.464\n",
      " * Prec@1 19.988 Prec@5 44.517\n",
      " * Prec@1 20.152 Prec@5 44.626\n",
      " * Prec@1 20.197 Prec@5 44.676\n",
      " * Prec@1 20.183 Prec@5 44.553\n",
      " * Prec@1 20.398 Prec@5 44.943\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.570 (0.504)\n",
      "\n",
      "Loss 2.8546 (3.7364)\n",
      "\n",
      "Prec@1 37.500 (20.552)\n",
      "\n",
      "Prec@5 62.500 (45.101)\n",
      "\n",
      " * Prec@1 20.552 Prec@5 45.101\n",
      " * Prec@1 20.536 Prec@5 45.089\n",
      " * Prec@1 20.575 Prec@5 45.188\n",
      " * Prec@1 20.504 Prec@5 45.230\n",
      " * Prec@1 20.543 Prec@5 45.326\n",
      " * Prec@1 20.636 Prec@5 45.366\n",
      " * Prec@1 20.620 Prec@5 45.299\n",
      " * Prec@1 20.657 Prec@5 45.339\n",
      " * Prec@1 20.536 Prec@5 45.168\n",
      " * Prec@1 20.469 Prec@5 45.000\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.473 (0.503)\n",
      "\n",
      "Loss 3.4748 (3.7302)\n",
      "\n",
      "Prec@1 12.500 (20.403)\n",
      "\n",
      "Prec@5 56.250 (45.093)\n",
      "\n",
      " * Prec@1 20.403 Prec@5 45.093\n",
      " * Prec@1 20.492 Prec@5 45.236\n",
      " * Prec@1 20.478 Prec@5 45.325\n",
      " * Prec@1 20.464 Prec@5 45.262\n",
      " * Prec@1 20.550 Prec@5 45.200\n",
      " * Prec@1 20.585 Prec@5 45.288\n",
      " * Prec@1 20.522 Prec@5 45.374\n",
      " * Prec@1 20.410 Prec@5 45.312\n",
      " * Prec@1 20.494 Prec@5 45.494\n",
      " * Prec@1 20.433 Prec@5 45.529\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.529 (0.504)\n",
      "\n",
      "Loss 4.1484 (3.7181)\n",
      "\n",
      "Prec@1 18.750 (20.420)\n",
      "\n",
      "Prec@5 37.500 (45.468)\n",
      "\n",
      " * Prec@1 20.420 Prec@5 45.468\n",
      " * Prec@1 20.360 Prec@5 45.265\n",
      " * Prec@1 20.395 Prec@5 45.301\n",
      " * Prec@1 20.429 Prec@5 45.289\n",
      " * Prec@1 20.370 Prec@5 45.231\n",
      " * Prec@1 20.267 Prec@5 45.267\n",
      " * Prec@1 20.210 Prec@5 45.210\n",
      " * Prec@1 20.199 Prec@5 45.199\n",
      " * Prec@1 20.189 Prec@5 45.144\n",
      " * Prec@1 20.268 Prec@5 45.134\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.494 (0.503)\n",
      "\n",
      "Loss 4.1833 (3.7231)\n",
      "\n",
      "Prec@1 6.250 (20.168)\n",
      "\n",
      "Prec@5 43.750 (45.124)\n",
      "\n",
      " * Prec@1 20.168 Prec@5 45.124\n",
      " * Prec@1 20.229 Prec@5 45.174\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1276]\t\\Time 0.515 (0.515)\tData 0.401 (0.401)\tLoss 2.8219 (2.8219)\tPrec@1 37.500 (37.500)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [8][100/1276]\t\\Time 0.497 (0.498)\tData 0.411 (0.398)\tLoss 2.8405 (3.1546)\tPrec@1 43.750 (28.342)\tPrec@5 62.500 (55.569)\n",
      "Epoch: [8][200/1276]\t\\Time 0.503 (0.497)\tData 0.392 (0.397)\tLoss 3.9344 (3.2526)\tPrec@1 31.250 (27.052)\tPrec@5 37.500 (52.985)\n",
      "Epoch: [8][300/1276]\t\\Time 0.530 (0.498)\tData 0.420 (0.397)\tLoss 3.0075 (3.2528)\tPrec@1 37.500 (26.723)\tPrec@5 56.250 (53.177)\n",
      "Epoch: [8][400/1276]\t\\Time 0.520 (0.498)\tData 0.444 (0.397)\tLoss 3.2344 (3.2658)\tPrec@1 12.500 (26.621)\tPrec@5 50.000 (53.070)\n",
      "Epoch: [8][500/1276]\t\\Time 0.531 (0.498)\tData 0.431 (0.397)\tLoss 3.4465 (3.2775)\tPrec@1 25.000 (26.485)\tPrec@5 56.250 (52.857)\n",
      "Epoch: [8][600/1276]\t\\Time 0.511 (0.498)\tData 0.391 (0.398)\tLoss 2.9272 (3.2834)\tPrec@1 25.000 (26.477)\tPrec@5 62.500 (52.725)\n",
      "Epoch: [8][700/1276]\t\\Time 0.461 (0.498)\tData 0.351 (0.397)\tLoss 3.0045 (3.2729)\tPrec@1 25.000 (26.730)\tPrec@5 56.250 (52.978)\n",
      "Epoch: [8][800/1276]\t\\Time 0.486 (0.498)\tData 0.390 (0.397)\tLoss 3.5915 (3.2699)\tPrec@1 12.500 (26.966)\tPrec@5 43.750 (53.129)\n",
      "Epoch: [8][900/1276]\t\\Time 0.460 (0.498)\tData 0.390 (0.398)\tLoss 3.9053 (3.2678)\tPrec@1 6.250 (27.060)\tPrec@5 43.750 (53.038)\n",
      "Epoch: [8][1000/1276]\t\\Time 0.552 (0.499)\tData 0.452 (0.398)\tLoss 2.8208 (3.2758)\tPrec@1 37.500 (26.842)\tPrec@5 68.750 (52.997)\n",
      "Epoch: [8][1100/1276]\t\\Time 0.533 (0.499)\tData 0.430 (0.398)\tLoss 2.1697 (3.2726)\tPrec@1 62.500 (27.015)\tPrec@5 75.000 (53.026)\n",
      "Epoch: [8][1200/1276]\t\\Time 0.511 (0.500)\tData 0.402 (0.399)\tLoss 3.8232 (3.2782)\tPrec@1 18.750 (26.998)\tPrec@5 43.750 (52.971)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.430 (0.430)\n",
      "\n",
      "Loss 4.0418 (4.0418)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 37.500 (37.500)\n",
      "\n",
      " * Prec@1 0.000 Prec@5 37.500\n",
      " * Prec@1 21.875 Prec@5 43.750\n",
      " * Prec@1 20.833 Prec@5 45.833\n",
      " * Prec@1 21.875 Prec@5 48.438\n",
      " * Prec@1 20.000 Prec@5 48.750\n",
      " * Prec@1 20.833 Prec@5 44.792\n",
      " * Prec@1 22.321 Prec@5 45.536\n",
      " * Prec@1 21.875 Prec@5 45.312\n",
      " * Prec@1 20.833 Prec@5 45.139\n",
      " * Prec@1 20.000 Prec@5 45.000\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.515 (0.491)\n",
      "\n",
      "Loss 3.2272 (3.5505)\n",
      "\n",
      "Prec@1 25.000 (20.455)\n",
      "\n",
      "Prec@5 56.250 (46.023)\n",
      "\n",
      " * Prec@1 20.455 Prec@5 46.023\n",
      " * Prec@1 20.833 Prec@5 47.396\n",
      " * Prec@1 21.635 Prec@5 48.077\n",
      " * Prec@1 22.321 Prec@5 48.214\n",
      " * Prec@1 22.500 Prec@5 48.333\n",
      " * Prec@1 21.484 Prec@5 48.047\n",
      " * Prec@1 22.794 Prec@5 49.265\n",
      " * Prec@1 23.958 Prec@5 50.000\n",
      " * Prec@1 24.342 Prec@5 50.000\n",
      " * Prec@1 23.750 Prec@5 49.375\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.542 (0.494)\n",
      "\n",
      "Loss 4.6770 (3.5624)\n",
      "\n",
      "Prec@1 12.500 (23.214)\n",
      "\n",
      "Prec@5 25.000 (48.214)\n",
      "\n",
      " * Prec@1 23.214 Prec@5 48.214\n",
      " * Prec@1 23.864 Prec@5 49.148\n",
      " * Prec@1 24.185 Prec@5 48.370\n",
      " * Prec@1 24.740 Prec@5 48.958\n",
      " * Prec@1 25.000 Prec@5 49.250\n",
      " * Prec@1 24.519 Prec@5 48.798\n",
      " * Prec@1 24.074 Prec@5 48.611\n",
      " * Prec@1 24.107 Prec@5 48.884\n",
      " * Prec@1 23.491 Prec@5 48.491\n",
      " * Prec@1 23.750 Prec@5 49.167\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.511 (0.497)\n",
      "\n",
      "Loss 4.3916 (3.5545)\n",
      "\n",
      "Prec@1 6.250 (23.185)\n",
      "\n",
      "Prec@5 31.250 (48.589)\n",
      "\n",
      " * Prec@1 23.185 Prec@5 48.589\n",
      " * Prec@1 23.438 Prec@5 48.438\n",
      " * Prec@1 23.295 Prec@5 48.295\n",
      " * Prec@1 22.978 Prec@5 48.346\n",
      " * Prec@1 23.214 Prec@5 48.214\n",
      " * Prec@1 23.438 Prec@5 48.438\n",
      " * Prec@1 23.311 Prec@5 47.804\n",
      " * Prec@1 23.191 Prec@5 48.520\n",
      " * Prec@1 23.237 Prec@5 48.558\n",
      " * Prec@1 22.969 Prec@5 48.438\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.451 (0.497)\n",
      "\n",
      "Loss 4.0093 (3.5738)\n",
      "\n",
      "Prec@1 18.750 (22.866)\n",
      "\n",
      "Prec@5 37.500 (48.171)\n",
      "\n",
      " * Prec@1 22.866 Prec@5 48.171\n",
      " * Prec@1 22.768 Prec@5 48.214\n",
      " * Prec@1 22.820 Prec@5 48.547\n",
      " * Prec@1 23.011 Prec@5 48.722\n",
      " * Prec@1 23.056 Prec@5 48.611\n",
      " * Prec@1 22.962 Prec@5 48.234\n",
      " * Prec@1 22.872 Prec@5 48.404\n",
      " * Prec@1 22.786 Prec@5 48.047\n",
      " * Prec@1 23.087 Prec@5 48.342\n",
      " * Prec@1 22.750 Prec@5 48.125\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.491 (0.497)\n",
      "\n",
      "Loss 2.5735 (3.6140)\n",
      "\n",
      "Prec@1 50.000 (23.284)\n",
      "\n",
      "Prec@5 62.500 (48.407)\n",
      "\n",
      " * Prec@1 23.284 Prec@5 48.407\n",
      " * Prec@1 23.197 Prec@5 48.317\n",
      " * Prec@1 23.113 Prec@5 48.467\n",
      " * Prec@1 23.148 Prec@5 48.495\n",
      " * Prec@1 23.068 Prec@5 48.409\n",
      " * Prec@1 22.991 Prec@5 48.103\n",
      " * Prec@1 23.136 Prec@5 48.246\n",
      " * Prec@1 23.384 Prec@5 48.384\n",
      " * Prec@1 23.305 Prec@5 48.623\n",
      " * Prec@1 23.229 Prec@5 48.542\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.466 (0.497)\n",
      "\n",
      "Loss 3.7234 (3.6036)\n",
      "\n",
      "Prec@1 37.500 (23.463)\n",
      "\n",
      "Prec@5 50.000 (48.566)\n",
      "\n",
      " * Prec@1 23.463 Prec@5 48.566\n",
      " * Prec@1 23.589 Prec@5 48.488\n",
      " * Prec@1 23.512 Prec@5 48.512\n",
      " * Prec@1 23.633 Prec@5 48.730\n",
      " * Prec@1 23.558 Prec@5 48.846\n",
      " * Prec@1 23.295 Prec@5 48.485\n",
      " * Prec@1 23.228 Prec@5 48.601\n",
      " * Prec@1 22.978 Prec@5 48.438\n",
      " * Prec@1 22.917 Prec@5 48.188\n",
      " * Prec@1 22.857 Prec@5 48.125\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.488 (0.499)\n",
      "\n",
      "Loss 4.6616 (3.6368)\n",
      "\n",
      "Prec@1 0.000 (22.535)\n",
      "\n",
      "Prec@5 31.250 (47.887)\n",
      "\n",
      " * Prec@1 22.535 Prec@5 47.887\n",
      " * Prec@1 22.569 Prec@5 47.743\n",
      " * Prec@1 22.603 Prec@5 47.860\n",
      " * Prec@1 22.635 Prec@5 47.804\n",
      " * Prec@1 22.500 Prec@5 47.917\n",
      " * Prec@1 22.451 Prec@5 47.780\n",
      " * Prec@1 22.484 Prec@5 47.646\n",
      " * Prec@1 22.276 Prec@5 47.436\n",
      " * Prec@1 22.152 Prec@5 47.310\n",
      " * Prec@1 21.953 Prec@5 47.031\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.531 (0.501)\n",
      "\n",
      "Loss 4.0713 (3.6652)\n",
      "\n",
      "Prec@1 25.000 (21.991)\n",
      "\n",
      "Prec@5 31.250 (46.836)\n",
      "\n",
      " * Prec@1 21.991 Prec@5 46.836\n",
      " * Prec@1 21.799 Prec@5 46.494\n",
      " * Prec@1 21.762 Prec@5 46.461\n",
      " * Prec@1 21.726 Prec@5 46.280\n",
      " * Prec@1 21.691 Prec@5 46.324\n",
      " * Prec@1 21.584 Prec@5 46.512\n",
      " * Prec@1 21.408 Prec@5 46.408\n",
      " * Prec@1 21.378 Prec@5 46.307\n",
      " * Prec@1 21.559 Prec@5 46.629\n",
      " * Prec@1 21.736 Prec@5 46.597\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.452 (0.502)\n",
      "\n",
      "Loss 3.6390 (3.6693)\n",
      "\n",
      "Prec@1 25.000 (21.772)\n",
      "\n",
      "Prec@5 43.750 (46.566)\n",
      "\n",
      " * Prec@1 21.772 Prec@5 46.566\n",
      " * Prec@1 21.535 Prec@5 46.535\n",
      " * Prec@1 21.505 Prec@5 46.640\n",
      " * Prec@1 21.543 Prec@5 46.742\n",
      " * Prec@1 21.513 Prec@5 46.776\n",
      " * Prec@1 21.419 Prec@5 46.745\n",
      " * Prec@1 21.585 Prec@5 46.907\n",
      " * Prec@1 21.492 Prec@5 46.747\n",
      " * Prec@1 21.591 Prec@5 46.907\n",
      " * Prec@1 21.562 Prec@5 46.750\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.531 (0.503)\n",
      "\n",
      "Loss 4.3284 (3.6758)\n",
      "\n",
      "Prec@1 18.750 (21.535)\n",
      "\n",
      "Prec@5 31.250 (46.597)\n",
      "\n",
      " * Prec@1 21.535 Prec@5 46.597\n",
      " * Prec@1 21.569 Prec@5 46.691\n",
      " * Prec@1 21.663 Prec@5 46.723\n",
      " * Prec@1 21.755 Prec@5 46.755\n",
      " * Prec@1 21.905 Prec@5 46.964\n",
      " * Prec@1 21.934 Prec@5 47.111\n",
      " * Prec@1 21.904 Prec@5 47.255\n",
      " * Prec@1 21.817 Prec@5 47.222\n",
      " * Prec@1 21.846 Prec@5 47.248\n",
      " * Prec@1 21.761 Prec@5 47.330\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.531 (0.502)\n",
      "\n",
      "Loss 2.8929 (3.6348)\n",
      "\n",
      "Prec@1 25.000 (21.791)\n",
      "\n",
      "Prec@5 56.250 (47.410)\n",
      "\n",
      " * Prec@1 21.791 Prec@5 47.410\n",
      " * Prec@1 21.875 Prec@5 47.489\n",
      " * Prec@1 21.847 Prec@5 47.456\n",
      " * Prec@1 21.820 Prec@5 47.423\n",
      " * Prec@1 21.739 Prec@5 47.391\n",
      " * Prec@1 21.713 Prec@5 47.414\n",
      " * Prec@1 21.741 Prec@5 47.436\n",
      " * Prec@1 21.875 Prec@5 47.511\n",
      " * Prec@1 21.849 Prec@5 47.374\n",
      " * Prec@1 21.771 Prec@5 47.240\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.511 (0.503)\n",
      "\n",
      "Loss 2.7360 (3.6213)\n",
      "\n",
      "Prec@1 43.750 (21.952)\n",
      "\n",
      "Prec@5 62.500 (47.366)\n",
      "\n",
      " * Prec@1 21.952 Prec@5 47.366\n",
      " * Prec@1 21.977 Prec@5 47.490\n",
      " * Prec@1 22.104 Prec@5 47.663\n",
      " * Prec@1 22.026 Prec@5 47.480\n",
      " * Prec@1 22.000 Prec@5 47.600\n",
      " * Prec@1 22.123 Prec@5 47.718\n",
      " * Prec@1 22.146 Prec@5 47.687\n",
      " * Prec@1 22.119 Prec@5 47.656\n",
      " * Prec@1 22.190 Prec@5 47.868\n",
      " * Prec@1 22.212 Prec@5 47.933\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.551 (0.503)\n",
      "\n",
      "Loss 4.4090 (3.6122)\n",
      "\n",
      "Prec@1 18.750 (22.185)\n",
      "\n",
      "Prec@5 43.750 (47.901)\n",
      "\n",
      " * Prec@1 22.185 Prec@5 47.901\n",
      " * Prec@1 22.254 Prec@5 48.011\n",
      " * Prec@1 22.180 Prec@5 47.979\n",
      " * Prec@1 22.201 Prec@5 47.948\n",
      " * Prec@1 22.315 Prec@5 48.102\n",
      " * Prec@1 22.426 Prec@5 48.070\n",
      " * Prec@1 22.445 Prec@5 48.084\n",
      " * Prec@1 22.418 Prec@5 48.007\n",
      " * Prec@1 22.392 Prec@5 48.067\n",
      " * Prec@1 22.366 Prec@5 48.036\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.496 (0.502)\n",
      "\n",
      "Loss 4.1029 (3.6103)\n",
      "\n",
      "Prec@1 25.000 (22.385)\n",
      "\n",
      "Prec@5 37.500 (47.961)\n",
      "\n",
      " * Prec@1 22.385 Prec@5 47.961\n",
      " * Prec@1 22.389 Prec@5 48.127\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1276]\t\\Time 0.520 (0.520)\tData 0.390 (0.390)\tLoss 3.5853 (3.5853)\tPrec@1 25.000 (25.000)\tPrec@5 43.750 (43.750)\n",
      "Epoch: [9][100/1276]\t\\Time 0.523 (0.500)\tData 0.422 (0.397)\tLoss 3.2632 (2.9645)\tPrec@1 18.750 (32.054)\tPrec@5 56.250 (60.891)\n",
      "Epoch: [9][200/1276]\t\\Time 0.522 (0.497)\tData 0.422 (0.396)\tLoss 3.1285 (2.9704)\tPrec@1 31.250 (32.369)\tPrec@5 68.750 (59.981)\n",
      "Epoch: [9][300/1276]\t\\Time 0.491 (0.498)\tData 0.411 (0.397)\tLoss 3.1618 (2.9648)\tPrec@1 25.000 (32.724)\tPrec@5 68.750 (60.133)\n",
      "Epoch: [9][400/1276]\t\\Time 0.555 (0.498)\tData 0.444 (0.397)\tLoss 2.4814 (2.9683)\tPrec@1 37.500 (32.700)\tPrec@5 62.500 (60.147)\n",
      "Epoch: [9][500/1276]\t\\Time 0.485 (0.499)\tData 0.374 (0.397)\tLoss 2.3675 (2.9691)\tPrec@1 43.750 (32.473)\tPrec@5 75.000 (60.005)\n",
      "Epoch: [9][600/1276]\t\\Time 0.538 (0.500)\tData 0.423 (0.398)\tLoss 3.3293 (2.9920)\tPrec@1 31.250 (32.144)\tPrec@5 62.500 (59.630)\n",
      "Epoch: [9][700/1276]\t\\Time 0.507 (0.500)\tData 0.396 (0.398)\tLoss 2.7205 (2.9973)\tPrec@1 31.250 (32.231)\tPrec@5 62.500 (59.486)\n",
      "Epoch: [9][800/1276]\t\\Time 0.471 (0.499)\tData 0.369 (0.398)\tLoss 3.1915 (2.9949)\tPrec@1 18.750 (32.296)\tPrec@5 62.500 (59.582)\n",
      "Epoch: [9][900/1276]\t\\Time 0.450 (0.500)\tData 0.380 (0.398)\tLoss 2.7756 (2.9982)\tPrec@1 31.250 (32.464)\tPrec@5 62.500 (59.545)\n",
      "Epoch: [9][1000/1276]\t\\Time 0.470 (0.500)\tData 0.390 (0.398)\tLoss 3.4095 (3.0089)\tPrec@1 18.750 (32.355)\tPrec@5 43.750 (59.303)\n",
      "Epoch: [9][1100/1276]\t\\Time 0.502 (0.500)\tData 0.426 (0.398)\tLoss 2.4357 (2.9970)\tPrec@1 25.000 (32.419)\tPrec@5 75.000 (59.537)\n",
      "Epoch: [9][1200/1276]\t\\Time 0.473 (0.500)\tData 0.369 (0.398)\tLoss 2.6736 (2.9957)\tPrec@1 25.000 (32.327)\tPrec@5 68.750 (59.523)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.494 (0.494)\n",
      "\n",
      "Loss 4.5792 (4.5792)\n",
      "\n",
      "Prec@1 18.750 (18.750)\n",
      "\n",
      "Prec@5 31.250 (31.250)\n",
      "\n",
      " * Prec@1 18.750 Prec@5 31.250\n",
      " * Prec@1 31.250 Prec@5 43.750\n",
      " * Prec@1 29.167 Prec@5 43.750\n",
      " * Prec@1 28.125 Prec@5 46.875\n",
      " * Prec@1 27.500 Prec@5 48.750\n",
      " * Prec@1 28.125 Prec@5 47.917\n",
      " * Prec@1 27.679 Prec@5 49.107\n",
      " * Prec@1 27.344 Prec@5 50.000\n",
      " * Prec@1 26.389 Prec@5 50.000\n",
      " * Prec@1 26.250 Prec@5 51.250\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.501 (0.497)\n",
      "\n",
      "Loss 3.0831 (3.4783)\n",
      "\n",
      "Prec@1 25.000 (26.136)\n",
      "\n",
      "Prec@5 62.500 (52.273)\n",
      "\n",
      " * Prec@1 26.136 Prec@5 52.273\n",
      " * Prec@1 26.562 Prec@5 52.083\n",
      " * Prec@1 26.923 Prec@5 51.442\n",
      " * Prec@1 27.232 Prec@5 52.679\n",
      " * Prec@1 27.083 Prec@5 52.500\n",
      " * Prec@1 26.562 Prec@5 51.562\n",
      " * Prec@1 26.103 Prec@5 53.309\n",
      " * Prec@1 26.736 Prec@5 53.472\n",
      " * Prec@1 27.632 Prec@5 55.592\n",
      " * Prec@1 26.250 Prec@5 53.750\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.523 (0.496)\n",
      "\n",
      "Loss 4.9327 (3.4523)\n",
      "\n",
      "Prec@1 6.250 (25.298)\n",
      "\n",
      "Prec@5 25.000 (52.381)\n",
      "\n",
      " * Prec@1 25.298 Prec@5 52.381\n",
      " * Prec@1 25.000 Prec@5 52.557\n",
      " * Prec@1 25.000 Prec@5 52.446\n",
      " * Prec@1 24.740 Prec@5 52.344\n",
      " * Prec@1 24.750 Prec@5 52.750\n",
      " * Prec@1 25.240 Prec@5 52.644\n",
      " * Prec@1 25.231 Prec@5 52.083\n",
      " * Prec@1 25.223 Prec@5 51.786\n",
      " * Prec@1 24.784 Prec@5 51.724\n",
      " * Prec@1 24.792 Prec@5 51.667\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.510 (0.497)\n",
      "\n",
      "Loss 4.5233 (3.4716)\n",
      "\n",
      "Prec@1 12.500 (24.395)\n",
      "\n",
      "Prec@5 43.750 (51.411)\n",
      "\n",
      " * Prec@1 24.395 Prec@5 51.411\n",
      " * Prec@1 24.414 Prec@5 50.977\n",
      " * Prec@1 24.621 Prec@5 51.326\n",
      " * Prec@1 25.000 Prec@5 51.654\n",
      " * Prec@1 24.821 Prec@5 51.250\n",
      " * Prec@1 25.000 Prec@5 51.736\n",
      " * Prec@1 25.000 Prec@5 51.520\n",
      " * Prec@1 25.000 Prec@5 51.316\n",
      " * Prec@1 25.160 Prec@5 51.442\n",
      " * Prec@1 25.156 Prec@5 51.406\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.456 (0.499)\n",
      "\n",
      "Loss 3.5529 (3.5129)\n",
      "\n",
      "Prec@1 31.250 (25.305)\n",
      "\n",
      "Prec@5 50.000 (51.372)\n",
      "\n",
      " * Prec@1 25.305 Prec@5 51.372\n",
      " * Prec@1 25.446 Prec@5 51.190\n",
      " * Prec@1 25.727 Prec@5 51.453\n",
      " * Prec@1 25.852 Prec@5 51.705\n",
      " * Prec@1 25.694 Prec@5 51.667\n",
      " * Prec@1 25.679 Prec@5 51.766\n",
      " * Prec@1 25.798 Prec@5 51.995\n",
      " * Prec@1 25.911 Prec@5 51.823\n",
      " * Prec@1 25.893 Prec@5 51.786\n",
      " * Prec@1 25.750 Prec@5 51.375\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.472 (0.496)\n",
      "\n",
      "Loss 1.9567 (3.5202)\n",
      "\n",
      "Prec@1 43.750 (26.103)\n",
      "\n",
      "Prec@5 87.500 (52.083)\n",
      "\n",
      " * Prec@1 26.103 Prec@5 52.083\n",
      " * Prec@1 25.962 Prec@5 51.923\n",
      " * Prec@1 26.179 Prec@5 51.887\n",
      " * Prec@1 26.157 Prec@5 52.083\n",
      " * Prec@1 26.250 Prec@5 52.159\n",
      " * Prec@1 26.228 Prec@5 52.009\n",
      " * Prec@1 25.987 Prec@5 52.193\n",
      " * Prec@1 26.401 Prec@5 52.478\n",
      " * Prec@1 26.483 Prec@5 52.542\n",
      " * Prec@1 26.250 Prec@5 52.500\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.471 (0.496)\n",
      "\n",
      "Loss 3.6298 (3.5292)\n",
      "\n",
      "Prec@1 37.500 (26.434)\n",
      "\n",
      "Prec@5 43.750 (52.357)\n",
      "\n",
      " * Prec@1 26.434 Prec@5 52.357\n",
      " * Prec@1 26.512 Prec@5 52.419\n",
      " * Prec@1 26.290 Prec@5 52.579\n",
      " * Prec@1 26.562 Prec@5 53.027\n",
      " * Prec@1 26.635 Prec@5 53.173\n",
      " * Prec@1 26.420 Prec@5 52.936\n",
      " * Prec@1 26.306 Prec@5 52.985\n",
      " * Prec@1 26.011 Prec@5 52.757\n",
      " * Prec@1 25.815 Prec@5 52.446\n",
      " * Prec@1 25.893 Prec@5 52.232\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.481 (0.499)\n",
      "\n",
      "Loss 4.2535 (3.5586)\n",
      "\n",
      "Prec@1 6.250 (25.616)\n",
      "\n",
      "Prec@5 50.000 (52.201)\n",
      "\n",
      " * Prec@1 25.616 Prec@5 52.201\n",
      " * Prec@1 25.521 Prec@5 52.170\n",
      " * Prec@1 25.514 Prec@5 52.226\n",
      " * Prec@1 25.338 Prec@5 52.196\n",
      " * Prec@1 25.250 Prec@5 52.083\n",
      " * Prec@1 25.082 Prec@5 51.891\n",
      " * Prec@1 25.325 Prec@5 51.867\n",
      " * Prec@1 25.160 Prec@5 52.003\n",
      " * Prec@1 25.158 Prec@5 51.978\n",
      " * Prec@1 25.078 Prec@5 51.797\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.538 (0.500)\n",
      "\n",
      "Loss 4.1121 (3.5917)\n",
      "\n",
      "Prec@1 25.000 (25.077)\n",
      "\n",
      "Prec@5 43.750 (51.698)\n",
      "\n",
      " * Prec@1 25.077 Prec@5 51.698\n",
      " * Prec@1 25.152 Prec@5 51.677\n",
      " * Prec@1 25.151 Prec@5 51.581\n",
      " * Prec@1 25.074 Prec@5 51.488\n",
      " * Prec@1 25.074 Prec@5 51.324\n",
      " * Prec@1 24.927 Prec@5 51.381\n",
      " * Prec@1 25.000 Prec@5 51.437\n",
      " * Prec@1 25.000 Prec@5 51.420\n",
      " * Prec@1 25.070 Prec@5 51.615\n",
      " * Prec@1 25.139 Prec@5 51.736\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.450 (0.499)\n",
      "\n",
      "Loss 3.4910 (3.5853)\n",
      "\n",
      "Prec@1 25.000 (25.137)\n",
      "\n",
      "Prec@5 56.250 (51.786)\n",
      "\n",
      " * Prec@1 25.137 Prec@5 51.786\n",
      " * Prec@1 25.068 Prec@5 51.562\n",
      " * Prec@1 25.067 Prec@5 51.546\n",
      " * Prec@1 25.133 Prec@5 51.662\n",
      " * Prec@1 25.066 Prec@5 51.842\n",
      " * Prec@1 25.130 Prec@5 51.823\n",
      " * Prec@1 25.193 Prec@5 52.062\n",
      " * Prec@1 25.191 Prec@5 51.977\n",
      " * Prec@1 25.126 Prec@5 51.894\n",
      " * Prec@1 25.188 Prec@5 51.812\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.563 (0.500)\n",
      "\n",
      "Loss 3.4847 (3.5772)\n",
      "\n",
      "Prec@1 25.000 (25.186)\n",
      "\n",
      "Prec@5 50.000 (51.795)\n",
      "\n",
      " * Prec@1 25.186 Prec@5 51.795\n",
      " * Prec@1 25.123 Prec@5 51.838\n",
      " * Prec@1 25.182 Prec@5 52.002\n",
      " * Prec@1 25.240 Prec@5 52.043\n",
      " * Prec@1 25.417 Prec@5 52.262\n",
      " * Prec@1 25.354 Prec@5 52.358\n",
      " * Prec@1 25.292 Prec@5 52.336\n",
      " * Prec@1 25.405 Prec@5 52.431\n",
      " * Prec@1 25.287 Prec@5 52.466\n",
      " * Prec@1 25.511 Prec@5 52.727\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.532 (0.500)\n",
      "\n",
      "Loss 2.9016 (3.5202)\n",
      "\n",
      "Prec@1 37.500 (25.619)\n",
      "\n",
      "Prec@5 68.750 (52.872)\n",
      "\n",
      " * Prec@1 25.619 Prec@5 52.872\n",
      " * Prec@1 25.614 Prec@5 52.902\n",
      " * Prec@1 25.885 Prec@5 53.042\n",
      " * Prec@1 25.932 Prec@5 52.961\n",
      " * Prec@1 25.924 Prec@5 52.880\n",
      " * Prec@1 26.078 Prec@5 52.963\n",
      " * Prec@1 26.068 Prec@5 52.885\n",
      " * Prec@1 25.953 Prec@5 53.019\n",
      " * Prec@1 25.840 Prec@5 52.994\n",
      " * Prec@1 25.781 Prec@5 52.917\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.492 (0.500)\n",
      "\n",
      "Loss 3.0617 (3.5003)\n",
      "\n",
      "Prec@1 31.250 (25.826)\n",
      "\n",
      "Prec@5 68.750 (53.048)\n",
      "\n",
      " * Prec@1 25.826 Prec@5 53.048\n",
      " * Prec@1 25.871 Prec@5 53.125\n",
      " * Prec@1 26.169 Prec@5 53.354\n",
      " * Prec@1 26.058 Prec@5 53.226\n",
      " * Prec@1 26.000 Prec@5 53.300\n",
      " * Prec@1 25.942 Prec@5 53.373\n",
      " * Prec@1 25.886 Prec@5 53.297\n",
      " * Prec@1 25.781 Prec@5 53.125\n",
      " * Prec@1 25.872 Prec@5 53.295\n",
      " * Prec@1 25.913 Prec@5 53.365\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.535 (0.501)\n",
      "\n",
      "Loss 3.7916 (3.4915)\n",
      "\n",
      "Prec@1 25.000 (25.906)\n",
      "\n",
      "Prec@5 50.000 (53.340)\n",
      "\n",
      " * Prec@1 25.906 Prec@5 53.340\n",
      " * Prec@1 25.994 Prec@5 53.551\n",
      " * Prec@1 25.987 Prec@5 53.524\n",
      " * Prec@1 26.119 Prec@5 53.591\n",
      " * Prec@1 26.157 Prec@5 53.657\n",
      " * Prec@1 26.103 Prec@5 53.676\n",
      " * Prec@1 26.095 Prec@5 53.650\n",
      " * Prec@1 26.132 Prec@5 53.668\n",
      " * Prec@1 26.169 Prec@5 53.732\n",
      " * Prec@1 26.116 Prec@5 53.795\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.474 (0.499)\n",
      "\n",
      "Loss 4.3539 (3.4766)\n",
      "\n",
      "Prec@1 12.500 (26.020)\n",
      "\n",
      "Prec@5 37.500 (53.679)\n",
      "\n",
      " * Prec@1 26.020 Prec@5 53.679\n",
      " * Prec@1 26.047 Prec@5 53.724\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [10][0/1276]\t\\Time 0.560 (0.560)\tData 0.400 (0.400)\tLoss 2.7765 (2.7765)\tPrec@1 43.750 (43.750)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [10][100/1276]\t\\Time 0.471 (0.500)\tData 0.394 (0.397)\tLoss 2.5415 (2.5520)\tPrec@1 50.000 (39.913)\tPrec@5 56.250 (68.069)\n",
      "Epoch: [10][200/1276]\t\\Time 0.470 (0.503)\tData 0.370 (0.400)\tLoss 2.9589 (2.5936)\tPrec@1 31.250 (40.019)\tPrec@5 50.000 (66.760)\n",
      "Epoch: [10][300/1276]\t\\Time 0.531 (0.499)\tData 0.400 (0.398)\tLoss 3.4996 (2.6200)\tPrec@1 25.000 (38.787)\tPrec@5 62.500 (66.570)\n",
      "Epoch: [10][400/1276]\t\\Time 0.542 (0.500)\tData 0.432 (0.398)\tLoss 2.2464 (2.6298)\tPrec@1 43.750 (38.435)\tPrec@5 75.000 (66.194)\n",
      "Epoch: [10][500/1276]\t\\Time 0.511 (0.500)\tData 0.401 (0.398)\tLoss 2.9515 (2.6251)\tPrec@1 37.500 (38.560)\tPrec@5 62.500 (66.342)\n",
      "Epoch: [10][600/1276]\t\\Time 0.480 (0.500)\tData 0.370 (0.398)\tLoss 3.1548 (2.6332)\tPrec@1 37.500 (38.446)\tPrec@5 56.250 (66.140)\n",
      "Epoch: [10][700/1276]\t\\Time 0.481 (0.499)\tData 0.360 (0.398)\tLoss 3.0273 (2.6366)\tPrec@1 31.250 (38.392)\tPrec@5 50.000 (66.031)\n",
      "Epoch: [10][800/1276]\t\\Time 0.510 (0.499)\tData 0.410 (0.398)\tLoss 2.6884 (2.6416)\tPrec@1 37.500 (38.553)\tPrec@5 62.500 (65.902)\n",
      "Epoch: [10][900/1276]\t\\Time 0.496 (0.499)\tData 0.381 (0.398)\tLoss 2.5099 (2.6485)\tPrec@1 31.250 (38.436)\tPrec@5 68.750 (65.906)\n",
      "Epoch: [10][1000/1276]\t\\Time 0.562 (0.500)\tData 0.452 (0.398)\tLoss 2.6405 (2.6560)\tPrec@1 37.500 (38.418)\tPrec@5 62.500 (65.815)\n",
      "Epoch: [10][1100/1276]\t\\Time 0.411 (0.500)\tData 0.296 (0.399)\tLoss 2.5944 (2.6585)\tPrec@1 43.750 (38.448)\tPrec@5 62.500 (65.866)\n",
      "Epoch: [10][1200/1276]\t\\Time 0.521 (0.501)\tData 0.403 (0.399)\tLoss 4.4156 (2.6554)\tPrec@1 12.500 (38.530)\tPrec@5 37.500 (65.955)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.435 (0.435)\n",
      "\n",
      "Loss 3.7055 (3.7055)\n",
      "\n",
      "Prec@1 18.750 (18.750)\n",
      "\n",
      "Prec@5 31.250 (31.250)\n",
      "\n",
      " * Prec@1 18.750 Prec@5 31.250\n",
      " * Prec@1 37.500 Prec@5 50.000\n",
      " * Prec@1 31.250 Prec@5 45.833\n",
      " * Prec@1 35.938 Prec@5 51.562\n",
      " * Prec@1 32.500 Prec@5 51.250\n",
      " * Prec@1 32.292 Prec@5 51.042\n",
      " * Prec@1 33.036 Prec@5 50.893\n",
      " * Prec@1 32.812 Prec@5 52.344\n",
      " * Prec@1 34.028 Prec@5 52.778\n",
      " * Prec@1 33.125 Prec@5 55.000\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.480 (0.491)\n",
      "\n",
      "Loss 3.1107 (3.1508)\n",
      "\n",
      "Prec@1 31.250 (32.955)\n",
      "\n",
      "Prec@5 62.500 (55.682)\n",
      "\n",
      " * Prec@1 32.955 Prec@5 55.682\n",
      " * Prec@1 33.333 Prec@5 57.292\n",
      " * Prec@1 32.692 Prec@5 57.212\n",
      " * Prec@1 33.929 Prec@5 59.375\n",
      " * Prec@1 33.333 Prec@5 58.750\n",
      " * Prec@1 33.203 Prec@5 57.812\n",
      " * Prec@1 33.824 Prec@5 59.191\n",
      " * Prec@1 33.333 Prec@5 60.069\n",
      " * Prec@1 34.211 Prec@5 60.526\n",
      " * Prec@1 34.062 Prec@5 59.375\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.570 (0.497)\n",
      "\n",
      "Loss 3.9214 (3.0162)\n",
      "\n",
      "Prec@1 25.000 (33.631)\n",
      "\n",
      "Prec@5 50.000 (58.929)\n",
      "\n",
      " * Prec@1 33.631 Prec@5 58.929\n",
      " * Prec@1 33.807 Prec@5 59.375\n",
      " * Prec@1 33.696 Prec@5 58.696\n",
      " * Prec@1 33.854 Prec@5 58.854\n",
      " * Prec@1 34.250 Prec@5 59.000\n",
      " * Prec@1 34.375 Prec@5 58.654\n",
      " * Prec@1 34.028 Prec@5 59.028\n",
      " * Prec@1 33.705 Prec@5 59.375\n",
      " * Prec@1 32.759 Prec@5 58.836\n",
      " * Prec@1 32.917 Prec@5 59.167\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.521 (0.498)\n",
      "\n",
      "Loss 3.8339 (3.0276)\n",
      "\n",
      "Prec@1 18.750 (32.460)\n",
      "\n",
      "Prec@5 31.250 (58.266)\n",
      "\n",
      " * Prec@1 32.460 Prec@5 58.266\n",
      " * Prec@1 33.203 Prec@5 58.398\n",
      " * Prec@1 32.955 Prec@5 58.902\n",
      " * Prec@1 32.904 Prec@5 58.824\n",
      " * Prec@1 32.679 Prec@5 58.750\n",
      " * Prec@1 32.465 Prec@5 58.681\n",
      " * Prec@1 32.601 Prec@5 58.615\n",
      " * Prec@1 33.059 Prec@5 58.717\n",
      " * Prec@1 33.013 Prec@5 58.814\n",
      " * Prec@1 32.969 Prec@5 58.750\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.478 (0.498)\n",
      "\n",
      "Loss 3.0190 (3.0095)\n",
      "\n",
      "Prec@1 43.750 (33.232)\n",
      "\n",
      "Prec@5 56.250 (58.689)\n",
      "\n",
      " * Prec@1 33.232 Prec@5 58.689\n",
      " * Prec@1 32.738 Prec@5 58.482\n",
      " * Prec@1 32.703 Prec@5 58.721\n",
      " * Prec@1 32.812 Prec@5 58.807\n",
      " * Prec@1 32.639 Prec@5 58.472\n",
      " * Prec@1 32.473 Prec@5 57.880\n",
      " * Prec@1 32.580 Prec@5 58.245\n",
      " * Prec@1 32.422 Prec@5 57.812\n",
      " * Prec@1 32.908 Prec@5 58.163\n",
      " * Prec@1 32.750 Prec@5 57.750\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.512 (0.500)\n",
      "\n",
      "Loss 2.3022 (3.0782)\n",
      "\n",
      "Prec@1 31.250 (32.721)\n",
      "\n",
      "Prec@5 68.750 (57.966)\n",
      "\n",
      " * Prec@1 32.721 Prec@5 57.966\n",
      " * Prec@1 32.572 Prec@5 58.053\n",
      " * Prec@1 32.665 Prec@5 57.901\n",
      " * Prec@1 32.755 Prec@5 57.986\n",
      " * Prec@1 32.955 Prec@5 58.182\n",
      " * Prec@1 33.036 Prec@5 58.147\n",
      " * Prec@1 33.114 Prec@5 58.224\n",
      " * Prec@1 33.297 Prec@5 58.405\n",
      " * Prec@1 33.369 Prec@5 58.369\n",
      " * Prec@1 33.229 Prec@5 58.021\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.462 (0.501)\n",
      "\n",
      "Loss 3.2309 (3.0883)\n",
      "\n",
      "Prec@1 37.500 (33.299)\n",
      "\n",
      "Prec@5 68.750 (58.197)\n",
      "\n",
      " * Prec@1 33.299 Prec@5 58.197\n",
      " * Prec@1 33.669 Prec@5 58.367\n",
      " * Prec@1 33.829 Prec@5 58.333\n",
      " * Prec@1 34.082 Prec@5 58.789\n",
      " * Prec@1 33.942 Prec@5 58.942\n",
      " * Prec@1 33.902 Prec@5 58.902\n",
      " * Prec@1 33.955 Prec@5 59.049\n",
      " * Prec@1 33.915 Prec@5 59.099\n",
      " * Prec@1 33.605 Prec@5 58.696\n",
      " * Prec@1 33.661 Prec@5 58.571\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.479 (0.504)\n",
      "\n",
      "Loss 3.9432 (3.1046)\n",
      "\n",
      "Prec@1 12.500 (33.363)\n",
      "\n",
      "Prec@5 37.500 (58.275)\n",
      "\n",
      " * Prec@1 33.363 Prec@5 58.275\n",
      " * Prec@1 33.507 Prec@5 58.247\n",
      " * Prec@1 33.562 Prec@5 58.219\n",
      " * Prec@1 33.446 Prec@5 58.024\n",
      " * Prec@1 33.333 Prec@5 58.167\n",
      " * Prec@1 33.306 Prec@5 58.059\n",
      " * Prec@1 33.360 Prec@5 58.279\n",
      " * Prec@1 33.413 Prec@5 58.173\n",
      " * Prec@1 33.228 Prec@5 57.991\n",
      " * Prec@1 32.812 Prec@5 57.734\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.555 (0.504)\n",
      "\n",
      "Loss 3.7614 (3.1490)\n",
      "\n",
      "Prec@1 37.500 (32.870)\n",
      "\n",
      "Prec@5 50.000 (57.639)\n",
      "\n",
      " * Prec@1 32.870 Prec@5 57.639\n",
      " * Prec@1 32.698 Prec@5 57.546\n",
      " * Prec@1 32.605 Prec@5 57.530\n",
      " * Prec@1 32.589 Prec@5 57.292\n",
      " * Prec@1 32.647 Prec@5 57.353\n",
      " * Prec@1 32.558 Prec@5 57.413\n",
      " * Prec@1 32.687 Prec@5 57.399\n",
      " * Prec@1 32.670 Prec@5 57.315\n",
      " * Prec@1 32.865 Prec@5 57.584\n",
      " * Prec@1 32.847 Prec@5 57.569\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.475 (0.505)\n",
      "\n",
      "Loss 3.1379 (3.1456)\n",
      "\n",
      "Prec@1 18.750 (32.692)\n",
      "\n",
      "Prec@5 62.500 (57.624)\n",
      "\n",
      " * Prec@1 32.692 Prec@5 57.624\n",
      " * Prec@1 32.541 Prec@5 57.541\n",
      " * Prec@1 32.661 Prec@5 57.661\n",
      " * Prec@1 32.713 Prec@5 57.779\n",
      " * Prec@1 32.697 Prec@5 57.829\n",
      " * Prec@1 32.747 Prec@5 57.878\n",
      " * Prec@1 32.861 Prec@5 58.054\n",
      " * Prec@1 32.589 Prec@5 57.844\n",
      " * Prec@1 32.702 Prec@5 57.955\n",
      " * Prec@1 32.625 Prec@5 57.875\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.505 (0.504)\n",
      "\n",
      "Loss 2.8885 (3.1446)\n",
      "\n",
      "Prec@1 37.500 (32.673)\n",
      "\n",
      "Prec@5 56.250 (57.859)\n",
      "\n",
      " * Prec@1 32.673 Prec@5 57.859\n",
      " * Prec@1 32.782 Prec@5 57.966\n",
      " * Prec@1 32.767 Prec@5 58.010\n",
      " * Prec@1 32.692 Prec@5 58.173\n",
      " * Prec@1 32.917 Prec@5 58.274\n",
      " * Prec@1 32.960 Prec@5 58.432\n",
      " * Prec@1 32.944 Prec@5 58.528\n",
      " * Prec@1 32.928 Prec@5 58.565\n",
      " * Prec@1 32.856 Prec@5 58.544\n",
      " * Prec@1 33.182 Prec@5 58.864\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.542 (0.503)\n",
      "\n",
      "Loss 2.5593 (3.1015)\n",
      "\n",
      "Prec@1 50.000 (33.333)\n",
      "\n",
      "Prec@5 62.500 (58.896)\n",
      "\n",
      " * Prec@1 33.333 Prec@5 58.896\n",
      " * Prec@1 33.371 Prec@5 58.929\n",
      " * Prec@1 33.407 Prec@5 59.015\n",
      " * Prec@1 33.388 Prec@5 58.991\n",
      " * Prec@1 33.370 Prec@5 58.967\n",
      " * Prec@1 33.459 Prec@5 59.052\n",
      " * Prec@1 33.494 Prec@5 58.974\n",
      " * Prec@1 33.369 Prec@5 59.110\n",
      " * Prec@1 33.351 Prec@5 59.139\n",
      " * Prec@1 33.177 Prec@5 59.062\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.536 (0.503)\n",
      "\n",
      "Loss 2.1919 (3.0933)\n",
      "\n",
      "Prec@1 68.750 (33.471)\n",
      "\n",
      "Prec@5 75.000 (59.194)\n",
      "\n",
      " * Prec@1 33.471 Prec@5 59.194\n",
      " * Prec@1 33.504 Prec@5 59.273\n",
      " * Prec@1 33.638 Prec@5 59.451\n",
      " * Prec@1 33.569 Prec@5 59.274\n",
      " * Prec@1 33.500 Prec@5 59.300\n",
      " * Prec@1 33.433 Prec@5 59.375\n",
      " * Prec@1 33.415 Prec@5 59.301\n",
      " * Prec@1 33.350 Prec@5 59.229\n",
      " * Prec@1 33.479 Prec@5 59.351\n",
      " * Prec@1 33.413 Prec@5 59.375\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.542 (0.504)\n",
      "\n",
      "Loss 3.8380 (3.0932)\n",
      "\n",
      "Prec@1 18.750 (33.302)\n",
      "\n",
      "Prec@5 50.000 (59.303)\n",
      "\n",
      " * Prec@1 33.302 Prec@5 59.303\n",
      " * Prec@1 33.381 Prec@5 59.233\n",
      " * Prec@1 33.412 Prec@5 59.211\n",
      " * Prec@1 33.349 Prec@5 59.188\n",
      " * Prec@1 33.380 Prec@5 59.259\n",
      " * Prec@1 33.502 Prec@5 59.283\n",
      " * Prec@1 33.394 Prec@5 59.261\n",
      " * Prec@1 33.424 Prec@5 59.239\n",
      " * Prec@1 33.498 Prec@5 59.263\n",
      " * Prec@1 33.393 Prec@5 59.241\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.520 (0.503)\n",
      "\n",
      "Loss 3.4484 (3.0926)\n",
      "\n",
      "Prec@1 37.500 (33.422)\n",
      "\n",
      "Prec@5 56.250 (59.220)\n",
      "\n",
      " * Prec@1 33.422 Prec@5 59.220\n",
      " * Prec@1 33.583 Prec@5 59.277\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [11][0/1276]\t\\Time 0.595 (0.595)\tData 0.434 (0.434)\tLoss 2.7970 (2.7970)\tPrec@1 31.250 (31.250)\tPrec@5 68.750 (68.750)\n",
      "Epoch: [11][100/1276]\t\\Time 0.507 (0.496)\tData 0.400 (0.397)\tLoss 2.6679 (2.0288)\tPrec@1 37.500 (50.928)\tPrec@5 75.000 (76.980)\n",
      "Epoch: [11][200/1276]\t\\Time 0.493 (0.499)\tData 0.382 (0.399)\tLoss 2.4208 (2.1346)\tPrec@1 56.250 (49.254)\tPrec@5 62.500 (75.280)\n",
      "Epoch: [11][300/1276]\t\\Time 0.531 (0.498)\tData 0.421 (0.399)\tLoss 1.8146 (2.1900)\tPrec@1 56.250 (48.090)\tPrec@5 81.250 (74.211)\n",
      "Epoch: [11][400/1276]\t\\Time 0.492 (0.497)\tData 0.420 (0.398)\tLoss 2.2786 (2.2265)\tPrec@1 37.500 (47.288)\tPrec@5 68.750 (73.504)\n",
      "Epoch: [11][500/1276]\t\\Time 0.420 (0.497)\tData 0.350 (0.398)\tLoss 2.2510 (2.2624)\tPrec@1 50.000 (46.719)\tPrec@5 81.250 (72.767)\n",
      "Epoch: [11][600/1276]\t\\Time 0.520 (0.499)\tData 0.421 (0.399)\tLoss 2.2977 (2.2820)\tPrec@1 43.750 (46.183)\tPrec@5 87.500 (72.473)\n",
      "Epoch: [11][700/1276]\t\\Time 0.500 (0.499)\tData 0.380 (0.400)\tLoss 2.2164 (2.3059)\tPrec@1 43.750 (45.685)\tPrec@5 87.500 (72.067)\n",
      "Epoch: [11][800/1276]\t\\Time 0.491 (0.500)\tData 0.421 (0.400)\tLoss 1.5035 (2.3065)\tPrec@1 68.750 (45.763)\tPrec@5 81.250 (72.191)\n",
      "Epoch: [11][900/1276]\t\\Time 0.520 (0.500)\tData 0.410 (0.400)\tLoss 2.8464 (2.3150)\tPrec@1 37.500 (45.602)\tPrec@5 56.250 (72.052)\n",
      "Epoch: [11][1000/1276]\t\\Time 0.540 (0.501)\tData 0.430 (0.400)\tLoss 2.0756 (2.3139)\tPrec@1 37.500 (45.667)\tPrec@5 68.750 (72.009)\n",
      "Epoch: [11][1100/1276]\t\\Time 0.493 (0.501)\tData 0.346 (0.400)\tLoss 2.2768 (2.3200)\tPrec@1 50.000 (45.572)\tPrec@5 68.750 (71.935)\n",
      "Epoch: [11][1200/1276]\t\\Time 0.490 (0.501)\tData 0.410 (0.400)\tLoss 2.1313 (2.3307)\tPrec@1 43.750 (45.374)\tPrec@5 75.000 (71.695)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.441 (0.441)\n",
      "\n",
      "Loss 3.2112 (3.2112)\n",
      "\n",
      "Prec@1 37.500 (37.500)\n",
      "\n",
      "Prec@5 62.500 (62.500)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 62.500\n",
      " * Prec@1 43.750 Prec@5 68.750\n",
      " * Prec@1 39.583 Prec@5 66.667\n",
      " * Prec@1 42.188 Prec@5 64.062\n",
      " * Prec@1 42.500 Prec@5 66.250\n",
      " * Prec@1 41.667 Prec@5 64.583\n",
      " * Prec@1 41.964 Prec@5 63.393\n",
      " * Prec@1 41.406 Prec@5 63.281\n",
      " * Prec@1 42.361 Prec@5 63.194\n",
      " * Prec@1 43.125 Prec@5 64.375\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.480 (0.498)\n",
      "\n",
      "Loss 2.6609 (2.7938)\n",
      "\n",
      "Prec@1 50.000 (43.750)\n",
      "\n",
      "Prec@5 68.750 (64.773)\n",
      "\n",
      " * Prec@1 43.750 Prec@5 64.773\n",
      " * Prec@1 42.708 Prec@5 63.542\n",
      " * Prec@1 41.346 Prec@5 63.942\n",
      " * Prec@1 42.857 Prec@5 64.286\n",
      " * Prec@1 42.083 Prec@5 63.333\n",
      " * Prec@1 41.016 Prec@5 62.109\n",
      " * Prec@1 42.279 Prec@5 64.338\n",
      " * Prec@1 42.708 Prec@5 64.236\n",
      " * Prec@1 42.434 Prec@5 65.132\n",
      " * Prec@1 41.875 Prec@5 64.688\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.540 (0.497)\n",
      "\n",
      "Loss 3.8384 (2.8291)\n",
      "\n",
      "Prec@1 18.750 (40.774)\n",
      "\n",
      "Prec@5 56.250 (64.286)\n",
      "\n",
      " * Prec@1 40.774 Prec@5 64.286\n",
      " * Prec@1 41.477 Prec@5 64.489\n",
      " * Prec@1 41.033 Prec@5 64.402\n",
      " * Prec@1 41.667 Prec@5 64.844\n",
      " * Prec@1 41.750 Prec@5 65.250\n",
      " * Prec@1 41.346 Prec@5 65.385\n",
      " * Prec@1 41.667 Prec@5 65.509\n",
      " * Prec@1 41.071 Prec@5 65.402\n",
      " * Prec@1 40.517 Prec@5 64.655\n",
      " * Prec@1 40.417 Prec@5 64.375\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.517 (0.500)\n",
      "\n",
      "Loss 4.0586 (2.8628)\n",
      "\n",
      "Prec@1 25.000 (39.919)\n",
      "\n",
      "Prec@5 50.000 (63.911)\n",
      "\n",
      " * Prec@1 39.919 Prec@5 63.911\n",
      " * Prec@1 39.844 Prec@5 64.062\n",
      " * Prec@1 39.773 Prec@5 63.636\n",
      " * Prec@1 39.706 Prec@5 63.419\n",
      " * Prec@1 39.643 Prec@5 63.571\n",
      " * Prec@1 39.583 Prec@5 63.368\n",
      " * Prec@1 39.358 Prec@5 63.176\n",
      " * Prec@1 39.803 Prec@5 63.487\n",
      " * Prec@1 39.423 Prec@5 63.622\n",
      " * Prec@1 39.062 Prec@5 63.125\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.470 (0.503)\n",
      "\n",
      "Loss 2.8950 (2.8730)\n",
      "\n",
      "Prec@1 43.750 (39.177)\n",
      "\n",
      "Prec@5 62.500 (63.110)\n",
      "\n",
      " * Prec@1 39.177 Prec@5 63.110\n",
      " * Prec@1 38.839 Prec@5 63.095\n",
      " * Prec@1 38.808 Prec@5 63.372\n",
      " * Prec@1 38.778 Prec@5 63.352\n",
      " * Prec@1 38.611 Prec@5 63.056\n",
      " * Prec@1 38.451 Prec@5 62.636\n",
      " * Prec@1 38.697 Prec@5 62.633\n",
      " * Prec@1 38.672 Prec@5 62.500\n",
      " * Prec@1 38.903 Prec@5 62.755\n",
      " * Prec@1 38.875 Prec@5 62.625\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.487 (0.501)\n",
      "\n",
      "Loss 1.4149 (2.8961)\n",
      "\n",
      "Prec@1 87.500 (39.828)\n",
      "\n",
      "Prec@5 93.750 (63.235)\n",
      "\n",
      " * Prec@1 39.828 Prec@5 63.235\n",
      " * Prec@1 39.904 Prec@5 63.341\n",
      " * Prec@1 39.976 Prec@5 63.090\n",
      " * Prec@1 39.931 Prec@5 62.847\n",
      " * Prec@1 40.114 Prec@5 63.068\n",
      " * Prec@1 40.067 Prec@5 63.281\n",
      " * Prec@1 40.022 Prec@5 63.158\n",
      " * Prec@1 40.302 Prec@5 63.147\n",
      " * Prec@1 40.042 Prec@5 63.030\n",
      " * Prec@1 39.896 Prec@5 62.917\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.480 (0.501)\n",
      "\n",
      "Loss 3.1071 (2.9239)\n",
      "\n",
      "Prec@1 50.000 (40.061)\n",
      "\n",
      "Prec@5 68.750 (63.012)\n",
      "\n",
      " * Prec@1 40.061 Prec@5 63.012\n",
      " * Prec@1 40.121 Prec@5 63.004\n",
      " * Prec@1 40.079 Prec@5 62.996\n",
      " * Prec@1 40.332 Prec@5 63.281\n",
      " * Prec@1 40.192 Prec@5 63.077\n",
      " * Prec@1 39.867 Prec@5 62.973\n",
      " * Prec@1 39.925 Prec@5 63.153\n",
      " * Prec@1 39.706 Prec@5 62.868\n",
      " * Prec@1 39.674 Prec@5 62.591\n",
      " * Prec@1 39.554 Prec@5 62.500\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.488 (0.503)\n",
      "\n",
      "Loss 4.4666 (2.9842)\n",
      "\n",
      "Prec@1 31.250 (39.437)\n",
      "\n",
      "Prec@5 43.750 (62.236)\n",
      "\n",
      " * Prec@1 39.437 Prec@5 62.236\n",
      " * Prec@1 39.323 Prec@5 62.153\n",
      " * Prec@1 39.555 Prec@5 62.414\n",
      " * Prec@1 39.274 Prec@5 62.162\n",
      " * Prec@1 39.250 Prec@5 62.167\n",
      " * Prec@1 39.145 Prec@5 62.253\n",
      " * Prec@1 39.042 Prec@5 62.338\n",
      " * Prec@1 38.782 Prec@5 62.179\n",
      " * Prec@1 38.608 Prec@5 62.104\n",
      " * Prec@1 38.281 Prec@5 61.797\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.537 (0.503)\n",
      "\n",
      "Loss 3.4554 (3.0332)\n",
      "\n",
      "Prec@1 31.250 (38.194)\n",
      "\n",
      "Prec@5 56.250 (61.728)\n",
      "\n",
      " * Prec@1 38.194 Prec@5 61.728\n",
      " * Prec@1 38.186 Prec@5 61.738\n",
      " * Prec@1 37.877 Prec@5 61.672\n",
      " * Prec@1 38.021 Prec@5 61.756\n",
      " * Prec@1 38.015 Prec@5 61.765\n",
      " * Prec@1 38.081 Prec@5 61.991\n",
      " * Prec@1 38.218 Prec@5 62.141\n",
      " * Prec@1 38.210 Prec@5 61.932\n",
      " * Prec@1 38.272 Prec@5 62.079\n",
      " * Prec@1 38.264 Prec@5 62.083\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.448 (0.503)\n",
      "\n",
      "Loss 2.8090 (3.0295)\n",
      "\n",
      "Prec@1 25.000 (38.118)\n",
      "\n",
      "Prec@5 75.000 (62.225)\n",
      "\n",
      " * Prec@1 38.118 Prec@5 62.225\n",
      " * Prec@1 37.840 Prec@5 62.092\n",
      " * Prec@1 37.702 Prec@5 62.097\n",
      " * Prec@1 37.633 Prec@5 61.968\n",
      " * Prec@1 37.632 Prec@5 61.974\n",
      " * Prec@1 37.500 Prec@5 62.240\n",
      " * Prec@1 37.693 Prec@5 62.564\n",
      " * Prec@1 37.500 Prec@5 62.500\n",
      " * Prec@1 37.626 Prec@5 62.374\n",
      " * Prec@1 37.562 Prec@5 62.250\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.539 (0.503)\n",
      "\n",
      "Loss 2.9487 (3.0364)\n",
      "\n",
      "Prec@1 43.750 (37.624)\n",
      "\n",
      "Prec@5 56.250 (62.191)\n",
      "\n",
      " * Prec@1 37.624 Prec@5 62.191\n",
      " * Prec@1 37.561 Prec@5 62.132\n",
      " * Prec@1 37.561 Prec@5 62.136\n",
      " * Prec@1 37.680 Prec@5 62.200\n",
      " * Prec@1 37.917 Prec@5 62.381\n",
      " * Prec@1 37.854 Prec@5 62.441\n",
      " * Prec@1 37.850 Prec@5 62.442\n",
      " * Prec@1 37.789 Prec@5 62.442\n",
      " * Prec@1 37.615 Prec@5 62.443\n",
      " * Prec@1 37.784 Prec@5 62.614\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.539 (0.502)\n",
      "\n",
      "Loss 2.8630 (3.0106)\n",
      "\n",
      "Prec@1 43.750 (37.838)\n",
      "\n",
      "Prec@5 50.000 (62.500)\n",
      "\n",
      " * Prec@1 37.838 Prec@5 62.500\n",
      " * Prec@1 37.835 Prec@5 62.500\n",
      " * Prec@1 37.998 Prec@5 62.666\n",
      " * Prec@1 37.993 Prec@5 62.500\n",
      " * Prec@1 38.043 Prec@5 62.500\n",
      " * Prec@1 38.147 Prec@5 62.500\n",
      " * Prec@1 38.301 Prec@5 62.607\n",
      " * Prec@1 38.294 Prec@5 62.553\n",
      " * Prec@1 38.183 Prec@5 62.447\n",
      " * Prec@1 38.073 Prec@5 62.344\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.491 (0.501)\n",
      "\n",
      "Loss 2.3088 (2.9974)\n",
      "\n",
      "Prec@1 56.250 (38.223)\n",
      "\n",
      "Prec@5 68.750 (62.397)\n",
      "\n",
      " * Prec@1 38.223 Prec@5 62.397\n",
      " * Prec@1 38.268 Prec@5 62.551\n",
      " * Prec@1 38.364 Prec@5 62.652\n",
      " * Prec@1 38.206 Prec@5 62.349\n",
      " * Prec@1 38.250 Prec@5 62.400\n",
      " * Prec@1 38.194 Prec@5 62.401\n",
      " * Prec@1 38.287 Prec@5 62.402\n",
      " * Prec@1 38.184 Prec@5 62.256\n",
      " * Prec@1 38.372 Prec@5 62.403\n",
      " * Prec@1 38.365 Prec@5 62.500\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.560 (0.503)\n",
      "\n",
      "Loss 3.5179 (2.9867)\n",
      "\n",
      "Prec@1 37.500 (38.359)\n",
      "\n",
      "Prec@5 50.000 (62.405)\n",
      "\n",
      " * Prec@1 38.359 Prec@5 62.405\n",
      " * Prec@1 38.447 Prec@5 62.453\n",
      " * Prec@1 38.487 Prec@5 62.453\n",
      " * Prec@1 38.386 Prec@5 62.407\n",
      " * Prec@1 38.472 Prec@5 62.546\n",
      " * Prec@1 38.465 Prec@5 62.638\n",
      " * Prec@1 38.412 Prec@5 62.682\n",
      " * Prec@1 38.451 Prec@5 62.636\n",
      " * Prec@1 38.444 Prec@5 62.680\n",
      " * Prec@1 38.348 Prec@5 62.500\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.491 (0.501)\n",
      "\n",
      "Loss 3.4209 (2.9918)\n",
      "\n",
      "Prec@1 31.250 (38.298)\n",
      "\n",
      "Prec@5 37.500 (62.323)\n",
      "\n",
      " * Prec@1 38.298 Prec@5 62.323\n",
      " * Prec@1 38.299 Prec@5 62.274\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [12][0/1276]\t\\Time 0.529 (0.529)\tData 0.412 (0.412)\tLoss 2.5123 (2.5123)\tPrec@1 50.000 (50.000)\tPrec@5 75.000 (75.000)\n",
      "Epoch: [12][100/1276]\t\\Time 0.513 (0.503)\tData 0.392 (0.401)\tLoss 1.2498 (1.8419)\tPrec@1 81.250 (55.817)\tPrec@5 93.750 (80.012)\n",
      "Epoch: [12][200/1276]\t\\Time 0.504 (0.500)\tData 0.394 (0.399)\tLoss 2.2483 (1.8445)\tPrec@1 50.000 (55.068)\tPrec@5 68.750 (79.975)\n",
      "Epoch: [12][300/1276]\t\\Time 0.454 (0.499)\tData 0.355 (0.398)\tLoss 1.4471 (1.8680)\tPrec@1 62.500 (54.963)\tPrec@5 93.750 (79.547)\n",
      "Epoch: [12][400/1276]\t\\Time 0.522 (0.498)\tData 0.412 (0.398)\tLoss 1.6018 (1.8862)\tPrec@1 62.500 (54.582)\tPrec@5 87.500 (79.271)\n",
      "Epoch: [12][500/1276]\t\\Time 0.502 (0.498)\tData 0.433 (0.398)\tLoss 2.0353 (1.9237)\tPrec@1 50.000 (53.593)\tPrec@5 87.500 (78.780)\n",
      "Epoch: [12][600/1276]\t\\Time 0.502 (0.498)\tData 0.392 (0.398)\tLoss 0.9702 (1.9395)\tPrec@1 75.000 (53.213)\tPrec@5 93.750 (78.640)\n",
      "Epoch: [12][700/1276]\t\\Time 0.412 (0.498)\tData 0.336 (0.398)\tLoss 2.0088 (1.9458)\tPrec@1 62.500 (53.014)\tPrec@5 75.000 (78.611)\n",
      "Epoch: [12][800/1276]\t\\Time 0.466 (0.498)\tData 0.359 (0.398)\tLoss 1.6486 (1.9451)\tPrec@1 75.000 (53.191)\tPrec@5 87.500 (78.613)\n",
      "Epoch: [12][900/1276]\t\\Time 0.502 (0.497)\tData 0.391 (0.398)\tLoss 2.2248 (1.9478)\tPrec@1 50.000 (53.337)\tPrec@5 81.250 (78.482)\n",
      "Epoch: [12][1000/1276]\t\\Time 0.492 (0.498)\tData 0.430 (0.398)\tLoss 1.9681 (1.9545)\tPrec@1 56.250 (53.216)\tPrec@5 75.000 (78.415)\n",
      "Epoch: [12][1100/1276]\t\\Time 0.515 (0.498)\tData 0.404 (0.398)\tLoss 1.4424 (1.9621)\tPrec@1 75.000 (53.145)\tPrec@5 87.500 (78.275)\n",
      "Epoch: [12][1200/1276]\t\\Time 0.552 (0.499)\tData 0.436 (0.399)\tLoss 1.8205 (1.9656)\tPrec@1 50.000 (53.070)\tPrec@5 81.250 (78.206)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.462 (0.462)\n",
      "\n",
      "Loss 3.0893 (3.0893)\n",
      "\n",
      "Prec@1 31.250 (31.250)\n",
      "\n",
      "Prec@5 62.500 (62.500)\n",
      "\n",
      " * Prec@1 31.250 Prec@5 62.500\n",
      " * Prec@1 37.500 Prec@5 71.875\n",
      " * Prec@1 37.500 Prec@5 68.750\n",
      " * Prec@1 40.625 Prec@5 68.750\n",
      " * Prec@1 37.500 Prec@5 67.500\n",
      " * Prec@1 36.458 Prec@5 64.583\n",
      " * Prec@1 37.500 Prec@5 65.179\n",
      " * Prec@1 37.500 Prec@5 64.844\n",
      " * Prec@1 39.583 Prec@5 64.583\n",
      " * Prec@1 39.375 Prec@5 65.000\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.477 (0.492)\n",
      "\n",
      "Loss 2.6088 (2.9290)\n",
      "\n",
      "Prec@1 37.500 (39.205)\n",
      "\n",
      "Prec@5 68.750 (65.341)\n",
      "\n",
      " * Prec@1 39.205 Prec@5 65.341\n",
      " * Prec@1 39.062 Prec@5 65.104\n",
      " * Prec@1 39.423 Prec@5 66.346\n",
      " * Prec@1 39.286 Prec@5 67.857\n",
      " * Prec@1 39.583 Prec@5 67.500\n",
      " * Prec@1 39.062 Prec@5 67.188\n",
      " * Prec@1 41.176 Prec@5 68.750\n",
      " * Prec@1 40.972 Prec@5 69.097\n",
      " * Prec@1 41.118 Prec@5 69.737\n",
      " * Prec@1 40.938 Prec@5 69.688\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.521 (0.494)\n",
      "\n",
      "Loss 3.4075 (2.7469)\n",
      "\n",
      "Prec@1 50.000 (41.369)\n",
      "\n",
      "Prec@5 68.750 (69.643)\n",
      "\n",
      " * Prec@1 41.369 Prec@5 69.643\n",
      " * Prec@1 41.761 Prec@5 69.602\n",
      " * Prec@1 42.120 Prec@5 69.565\n",
      " * Prec@1 42.708 Prec@5 69.271\n",
      " * Prec@1 43.250 Prec@5 70.000\n",
      " * Prec@1 43.029 Prec@5 69.952\n",
      " * Prec@1 42.824 Prec@5 69.676\n",
      " * Prec@1 42.411 Prec@5 69.420\n",
      " * Prec@1 42.026 Prec@5 68.750\n",
      " * Prec@1 41.875 Prec@5 68.542\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.513 (0.500)\n",
      "\n",
      "Loss 3.7540 (2.7746)\n",
      "\n",
      "Prec@1 18.750 (41.129)\n",
      "\n",
      "Prec@5 56.250 (68.145)\n",
      "\n",
      " * Prec@1 41.129 Prec@5 68.145\n",
      " * Prec@1 41.406 Prec@5 68.164\n",
      " * Prec@1 41.477 Prec@5 68.182\n",
      " * Prec@1 41.176 Prec@5 67.647\n",
      " * Prec@1 41.071 Prec@5 67.143\n",
      " * Prec@1 41.319 Prec@5 67.535\n",
      " * Prec@1 41.723 Prec@5 67.568\n",
      " * Prec@1 41.776 Prec@5 67.928\n",
      " * Prec@1 41.987 Prec@5 67.949\n",
      " * Prec@1 41.719 Prec@5 67.656\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.442 (0.500)\n",
      "\n",
      "Loss 3.1833 (2.7842)\n",
      "\n",
      "Prec@1 43.750 (41.768)\n",
      "\n",
      "Prec@5 62.500 (67.530)\n",
      "\n",
      " * Prec@1 41.768 Prec@5 67.530\n",
      " * Prec@1 41.220 Prec@5 66.964\n",
      " * Prec@1 41.134 Prec@5 66.715\n",
      " * Prec@1 40.767 Prec@5 66.761\n",
      " * Prec@1 40.417 Prec@5 66.528\n",
      " * Prec@1 40.082 Prec@5 66.033\n",
      " * Prec@1 40.160 Prec@5 66.356\n",
      " * Prec@1 40.365 Prec@5 66.406\n",
      " * Prec@1 40.561 Prec@5 66.582\n",
      " * Prec@1 40.250 Prec@5 66.375\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.469 (0.498)\n",
      "\n",
      "Loss 1.4717 (2.8065)\n",
      "\n",
      "Prec@1 50.000 (40.441)\n",
      "\n",
      "Prec@5 81.250 (66.667)\n",
      "\n",
      " * Prec@1 40.441 Prec@5 66.667\n",
      " * Prec@1 40.385 Prec@5 66.587\n",
      " * Prec@1 40.330 Prec@5 66.392\n",
      " * Prec@1 40.625 Prec@5 66.551\n",
      " * Prec@1 40.795 Prec@5 66.818\n",
      " * Prec@1 40.848 Prec@5 66.853\n",
      " * Prec@1 41.009 Prec@5 66.776\n",
      " * Prec@1 41.272 Prec@5 66.918\n",
      " * Prec@1 41.314 Prec@5 66.843\n",
      " * Prec@1 41.562 Prec@5 66.771\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.485 (0.500)\n",
      "\n",
      "Loss 2.6227 (2.7984)\n",
      "\n",
      "Prec@1 43.750 (41.598)\n",
      "\n",
      "Prec@5 75.000 (66.906)\n",
      "\n",
      " * Prec@1 41.598 Prec@5 66.906\n",
      " * Prec@1 41.633 Prec@5 66.835\n",
      " * Prec@1 41.865 Prec@5 67.063\n",
      " * Prec@1 42.285 Prec@5 67.480\n",
      " * Prec@1 42.308 Prec@5 67.404\n",
      " * Prec@1 42.140 Prec@5 67.235\n",
      " * Prec@1 42.537 Prec@5 67.444\n",
      " * Prec@1 42.371 Prec@5 67.371\n",
      " * Prec@1 42.301 Prec@5 67.120\n",
      " * Prec@1 42.232 Prec@5 66.786\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.472 (0.502)\n",
      "\n",
      "Loss 3.5461 (2.8298)\n",
      "\n",
      "Prec@1 37.500 (42.165)\n",
      "\n",
      "Prec@5 50.000 (66.549)\n",
      "\n",
      " * Prec@1 42.165 Prec@5 66.549\n",
      " * Prec@1 42.014 Prec@5 66.406\n",
      " * Prec@1 41.866 Prec@5 66.353\n",
      " * Prec@1 41.723 Prec@5 66.216\n",
      " * Prec@1 41.500 Prec@5 66.000\n",
      " * Prec@1 41.447 Prec@5 66.118\n",
      " * Prec@1 41.558 Prec@5 66.234\n",
      " * Prec@1 41.747 Prec@5 66.346\n",
      " * Prec@1 41.535 Prec@5 66.456\n",
      " * Prec@1 41.250 Prec@5 66.094\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.531 (0.503)\n",
      "\n",
      "Loss 3.6166 (2.8846)\n",
      "\n",
      "Prec@1 25.000 (41.049)\n",
      "\n",
      "Prec@5 56.250 (65.972)\n",
      "\n",
      " * Prec@1 41.049 Prec@5 65.972\n",
      " * Prec@1 41.006 Prec@5 65.777\n",
      " * Prec@1 40.964 Prec@5 65.738\n",
      " * Prec@1 40.997 Prec@5 65.699\n",
      " * Prec@1 41.103 Prec@5 65.735\n",
      " * Prec@1 41.061 Prec@5 65.916\n",
      " * Prec@1 41.164 Prec@5 65.948\n",
      " * Prec@1 40.980 Prec@5 65.909\n",
      " * Prec@1 41.011 Prec@5 66.011\n",
      " * Prec@1 40.972 Prec@5 65.972\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.470 (0.503)\n",
      "\n",
      "Loss 3.1360 (2.8988)\n",
      "\n",
      "Prec@1 25.000 (40.797)\n",
      "\n",
      "Prec@5 62.500 (65.934)\n",
      "\n",
      " * Prec@1 40.797 Prec@5 65.934\n",
      " * Prec@1 40.625 Prec@5 65.897\n",
      " * Prec@1 40.793 Prec@5 65.860\n",
      " * Prec@1 40.758 Prec@5 65.758\n",
      " * Prec@1 40.592 Prec@5 65.724\n",
      " * Prec@1 40.755 Prec@5 65.951\n",
      " * Prec@1 40.915 Prec@5 66.108\n",
      " * Prec@1 40.944 Prec@5 66.071\n",
      " * Prec@1 40.972 Prec@5 66.162\n",
      " * Prec@1 40.812 Prec@5 66.188\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.525 (0.503)\n",
      "\n",
      "Loss 2.4066 (2.8922)\n",
      "\n",
      "Prec@1 43.750 (40.842)\n",
      "\n",
      "Prec@5 68.750 (66.213)\n",
      "\n",
      " * Prec@1 40.842 Prec@5 66.213\n",
      " * Prec@1 40.870 Prec@5 66.238\n",
      " * Prec@1 40.837 Prec@5 66.262\n",
      " * Prec@1 40.805 Prec@5 66.346\n",
      " * Prec@1 41.131 Prec@5 66.488\n",
      " * Prec@1 41.215 Prec@5 66.568\n",
      " * Prec@1 41.297 Prec@5 66.706\n",
      " * Prec@1 41.262 Prec@5 66.667\n",
      " * Prec@1 41.170 Prec@5 66.628\n",
      " * Prec@1 41.250 Prec@5 66.761\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.531 (0.503)\n",
      "\n",
      "Loss 2.1352 (2.8541)\n",
      "\n",
      "Prec@1 50.000 (41.329)\n",
      "\n",
      "Prec@5 81.250 (66.892)\n",
      "\n",
      " * Prec@1 41.329 Prec@5 66.892\n",
      " * Prec@1 41.295 Prec@5 66.964\n",
      " * Prec@1 41.427 Prec@5 67.091\n",
      " * Prec@1 41.447 Prec@5 66.996\n",
      " * Prec@1 41.413 Prec@5 67.011\n",
      " * Prec@1 41.541 Prec@5 67.080\n",
      " * Prec@1 41.346 Prec@5 66.880\n",
      " * Prec@1 41.367 Prec@5 66.896\n",
      " * Prec@1 41.387 Prec@5 67.069\n",
      " * Prec@1 41.250 Prec@5 66.875\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.500 (0.503)\n",
      "\n",
      "Loss 2.2897 (2.8445)\n",
      "\n",
      "Prec@1 62.500 (41.426)\n",
      "\n",
      "Prec@5 75.000 (66.942)\n",
      "\n",
      " * Prec@1 41.426 Prec@5 66.942\n",
      " * Prec@1 41.547 Prec@5 67.059\n",
      " * Prec@1 41.667 Prec@5 67.175\n",
      " * Prec@1 41.482 Prec@5 66.935\n",
      " * Prec@1 41.450 Prec@5 66.900\n",
      " * Prec@1 41.369 Prec@5 66.766\n",
      " * Prec@1 41.339 Prec@5 66.781\n",
      " * Prec@1 41.211 Prec@5 66.602\n",
      " * Prec@1 41.279 Prec@5 66.667\n",
      " * Prec@1 41.298 Prec@5 66.635\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.548 (0.504)\n",
      "\n",
      "Loss 2.8602 (2.8444)\n",
      "\n",
      "Prec@1 37.500 (41.269)\n",
      "\n",
      "Prec@5 68.750 (66.651)\n",
      "\n",
      " * Prec@1 41.269 Prec@5 66.651\n",
      " * Prec@1 41.288 Prec@5 66.619\n",
      " * Prec@1 41.353 Prec@5 66.682\n",
      " * Prec@1 41.371 Prec@5 66.604\n",
      " * Prec@1 41.528 Prec@5 66.713\n",
      " * Prec@1 41.590 Prec@5 66.728\n",
      " * Prec@1 41.560 Prec@5 66.697\n",
      " * Prec@1 41.621 Prec@5 66.712\n",
      " * Prec@1 41.637 Prec@5 66.637\n",
      " * Prec@1 41.607 Prec@5 66.696\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.495 (0.503)\n",
      "\n",
      "Loss 3.1281 (2.8379)\n",
      "\n",
      "Prec@1 37.500 (41.578)\n",
      "\n",
      "Prec@5 62.500 (66.667)\n",
      "\n",
      " * Prec@1 41.578 Prec@5 66.667\n",
      " * Prec@1 41.648 Prec@5 66.681\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [13][0/1276]\t\\Time 0.538 (0.538)\tData 0.375 (0.375)\tLoss 1.8211 (1.8211)\tPrec@1 37.500 (37.500)\tPrec@5 81.250 (81.250)\n",
      "Epoch: [13][100/1276]\t\\Time 0.509 (0.502)\tData 0.409 (0.403)\tLoss 1.6722 (1.3840)\tPrec@1 50.000 (63.614)\tPrec@5 81.250 (87.252)\n",
      "Epoch: [13][200/1276]\t\\Time 0.472 (0.501)\tData 0.350 (0.403)\tLoss 1.5953 (1.4935)\tPrec@1 56.250 (61.909)\tPrec@5 93.750 (85.603)\n",
      "Epoch: [13][300/1276]\t\\Time 0.470 (0.501)\tData 0.367 (0.401)\tLoss 1.3486 (1.5132)\tPrec@1 68.750 (62.189)\tPrec@5 87.500 (84.988)\n",
      "Epoch: [13][400/1276]\t\\Time 0.549 (0.500)\tData 0.441 (0.401)\tLoss 1.4409 (1.5434)\tPrec@1 50.000 (61.284)\tPrec@5 93.750 (84.679)\n",
      "Epoch: [13][500/1276]\t\\Time 0.521 (0.499)\tData 0.418 (0.400)\tLoss 2.2275 (1.5539)\tPrec@1 50.000 (60.878)\tPrec@5 75.000 (84.444)\n",
      "Epoch: [13][600/1276]\t\\Time 0.473 (0.499)\tData 0.363 (0.400)\tLoss 0.8497 (1.5657)\tPrec@1 81.250 (60.971)\tPrec@5 93.750 (84.255)\n",
      "Epoch: [13][700/1276]\t\\Time 0.557 (0.498)\tData 0.443 (0.399)\tLoss 2.1708 (1.5784)\tPrec@1 56.250 (60.726)\tPrec@5 68.750 (83.898)\n",
      "Epoch: [13][800/1276]\t\\Time 0.478 (0.499)\tData 0.371 (0.399)\tLoss 2.1022 (1.5912)\tPrec@1 50.000 (60.284)\tPrec@5 81.250 (83.591)\n",
      "Epoch: [13][900/1276]\t\\Time 0.479 (0.499)\tData 0.407 (0.399)\tLoss 1.3804 (1.6134)\tPrec@1 75.000 (60.072)\tPrec@5 87.500 (83.289)\n",
      "Epoch: [13][1000/1276]\t\\Time 0.527 (0.499)\tData 0.414 (0.399)\tLoss 1.9758 (1.6187)\tPrec@1 56.250 (60.002)\tPrec@5 81.250 (83.279)\n",
      "Epoch: [13][1100/1276]\t\\Time 0.494 (0.499)\tData 0.408 (0.399)\tLoss 2.1861 (1.6280)\tPrec@1 43.750 (59.843)\tPrec@5 81.250 (83.191)\n",
      "Epoch: [13][1200/1276]\t\\Time 0.556 (0.499)\tData 0.447 (0.399)\tLoss 1.4564 (1.6271)\tPrec@1 50.000 (59.867)\tPrec@5 93.750 (83.238)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.502 (0.502)\n",
      "\n",
      "Loss 2.8499 (2.8499)\n",
      "\n",
      "Prec@1 37.500 (37.500)\n",
      "\n",
      "Prec@5 62.500 (62.500)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 62.500\n",
      " * Prec@1 46.875 Prec@5 68.750\n",
      " * Prec@1 43.750 Prec@5 64.583\n",
      " * Prec@1 50.000 Prec@5 65.625\n",
      " * Prec@1 52.500 Prec@5 67.500\n",
      " * Prec@1 51.042 Prec@5 67.708\n",
      " * Prec@1 50.000 Prec@5 68.750\n",
      " * Prec@1 51.562 Prec@5 70.312\n",
      " * Prec@1 52.083 Prec@5 70.139\n",
      " * Prec@1 51.250 Prec@5 70.000\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.502 (0.493)\n",
      "\n",
      "Loss 2.4108 (2.4925)\n",
      "\n",
      "Prec@1 31.250 (49.432)\n",
      "\n",
      "Prec@5 75.000 (70.455)\n",
      "\n",
      " * Prec@1 49.432 Prec@5 70.455\n",
      " * Prec@1 48.958 Prec@5 70.833\n",
      " * Prec@1 49.038 Prec@5 71.154\n",
      " * Prec@1 50.000 Prec@5 72.321\n",
      " * Prec@1 49.167 Prec@5 71.667\n",
      " * Prec@1 49.219 Prec@5 71.094\n",
      " * Prec@1 50.368 Prec@5 72.794\n",
      " * Prec@1 50.694 Prec@5 72.917\n",
      " * Prec@1 50.000 Prec@5 73.026\n",
      " * Prec@1 49.062 Prec@5 72.500\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.514 (0.502)\n",
      "\n",
      "Loss 3.5325 (2.4513)\n",
      "\n",
      "Prec@1 37.500 (48.512)\n",
      "\n",
      "Prec@5 68.750 (72.321)\n",
      "\n",
      " * Prec@1 48.512 Prec@5 72.321\n",
      " * Prec@1 48.580 Prec@5 72.159\n",
      " * Prec@1 49.185 Prec@5 72.826\n",
      " * Prec@1 48.958 Prec@5 71.875\n",
      " * Prec@1 50.000 Prec@5 72.500\n",
      " * Prec@1 50.481 Prec@5 72.596\n",
      " * Prec@1 50.000 Prec@5 72.917\n",
      " * Prec@1 50.000 Prec@5 72.991\n",
      " * Prec@1 49.784 Prec@5 72.414\n",
      " * Prec@1 49.167 Prec@5 72.083\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.522 (0.502)\n",
      "\n",
      "Loss 3.7416 (2.5112)\n",
      "\n",
      "Prec@1 25.000 (48.387)\n",
      "\n",
      "Prec@5 62.500 (71.774)\n",
      "\n",
      " * Prec@1 48.387 Prec@5 71.774\n",
      " * Prec@1 48.633 Prec@5 71.680\n",
      " * Prec@1 47.917 Prec@5 71.970\n",
      " * Prec@1 48.346 Prec@5 72.059\n",
      " * Prec@1 48.036 Prec@5 71.964\n",
      " * Prec@1 47.917 Prec@5 71.875\n",
      " * Prec@1 47.804 Prec@5 71.453\n",
      " * Prec@1 47.533 Prec@5 71.546\n",
      " * Prec@1 47.596 Prec@5 71.474\n",
      " * Prec@1 47.344 Prec@5 71.250\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.466 (0.502)\n",
      "\n",
      "Loss 3.0073 (2.5362)\n",
      "\n",
      "Prec@1 37.500 (47.104)\n",
      "\n",
      "Prec@5 68.750 (71.189)\n",
      "\n",
      " * Prec@1 47.104 Prec@5 71.189\n",
      " * Prec@1 46.577 Prec@5 70.982\n",
      " * Prec@1 46.657 Prec@5 71.221\n",
      " * Prec@1 46.733 Prec@5 71.023\n",
      " * Prec@1 46.667 Prec@5 70.833\n",
      " * Prec@1 46.332 Prec@5 70.516\n",
      " * Prec@1 46.144 Prec@5 70.346\n",
      " * Prec@1 46.094 Prec@5 70.052\n",
      " * Prec@1 46.046 Prec@5 70.153\n",
      " * Prec@1 45.500 Prec@5 69.625\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.536 (0.505)\n",
      "\n",
      "Loss 1.2682 (2.5842)\n",
      "\n",
      "Prec@1 62.500 (45.833)\n",
      "\n",
      "Prec@5 93.750 (70.098)\n",
      "\n",
      " * Prec@1 45.833 Prec@5 70.098\n",
      " * Prec@1 45.793 Prec@5 69.832\n",
      " * Prec@1 45.637 Prec@5 69.458\n",
      " * Prec@1 45.602 Prec@5 69.676\n",
      " * Prec@1 45.795 Prec@5 69.773\n",
      " * Prec@1 46.094 Prec@5 69.866\n",
      " * Prec@1 45.943 Prec@5 69.518\n",
      " * Prec@1 46.228 Prec@5 69.397\n",
      " * Prec@1 46.292 Prec@5 69.280\n",
      " * Prec@1 46.354 Prec@5 69.271\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.484 (0.505)\n",
      "\n",
      "Loss 2.4111 (2.6292)\n",
      "\n",
      "Prec@1 62.500 (46.619)\n",
      "\n",
      "Prec@5 81.250 (69.467)\n",
      "\n",
      " * Prec@1 46.619 Prec@5 69.467\n",
      " * Prec@1 46.573 Prec@5 69.355\n",
      " * Prec@1 46.528 Prec@5 69.345\n",
      " * Prec@1 46.680 Prec@5 69.629\n",
      " * Prec@1 46.442 Prec@5 69.519\n",
      " * Prec@1 46.402 Prec@5 69.602\n",
      " * Prec@1 46.642 Prec@5 69.869\n",
      " * Prec@1 46.507 Prec@5 69.853\n",
      " * Prec@1 46.649 Prec@5 69.746\n",
      " * Prec@1 46.696 Prec@5 69.643\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.474 (0.508)\n",
      "\n",
      "Loss 3.3554 (2.6652)\n",
      "\n",
      "Prec@1 50.000 (46.743)\n",
      "\n",
      "Prec@5 50.000 (69.366)\n",
      "\n",
      " * Prec@1 46.743 Prec@5 69.366\n",
      " * Prec@1 46.875 Prec@5 69.271\n",
      " * Prec@1 46.918 Prec@5 69.264\n",
      " * Prec@1 46.622 Prec@5 68.834\n",
      " * Prec@1 46.667 Prec@5 68.917\n",
      " * Prec@1 46.546 Prec@5 68.997\n",
      " * Prec@1 46.591 Prec@5 68.994\n",
      " * Prec@1 46.554 Prec@5 69.071\n",
      " * Prec@1 46.203 Prec@5 68.908\n",
      " * Prec@1 45.859 Prec@5 68.594\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.552 (0.510)\n",
      "\n",
      "Loss 2.9835 (2.7059)\n",
      "\n",
      "Prec@1 50.000 (45.910)\n",
      "\n",
      "Prec@5 62.500 (68.519)\n",
      "\n",
      " * Prec@1 45.910 Prec@5 68.519\n",
      " * Prec@1 46.037 Prec@5 68.445\n",
      " * Prec@1 45.858 Prec@5 68.298\n",
      " * Prec@1 45.908 Prec@5 68.378\n",
      " * Prec@1 46.103 Prec@5 68.603\n",
      " * Prec@1 46.148 Prec@5 68.605\n",
      " * Prec@1 46.336 Prec@5 68.750\n",
      " * Prec@1 46.378 Prec@5 68.750\n",
      " * Prec@1 46.419 Prec@5 68.890\n",
      " * Prec@1 46.319 Prec@5 68.819\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.498 (0.511)\n",
      "\n",
      "Loss 2.9600 (2.7047)\n",
      "\n",
      "Prec@1 50.000 (46.360)\n",
      "\n",
      "Prec@5 75.000 (68.887)\n",
      "\n",
      " * Prec@1 46.360 Prec@5 68.887\n",
      " * Prec@1 46.399 Prec@5 68.954\n",
      " * Prec@1 46.505 Prec@5 68.952\n",
      " * Prec@1 46.543 Prec@5 68.883\n",
      " * Prec@1 46.579 Prec@5 68.750\n",
      " * Prec@1 46.549 Prec@5 68.880\n",
      " * Prec@1 46.649 Prec@5 69.008\n",
      " * Prec@1 46.684 Prec@5 69.005\n",
      " * Prec@1 46.654 Prec@5 68.939\n",
      " * Prec@1 46.562 Prec@5 68.812\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.517 (0.509)\n",
      "\n",
      "Loss 2.5287 (2.6993)\n",
      "\n",
      "Prec@1 56.250 (46.658)\n",
      "\n",
      "Prec@5 68.750 (68.812)\n",
      "\n",
      " * Prec@1 46.658 Prec@5 68.812\n",
      " * Prec@1 46.691 Prec@5 68.811\n",
      " * Prec@1 46.723 Prec@5 68.811\n",
      " * Prec@1 46.875 Prec@5 68.750\n",
      " * Prec@1 46.964 Prec@5 68.750\n",
      " * Prec@1 47.052 Prec@5 68.809\n",
      " * Prec@1 47.079 Prec@5 68.867\n",
      " * Prec@1 47.049 Prec@5 68.808\n",
      " * Prec@1 47.133 Prec@5 68.807\n",
      " * Prec@1 47.159 Prec@5 68.920\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.566 (0.508)\n",
      "\n",
      "Loss 2.0408 (2.6683)\n",
      "\n",
      "Prec@1 50.000 (47.185)\n",
      "\n",
      "Prec@5 81.250 (69.032)\n",
      "\n",
      " * Prec@1 47.185 Prec@5 69.032\n",
      " * Prec@1 47.210 Prec@5 68.973\n",
      " * Prec@1 47.290 Prec@5 69.027\n",
      " * Prec@1 47.314 Prec@5 68.969\n",
      " * Prec@1 47.446 Prec@5 68.913\n",
      " * Prec@1 47.414 Prec@5 69.073\n",
      " * Prec@1 47.276 Prec@5 69.017\n",
      " * Prec@1 47.352 Prec@5 69.068\n",
      " * Prec@1 47.269 Prec@5 68.960\n",
      " * Prec@1 47.135 Prec@5 68.958\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.503 (0.508)\n",
      "\n",
      "Loss 1.8498 (2.6688)\n",
      "\n",
      "Prec@1 62.500 (47.262)\n",
      "\n",
      "Prec@5 81.250 (69.060)\n",
      "\n",
      " * Prec@1 47.262 Prec@5 69.060\n",
      " * Prec@1 47.336 Prec@5 69.109\n",
      " * Prec@1 47.510 Prec@5 69.309\n",
      " * Prec@1 47.228 Prec@5 69.002\n",
      " * Prec@1 47.200 Prec@5 68.950\n",
      " * Prec@1 47.173 Prec@5 68.849\n",
      " * Prec@1 47.293 Prec@5 68.947\n",
      " * Prec@1 47.217 Prec@5 68.945\n",
      " * Prec@1 47.335 Prec@5 69.138\n",
      " * Prec@1 47.308 Prec@5 69.183\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.519 (0.508)\n",
      "\n",
      "Loss 3.2565 (2.6573)\n",
      "\n",
      "Prec@1 43.750 (47.281)\n",
      "\n",
      "Prec@5 62.500 (69.132)\n",
      "\n",
      " * Prec@1 47.281 Prec@5 69.132\n",
      " * Prec@1 47.396 Prec@5 69.176\n",
      " * Prec@1 47.462 Prec@5 69.126\n",
      " * Prec@1 47.388 Prec@5 69.076\n",
      " * Prec@1 47.454 Prec@5 69.167\n",
      " * Prec@1 47.564 Prec@5 69.210\n",
      " * Prec@1 47.582 Prec@5 69.297\n",
      " * Prec@1 47.600 Prec@5 69.248\n",
      " * Prec@1 47.707 Prec@5 69.245\n",
      " * Prec@1 47.723 Prec@5 69.286\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.493 (0.507)\n",
      "\n",
      "Loss 2.7331 (2.6361)\n",
      "\n",
      "Prec@1 43.750 (47.695)\n",
      "\n",
      "Prec@5 75.000 (69.326)\n",
      "\n",
      " * Prec@1 47.695 Prec@5 69.326\n",
      " * Prec@1 47.642 Prec@5 69.370\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [14][0/1276]\t\\Time 0.570 (0.570)\tData 0.430 (0.430)\tLoss 1.2897 (1.2897)\tPrec@1 62.500 (62.500)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [14][100/1276]\t\\Time 0.510 (0.495)\tData 0.390 (0.396)\tLoss 1.3164 (1.1469)\tPrec@1 68.750 (70.978)\tPrec@5 87.500 (89.790)\n",
      "Epoch: [14][200/1276]\t\\Time 0.531 (0.499)\tData 0.430 (0.399)\tLoss 0.9564 (1.1306)\tPrec@1 62.500 (70.833)\tPrec@5 93.750 (91.045)\n",
      "Epoch: [14][300/1276]\t\\Time 0.470 (0.499)\tData 0.390 (0.400)\tLoss 1.1096 (1.1515)\tPrec@1 81.250 (70.411)\tPrec@5 93.750 (90.718)\n",
      "Epoch: [14][400/1276]\t\\Time 0.471 (0.499)\tData 0.366 (0.399)\tLoss 1.5038 (1.1771)\tPrec@1 62.500 (69.888)\tPrec@5 81.250 (90.150)\n",
      "Epoch: [14][500/1276]\t\\Time 0.541 (0.500)\tData 0.431 (0.399)\tLoss 1.4154 (1.1929)\tPrec@1 68.750 (69.548)\tPrec@5 93.750 (89.870)\n",
      "Epoch: [14][600/1276]\t\\Time 0.500 (0.499)\tData 0.400 (0.399)\tLoss 1.4445 (1.2358)\tPrec@1 62.500 (68.448)\tPrec@5 93.750 (89.081)\n",
      "Epoch: [14][700/1276]\t\\Time 0.530 (0.499)\tData 0.421 (0.399)\tLoss 1.9092 (1.2447)\tPrec@1 68.750 (68.447)\tPrec@5 75.000 (88.989)\n",
      "Epoch: [14][800/1276]\t\\Time 0.547 (0.499)\tData 0.437 (0.399)\tLoss 1.1366 (1.2531)\tPrec@1 68.750 (68.118)\tPrec@5 93.750 (88.826)\n",
      "Epoch: [14][900/1276]\t\\Time 0.501 (0.499)\tData 0.401 (0.399)\tLoss 2.0146 (1.2638)\tPrec@1 50.000 (67.848)\tPrec@5 87.500 (88.624)\n",
      "Epoch: [14][1000/1276]\t\\Time 0.490 (0.499)\tData 0.410 (0.399)\tLoss 1.6330 (1.2700)\tPrec@1 56.250 (67.751)\tPrec@5 81.250 (88.536)\n",
      "Epoch: [14][1100/1276]\t\\Time 0.394 (0.499)\tData 0.324 (0.399)\tLoss 1.5945 (1.2816)\tPrec@1 68.750 (67.501)\tPrec@5 81.250 (88.215)\n",
      "Epoch: [14][1200/1276]\t\\Time 0.457 (0.499)\tData 0.377 (0.399)\tLoss 1.3299 (1.2907)\tPrec@1 68.750 (67.340)\tPrec@5 81.250 (88.067)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.412 (0.412)\n",
      "\n",
      "Loss 3.1526 (3.1526)\n",
      "\n",
      "Prec@1 37.500 (37.500)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 68.750\n",
      " * Prec@1 46.875 Prec@5 71.875\n",
      " * Prec@1 41.667 Prec@5 66.667\n",
      " * Prec@1 42.188 Prec@5 65.625\n",
      " * Prec@1 42.500 Prec@5 66.250\n",
      " * Prec@1 41.667 Prec@5 66.667\n",
      " * Prec@1 42.857 Prec@5 67.857\n",
      " * Prec@1 43.750 Prec@5 68.750\n",
      " * Prec@1 43.056 Prec@5 68.056\n",
      " * Prec@1 45.625 Prec@5 68.750\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.481 (0.491)\n",
      "\n",
      "Loss 2.0184 (2.6799)\n",
      "\n",
      "Prec@1 56.250 (46.591)\n",
      "\n",
      "Prec@5 81.250 (69.886)\n",
      "\n",
      " * Prec@1 46.591 Prec@5 69.886\n",
      " * Prec@1 47.396 Prec@5 70.833\n",
      " * Prec@1 47.596 Prec@5 71.154\n",
      " * Prec@1 48.214 Prec@5 71.429\n",
      " * Prec@1 48.750 Prec@5 71.250\n",
      " * Prec@1 48.438 Prec@5 70.703\n",
      " * Prec@1 50.735 Prec@5 72.426\n",
      " * Prec@1 51.389 Prec@5 72.917\n",
      " * Prec@1 50.987 Prec@5 72.697\n",
      " * Prec@1 51.250 Prec@5 72.500\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.526 (0.494)\n",
      "\n",
      "Loss 3.3908 (2.4916)\n",
      "\n",
      "Prec@1 56.250 (51.488)\n",
      "\n",
      "Prec@5 68.750 (72.321)\n",
      "\n",
      " * Prec@1 51.488 Prec@5 72.321\n",
      " * Prec@1 51.705 Prec@5 71.875\n",
      " * Prec@1 51.902 Prec@5 72.011\n",
      " * Prec@1 51.562 Prec@5 72.135\n",
      " * Prec@1 51.750 Prec@5 72.750\n",
      " * Prec@1 51.923 Prec@5 72.837\n",
      " * Prec@1 52.083 Prec@5 72.917\n",
      " * Prec@1 51.562 Prec@5 72.545\n",
      " * Prec@1 50.862 Prec@5 72.414\n",
      " * Prec@1 50.625 Prec@5 71.875\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.532 (0.495)\n",
      "\n",
      "Loss 4.2645 (2.4952)\n",
      "\n",
      "Prec@1 25.000 (49.798)\n",
      "\n",
      "Prec@5 62.500 (71.573)\n",
      "\n",
      " * Prec@1 49.798 Prec@5 71.573\n",
      " * Prec@1 49.609 Prec@5 71.875\n",
      " * Prec@1 49.432 Prec@5 72.159\n",
      " * Prec@1 49.816 Prec@5 72.059\n",
      " * Prec@1 49.821 Prec@5 72.143\n",
      " * Prec@1 49.479 Prec@5 72.049\n",
      " * Prec@1 49.662 Prec@5 72.128\n",
      " * Prec@1 49.507 Prec@5 72.039\n",
      " * Prec@1 49.679 Prec@5 72.115\n",
      " * Prec@1 49.688 Prec@5 72.031\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.432 (0.496)\n",
      "\n",
      "Loss 3.5811 (2.5142)\n",
      "\n",
      "Prec@1 37.500 (49.390)\n",
      "\n",
      "Prec@5 50.000 (71.494)\n",
      "\n",
      " * Prec@1 49.390 Prec@5 71.494\n",
      " * Prec@1 48.958 Prec@5 70.833\n",
      " * Prec@1 48.983 Prec@5 71.076\n",
      " * Prec@1 49.006 Prec@5 71.165\n",
      " * Prec@1 48.889 Prec@5 70.972\n",
      " * Prec@1 48.777 Prec@5 70.788\n",
      " * Prec@1 48.803 Prec@5 70.878\n",
      " * Prec@1 48.438 Prec@5 70.833\n",
      " * Prec@1 48.724 Prec@5 70.791\n",
      " * Prec@1 48.500 Prec@5 70.250\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.481 (0.496)\n",
      "\n",
      "Loss 1.3368 (2.5792)\n",
      "\n",
      "Prec@1 68.750 (48.897)\n",
      "\n",
      "Prec@5 81.250 (70.466)\n",
      "\n",
      " * Prec@1 48.897 Prec@5 70.466\n",
      " * Prec@1 48.798 Prec@5 70.433\n",
      " * Prec@1 48.585 Prec@5 70.283\n",
      " * Prec@1 48.958 Prec@5 70.486\n",
      " * Prec@1 49.091 Prec@5 70.682\n",
      " * Prec@1 49.107 Prec@5 70.871\n",
      " * Prec@1 49.013 Prec@5 70.724\n",
      " * Prec@1 49.353 Prec@5 70.797\n",
      " * Prec@1 49.364 Prec@5 70.657\n",
      " * Prec@1 49.271 Prec@5 70.729\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.484 (0.498)\n",
      "\n",
      "Loss 3.0757 (2.5895)\n",
      "\n",
      "Prec@1 56.250 (49.385)\n",
      "\n",
      "Prec@5 75.000 (70.799)\n",
      "\n",
      " * Prec@1 49.385 Prec@5 70.799\n",
      " * Prec@1 49.597 Prec@5 70.766\n",
      " * Prec@1 49.802 Prec@5 70.635\n",
      " * Prec@1 49.805 Prec@5 70.996\n",
      " * Prec@1 49.712 Prec@5 71.154\n",
      " * Prec@1 49.905 Prec@5 71.117\n",
      " * Prec@1 50.187 Prec@5 71.362\n",
      " * Prec@1 50.092 Prec@5 71.324\n",
      " * Prec@1 50.181 Prec@5 71.286\n",
      " * Prec@1 50.000 Prec@5 71.250\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.521 (0.502)\n",
      "\n",
      "Loss 2.7440 (2.5718)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 68.750 (71.215)\n",
      "\n",
      " * Prec@1 50.000 Prec@5 71.215\n",
      " * Prec@1 49.913 Prec@5 71.181\n",
      " * Prec@1 49.914 Prec@5 71.147\n",
      " * Prec@1 49.747 Prec@5 70.861\n",
      " * Prec@1 49.750 Prec@5 70.917\n",
      " * Prec@1 49.671 Prec@5 70.806\n",
      " * Prec@1 49.756 Prec@5 70.860\n",
      " * Prec@1 49.840 Prec@5 70.833\n",
      " * Prec@1 49.684 Prec@5 70.728\n",
      " * Prec@1 49.375 Prec@5 70.625\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.528 (0.503)\n",
      "\n",
      "Loss 3.3914 (2.6372)\n",
      "\n",
      "Prec@1 43.750 (49.306)\n",
      "\n",
      "Prec@5 56.250 (70.448)\n",
      "\n",
      " * Prec@1 49.306 Prec@5 70.448\n",
      " * Prec@1 49.162 Prec@5 70.351\n",
      " * Prec@1 49.172 Prec@5 70.256\n",
      " * Prec@1 49.182 Prec@5 70.238\n",
      " * Prec@1 49.412 Prec@5 70.368\n",
      " * Prec@1 49.564 Prec@5 70.567\n",
      " * Prec@1 49.856 Prec@5 70.690\n",
      " * Prec@1 49.929 Prec@5 70.810\n",
      " * Prec@1 50.140 Prec@5 70.927\n",
      " * Prec@1 50.069 Prec@5 70.972\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.450 (0.503)\n",
      "\n",
      "Loss 2.6756 (2.6269)\n",
      "\n",
      "Prec@1 56.250 (50.137)\n",
      "\n",
      "Prec@5 75.000 (71.016)\n",
      "\n",
      " * Prec@1 50.137 Prec@5 71.016\n",
      " * Prec@1 50.272 Prec@5 71.060\n",
      " * Prec@1 50.403 Prec@5 71.169\n",
      " * Prec@1 50.266 Prec@5 71.210\n",
      " * Prec@1 50.263 Prec@5 71.118\n",
      " * Prec@1 50.456 Prec@5 71.354\n",
      " * Prec@1 50.580 Prec@5 71.521\n",
      " * Prec@1 50.446 Prec@5 71.429\n",
      " * Prec@1 50.442 Prec@5 71.465\n",
      " * Prec@1 50.438 Prec@5 71.500\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.565 (0.503)\n",
      "\n",
      "Loss 2.2812 (2.6014)\n",
      "\n",
      "Prec@1 50.000 (50.433)\n",
      "\n",
      "Prec@5 62.500 (71.411)\n",
      "\n",
      " * Prec@1 50.433 Prec@5 71.411\n",
      " * Prec@1 50.490 Prec@5 71.385\n",
      " * Prec@1 50.546 Prec@5 71.420\n",
      " * Prec@1 50.601 Prec@5 71.514\n",
      " * Prec@1 50.714 Prec@5 71.607\n",
      " * Prec@1 50.708 Prec@5 71.757\n",
      " * Prec@1 50.818 Prec@5 71.787\n",
      " * Prec@1 50.810 Prec@5 71.701\n",
      " * Prec@1 50.860 Prec@5 71.732\n",
      " * Prec@1 50.909 Prec@5 71.989\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.532 (0.503)\n",
      "\n",
      "Loss 2.4035 (2.5640)\n",
      "\n",
      "Prec@1 56.250 (50.957)\n",
      "\n",
      "Prec@5 62.500 (71.903)\n",
      "\n",
      " * Prec@1 50.957 Prec@5 71.903\n",
      " * Prec@1 51.060 Prec@5 71.931\n",
      " * Prec@1 51.106 Prec@5 72.013\n",
      " * Prec@1 51.042 Prec@5 71.930\n",
      " * Prec@1 50.924 Prec@5 71.957\n",
      " * Prec@1 50.970 Prec@5 71.929\n",
      " * Prec@1 50.908 Prec@5 71.795\n",
      " * Prec@1 50.794 Prec@5 71.716\n",
      " * Prec@1 50.893 Prec@5 71.796\n",
      " * Prec@1 50.833 Prec@5 71.771\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.501 (0.503)\n",
      "\n",
      "Loss 1.6087 (2.5617)\n",
      "\n",
      "Prec@1 75.000 (51.033)\n",
      "\n",
      "Prec@5 81.250 (71.849)\n",
      "\n",
      " * Prec@1 51.033 Prec@5 71.849\n",
      " * Prec@1 51.127 Prec@5 71.875\n",
      " * Prec@1 51.270 Prec@5 72.053\n",
      " * Prec@1 51.008 Prec@5 71.825\n",
      " * Prec@1 51.000 Prec@5 71.850\n",
      " * Prec@1 50.942 Prec@5 71.925\n",
      " * Prec@1 50.935 Prec@5 71.998\n",
      " * Prec@1 51.074 Prec@5 72.021\n",
      " * Prec@1 51.163 Prec@5 72.093\n",
      " * Prec@1 51.250 Prec@5 72.212\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.501 (0.503)\n",
      "\n",
      "Loss 3.3220 (2.5570)\n",
      "\n",
      "Prec@1 50.000 (51.240)\n",
      "\n",
      "Prec@5 62.500 (72.137)\n",
      "\n",
      " * Prec@1 51.240 Prec@5 72.137\n",
      " * Prec@1 51.326 Prec@5 72.159\n",
      " * Prec@1 51.363 Prec@5 72.086\n",
      " * Prec@1 51.353 Prec@5 72.015\n",
      " * Prec@1 51.574 Prec@5 72.130\n",
      " * Prec@1 51.562 Prec@5 72.105\n",
      " * Prec@1 51.551 Prec@5 72.126\n",
      " * Prec@1 51.585 Prec@5 72.101\n",
      " * Prec@1 51.574 Prec@5 72.077\n",
      " * Prec@1 51.607 Prec@5 72.143\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.483 (0.502)\n",
      "\n",
      "Loss 2.3465 (2.5538)\n",
      "\n",
      "Prec@1 62.500 (51.684)\n",
      "\n",
      "Prec@5 81.250 (72.207)\n",
      "\n",
      " * Prec@1 51.684 Prec@5 72.207\n",
      " * Prec@1 51.697 Prec@5 72.234\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [15][0/1276]\t\\Time 0.500 (0.500)\tData 0.380 (0.380)\tLoss 0.6017 (0.6017)\tPrec@1 81.250 (81.250)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [15][100/1276]\t\\Time 0.495 (0.505)\tData 0.412 (0.404)\tLoss 0.7164 (0.7722)\tPrec@1 81.250 (79.270)\tPrec@5 93.750 (95.050)\n",
      "Epoch: [15][200/1276]\t\\Time 0.517 (0.501)\tData 0.417 (0.401)\tLoss 1.0370 (0.7672)\tPrec@1 75.000 (79.353)\tPrec@5 81.250 (94.652)\n",
      "Epoch: [15][300/1276]\t\\Time 0.552 (0.501)\tData 0.442 (0.401)\tLoss 0.9820 (0.7837)\tPrec@1 75.000 (79.132)\tPrec@5 93.750 (94.311)\n",
      "Epoch: [15][400/1276]\t\\Time 0.440 (0.501)\tData 0.320 (0.400)\tLoss 1.4186 (0.8256)\tPrec@1 50.000 (77.837)\tPrec@5 93.750 (93.984)\n",
      "Epoch: [15][500/1276]\t\\Time 0.491 (0.500)\tData 0.380 (0.400)\tLoss 1.3202 (0.8432)\tPrec@1 62.500 (77.607)\tPrec@5 87.500 (93.825)\n",
      "Epoch: [15][600/1276]\t\\Time 0.500 (0.500)\tData 0.370 (0.399)\tLoss 0.8813 (0.8752)\tPrec@1 62.500 (76.674)\tPrec@5 93.750 (93.459)\n",
      "Epoch: [15][700/1276]\t\\Time 0.493 (0.500)\tData 0.411 (0.400)\tLoss 1.2198 (0.9043)\tPrec@1 75.000 (75.811)\tPrec@5 87.500 (93.197)\n",
      "Epoch: [15][800/1276]\t\\Time 0.528 (0.501)\tData 0.418 (0.401)\tLoss 0.9080 (0.9266)\tPrec@1 68.750 (75.382)\tPrec@5 100.000 (92.900)\n",
      "Epoch: [15][900/1276]\t\\Time 0.540 (0.501)\tData 0.430 (0.400)\tLoss 0.6461 (0.9432)\tPrec@1 81.250 (75.118)\tPrec@5 100.000 (92.709)\n",
      "Epoch: [15][1000/1276]\t\\Time 0.451 (0.501)\tData 0.371 (0.401)\tLoss 0.4668 (0.9572)\tPrec@1 93.750 (74.831)\tPrec@5 100.000 (92.526)\n",
      "Epoch: [15][1100/1276]\t\\Time 0.492 (0.501)\tData 0.391 (0.401)\tLoss 1.4734 (0.9700)\tPrec@1 75.000 (74.483)\tPrec@5 87.500 (92.365)\n",
      "Epoch: [15][1200/1276]\t\\Time 0.501 (0.502)\tData 0.421 (0.402)\tLoss 1.4003 (0.9873)\tPrec@1 68.750 (74.048)\tPrec@5 81.250 (92.158)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.450 (0.450)\n",
      "\n",
      "Loss 3.0428 (3.0428)\n",
      "\n",
      "Prec@1 56.250 (56.250)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 68.750\n",
      " * Prec@1 59.375 Prec@5 78.125\n",
      " * Prec@1 58.333 Prec@5 72.917\n",
      " * Prec@1 56.250 Prec@5 68.750\n",
      " * Prec@1 56.250 Prec@5 68.750\n",
      " * Prec@1 55.208 Prec@5 68.750\n",
      " * Prec@1 57.143 Prec@5 68.750\n",
      " * Prec@1 56.250 Prec@5 70.312\n",
      " * Prec@1 56.250 Prec@5 70.139\n",
      " * Prec@1 56.250 Prec@5 71.250\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.481 (0.485)\n",
      "\n",
      "Loss 1.8555 (2.5300)\n",
      "\n",
      "Prec@1 81.250 (58.523)\n",
      "\n",
      "Prec@5 81.250 (72.159)\n",
      "\n",
      " * Prec@1 58.523 Prec@5 72.159\n",
      " * Prec@1 58.854 Prec@5 72.917\n",
      " * Prec@1 57.692 Prec@5 73.558\n",
      " * Prec@1 57.589 Prec@5 74.107\n",
      " * Prec@1 57.917 Prec@5 75.417\n",
      " * Prec@1 57.422 Prec@5 75.391\n",
      " * Prec@1 59.191 Prec@5 76.838\n",
      " * Prec@1 58.333 Prec@5 77.083\n",
      " * Prec@1 58.224 Prec@5 77.303\n",
      " * Prec@1 57.500 Prec@5 76.562\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.588 (0.499)\n",
      "\n",
      "Loss 3.4769 (2.3086)\n",
      "\n",
      "Prec@1 50.000 (57.143)\n",
      "\n",
      "Prec@5 68.750 (76.190)\n",
      "\n",
      " * Prec@1 57.143 Prec@5 76.190\n",
      " * Prec@1 57.386 Prec@5 75.852\n",
      " * Prec@1 57.880 Prec@5 76.087\n",
      " * Prec@1 58.073 Prec@5 76.302\n",
      " * Prec@1 59.000 Prec@5 76.750\n",
      " * Prec@1 58.894 Prec@5 76.683\n",
      " * Prec@1 59.259 Prec@5 76.852\n",
      " * Prec@1 58.929 Prec@5 76.786\n",
      " * Prec@1 58.405 Prec@5 76.509\n",
      " * Prec@1 58.333 Prec@5 76.250\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.511 (0.501)\n",
      "\n",
      "Loss 4.1774 (2.3434)\n",
      "\n",
      "Prec@1 43.750 (57.863)\n",
      "\n",
      "Prec@5 56.250 (75.605)\n",
      "\n",
      " * Prec@1 57.863 Prec@5 75.605\n",
      " * Prec@1 58.008 Prec@5 75.586\n",
      " * Prec@1 57.955 Prec@5 75.758\n",
      " * Prec@1 58.088 Prec@5 75.735\n",
      " * Prec@1 57.679 Prec@5 75.536\n",
      " * Prec@1 58.160 Prec@5 75.868\n",
      " * Prec@1 58.108 Prec@5 75.845\n",
      " * Prec@1 57.895 Prec@5 75.493\n",
      " * Prec@1 57.532 Prec@5 75.641\n",
      " * Prec@1 57.812 Prec@5 75.781\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.450 (0.500)\n",
      "\n",
      "Loss 2.6150 (2.3167)\n",
      "\n",
      "Prec@1 56.250 (57.774)\n",
      "\n",
      "Prec@5 75.000 (75.762)\n",
      "\n",
      " * Prec@1 57.774 Prec@5 75.762\n",
      " * Prec@1 57.143 Prec@5 75.149\n",
      " * Prec@1 57.267 Prec@5 75.291\n",
      " * Prec@1 57.244 Prec@5 75.284\n",
      " * Prec@1 56.389 Prec@5 74.722\n",
      " * Prec@1 56.386 Prec@5 74.728\n",
      " * Prec@1 56.516 Prec@5 74.734\n",
      " * Prec@1 56.510 Prec@5 74.609\n",
      " * Prec@1 56.888 Prec@5 74.872\n",
      " * Prec@1 56.750 Prec@5 74.750\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.470 (0.498)\n",
      "\n",
      "Loss 1.3459 (2.3808)\n",
      "\n",
      "Prec@1 75.000 (57.108)\n",
      "\n",
      "Prec@5 87.500 (75.000)\n",
      "\n",
      " * Prec@1 57.108 Prec@5 75.000\n",
      " * Prec@1 56.971 Prec@5 75.000\n",
      " * Prec@1 56.840 Prec@5 74.764\n",
      " * Prec@1 56.944 Prec@5 74.884\n",
      " * Prec@1 57.273 Prec@5 75.000\n",
      " * Prec@1 57.031 Prec@5 75.000\n",
      " * Prec@1 56.798 Prec@5 74.781\n",
      " * Prec@1 57.112 Prec@5 74.784\n",
      " * Prec@1 57.097 Prec@5 74.788\n",
      " * Prec@1 56.979 Prec@5 74.688\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.473 (0.500)\n",
      "\n",
      "Loss 2.2950 (2.4312)\n",
      "\n",
      "Prec@1 75.000 (57.275)\n",
      "\n",
      "Prec@5 81.250 (74.795)\n",
      "\n",
      " * Prec@1 57.275 Prec@5 74.795\n",
      " * Prec@1 57.359 Prec@5 74.798\n",
      " * Prec@1 57.341 Prec@5 74.702\n",
      " * Prec@1 57.520 Prec@5 74.902\n",
      " * Prec@1 57.500 Prec@5 74.904\n",
      " * Prec@1 57.197 Prec@5 74.811\n",
      " * Prec@1 57.369 Prec@5 75.093\n",
      " * Prec@1 57.445 Prec@5 75.092\n",
      " * Prec@1 57.246 Prec@5 74.909\n",
      " * Prec@1 57.321 Prec@5 74.821\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.500 (0.504)\n",
      "\n",
      "Loss 3.2280 (2.4385)\n",
      "\n",
      "Prec@1 62.500 (57.394)\n",
      "\n",
      "Prec@5 62.500 (74.648)\n",
      "\n",
      " * Prec@1 57.394 Prec@5 74.648\n",
      " * Prec@1 57.292 Prec@5 74.479\n",
      " * Prec@1 57.021 Prec@5 74.315\n",
      " * Prec@1 56.503 Prec@5 74.071\n",
      " * Prec@1 56.417 Prec@5 74.000\n",
      " * Prec@1 56.332 Prec@5 74.013\n",
      " * Prec@1 56.494 Prec@5 74.026\n",
      " * Prec@1 56.250 Prec@5 73.958\n",
      " * Prec@1 56.329 Prec@5 74.130\n",
      " * Prec@1 56.094 Prec@5 73.984\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.488 (0.504)\n",
      "\n",
      "Loss 3.2870 (2.5234)\n",
      "\n",
      "Prec@1 31.250 (55.787)\n",
      "\n",
      "Prec@5 62.500 (73.843)\n",
      "\n",
      " * Prec@1 55.787 Prec@5 73.843\n",
      " * Prec@1 55.716 Prec@5 73.780\n",
      " * Prec@1 55.648 Prec@5 73.494\n",
      " * Prec@1 55.804 Prec@5 73.586\n",
      " * Prec@1 55.956 Prec@5 73.676\n",
      " * Prec@1 56.032 Prec@5 73.837\n",
      " * Prec@1 56.178 Prec@5 73.994\n",
      " * Prec@1 56.392 Prec@5 74.077\n",
      " * Prec@1 56.461 Prec@5 74.157\n",
      " * Prec@1 56.458 Prec@5 74.028\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.450 (0.504)\n",
      "\n",
      "Loss 3.6012 (2.5489)\n",
      "\n",
      "Prec@1 37.500 (56.250)\n",
      "\n",
      "Prec@5 62.500 (73.901)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 73.901\n",
      " * Prec@1 56.182 Prec@5 73.913\n",
      " * Prec@1 56.317 Prec@5 73.925\n",
      " * Prec@1 56.449 Prec@5 73.870\n",
      " * Prec@1 56.513 Prec@5 73.816\n",
      " * Prec@1 56.706 Prec@5 73.958\n",
      " * Prec@1 56.765 Prec@5 74.098\n",
      " * Prec@1 56.760 Prec@5 74.107\n",
      " * Prec@1 56.755 Prec@5 74.116\n",
      " * Prec@1 56.750 Prec@5 74.062\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.561 (0.504)\n",
      "\n",
      "Loss 2.5106 (2.5403)\n",
      "\n",
      "Prec@1 50.000 (56.683)\n",
      "\n",
      "Prec@5 75.000 (74.072)\n",
      "\n",
      " * Prec@1 56.683 Prec@5 74.072\n",
      " * Prec@1 56.801 Prec@5 74.081\n",
      " * Prec@1 56.857 Prec@5 74.211\n",
      " * Prec@1 56.851 Prec@5 74.339\n",
      " * Prec@1 56.905 Prec@5 74.464\n",
      " * Prec@1 56.840 Prec@5 74.528\n",
      " * Prec@1 56.776 Prec@5 74.591\n",
      " * Prec@1 56.829 Prec@5 74.537\n",
      " * Prec@1 56.766 Prec@5 74.484\n",
      " * Prec@1 57.102 Prec@5 74.716\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.510 (0.503)\n",
      "\n",
      "Loss 2.7780 (2.5119)\n",
      "\n",
      "Prec@1 50.000 (57.038)\n",
      "\n",
      "Prec@5 81.250 (74.775)\n",
      "\n",
      " * Prec@1 57.038 Prec@5 74.775\n",
      " * Prec@1 57.087 Prec@5 74.833\n",
      " * Prec@1 57.135 Prec@5 74.889\n",
      " * Prec@1 57.072 Prec@5 74.890\n",
      " * Prec@1 57.283 Prec@5 74.946\n",
      " * Prec@1 57.220 Prec@5 75.000\n",
      " * Prec@1 57.158 Prec@5 74.893\n",
      " * Prec@1 57.097 Prec@5 74.841\n",
      " * Prec@1 57.195 Prec@5 74.947\n",
      " * Prec@1 57.188 Prec@5 74.948\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.480 (0.504)\n",
      "\n",
      "Loss 1.3185 (2.4947)\n",
      "\n",
      "Prec@1 68.750 (57.283)\n",
      "\n",
      "Prec@5 87.500 (75.052)\n",
      "\n",
      " * Prec@1 57.283 Prec@5 75.052\n",
      " * Prec@1 57.377 Prec@5 75.051\n",
      " * Prec@1 57.470 Prec@5 75.203\n",
      " * Prec@1 57.308 Prec@5 75.000\n",
      " * Prec@1 57.350 Prec@5 75.000\n",
      " * Prec@1 57.242 Prec@5 75.000\n",
      " * Prec@1 57.283 Prec@5 75.049\n",
      " * Prec@1 57.178 Prec@5 74.951\n",
      " * Prec@1 57.316 Prec@5 75.097\n",
      " * Prec@1 57.308 Prec@5 75.240\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.541 (0.505)\n",
      "\n",
      "Loss 2.7010 (2.4802)\n",
      "\n",
      "Prec@1 56.250 (57.300)\n",
      "\n",
      "Prec@5 68.750 (75.191)\n",
      "\n",
      " * Prec@1 57.300 Prec@5 75.191\n",
      " * Prec@1 57.339 Prec@5 75.189\n",
      " * Prec@1 57.331 Prec@5 75.235\n",
      " * Prec@1 57.183 Prec@5 75.047\n",
      " * Prec@1 57.176 Prec@5 75.046\n",
      " * Prec@1 57.169 Prec@5 75.000\n",
      " * Prec@1 57.162 Prec@5 74.863\n",
      " * Prec@1 57.292 Prec@5 74.909\n",
      " * Prec@1 57.284 Prec@5 74.910\n",
      " * Prec@1 57.411 Prec@5 75.000\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.506 (0.503)\n",
      "\n",
      "Loss 2.6375 (2.4846)\n",
      "\n",
      "Prec@1 50.000 (57.358)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      " * Prec@1 57.358 Prec@5 75.000\n",
      " * Prec@1 57.338 Prec@5 75.055\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [16][0/1276]\t\\Time 0.511 (0.511)\tData 0.411 (0.411)\tLoss 0.4580 (0.4580)\tPrec@1 93.750 (93.750)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [16][100/1276]\t\\Time 0.571 (0.500)\tData 0.471 (0.400)\tLoss 0.2282 (0.5625)\tPrec@1 100.000 (84.097)\tPrec@5 100.000 (97.339)\n",
      "Epoch: [16][200/1276]\t\\Time 0.451 (0.502)\tData 0.351 (0.401)\tLoss 0.3741 (0.5770)\tPrec@1 87.500 (83.862)\tPrec@5 93.750 (97.233)\n",
      "Epoch: [16][300/1276]\t\\Time 0.553 (0.502)\tData 0.443 (0.402)\tLoss 0.7018 (0.5997)\tPrec@1 75.000 (83.472)\tPrec@5 100.000 (96.761)\n",
      "Epoch: [16][400/1276]\t\\Time 0.545 (0.500)\tData 0.431 (0.400)\tLoss 0.2540 (0.6007)\tPrec@1 87.500 (83.557)\tPrec@5 100.000 (96.680)\n",
      "Epoch: [16][500/1276]\t\\Time 0.527 (0.502)\tData 0.413 (0.402)\tLoss 0.9417 (0.5993)\tPrec@1 68.750 (83.483)\tPrec@5 100.000 (96.707)\n",
      "Epoch: [16][600/1276]\t\\Time 0.409 (0.502)\tData 0.329 (0.402)\tLoss 0.5653 (0.6044)\tPrec@1 87.500 (83.288)\tPrec@5 100.000 (96.672)\n",
      "Epoch: [16][700/1276]\t\\Time 0.521 (0.502)\tData 0.391 (0.402)\tLoss 1.5014 (0.6220)\tPrec@1 75.000 (82.926)\tPrec@5 81.250 (96.532)\n",
      "Epoch: [16][800/1276]\t\\Time 0.491 (0.503)\tData 0.409 (0.403)\tLoss 0.6852 (0.6471)\tPrec@1 75.000 (82.233)\tPrec@5 100.000 (96.255)\n",
      "Epoch: [16][900/1276]\t\\Time 0.491 (0.503)\tData 0.383 (0.403)\tLoss 1.2561 (0.6585)\tPrec@1 68.750 (81.853)\tPrec@5 93.750 (96.095)\n",
      "Epoch: [16][1000/1276]\t\\Time 0.410 (0.503)\tData 0.330 (0.403)\tLoss 0.8819 (0.6748)\tPrec@1 81.250 (81.537)\tPrec@5 87.500 (95.848)\n",
      "Epoch: [16][1100/1276]\t\\Time 0.540 (0.504)\tData 0.410 (0.403)\tLoss 0.5777 (0.6813)\tPrec@1 75.000 (81.352)\tPrec@5 87.500 (95.748)\n",
      "Epoch: [16][1200/1276]\t\\Time 0.483 (0.505)\tData 0.381 (0.404)\tLoss 0.9720 (0.6951)\tPrec@1 81.250 (80.953)\tPrec@5 87.500 (95.618)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.490 (0.490)\n",
      "\n",
      "Loss 3.2258 (3.2258)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 62.500 (62.500)\n",
      "\n",
      " * Prec@1 50.000 Prec@5 62.500\n",
      " * Prec@1 62.500 Prec@5 75.000\n",
      " * Prec@1 62.500 Prec@5 72.917\n",
      " * Prec@1 64.062 Prec@5 73.438\n",
      " * Prec@1 61.250 Prec@5 73.750\n",
      " * Prec@1 61.458 Prec@5 76.042\n",
      " * Prec@1 60.714 Prec@5 75.893\n",
      " * Prec@1 64.062 Prec@5 77.344\n",
      " * Prec@1 63.194 Prec@5 76.389\n",
      " * Prec@1 63.750 Prec@5 76.875\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.510 (0.522)\n",
      "\n",
      "Loss 1.7703 (2.3641)\n",
      "\n",
      "Prec@1 68.750 (64.205)\n",
      "\n",
      "Prec@5 81.250 (77.273)\n",
      "\n",
      " * Prec@1 64.205 Prec@5 77.273\n",
      " * Prec@1 63.542 Prec@5 77.083\n",
      " * Prec@1 63.942 Prec@5 77.885\n",
      " * Prec@1 64.732 Prec@5 79.018\n",
      " * Prec@1 65.417 Prec@5 79.583\n",
      " * Prec@1 64.453 Prec@5 78.516\n",
      " * Prec@1 66.176 Prec@5 79.779\n",
      " * Prec@1 66.319 Prec@5 79.167\n",
      " * Prec@1 65.789 Prec@5 78.947\n",
      " * Prec@1 64.688 Prec@5 78.750\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.532 (0.516)\n",
      "\n",
      "Loss 2.8568 (2.1855)\n",
      "\n",
      "Prec@1 68.750 (64.881)\n",
      "\n",
      "Prec@5 75.000 (78.571)\n",
      "\n",
      " * Prec@1 64.881 Prec@5 78.571\n",
      " * Prec@1 63.920 Prec@5 77.841\n",
      " * Prec@1 64.674 Prec@5 78.533\n",
      " * Prec@1 65.104 Prec@5 78.646\n",
      " * Prec@1 65.500 Prec@5 79.250\n",
      " * Prec@1 65.385 Prec@5 79.567\n",
      " * Prec@1 65.972 Prec@5 79.630\n",
      " * Prec@1 65.625 Prec@5 79.241\n",
      " * Prec@1 65.086 Prec@5 78.664\n",
      " * Prec@1 64.583 Prec@5 77.917\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.533 (0.520)\n",
      "\n",
      "Loss 4.5915 (2.2748)\n",
      "\n",
      "Prec@1 50.000 (64.113)\n",
      "\n",
      "Prec@5 62.500 (77.419)\n",
      "\n",
      " * Prec@1 64.113 Prec@5 77.419\n",
      " * Prec@1 64.258 Prec@5 77.539\n",
      " * Prec@1 64.583 Prec@5 77.462\n",
      " * Prec@1 64.890 Prec@5 77.390\n",
      " * Prec@1 65.000 Prec@5 77.321\n",
      " * Prec@1 65.278 Prec@5 77.778\n",
      " * Prec@1 65.034 Prec@5 77.703\n",
      " * Prec@1 65.132 Prec@5 78.125\n",
      " * Prec@1 65.224 Prec@5 78.205\n",
      " * Prec@1 65.000 Prec@5 78.438\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.509 (0.521)\n",
      "\n",
      "Loss 3.4130 (2.2328)\n",
      "\n",
      "Prec@1 37.500 (64.329)\n",
      "\n",
      "Prec@5 68.750 (78.201)\n",
      "\n",
      " * Prec@1 64.329 Prec@5 78.201\n",
      " * Prec@1 63.839 Prec@5 77.976\n",
      " * Prec@1 64.099 Prec@5 78.198\n",
      " * Prec@1 63.920 Prec@5 78.267\n",
      " * Prec@1 63.472 Prec@5 77.639\n",
      " * Prec@1 63.587 Prec@5 77.717\n",
      " * Prec@1 63.697 Prec@5 77.793\n",
      " * Prec@1 63.672 Prec@5 77.734\n",
      " * Prec@1 64.031 Prec@5 77.806\n",
      " * Prec@1 64.000 Prec@5 77.625\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.503 (0.519)\n",
      "\n",
      "Loss 0.7233 (2.2658)\n",
      "\n",
      "Prec@1 81.250 (64.338)\n",
      "\n",
      "Prec@5 93.750 (77.941)\n",
      "\n",
      " * Prec@1 64.338 Prec@5 77.941\n",
      " * Prec@1 64.062 Prec@5 77.885\n",
      " * Prec@1 63.679 Prec@5 77.358\n",
      " * Prec@1 64.005 Prec@5 77.546\n",
      " * Prec@1 64.091 Prec@5 77.614\n",
      " * Prec@1 64.062 Prec@5 77.567\n",
      " * Prec@1 63.816 Prec@5 77.303\n",
      " * Prec@1 63.901 Prec@5 77.371\n",
      " * Prec@1 63.983 Prec@5 77.331\n",
      " * Prec@1 63.958 Prec@5 77.292\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.466 (0.521)\n",
      "\n",
      "Loss 2.7582 (2.3179)\n",
      "\n",
      "Prec@1 68.750 (64.037)\n",
      "\n",
      "Prec@5 81.250 (77.357)\n",
      "\n",
      " * Prec@1 64.037 Prec@5 77.357\n",
      " * Prec@1 64.113 Prec@5 77.319\n",
      " * Prec@1 64.286 Prec@5 77.381\n",
      " * Prec@1 64.648 Prec@5 77.539\n",
      " * Prec@1 64.519 Prec@5 77.596\n",
      " * Prec@1 64.489 Prec@5 77.652\n",
      " * Prec@1 64.366 Prec@5 77.799\n",
      " * Prec@1 64.522 Prec@5 77.757\n",
      " * Prec@1 64.493 Prec@5 77.717\n",
      " * Prec@1 64.286 Prec@5 77.679\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.509 (0.523)\n",
      "\n",
      "Loss 2.2310 (2.2997)\n",
      "\n",
      "Prec@1 68.750 (64.349)\n",
      "\n",
      "Prec@5 75.000 (77.641)\n",
      "\n",
      " * Prec@1 64.349 Prec@5 77.641\n",
      " * Prec@1 64.149 Prec@5 77.604\n",
      " * Prec@1 63.955 Prec@5 77.483\n",
      " * Prec@1 63.598 Prec@5 77.111\n",
      " * Prec@1 63.417 Prec@5 77.083\n",
      " * Prec@1 63.405 Prec@5 77.056\n",
      " * Prec@1 63.555 Prec@5 77.029\n",
      " * Prec@1 63.702 Prec@5 77.003\n",
      " * Prec@1 63.766 Prec@5 77.057\n",
      " * Prec@1 63.516 Prec@5 76.953\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.536 (0.522)\n",
      "\n",
      "Loss 3.0435 (2.3819)\n",
      "\n",
      "Prec@1 50.000 (63.349)\n",
      "\n",
      "Prec@5 75.000 (76.929)\n",
      "\n",
      " * Prec@1 63.349 Prec@5 76.929\n",
      " * Prec@1 63.567 Prec@5 76.982\n",
      " * Prec@1 63.479 Prec@5 76.883\n",
      " * Prec@1 63.393 Prec@5 76.935\n",
      " * Prec@1 63.529 Prec@5 77.059\n",
      " * Prec@1 63.590 Prec@5 77.180\n",
      " * Prec@1 63.721 Prec@5 77.299\n",
      " * Prec@1 63.636 Prec@5 77.344\n",
      " * Prec@1 63.694 Prec@5 77.388\n",
      " * Prec@1 63.611 Prec@5 77.361\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.463 (0.523)\n",
      "\n",
      "Loss 3.5889 (2.3891)\n",
      "\n",
      "Prec@1 56.250 (63.530)\n",
      "\n",
      "Prec@5 68.750 (77.266)\n",
      "\n",
      " * Prec@1 63.530 Prec@5 77.266\n",
      " * Prec@1 63.519 Prec@5 77.310\n",
      " * Prec@1 63.642 Prec@5 77.285\n",
      " * Prec@1 63.564 Prec@5 77.327\n",
      " * Prec@1 63.553 Prec@5 77.171\n",
      " * Prec@1 63.607 Prec@5 77.279\n",
      " * Prec@1 63.789 Prec@5 77.320\n",
      " * Prec@1 63.776 Prec@5 77.296\n",
      " * Prec@1 63.826 Prec@5 77.336\n",
      " * Prec@1 63.812 Prec@5 77.375\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.552 (0.522)\n",
      "\n",
      "Loss 1.8345 (2.3837)\n",
      "\n",
      "Prec@1 68.750 (63.861)\n",
      "\n",
      "Prec@5 75.000 (77.351)\n",
      "\n",
      " * Prec@1 63.861 Prec@5 77.351\n",
      " * Prec@1 63.971 Prec@5 77.328\n",
      " * Prec@1 63.896 Prec@5 77.367\n",
      " * Prec@1 64.002 Prec@5 77.464\n",
      " * Prec@1 64.167 Prec@5 77.560\n",
      " * Prec@1 64.210 Prec@5 77.594\n",
      " * Prec@1 64.311 Prec@5 77.629\n",
      " * Prec@1 64.120 Prec@5 77.488\n",
      " * Prec@1 64.163 Prec@5 77.408\n",
      " * Prec@1 64.205 Prec@5 77.443\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.572 (0.522)\n",
      "\n",
      "Loss 2.1521 (2.3579)\n",
      "\n",
      "Prec@1 62.500 (64.189)\n",
      "\n",
      "Prec@5 75.000 (77.421)\n",
      "\n",
      " * Prec@1 64.189 Prec@5 77.421\n",
      " * Prec@1 64.230 Prec@5 77.511\n",
      " * Prec@1 64.215 Prec@5 77.544\n",
      " * Prec@1 63.980 Prec@5 77.412\n",
      " * Prec@1 63.913 Prec@5 77.337\n",
      " * Prec@1 63.955 Prec@5 77.317\n",
      " * Prec@1 63.835 Prec@5 77.297\n",
      " * Prec@1 63.877 Prec@5 77.278\n",
      " * Prec@1 63.866 Prec@5 77.363\n",
      " * Prec@1 63.802 Prec@5 77.396\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.531 (0.522)\n",
      "\n",
      "Loss 1.0220 (2.3603)\n",
      "\n",
      "Prec@1 75.000 (63.895)\n",
      "\n",
      "Prec@5 93.750 (77.531)\n",
      "\n",
      " * Prec@1 63.895 Prec@5 77.531\n",
      " * Prec@1 64.037 Prec@5 77.561\n",
      " * Prec@1 64.278 Prec@5 77.693\n",
      " * Prec@1 63.962 Prec@5 77.470\n",
      " * Prec@1 63.850 Prec@5 77.450\n",
      " * Prec@1 63.889 Prec@5 77.480\n",
      " * Prec@1 64.026 Prec@5 77.559\n",
      " * Prec@1 63.965 Prec@5 77.490\n",
      " * Prec@1 64.002 Prec@5 77.471\n",
      " * Prec@1 64.183 Prec@5 77.596\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.572 (0.523)\n",
      "\n",
      "Loss 2.6023 (2.3442)\n",
      "\n",
      "Prec@1 56.250 (64.122)\n",
      "\n",
      "Prec@5 75.000 (77.576)\n",
      "\n",
      " * Prec@1 64.122 Prec@5 77.576\n",
      " * Prec@1 64.205 Prec@5 77.652\n",
      " * Prec@1 64.239 Prec@5 77.585\n",
      " * Prec@1 64.039 Prec@5 77.565\n",
      " * Prec@1 64.120 Prec@5 77.593\n",
      " * Prec@1 64.108 Prec@5 77.574\n",
      " * Prec@1 64.005 Prec@5 77.464\n",
      " * Prec@1 64.085 Prec@5 77.446\n",
      " * Prec@1 64.164 Prec@5 77.428\n",
      " * Prec@1 64.286 Prec@5 77.500\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.515 (0.521)\n",
      "\n",
      "Loss 2.6313 (2.3458)\n",
      "\n",
      "Prec@1 56.250 (64.229)\n",
      "\n",
      "Prec@5 81.250 (77.527)\n",
      "\n",
      " * Prec@1 64.229 Prec@5 77.527\n",
      " * Prec@1 64.301 Prec@5 77.611\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [17][0/1276]\t\\Time 0.610 (0.610)\tData 0.451 (0.451)\tLoss 0.1283 (0.1283)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/1276]\t\\Time 0.513 (0.504)\tData 0.399 (0.403)\tLoss 1.0247 (0.3985)\tPrec@1 75.000 (88.181)\tPrec@5 100.000 (98.762)\n",
      "Epoch: [17][200/1276]\t\\Time 0.521 (0.502)\tData 0.416 (0.401)\tLoss 0.4032 (0.4053)\tPrec@1 87.500 (88.650)\tPrec@5 100.000 (98.383)\n",
      "Epoch: [17][300/1276]\t\\Time 0.552 (0.503)\tData 0.451 (0.403)\tLoss 0.3647 (0.4055)\tPrec@1 87.500 (88.268)\tPrec@5 100.000 (98.401)\n",
      "Epoch: [17][400/1276]\t\\Time 0.492 (0.503)\tData 0.422 (0.402)\tLoss 0.4837 (0.4122)\tPrec@1 87.500 (88.170)\tPrec@5 100.000 (98.441)\n",
      "Epoch: [17][500/1276]\t\\Time 0.483 (0.502)\tData 0.381 (0.402)\tLoss 0.7200 (0.4244)\tPrec@1 68.750 (87.762)\tPrec@5 100.000 (98.366)\n",
      "Epoch: [17][600/1276]\t\\Time 0.501 (0.501)\tData 0.401 (0.401)\tLoss 0.2889 (0.4424)\tPrec@1 87.500 (87.167)\tPrec@5 100.000 (98.201)\n",
      "Epoch: [17][700/1276]\t\\Time 0.440 (0.501)\tData 0.370 (0.401)\tLoss 0.9264 (0.4472)\tPrec@1 81.250 (87.090)\tPrec@5 87.500 (98.101)\n",
      "Epoch: [17][800/1276]\t\\Time 0.450 (0.501)\tData 0.380 (0.401)\tLoss 0.1122 (0.4517)\tPrec@1 100.000 (87.086)\tPrec@5 100.000 (98.002)\n",
      "Epoch: [17][900/1276]\t\\Time 0.472 (0.502)\tData 0.362 (0.402)\tLoss 0.7686 (0.4610)\tPrec@1 81.250 (86.917)\tPrec@5 87.500 (97.912)\n",
      "Epoch: [17][1000/1276]\t\\Time 0.424 (0.501)\tData 0.350 (0.402)\tLoss 0.4354 (0.4693)\tPrec@1 87.500 (86.645)\tPrec@5 93.750 (97.871)\n",
      "Epoch: [17][1100/1276]\t\\Time 0.531 (0.502)\tData 0.401 (0.402)\tLoss 0.3495 (0.4791)\tPrec@1 81.250 (86.348)\tPrec@5 100.000 (97.809)\n",
      "Epoch: [17][1200/1276]\t\\Time 0.511 (0.502)\tData 0.390 (0.402)\tLoss 0.4075 (0.4962)\tPrec@1 93.750 (85.882)\tPrec@5 100.000 (97.695)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.470 (0.470)\n",
      "\n",
      "Loss 3.1502 (3.1502)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 62.500 (62.500)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 62.500\n",
      " * Prec@1 68.750 Prec@5 75.000\n",
      " * Prec@1 64.583 Prec@5 70.833\n",
      " * Prec@1 62.500 Prec@5 70.312\n",
      " * Prec@1 62.500 Prec@5 71.250\n",
      " * Prec@1 62.500 Prec@5 72.917\n",
      " * Prec@1 61.607 Prec@5 73.214\n",
      " * Prec@1 62.500 Prec@5 74.219\n",
      " * Prec@1 61.111 Prec@5 72.917\n",
      " * Prec@1 61.250 Prec@5 75.000\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.491 (0.505)\n",
      "\n",
      "Loss 2.0856 (2.5687)\n",
      "\n",
      "Prec@1 62.500 (61.364)\n",
      "\n",
      "Prec@5 81.250 (75.568)\n",
      "\n",
      " * Prec@1 61.364 Prec@5 75.568\n",
      " * Prec@1 60.938 Prec@5 76.042\n",
      " * Prec@1 61.538 Prec@5 76.923\n",
      " * Prec@1 62.054 Prec@5 77.679\n",
      " * Prec@1 63.333 Prec@5 78.333\n",
      " * Prec@1 62.500 Prec@5 77.734\n",
      " * Prec@1 64.338 Prec@5 79.044\n",
      " * Prec@1 64.236 Prec@5 79.167\n",
      " * Prec@1 63.816 Prec@5 78.618\n",
      " * Prec@1 64.688 Prec@5 79.062\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.532 (0.502)\n",
      "\n",
      "Loss 3.5721 (2.3197)\n",
      "\n",
      "Prec@1 62.500 (64.583)\n",
      "\n",
      "Prec@5 75.000 (78.869)\n",
      "\n",
      " * Prec@1 64.583 Prec@5 78.869\n",
      " * Prec@1 64.773 Prec@5 78.693\n",
      " * Prec@1 65.217 Prec@5 79.076\n",
      " * Prec@1 65.104 Prec@5 78.906\n",
      " * Prec@1 66.000 Prec@5 79.500\n",
      " * Prec@1 66.587 Prec@5 79.808\n",
      " * Prec@1 67.130 Prec@5 79.861\n",
      " * Prec@1 67.188 Prec@5 79.688\n",
      " * Prec@1 66.595 Prec@5 79.310\n",
      " * Prec@1 66.250 Prec@5 78.958\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.531 (0.503)\n",
      "\n",
      "Loss 4.3933 (2.3627)\n",
      "\n",
      "Prec@1 43.750 (65.524)\n",
      "\n",
      "Prec@5 68.750 (78.629)\n",
      "\n",
      " * Prec@1 65.524 Prec@5 78.629\n",
      " * Prec@1 65.820 Prec@5 78.711\n",
      " * Prec@1 65.720 Prec@5 78.598\n",
      " * Prec@1 65.257 Prec@5 78.493\n",
      " * Prec@1 65.357 Prec@5 78.571\n",
      " * Prec@1 65.451 Prec@5 78.819\n",
      " * Prec@1 65.541 Prec@5 78.716\n",
      " * Prec@1 65.789 Prec@5 78.947\n",
      " * Prec@1 65.545 Prec@5 78.846\n",
      " * Prec@1 65.312 Prec@5 78.594\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.450 (0.506)\n",
      "\n",
      "Loss 2.3387 (2.3396)\n",
      "\n",
      "Prec@1 56.250 (65.091)\n",
      "\n",
      "Prec@5 75.000 (78.506)\n",
      "\n",
      " * Prec@1 65.091 Prec@5 78.506\n",
      " * Prec@1 64.435 Prec@5 77.976\n",
      " * Prec@1 63.953 Prec@5 78.198\n",
      " * Prec@1 63.778 Prec@5 78.125\n",
      " * Prec@1 63.333 Prec@5 77.778\n",
      " * Prec@1 63.179 Prec@5 77.582\n",
      " * Prec@1 63.298 Prec@5 77.527\n",
      " * Prec@1 63.411 Prec@5 77.474\n",
      " * Prec@1 63.648 Prec@5 77.806\n",
      " * Prec@1 63.750 Prec@5 77.750\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.497 (0.505)\n",
      "\n",
      "Loss 0.9049 (2.3898)\n",
      "\n",
      "Prec@1 75.000 (63.971)\n",
      "\n",
      "Prec@5 100.000 (78.186)\n",
      "\n",
      " * Prec@1 63.971 Prec@5 78.186\n",
      " * Prec@1 63.942 Prec@5 78.125\n",
      " * Prec@1 63.679 Prec@5 77.830\n",
      " * Prec@1 63.889 Prec@5 78.009\n",
      " * Prec@1 63.864 Prec@5 77.955\n",
      " * Prec@1 63.951 Prec@5 78.013\n",
      " * Prec@1 63.816 Prec@5 77.851\n",
      " * Prec@1 64.009 Prec@5 77.909\n",
      " * Prec@1 63.983 Prec@5 77.860\n",
      " * Prec@1 63.854 Prec@5 77.604\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.488 (0.505)\n",
      "\n",
      "Loss 2.7142 (2.4434)\n",
      "\n",
      "Prec@1 62.500 (63.832)\n",
      "\n",
      "Prec@5 75.000 (77.561)\n",
      "\n",
      " * Prec@1 63.832 Prec@5 77.561\n",
      " * Prec@1 64.012 Prec@5 77.520\n",
      " * Prec@1 63.988 Prec@5 77.579\n",
      " * Prec@1 64.160 Prec@5 77.930\n",
      " * Prec@1 64.135 Prec@5 77.885\n",
      " * Prec@1 64.205 Prec@5 77.841\n",
      " * Prec@1 64.179 Prec@5 77.985\n",
      " * Prec@1 64.154 Prec@5 78.125\n",
      " * Prec@1 64.221 Prec@5 78.080\n",
      " * Prec@1 64.107 Prec@5 77.768\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.492 (0.508)\n",
      "\n",
      "Loss 1.9575 (2.4409)\n",
      "\n",
      "Prec@1 68.750 (64.173)\n",
      "\n",
      "Prec@5 81.250 (77.817)\n",
      "\n",
      " * Prec@1 64.173 Prec@5 77.817\n",
      " * Prec@1 64.062 Prec@5 77.865\n",
      " * Prec@1 63.870 Prec@5 77.911\n",
      " * Prec@1 63.514 Prec@5 77.449\n",
      " * Prec@1 63.417 Prec@5 77.500\n",
      " * Prec@1 63.487 Prec@5 77.385\n",
      " * Prec@1 63.474 Prec@5 77.354\n",
      " * Prec@1 63.542 Prec@5 77.324\n",
      " * Prec@1 63.608 Prec@5 77.453\n",
      " * Prec@1 63.438 Prec@5 77.188\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.521 (0.508)\n",
      "\n",
      "Loss 3.3325 (2.5090)\n",
      "\n",
      "Prec@1 62.500 (63.426)\n",
      "\n",
      "Prec@5 68.750 (77.083)\n",
      "\n",
      " * Prec@1 63.426 Prec@5 77.083\n",
      " * Prec@1 63.415 Prec@5 77.058\n",
      " * Prec@1 63.328 Prec@5 76.958\n",
      " * Prec@1 63.393 Prec@5 77.009\n",
      " * Prec@1 63.603 Prec@5 77.132\n",
      " * Prec@1 63.735 Prec@5 77.180\n",
      " * Prec@1 63.937 Prec@5 77.299\n",
      " * Prec@1 64.062 Prec@5 77.273\n",
      " * Prec@1 64.185 Prec@5 77.317\n",
      " * Prec@1 64.028 Prec@5 77.292\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.440 (0.509)\n",
      "\n",
      "Loss 3.5149 (2.5160)\n",
      "\n",
      "Prec@1 43.750 (63.805)\n",
      "\n",
      "Prec@5 68.750 (77.198)\n",
      "\n",
      " * Prec@1 63.805 Prec@5 77.198\n",
      " * Prec@1 63.791 Prec@5 77.242\n",
      " * Prec@1 63.911 Prec@5 77.352\n",
      " * Prec@1 63.896 Prec@5 77.261\n",
      " * Prec@1 63.947 Prec@5 77.303\n",
      " * Prec@1 64.128 Prec@5 77.409\n",
      " * Prec@1 64.240 Prec@5 77.448\n",
      " * Prec@1 64.349 Prec@5 77.423\n",
      " * Prec@1 64.331 Prec@5 77.399\n",
      " * Prec@1 64.438 Prec@5 77.375\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.569 (0.509)\n",
      "\n",
      "Loss 1.8686 (2.4781)\n",
      "\n",
      "Prec@1 68.750 (64.480)\n",
      "\n",
      "Prec@5 81.250 (77.413)\n",
      "\n",
      " * Prec@1 64.480 Prec@5 77.413\n",
      " * Prec@1 64.583 Prec@5 77.390\n",
      " * Prec@1 64.502 Prec@5 77.488\n",
      " * Prec@1 64.603 Prec@5 77.524\n",
      " * Prec@1 64.643 Prec@5 77.619\n",
      " * Prec@1 64.741 Prec@5 77.653\n",
      " * Prec@1 64.836 Prec@5 77.745\n",
      " * Prec@1 64.815 Prec@5 77.662\n",
      " * Prec@1 64.736 Prec@5 77.580\n",
      " * Prec@1 64.830 Prec@5 77.727\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.544 (0.509)\n",
      "\n",
      "Loss 2.0290 (2.4550)\n",
      "\n",
      "Prec@1 56.250 (64.752)\n",
      "\n",
      "Prec@5 81.250 (77.759)\n",
      "\n",
      " * Prec@1 64.752 Prec@5 77.759\n",
      " * Prec@1 64.732 Prec@5 77.790\n",
      " * Prec@1 64.712 Prec@5 77.821\n",
      " * Prec@1 64.529 Prec@5 77.632\n",
      " * Prec@1 64.620 Prec@5 77.663\n",
      " * Prec@1 64.601 Prec@5 77.640\n",
      " * Prec@1 64.530 Prec@5 77.564\n",
      " * Prec@1 64.460 Prec@5 77.542\n",
      " * Prec@1 64.496 Prec@5 77.574\n",
      " * Prec@1 64.479 Prec@5 77.604\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.492 (0.509)\n",
      "\n",
      "Loss 1.5812 (2.4585)\n",
      "\n",
      "Prec@1 75.000 (64.566)\n",
      "\n",
      "Prec@5 87.500 (77.686)\n",
      "\n",
      " * Prec@1 64.566 Prec@5 77.686\n",
      " * Prec@1 64.498 Prec@5 77.715\n",
      " * Prec@1 64.685 Prec@5 77.846\n",
      " * Prec@1 64.315 Prec@5 77.571\n",
      " * Prec@1 64.350 Prec@5 77.550\n",
      " * Prec@1 64.335 Prec@5 77.679\n",
      " * Prec@1 64.370 Prec@5 77.707\n",
      " * Prec@1 64.209 Prec@5 77.588\n",
      " * Prec@1 64.244 Prec@5 77.665\n",
      " * Prec@1 64.423 Prec@5 77.788\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.586 (0.510)\n",
      "\n",
      "Loss 3.3447 (2.4421)\n",
      "\n",
      "Prec@1 43.750 (64.265)\n",
      "\n",
      "Prec@5 62.500 (77.672)\n",
      "\n",
      " * Prec@1 64.265 Prec@5 77.672\n",
      " * Prec@1 64.347 Prec@5 77.794\n",
      " * Prec@1 64.380 Prec@5 77.773\n",
      " * Prec@1 64.226 Prec@5 77.565\n",
      " * Prec@1 64.352 Prec@5 77.639\n",
      " * Prec@1 64.384 Prec@5 77.619\n",
      " * Prec@1 64.325 Prec@5 77.555\n",
      " * Prec@1 64.402 Prec@5 77.582\n",
      " * Prec@1 64.388 Prec@5 77.563\n",
      " * Prec@1 64.554 Prec@5 77.634\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.488 (0.508)\n",
      "\n",
      "Loss 2.4826 (2.4352)\n",
      "\n",
      "Prec@1 75.000 (64.628)\n",
      "\n",
      "Prec@5 75.000 (77.615)\n",
      "\n",
      " * Prec@1 64.628 Prec@5 77.615\n",
      " * Prec@1 64.654 Prec@5 77.699\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [18][0/1276]\t\\Time 0.470 (0.470)\tData 0.361 (0.361)\tLoss 0.3133 (0.3133)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/1276]\t\\Time 0.512 (0.499)\tData 0.400 (0.400)\tLoss 0.0089 (0.2933)\tPrec@1 100.000 (91.646)\tPrec@5 100.000 (99.319)\n",
      "Epoch: [18][200/1276]\t\\Time 0.492 (0.504)\tData 0.411 (0.405)\tLoss 0.1551 (0.2598)\tPrec@1 93.750 (92.755)\tPrec@5 100.000 (99.565)\n",
      "Epoch: [18][300/1276]\t\\Time 0.491 (0.506)\tData 0.381 (0.406)\tLoss 0.0510 (0.2524)\tPrec@1 100.000 (93.189)\tPrec@5 100.000 (99.460)\n",
      "Epoch: [18][400/1276]\t\\Time 0.452 (0.505)\tData 0.371 (0.405)\tLoss 0.1114 (0.2537)\tPrec@1 100.000 (93.158)\tPrec@5 100.000 (99.361)\n",
      "Epoch: [18][500/1276]\t\\Time 0.489 (0.504)\tData 0.394 (0.404)\tLoss 0.2309 (0.2604)\tPrec@1 87.500 (93.001)\tPrec@5 100.000 (99.301)\n",
      "Epoch: [18][600/1276]\t\\Time 0.501 (0.503)\tData 0.410 (0.404)\tLoss 0.4304 (0.2623)\tPrec@1 81.250 (92.939)\tPrec@5 93.750 (99.303)\n",
      "Epoch: [18][700/1276]\t\\Time 0.481 (0.504)\tData 0.411 (0.404)\tLoss 0.3339 (0.2689)\tPrec@1 87.500 (92.636)\tPrec@5 100.000 (99.287)\n",
      "Epoch: [18][800/1276]\t\\Time 0.471 (0.504)\tData 0.400 (0.404)\tLoss 0.7351 (0.2724)\tPrec@1 87.500 (92.548)\tPrec@5 93.750 (99.251)\n",
      "Epoch: [18][900/1276]\t\\Time 0.501 (0.504)\tData 0.380 (0.404)\tLoss 0.1611 (0.2804)\tPrec@1 93.750 (92.411)\tPrec@5 100.000 (99.216)\n",
      "Epoch: [18][1000/1276]\t\\Time 0.556 (0.504)\tData 0.444 (0.405)\tLoss 0.1571 (0.2843)\tPrec@1 93.750 (92.326)\tPrec@5 100.000 (99.163)\n",
      "Epoch: [18][1100/1276]\t\\Time 0.532 (0.505)\tData 0.411 (0.405)\tLoss 0.5593 (0.2930)\tPrec@1 93.750 (91.985)\tPrec@5 100.000 (99.131)\n",
      "Epoch: [18][1200/1276]\t\\Time 0.513 (0.506)\tData 0.405 (0.406)\tLoss 0.3931 (0.3020)\tPrec@1 93.750 (91.674)\tPrec@5 93.750 (99.095)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.497 (0.497)\n",
      "\n",
      "Loss 3.3858 (3.3858)\n",
      "\n",
      "Prec@1 56.250 (56.250)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 68.750\n",
      " * Prec@1 65.625 Prec@5 75.000\n",
      " * Prec@1 62.500 Prec@5 70.833\n",
      " * Prec@1 64.062 Prec@5 71.875\n",
      " * Prec@1 62.500 Prec@5 71.250\n",
      " * Prec@1 63.542 Prec@5 72.917\n",
      " * Prec@1 64.286 Prec@5 75.000\n",
      " * Prec@1 66.406 Prec@5 76.562\n",
      " * Prec@1 65.278 Prec@5 75.694\n",
      " * Prec@1 65.000 Prec@5 76.875\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.517 (0.521)\n",
      "\n",
      "Loss 2.2585 (2.7019)\n",
      "\n",
      "Prec@1 68.750 (65.341)\n",
      "\n",
      "Prec@5 87.500 (77.841)\n",
      "\n",
      " * Prec@1 65.341 Prec@5 77.841\n",
      " * Prec@1 66.667 Prec@5 78.125\n",
      " * Prec@1 66.827 Prec@5 78.846\n",
      " * Prec@1 68.304 Prec@5 79.464\n",
      " * Prec@1 69.583 Prec@5 80.000\n",
      " * Prec@1 68.750 Prec@5 79.688\n",
      " * Prec@1 69.485 Prec@5 80.882\n",
      " * Prec@1 68.403 Prec@5 80.556\n",
      " * Prec@1 68.092 Prec@5 80.592\n",
      " * Prec@1 68.125 Prec@5 80.938\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.546 (0.518)\n",
      "\n",
      "Loss 3.4338 (2.2965)\n",
      "\n",
      "Prec@1 68.750 (68.155)\n",
      "\n",
      "Prec@5 68.750 (80.357)\n",
      "\n",
      " * Prec@1 68.155 Prec@5 80.357\n",
      " * Prec@1 67.898 Prec@5 80.682\n",
      " * Prec@1 68.207 Prec@5 80.978\n",
      " * Prec@1 68.229 Prec@5 81.250\n",
      " * Prec@1 68.750 Prec@5 81.750\n",
      " * Prec@1 69.231 Prec@5 81.971\n",
      " * Prec@1 69.444 Prec@5 81.713\n",
      " * Prec@1 69.420 Prec@5 81.473\n",
      " * Prec@1 68.966 Prec@5 81.250\n",
      " * Prec@1 68.542 Prec@5 80.625\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.551 (0.518)\n",
      "\n",
      "Loss 4.6161 (2.3291)\n",
      "\n",
      "Prec@1 43.750 (67.742)\n",
      "\n",
      "Prec@5 62.500 (80.040)\n",
      "\n",
      " * Prec@1 67.742 Prec@5 80.040\n",
      " * Prec@1 67.578 Prec@5 79.883\n",
      " * Prec@1 67.614 Prec@5 79.924\n",
      " * Prec@1 67.831 Prec@5 79.963\n",
      " * Prec@1 67.857 Prec@5 80.000\n",
      " * Prec@1 67.535 Prec@5 80.208\n",
      " * Prec@1 67.568 Prec@5 80.068\n",
      " * Prec@1 67.599 Prec@5 80.099\n",
      " * Prec@1 67.308 Prec@5 80.128\n",
      " * Prec@1 67.344 Prec@5 80.000\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.496 (0.522)\n",
      "\n",
      "Loss 3.0633 (2.3052)\n",
      "\n",
      "Prec@1 56.250 (67.073)\n",
      "\n",
      "Prec@5 68.750 (79.726)\n",
      "\n",
      " * Prec@1 67.073 Prec@5 79.726\n",
      " * Prec@1 66.518 Prec@5 79.464\n",
      " * Prec@1 66.860 Prec@5 79.797\n",
      " * Prec@1 67.045 Prec@5 79.830\n",
      " * Prec@1 66.528 Prec@5 79.444\n",
      " * Prec@1 66.440 Prec@5 79.348\n",
      " * Prec@1 66.489 Prec@5 79.255\n",
      " * Prec@1 66.536 Prec@5 79.167\n",
      " * Prec@1 66.837 Prec@5 79.592\n",
      " * Prec@1 66.750 Prec@5 79.500\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.510 (0.521)\n",
      "\n",
      "Loss 0.7900 (2.3688)\n",
      "\n",
      "Prec@1 87.500 (67.157)\n",
      "\n",
      "Prec@5 100.000 (79.902)\n",
      "\n",
      " * Prec@1 67.157 Prec@5 79.902\n",
      " * Prec@1 67.067 Prec@5 79.688\n",
      " * Prec@1 66.863 Prec@5 79.245\n",
      " * Prec@1 67.130 Prec@5 79.514\n",
      " * Prec@1 67.273 Prec@5 79.545\n",
      " * Prec@1 67.299 Prec@5 79.464\n",
      " * Prec@1 66.996 Prec@5 79.167\n",
      " * Prec@1 67.241 Prec@5 79.203\n",
      " * Prec@1 67.161 Prec@5 79.131\n",
      " * Prec@1 67.083 Prec@5 78.854\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.490 (0.520)\n",
      "\n",
      "Loss 2.8306 (2.4565)\n",
      "\n",
      "Prec@1 75.000 (67.213)\n",
      "\n",
      "Prec@5 81.250 (78.893)\n",
      "\n",
      " * Prec@1 67.213 Prec@5 78.893\n",
      " * Prec@1 67.238 Prec@5 78.831\n",
      " * Prec@1 67.361 Prec@5 78.770\n",
      " * Prec@1 67.383 Prec@5 79.102\n",
      " * Prec@1 67.404 Prec@5 79.135\n",
      " * Prec@1 67.330 Prec@5 79.167\n",
      " * Prec@1 67.537 Prec@5 79.384\n",
      " * Prec@1 67.463 Prec@5 79.228\n",
      " * Prec@1 67.301 Prec@5 79.167\n",
      " * Prec@1 67.232 Prec@5 79.018\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.501 (0.523)\n",
      "\n",
      "Loss 2.0898 (2.4461)\n",
      "\n",
      "Prec@1 68.750 (67.254)\n",
      "\n",
      "Prec@5 81.250 (79.049)\n",
      "\n",
      " * Prec@1 67.254 Prec@5 79.049\n",
      " * Prec@1 67.274 Prec@5 78.906\n",
      " * Prec@1 67.038 Prec@5 78.682\n",
      " * Prec@1 66.807 Prec@5 78.294\n",
      " * Prec@1 66.833 Prec@5 78.250\n",
      " * Prec@1 66.859 Prec@5 78.207\n",
      " * Prec@1 66.964 Prec@5 78.166\n",
      " * Prec@1 67.067 Prec@5 78.125\n",
      " * Prec@1 67.089 Prec@5 78.244\n",
      " * Prec@1 66.875 Prec@5 78.125\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.567 (0.522)\n",
      "\n",
      "Loss 2.7510 (2.4919)\n",
      "\n",
      "Prec@1 68.750 (66.898)\n",
      "\n",
      "Prec@5 68.750 (78.009)\n",
      "\n",
      " * Prec@1 66.898 Prec@5 78.009\n",
      " * Prec@1 66.997 Prec@5 77.973\n",
      " * Prec@1 66.792 Prec@5 77.786\n",
      " * Prec@1 66.890 Prec@5 77.827\n",
      " * Prec@1 67.132 Prec@5 77.941\n",
      " * Prec@1 67.224 Prec@5 78.052\n",
      " * Prec@1 67.385 Prec@5 78.089\n",
      " * Prec@1 67.401 Prec@5 78.196\n",
      " * Prec@1 67.486 Prec@5 78.230\n",
      " * Prec@1 67.361 Prec@5 78.194\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.471 (0.522)\n",
      "\n",
      "Loss 2.6822 (2.4981)\n",
      "\n",
      "Prec@1 62.500 (67.308)\n",
      "\n",
      "Prec@5 75.000 (78.159)\n",
      "\n",
      " * Prec@1 67.308 Prec@5 78.159\n",
      " * Prec@1 67.323 Prec@5 78.193\n",
      " * Prec@1 67.339 Prec@5 78.293\n",
      " * Prec@1 67.287 Prec@5 78.125\n",
      " * Prec@1 67.303 Prec@5 78.026\n",
      " * Prec@1 67.318 Prec@5 78.060\n",
      " * Prec@1 67.397 Prec@5 78.157\n",
      " * Prec@1 67.347 Prec@5 78.125\n",
      " * Prec@1 67.361 Prec@5 78.157\n",
      " * Prec@1 67.250 Prec@5 78.125\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.563 (0.524)\n",
      "\n",
      "Loss 2.4611 (2.4973)\n",
      "\n",
      "Prec@1 62.500 (67.203)\n",
      "\n",
      "Prec@5 81.250 (78.156)\n",
      "\n",
      " * Prec@1 67.203 Prec@5 78.156\n",
      " * Prec@1 67.279 Prec@5 78.125\n",
      " * Prec@1 67.233 Prec@5 78.155\n",
      " * Prec@1 67.248 Prec@5 78.185\n",
      " * Prec@1 67.262 Prec@5 78.214\n",
      " * Prec@1 67.276 Prec@5 78.243\n",
      " * Prec@1 67.407 Prec@5 78.271\n",
      " * Prec@1 67.303 Prec@5 78.183\n",
      " * Prec@1 67.317 Prec@5 78.096\n",
      " * Prec@1 67.386 Prec@5 78.295\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.560 (0.523)\n",
      "\n",
      "Loss 2.1141 (2.4695)\n",
      "\n",
      "Prec@1 68.750 (67.399)\n",
      "\n",
      "Prec@5 81.250 (78.322)\n",
      "\n",
      " * Prec@1 67.399 Prec@5 78.322\n",
      " * Prec@1 67.355 Prec@5 78.460\n",
      " * Prec@1 67.312 Prec@5 78.485\n",
      " * Prec@1 67.105 Prec@5 78.344\n",
      " * Prec@1 67.065 Prec@5 78.315\n",
      " * Prec@1 67.080 Prec@5 78.287\n",
      " * Prec@1 66.987 Prec@5 78.098\n",
      " * Prec@1 67.002 Prec@5 78.019\n",
      " * Prec@1 67.227 Prec@5 78.151\n",
      " * Prec@1 67.188 Prec@5 78.177\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.524 (0.523)\n",
      "\n",
      "Loss 2.0199 (2.4816)\n",
      "\n",
      "Prec@1 81.250 (67.304)\n",
      "\n",
      "Prec@5 87.500 (78.254)\n",
      "\n",
      " * Prec@1 67.304 Prec@5 78.254\n",
      " * Prec@1 67.213 Prec@5 78.330\n",
      " * Prec@1 67.378 Prec@5 78.455\n",
      " * Prec@1 67.288 Prec@5 78.276\n",
      " * Prec@1 67.250 Prec@5 78.250\n",
      " * Prec@1 67.163 Prec@5 78.224\n",
      " * Prec@1 67.224 Prec@5 78.248\n",
      " * Prec@1 67.236 Prec@5 78.223\n",
      " * Prec@1 67.248 Prec@5 78.246\n",
      " * Prec@1 67.452 Prec@5 78.365\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.553 (0.524)\n",
      "\n",
      "Loss 3.4640 (2.4808)\n",
      "\n",
      "Prec@1 62.500 (67.414)\n",
      "\n",
      "Prec@5 62.500 (78.244)\n",
      "\n",
      " * Prec@1 67.414 Prec@5 78.244\n",
      " * Prec@1 67.566 Prec@5 78.314\n",
      " * Prec@1 67.528 Prec@5 78.289\n",
      " * Prec@1 67.351 Prec@5 78.078\n",
      " * Prec@1 67.454 Prec@5 78.102\n",
      " * Prec@1 67.463 Prec@5 78.033\n",
      " * Prec@1 67.381 Prec@5 77.920\n",
      " * Prec@1 67.437 Prec@5 77.944\n",
      " * Prec@1 67.401 Prec@5 77.968\n",
      " * Prec@1 67.455 Prec@5 78.080\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.511 (0.522)\n",
      "\n",
      "Loss 2.1111 (2.4756)\n",
      "\n",
      "Prec@1 68.750 (67.465)\n",
      "\n",
      "Prec@5 81.250 (78.103)\n",
      "\n",
      " * Prec@1 67.465 Prec@5 78.103\n",
      " * Prec@1 67.563 Prec@5 78.140\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [19][0/1276]\t\\Time 0.503 (0.503)\tData 0.385 (0.385)\tLoss 0.2268 (0.2268)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][100/1276]\t\\Time 0.537 (0.501)\tData 0.431 (0.402)\tLoss 0.1018 (0.1869)\tPrec@1 100.000 (95.483)\tPrec@5 100.000 (99.691)\n",
      "Epoch: [19][200/1276]\t\\Time 0.513 (0.500)\tData 0.402 (0.400)\tLoss 0.2390 (0.1799)\tPrec@1 93.750 (95.274)\tPrec@5 100.000 (99.596)\n",
      "Epoch: [19][300/1276]\t\\Time 0.534 (0.500)\tData 0.410 (0.400)\tLoss 0.1032 (0.1774)\tPrec@1 100.000 (95.411)\tPrec@5 100.000 (99.605)\n",
      "Epoch: [19][400/1276]\t\\Time 0.602 (0.500)\tData 0.482 (0.400)\tLoss 0.1579 (0.1703)\tPrec@1 93.750 (95.558)\tPrec@5 100.000 (99.610)\n",
      "Epoch: [19][500/1276]\t\\Time 0.511 (0.500)\tData 0.401 (0.400)\tLoss 0.4123 (0.1744)\tPrec@1 81.250 (95.372)\tPrec@5 100.000 (99.613)\n",
      "Epoch: [19][600/1276]\t\\Time 0.441 (0.500)\tData 0.371 (0.400)\tLoss 0.1370 (0.1764)\tPrec@1 93.750 (95.206)\tPrec@5 100.000 (99.646)\n",
      "Epoch: [19][700/1276]\t\\Time 0.540 (0.501)\tData 0.430 (0.401)\tLoss 0.1938 (0.1764)\tPrec@1 93.750 (95.266)\tPrec@5 100.000 (99.670)\n",
      "Epoch: [19][800/1276]\t\\Time 0.541 (0.502)\tData 0.440 (0.401)\tLoss 0.0560 (0.1746)\tPrec@1 100.000 (95.373)\tPrec@5 100.000 (99.680)\n",
      "Epoch: [19][900/1276]\t\\Time 0.564 (0.502)\tData 0.449 (0.402)\tLoss 0.0456 (0.1747)\tPrec@1 100.000 (95.352)\tPrec@5 100.000 (99.660)\n",
      "Epoch: [19][1000/1276]\t\\Time 0.490 (0.502)\tData 0.370 (0.402)\tLoss 0.5229 (0.1831)\tPrec@1 81.250 (95.142)\tPrec@5 100.000 (99.607)\n",
      "Epoch: [19][1100/1276]\t\\Time 0.540 (0.503)\tData 0.440 (0.402)\tLoss 0.2118 (0.1886)\tPrec@1 93.750 (94.948)\tPrec@5 100.000 (99.586)\n",
      "Epoch: [19][1200/1276]\t\\Time 0.550 (0.503)\tData 0.450 (0.403)\tLoss 0.2583 (0.1930)\tPrec@1 87.500 (94.812)\tPrec@5 100.000 (99.568)\n",
      "Test: [0/142]\n",
      "\n",
      "Time 0.469 (0.469)\n",
      "\n",
      "Loss 3.6232 (3.6232)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 68.750\n",
      " * Prec@1 68.750 Prec@5 75.000\n",
      " * Prec@1 66.667 Prec@5 72.917\n",
      " * Prec@1 64.062 Prec@5 71.875\n",
      " * Prec@1 65.000 Prec@5 71.250\n",
      " * Prec@1 65.625 Prec@5 72.917\n",
      " * Prec@1 66.071 Prec@5 74.107\n",
      " * Prec@1 67.188 Prec@5 75.781\n",
      " * Prec@1 65.972 Prec@5 73.611\n",
      " * Prec@1 66.875 Prec@5 74.375\n",
      "Test: [10/142]\n",
      "\n",
      "Time 0.530 (0.516)\n",
      "\n",
      "Loss 2.3313 (2.7729)\n",
      "\n",
      "Prec@1 62.500 (66.477)\n",
      "\n",
      "Prec@5 75.000 (74.432)\n",
      "\n",
      " * Prec@1 66.477 Prec@5 74.432\n",
      " * Prec@1 67.708 Prec@5 75.521\n",
      " * Prec@1 68.269 Prec@5 76.442\n",
      " * Prec@1 69.196 Prec@5 77.232\n",
      " * Prec@1 70.000 Prec@5 78.333\n",
      " * Prec@1 69.531 Prec@5 77.344\n",
      " * Prec@1 70.588 Prec@5 78.676\n",
      " * Prec@1 70.139 Prec@5 78.125\n",
      " * Prec@1 69.737 Prec@5 77.632\n",
      " * Prec@1 69.375 Prec@5 78.125\n",
      "Test: [20/142]\n",
      "\n",
      "Time 0.523 (0.515)\n",
      "\n",
      "Loss 3.0399 (2.3953)\n",
      "\n",
      "Prec@1 75.000 (69.643)\n",
      "\n",
      "Prec@5 75.000 (77.976)\n",
      "\n",
      " * Prec@1 69.643 Prec@5 77.976\n",
      " * Prec@1 69.602 Prec@5 77.557\n",
      " * Prec@1 70.380 Prec@5 78.261\n",
      " * Prec@1 70.573 Prec@5 78.385\n",
      " * Prec@1 71.500 Prec@5 79.000\n",
      " * Prec@1 72.115 Prec@5 79.567\n",
      " * Prec@1 71.991 Prec@5 79.861\n",
      " * Prec@1 71.652 Prec@5 79.464\n",
      " * Prec@1 70.690 Prec@5 78.879\n",
      " * Prec@1 70.208 Prec@5 78.750\n",
      "Test: [30/142]\n",
      "\n",
      "Time 0.540 (0.516)\n",
      "\n",
      "Loss 4.8857 (2.3772)\n",
      "\n",
      "Prec@1 56.250 (69.758)\n",
      "\n",
      "Prec@5 62.500 (78.226)\n",
      "\n",
      " * Prec@1 69.758 Prec@5 78.226\n",
      " * Prec@1 70.117 Prec@5 78.320\n",
      " * Prec@1 70.265 Prec@5 78.409\n",
      " * Prec@1 70.404 Prec@5 78.309\n",
      " * Prec@1 70.714 Prec@5 78.393\n",
      " * Prec@1 71.007 Prec@5 78.646\n",
      " * Prec@1 71.115 Prec@5 78.547\n",
      " * Prec@1 71.382 Prec@5 78.618\n",
      " * Prec@1 71.154 Prec@5 78.526\n",
      " * Prec@1 70.938 Prec@5 78.438\n",
      "Test: [40/142]\n",
      "\n",
      "Time 0.490 (0.517)\n",
      "\n",
      "Loss 3.6971 (2.3644)\n",
      "\n",
      "Prec@1 56.250 (70.579)\n",
      "\n",
      "Prec@5 68.750 (78.201)\n",
      "\n",
      " * Prec@1 70.579 Prec@5 78.201\n",
      " * Prec@1 69.940 Prec@5 78.125\n",
      " * Prec@1 70.203 Prec@5 78.343\n",
      " * Prec@1 70.170 Prec@5 78.267\n",
      " * Prec@1 69.722 Prec@5 77.917\n",
      " * Prec@1 69.701 Prec@5 78.125\n",
      " * Prec@1 69.814 Prec@5 78.191\n",
      " * Prec@1 69.661 Prec@5 78.255\n",
      " * Prec@1 70.026 Prec@5 78.571\n",
      " * Prec@1 70.250 Prec@5 78.625\n",
      "Test: [50/142]\n",
      "\n",
      "Time 0.515 (0.516)\n",
      "\n",
      "Loss 0.8556 (2.3286)\n",
      "\n",
      "Prec@1 68.750 (70.221)\n",
      "\n",
      "Prec@5 100.000 (79.044)\n",
      "\n",
      " * Prec@1 70.221 Prec@5 79.044\n",
      " * Prec@1 70.072 Prec@5 78.966\n",
      " * Prec@1 69.811 Prec@5 78.892\n",
      " * Prec@1 70.023 Prec@5 79.051\n",
      " * Prec@1 70.227 Prec@5 79.091\n",
      " * Prec@1 70.089 Prec@5 79.018\n",
      " * Prec@1 69.846 Prec@5 78.728\n",
      " * Prec@1 69.935 Prec@5 78.772\n",
      " * Prec@1 69.809 Prec@5 78.708\n",
      " * Prec@1 69.583 Prec@5 78.542\n",
      "Test: [60/142]\n",
      "\n",
      "Time 0.451 (0.515)\n",
      "\n",
      "Loss 2.1784 (2.3903)\n",
      "\n",
      "Prec@1 81.250 (69.775)\n",
      "\n",
      "Prec@5 81.250 (78.586)\n",
      "\n",
      " * Prec@1 69.775 Prec@5 78.586\n",
      " * Prec@1 69.859 Prec@5 78.528\n",
      " * Prec@1 69.940 Prec@5 78.571\n",
      " * Prec@1 70.117 Prec@5 78.809\n",
      " * Prec@1 70.000 Prec@5 78.654\n",
      " * Prec@1 69.886 Prec@5 78.693\n",
      " * Prec@1 70.056 Prec@5 78.918\n",
      " * Prec@1 69.945 Prec@5 78.860\n",
      " * Prec@1 69.837 Prec@5 78.804\n",
      " * Prec@1 69.643 Prec@5 78.661\n",
      "Test: [70/142]\n",
      "\n",
      "Time 0.488 (0.517)\n",
      "\n",
      "Loss 1.9570 (2.3953)\n",
      "\n",
      "Prec@1 75.000 (69.718)\n",
      "\n",
      "Prec@5 81.250 (78.697)\n",
      "\n",
      " * Prec@1 69.718 Prec@5 78.697\n",
      " * Prec@1 69.792 Prec@5 78.646\n",
      " * Prec@1 69.692 Prec@5 78.596\n",
      " * Prec@1 69.257 Prec@5 78.209\n",
      " * Prec@1 69.250 Prec@5 78.167\n",
      " * Prec@1 69.161 Prec@5 78.125\n",
      " * Prec@1 69.237 Prec@5 78.084\n",
      " * Prec@1 69.231 Prec@5 78.045\n",
      " * Prec@1 69.225 Prec@5 78.085\n",
      " * Prec@1 69.062 Prec@5 77.969\n",
      "Test: [80/142]\n",
      "\n",
      "Time 0.567 (0.519)\n",
      "\n",
      "Loss 3.1931 (2.4678)\n",
      "\n",
      "Prec@1 56.250 (68.904)\n",
      "\n",
      "Prec@5 68.750 (77.855)\n",
      "\n",
      " * Prec@1 68.904 Prec@5 77.855\n",
      " * Prec@1 68.902 Prec@5 77.896\n",
      " * Prec@1 68.750 Prec@5 77.711\n",
      " * Prec@1 68.824 Prec@5 77.753\n",
      " * Prec@1 69.044 Prec@5 77.868\n",
      " * Prec@1 69.186 Prec@5 77.907\n",
      " * Prec@1 69.325 Prec@5 77.945\n",
      " * Prec@1 69.318 Prec@5 77.912\n",
      " * Prec@1 69.312 Prec@5 77.879\n",
      " * Prec@1 69.236 Prec@5 77.708\n",
      "Test: [90/142]\n",
      "\n",
      "Time 0.460 (0.518)\n",
      "\n",
      "Loss 3.1440 (2.4786)\n",
      "\n",
      "Prec@1 62.500 (69.162)\n",
      "\n",
      "Prec@5 68.750 (77.610)\n",
      "\n",
      " * Prec@1 69.162 Prec@5 77.610\n",
      " * Prec@1 69.226 Prec@5 77.649\n",
      " * Prec@1 69.355 Prec@5 77.688\n",
      " * Prec@1 69.348 Prec@5 77.593\n",
      " * Prec@1 69.276 Prec@5 77.434\n",
      " * Prec@1 69.206 Prec@5 77.539\n",
      " * Prec@1 69.330 Prec@5 77.642\n",
      " * Prec@1 69.260 Prec@5 77.615\n",
      " * Prec@1 69.255 Prec@5 77.652\n",
      " * Prec@1 69.250 Prec@5 77.688\n",
      "Test: [100/142]\n",
      "\n",
      "Time 0.550 (0.518)\n",
      "\n",
      "Loss 2.0515 (2.4689)\n",
      "\n",
      "Prec@1 68.750 (69.245)\n",
      "\n",
      "Prec@5 87.500 (77.785)\n",
      "\n",
      " * Prec@1 69.245 Prec@5 77.785\n",
      " * Prec@1 69.301 Prec@5 77.757\n",
      " * Prec@1 69.357 Prec@5 77.852\n",
      " * Prec@1 69.531 Prec@5 77.945\n",
      " * Prec@1 69.643 Prec@5 78.095\n",
      " * Prec@1 69.693 Prec@5 78.184\n",
      " * Prec@1 69.801 Prec@5 78.213\n",
      " * Prec@1 69.676 Prec@5 78.183\n",
      " * Prec@1 69.667 Prec@5 78.096\n",
      " * Prec@1 69.659 Prec@5 78.295\n",
      "Test: [110/142]\n",
      "\n",
      "Time 0.550 (0.519)\n",
      "\n",
      "Loss 2.9836 (2.4529)\n",
      "\n",
      "Prec@1 56.250 (69.538)\n",
      "\n",
      "Prec@5 75.000 (78.266)\n",
      "\n",
      " * Prec@1 69.538 Prec@5 78.266\n",
      " * Prec@1 69.531 Prec@5 78.348\n",
      " * Prec@1 69.524 Prec@5 78.319\n",
      " * Prec@1 69.298 Prec@5 78.235\n",
      " * Prec@1 69.348 Prec@5 78.207\n",
      " * Prec@1 69.181 Prec@5 78.071\n",
      " * Prec@1 69.017 Prec@5 77.991\n",
      " * Prec@1 69.015 Prec@5 77.966\n",
      " * Prec@1 69.065 Prec@5 78.046\n",
      " * Prec@1 69.010 Prec@5 78.125\n",
      "Test: [120/142]\n",
      "\n",
      "Time 0.520 (0.518)\n",
      "\n",
      "Loss 1.3415 (2.4676)\n",
      "\n",
      "Prec@1 81.250 (69.112)\n",
      "\n",
      "Prec@5 87.500 (78.202)\n",
      "\n",
      " * Prec@1 69.112 Prec@5 78.202\n",
      " * Prec@1 69.211 Prec@5 78.330\n",
      " * Prec@1 69.411 Prec@5 78.455\n",
      " * Prec@1 69.254 Prec@5 78.276\n",
      " * Prec@1 69.250 Prec@5 78.250\n",
      " * Prec@1 69.147 Prec@5 78.274\n",
      " * Prec@1 69.193 Prec@5 78.297\n",
      " * Prec@1 69.189 Prec@5 78.271\n",
      " * Prec@1 69.234 Prec@5 78.343\n",
      " * Prec@1 69.423 Prec@5 78.462\n",
      "Test: [130/142]\n",
      "\n",
      "Time 0.521 (0.518)\n",
      "\n",
      "Loss 3.7938 (2.4524)\n",
      "\n",
      "Prec@1 62.500 (69.370)\n",
      "\n",
      "Prec@5 68.750 (78.387)\n",
      "\n",
      " * Prec@1 69.370 Prec@5 78.387\n",
      " * Prec@1 69.508 Prec@5 78.456\n",
      " * Prec@1 69.502 Prec@5 78.383\n",
      " * Prec@1 69.263 Prec@5 78.172\n",
      " * Prec@1 69.259 Prec@5 78.241\n",
      " * Prec@1 69.210 Prec@5 78.171\n",
      " * Prec@1 69.161 Prec@5 78.057\n",
      " * Prec@1 69.203 Prec@5 78.080\n",
      " * Prec@1 69.200 Prec@5 78.058\n",
      " * Prec@1 69.286 Prec@5 78.125\n",
      "Test: [140/142]\n",
      "\n",
      "Time 0.488 (0.516)\n",
      "\n",
      "Loss 2.2395 (2.4710)\n",
      "\n",
      "Prec@1 75.000 (69.326)\n",
      "\n",
      "Prec@5 81.250 (78.147)\n",
      "\n",
      " * Prec@1 69.326 Prec@5 78.147\n",
      " * Prec@1 69.370 Prec@5 78.184\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights = None)\n",
    "\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 300, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_300targets_weights_none_seed'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('C:/Users/vjosv/master/top_300_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(2610)\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83308410-7f50-41cd-a93f-93111b2fb661",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/vit_b_16_artsobservasjoner224_100targets_weights_seed211_split8020_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/559]\t\\Time 1.804 (1.804)\tData 0.446 (0.446)\tLoss 4.6828 (4.6828)\tPrec@1 0.000 (0.000)\tPrec@5 6.250 (6.250)\n",
      "Epoch: [0][100/559]\t\\Time 0.476 (0.664)\tData 0.400 (0.516)\tLoss 4.4492 (4.5853)\tPrec@1 6.250 (3.589)\tPrec@5 18.750 (10.953)\n",
      "Epoch: [0][200/559]\t\\Time 0.554 (0.598)\tData 0.471 (0.477)\tLoss 4.7595 (4.5624)\tPrec@1 0.000 (3.296)\tPrec@5 0.000 (11.816)\n",
      "Epoch: [0][300/559]\t\\Time 0.535 (0.583)\tData 0.435 (0.469)\tLoss 4.5231 (4.5510)\tPrec@1 0.000 (3.322)\tPrec@5 0.000 (11.898)\n",
      "Epoch: [0][400/559]\t\\Time 0.491 (0.576)\tData 0.396 (0.465)\tLoss 4.4330 (4.5251)\tPrec@1 6.250 (3.538)\tPrec@5 6.250 (12.547)\n",
      "Epoch: [0][500/559]\t\\Time 0.480 (0.568)\tData 0.380 (0.460)\tLoss 4.4567 (4.5030)\tPrec@1 6.250 (3.505)\tPrec@5 6.250 (13.111)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.540 (0.540)\n",
      "\n",
      "Loss 4.2261 (4.2261)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 18.750 (18.750)\n",
      "\n",
      " * Prec@1 0.000 Prec@5 18.750\n",
      " * Prec@1 0.000 Prec@5 18.750\n",
      " * Prec@1 0.000 Prec@5 12.500\n",
      " * Prec@1 3.125 Prec@5 12.500\n",
      " * Prec@1 2.500 Prec@5 11.250\n",
      " * Prec@1 2.083 Prec@5 9.375\n",
      " * Prec@1 1.786 Prec@5 8.036\n",
      " * Prec@1 1.562 Prec@5 7.812\n",
      " * Prec@1 2.083 Prec@5 10.417\n",
      " * Prec@1 1.875 Prec@5 10.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.562 (0.705)\n",
      "\n",
      "Loss 4.5261 (4.5176)\n",
      "\n",
      "Prec@1 0.000 (1.705)\n",
      "\n",
      "Prec@5 12.500 (10.795)\n",
      "\n",
      " * Prec@1 1.705 Prec@5 10.795\n",
      " * Prec@1 2.604 Prec@5 12.500\n",
      " * Prec@1 2.404 Prec@5 11.538\n",
      " * Prec@1 3.571 Prec@5 12.054\n",
      " * Prec@1 3.333 Prec@5 12.083\n",
      " * Prec@1 3.125 Prec@5 12.500\n",
      " * Prec@1 2.941 Prec@5 11.765\n",
      " * Prec@1 2.778 Prec@5 11.806\n",
      " * Prec@1 2.632 Prec@5 11.842\n",
      " * Prec@1 2.500 Prec@5 11.562\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.575 (0.685)\n",
      "\n",
      "Loss 4.3015 (4.4463)\n",
      "\n",
      "Prec@1 6.250 (2.679)\n",
      "\n",
      "Prec@5 12.500 (11.607)\n",
      "\n",
      " * Prec@1 2.679 Prec@5 11.607\n",
      " * Prec@1 2.841 Prec@5 11.932\n",
      " * Prec@1 2.717 Prec@5 11.957\n",
      " * Prec@1 2.604 Prec@5 11.458\n",
      " * Prec@1 2.500 Prec@5 11.000\n",
      " * Prec@1 2.885 Prec@5 11.538\n",
      " * Prec@1 2.778 Prec@5 11.111\n",
      " * Prec@1 2.679 Prec@5 10.938\n",
      " * Prec@1 2.802 Prec@5 11.638\n",
      " * Prec@1 2.917 Prec@5 11.875\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.692 (0.685)\n",
      "\n",
      "Loss 4.7307 (4.4806)\n",
      "\n",
      "Prec@1 0.000 (2.823)\n",
      "\n",
      "Prec@5 6.250 (11.694)\n",
      "\n",
      " * Prec@1 2.823 Prec@5 11.694\n",
      " * Prec@1 2.734 Prec@5 11.719\n",
      " * Prec@1 3.220 Prec@5 12.121\n",
      " * Prec@1 3.309 Prec@5 12.316\n",
      " * Prec@1 3.571 Prec@5 12.500\n",
      " * Prec@1 3.472 Prec@5 12.674\n",
      " * Prec@1 3.547 Prec@5 12.838\n",
      " * Prec@1 3.454 Prec@5 12.829\n",
      " * Prec@1 3.365 Prec@5 12.821\n",
      " * Prec@1 3.438 Prec@5 12.969\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.620 (0.690)\n",
      "\n",
      "Loss 4.4543 (4.4458)\n",
      "\n",
      "Prec@1 0.000 (3.354)\n",
      "\n",
      "Prec@5 6.250 (12.805)\n",
      "\n",
      " * Prec@1 3.354 Prec@5 12.805\n",
      " * Prec@1 3.274 Prec@5 12.649\n",
      " * Prec@1 3.343 Prec@5 12.645\n",
      " * Prec@1 3.693 Prec@5 12.926\n",
      " * Prec@1 3.750 Prec@5 13.056\n",
      " * Prec@1 3.804 Prec@5 13.043\n",
      " * Prec@1 3.723 Prec@5 13.032\n",
      " * Prec@1 3.646 Prec@5 12.760\n",
      " * Prec@1 3.571 Prec@5 12.883\n",
      " * Prec@1 3.500 Prec@5 13.125\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.641 (0.685)\n",
      "\n",
      "Loss 4.5882 (4.4484)\n",
      "\n",
      "Prec@1 6.250 (3.554)\n",
      "\n",
      "Prec@5 6.250 (12.990)\n",
      "\n",
      " * Prec@1 3.554 Prec@5 12.990\n",
      " * Prec@1 3.486 Prec@5 12.740\n",
      " * Prec@1 3.420 Prec@5 12.618\n",
      " * Prec@1 3.472 Prec@5 12.500\n",
      " * Prec@1 3.750 Prec@5 12.614\n",
      " * Prec@1 3.795 Prec@5 12.500\n",
      " * Prec@1 3.838 Prec@5 12.610\n",
      " * Prec@1 3.772 Prec@5 12.716\n",
      " * Prec@1 3.708 Prec@5 12.500\n",
      " * Prec@1 3.646 Prec@5 12.292\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.661 (0.684)\n",
      "\n",
      "Loss 4.1700 (4.4549)\n",
      "\n",
      "Prec@1 12.500 (3.791)\n",
      "\n",
      "Prec@5 25.000 (12.500)\n",
      "\n",
      " * Prec@1 3.791 Prec@5 12.500\n",
      " * Prec@1 3.831 Prec@5 12.601\n",
      " * Prec@1 3.770 Prec@5 12.798\n",
      " * Prec@1 3.809 Prec@5 12.695\n",
      " * Prec@1 3.750 Prec@5 12.596\n",
      " * Prec@1 3.788 Prec@5 12.973\n",
      " * Prec@1 3.825 Prec@5 13.060\n",
      " * Prec@1 3.860 Prec@5 13.235\n",
      " * Prec@1 3.804 Prec@5 13.134\n",
      " * Prec@1 3.839 Prec@5 13.036\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.694 (0.688)\n",
      "\n",
      "Loss 4.1082 (4.4400)\n",
      "\n",
      "Prec@1 18.750 (4.049)\n",
      "\n",
      "Prec@5 31.250 (13.292)\n",
      "\n",
      " * Prec@1 4.049 Prec@5 13.292\n",
      " * Prec@1 3.993 Prec@5 13.281\n",
      " * Prec@1 3.938 Prec@5 13.356\n",
      " * Prec@1 3.885 Prec@5 13.345\n",
      " * Prec@1 3.833 Prec@5 13.333\n",
      " * Prec@1 3.865 Prec@5 13.322\n",
      " * Prec@1 3.896 Prec@5 13.555\n",
      " * Prec@1 3.846 Prec@5 13.542\n",
      " * Prec@1 3.877 Prec@5 13.687\n",
      " * Prec@1 3.828 Prec@5 13.516\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.606 (0.690)\n",
      "\n",
      "Loss 4.4761 (4.4447)\n",
      "\n",
      "Prec@1 0.000 (3.781)\n",
      "\n",
      "Prec@5 18.750 (13.580)\n",
      "\n",
      " * Prec@1 3.781 Prec@5 13.580\n",
      " * Prec@1 3.735 Prec@5 13.415\n",
      " * Prec@1 3.840 Prec@5 13.630\n",
      " * Prec@1 3.795 Prec@5 13.616\n",
      " * Prec@1 3.750 Prec@5 13.456\n",
      " * Prec@1 3.706 Prec@5 13.299\n",
      " * Prec@1 3.736 Prec@5 13.290\n",
      " * Prec@1 3.693 Prec@5 13.281\n",
      " * Prec@1 3.652 Prec@5 13.272\n",
      " * Prec@1 3.611 Prec@5 13.333\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.720 (0.691)\n",
      "\n",
      "Loss 4.3955 (4.4498)\n",
      "\n",
      "Prec@1 0.000 (3.571)\n",
      "\n",
      "Prec@5 12.500 (13.324)\n",
      "\n",
      " * Prec@1 3.571 Prec@5 13.324\n",
      " * Prec@1 3.533 Prec@5 13.247\n",
      " * Prec@1 3.495 Prec@5 13.306\n",
      " * Prec@1 3.524 Prec@5 13.364\n",
      " * Prec@1 3.487 Prec@5 13.421\n",
      " * Prec@1 3.516 Prec@5 13.411\n",
      " * Prec@1 3.479 Prec@5 13.466\n",
      " * Prec@1 3.444 Prec@5 13.520\n",
      " * Prec@1 3.409 Prec@5 13.447\n",
      " * Prec@1 3.438 Prec@5 13.438\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.662 (0.693)\n",
      "\n",
      "Loss 4.5177 (4.4458)\n",
      "\n",
      "Prec@1 0.000 (3.403)\n",
      "\n",
      "Prec@5 12.500 (13.428)\n",
      "\n",
      " * Prec@1 3.403 Prec@5 13.428\n",
      " * Prec@1 3.431 Prec@5 13.419\n",
      " * Prec@1 3.398 Prec@5 13.471\n",
      " * Prec@1 3.486 Prec@5 13.582\n",
      " * Prec@1 3.452 Prec@5 13.571\n",
      " * Prec@1 3.479 Prec@5 13.620\n",
      " * Prec@1 3.446 Prec@5 13.551\n",
      " * Prec@1 3.530 Prec@5 13.600\n",
      " * Prec@1 3.555 Prec@5 13.589\n",
      " * Prec@1 3.523 Prec@5 13.580\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.620 (0.690)\n",
      "\n",
      "Loss 4.3665 (4.4413)\n",
      "\n",
      "Prec@1 0.000 (3.491)\n",
      "\n",
      "Prec@5 18.750 (13.626)\n",
      "\n",
      " * Prec@1 3.491 Prec@5 13.626\n",
      " * Prec@1 3.460 Prec@5 13.616\n",
      " * Prec@1 3.485 Prec@5 13.606\n",
      " * Prec@1 3.454 Prec@5 13.487\n",
      " * Prec@1 3.587 Prec@5 13.587\n",
      " * Prec@1 3.556 Prec@5 13.578\n",
      " * Prec@1 3.526 Prec@5 13.515\n",
      " * Prec@1 3.496 Prec@5 13.506\n",
      " * Prec@1 3.466 Prec@5 13.445\n",
      " * Prec@1 3.490 Prec@5 13.542\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.714 (0.689)\n",
      "\n",
      "Loss 4.6507 (4.4429)\n",
      "\n",
      "Prec@1 6.250 (3.512)\n",
      "\n",
      "Prec@5 12.500 (13.533)\n",
      "\n",
      " * Prec@1 3.512 Prec@5 13.533\n",
      " * Prec@1 3.484 Prec@5 13.525\n",
      " * Prec@1 3.557 Prec@5 13.567\n",
      " * Prec@1 3.528 Prec@5 13.710\n",
      " * Prec@1 3.500 Prec@5 13.800\n",
      " * Prec@1 3.472 Prec@5 13.740\n",
      " * Prec@1 3.494 Prec@5 13.780\n",
      " * Prec@1 3.516 Prec@5 13.770\n",
      " * Prec@1 3.537 Prec@5 13.857\n",
      " * Prec@1 3.558 Prec@5 13.990\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.711 (0.689)\n",
      "\n",
      "Loss 4.4712 (4.4390)\n",
      "\n",
      "Prec@1 0.000 (3.531)\n",
      "\n",
      "Prec@5 25.000 (14.074)\n",
      "\n",
      " * Prec@1 3.531 Prec@5 14.074\n",
      " * Prec@1 3.504 Prec@5 14.062\n",
      " * Prec@1 3.571 Prec@5 14.098\n",
      " * Prec@1 3.545 Prec@5 14.039\n",
      " * Prec@1 3.565 Prec@5 14.028\n",
      " * Prec@1 3.585 Prec@5 14.062\n",
      " * Prec@1 3.650 Prec@5 14.097\n",
      " * Prec@1 3.623 Prec@5 14.085\n",
      " * Prec@1 3.597 Prec@5 14.074\n",
      " * Prec@1 3.672 Prec@5 14.107\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/559]\t\\Time 0.555 (0.555)\tData 0.452 (0.452)\tLoss 4.0784 (4.0784)\tPrec@1 12.500 (12.500)\tPrec@5 31.250 (31.250)\n",
      "Epoch: [1][100/559]\t\\Time 0.465 (0.538)\tData 0.375 (0.442)\tLoss 4.2461 (4.3389)\tPrec@1 6.250 (5.260)\tPrec@5 6.250 (17.327)\n",
      "Epoch: [1][200/559]\t\\Time 0.623 (0.544)\tData 0.519 (0.446)\tLoss 4.2623 (4.2648)\tPrec@1 12.500 (5.877)\tPrec@5 25.000 (19.496)\n",
      "Epoch: [1][300/559]\t\\Time 0.557 (0.544)\tData 0.452 (0.447)\tLoss 3.3835 (4.1638)\tPrec@1 12.500 (6.582)\tPrec@5 31.250 (22.093)\n",
      "Epoch: [1][400/559]\t\\Time 0.521 (0.545)\tData 0.411 (0.446)\tLoss 3.8898 (4.0783)\tPrec@1 12.500 (7.544)\tPrec@5 31.250 (24.299)\n",
      "Epoch: [1][500/559]\t\\Time 0.567 (0.550)\tData 0.455 (0.451)\tLoss 3.7659 (3.9961)\tPrec@1 6.250 (8.570)\tPrec@5 37.500 (26.971)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.512 (0.512)\n",
      "\n",
      "Loss 3.9538 (3.9538)\n",
      "\n",
      "Prec@1 6.250 (6.250)\n",
      "\n",
      "Prec@5 31.250 (31.250)\n",
      "\n",
      " * Prec@1 6.250 Prec@5 31.250\n",
      " * Prec@1 12.500 Prec@5 37.500\n",
      " * Prec@1 10.417 Prec@5 33.333\n",
      " * Prec@1 9.375 Prec@5 37.500\n",
      " * Prec@1 11.250 Prec@5 36.250\n",
      " * Prec@1 11.458 Prec@5 34.375\n",
      " * Prec@1 9.821 Prec@5 33.036\n",
      " * Prec@1 9.375 Prec@5 32.812\n",
      " * Prec@1 8.333 Prec@5 31.250\n",
      " * Prec@1 8.125 Prec@5 31.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.890 (0.997)\n",
      "\n",
      "Loss 3.9140 (3.9724)\n",
      "\n",
      "Prec@1 18.750 (9.091)\n",
      "\n",
      "Prec@5 31.250 (31.250)\n",
      "\n",
      " * Prec@1 9.091 Prec@5 31.250\n",
      " * Prec@1 9.375 Prec@5 31.771\n",
      " * Prec@1 9.135 Prec@5 30.769\n",
      " * Prec@1 9.375 Prec@5 30.804\n",
      " * Prec@1 9.583 Prec@5 30.417\n",
      " * Prec@1 10.547 Prec@5 31.641\n",
      " * Prec@1 9.926 Prec@5 30.515\n",
      " * Prec@1 10.069 Prec@5 31.250\n",
      " * Prec@1 10.197 Prec@5 31.908\n",
      " * Prec@1 10.000 Prec@5 32.188\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.649 (0.874)\n",
      "\n",
      "Loss 3.4758 (3.9552)\n",
      "\n",
      "Prec@1 12.500 (10.119)\n",
      "\n",
      "Prec@5 37.500 (32.440)\n",
      "\n",
      " * Prec@1 10.119 Prec@5 32.440\n",
      " * Prec@1 10.227 Prec@5 32.955\n",
      " * Prec@1 10.598 Prec@5 33.424\n",
      " * Prec@1 10.156 Prec@5 32.552\n",
      " * Prec@1 10.500 Prec@5 32.750\n",
      " * Prec@1 10.817 Prec@5 32.933\n",
      " * Prec@1 10.648 Prec@5 32.176\n",
      " * Prec@1 10.938 Prec@5 32.812\n",
      " * Prec@1 11.422 Prec@5 33.190\n",
      " * Prec@1 11.458 Prec@5 33.750\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.992 (0.889)\n",
      "\n",
      "Loss 3.4818 (3.8751)\n",
      "\n",
      "Prec@1 6.250 (11.290)\n",
      "\n",
      "Prec@5 25.000 (33.468)\n",
      "\n",
      " * Prec@1 11.290 Prec@5 33.468\n",
      " * Prec@1 11.719 Prec@5 33.398\n",
      " * Prec@1 12.121 Prec@5 33.712\n",
      " * Prec@1 12.316 Prec@5 34.007\n",
      " * Prec@1 12.500 Prec@5 34.464\n",
      " * Prec@1 12.674 Prec@5 34.028\n",
      " * Prec@1 12.838 Prec@5 34.122\n",
      " * Prec@1 12.829 Prec@5 34.704\n",
      " * Prec@1 12.660 Prec@5 34.455\n",
      " * Prec@1 12.656 Prec@5 34.219\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.684 (0.889)\n",
      "\n",
      "Loss 4.3581 (3.8396)\n",
      "\n",
      "Prec@1 0.000 (12.348)\n",
      "\n",
      "Prec@5 18.750 (33.841)\n",
      "\n",
      " * Prec@1 12.348 Prec@5 33.841\n",
      " * Prec@1 12.202 Prec@5 33.631\n",
      " * Prec@1 12.064 Prec@5 33.285\n",
      " * Prec@1 11.790 Prec@5 33.381\n",
      " * Prec@1 11.806 Prec@5 33.194\n",
      " * Prec@1 11.821 Prec@5 33.288\n",
      " * Prec@1 11.569 Prec@5 32.846\n",
      " * Prec@1 11.719 Prec@5 32.943\n",
      " * Prec@1 11.735 Prec@5 33.036\n",
      " * Prec@1 12.250 Prec@5 33.750\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.814 (0.879)\n",
      "\n",
      "Loss 3.3861 (3.8447)\n",
      "\n",
      "Prec@1 18.750 (12.377)\n",
      "\n",
      "Prec@5 37.500 (33.824)\n",
      "\n",
      " * Prec@1 12.377 Prec@5 33.824\n",
      " * Prec@1 12.380 Prec@5 33.894\n",
      " * Prec@1 12.382 Prec@5 34.080\n",
      " * Prec@1 12.384 Prec@5 34.144\n",
      " * Prec@1 12.500 Prec@5 34.318\n",
      " * Prec@1 12.612 Prec@5 34.263\n",
      " * Prec@1 12.390 Prec@5 34.211\n",
      " * Prec@1 12.284 Prec@5 34.159\n",
      " * Prec@1 12.288 Prec@5 34.110\n",
      " * Prec@1 12.188 Prec@5 33.958\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.938 (0.889)\n",
      "\n",
      "Loss 3.4639 (3.8411)\n",
      "\n",
      "Prec@1 25.000 (12.398)\n",
      "\n",
      "Prec@5 37.500 (34.016)\n",
      "\n",
      " * Prec@1 12.398 Prec@5 34.016\n",
      " * Prec@1 12.399 Prec@5 33.972\n",
      " * Prec@1 12.202 Prec@5 34.127\n",
      " * Prec@1 12.207 Prec@5 34.375\n",
      " * Prec@1 12.212 Prec@5 34.615\n",
      " * Prec@1 12.405 Prec@5 34.848\n",
      " * Prec@1 12.313 Prec@5 34.795\n",
      " * Prec@1 12.316 Prec@5 34.835\n",
      " * Prec@1 12.409 Prec@5 35.054\n",
      " * Prec@1 12.500 Prec@5 34.911\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.696 (0.876)\n",
      "\n",
      "Loss 2.5777 (3.7924)\n",
      "\n",
      "Prec@1 25.000 (12.676)\n",
      "\n",
      "Prec@5 56.250 (35.211)\n",
      "\n",
      " * Prec@1 12.676 Prec@5 35.211\n",
      " * Prec@1 12.587 Prec@5 35.503\n",
      " * Prec@1 12.500 Prec@5 35.616\n",
      " * Prec@1 12.669 Prec@5 35.726\n",
      " * Prec@1 12.750 Prec@5 35.917\n",
      " * Prec@1 12.747 Prec@5 35.938\n",
      " * Prec@1 12.662 Prec@5 36.039\n",
      " * Prec@1 12.660 Prec@5 36.138\n",
      " * Prec@1 12.658 Prec@5 36.234\n",
      " * Prec@1 12.500 Prec@5 35.938\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.650 (0.856)\n",
      "\n",
      "Loss 3.7777 (3.7635)\n",
      "\n",
      "Prec@1 0.000 (12.346)\n",
      "\n",
      "Prec@5 31.250 (35.880)\n",
      "\n",
      " * Prec@1 12.346 Prec@5 35.880\n",
      " * Prec@1 12.500 Prec@5 35.976\n",
      " * Prec@1 12.425 Prec@5 36.145\n",
      " * Prec@1 12.351 Prec@5 36.086\n",
      " * Prec@1 12.353 Prec@5 36.029\n",
      " * Prec@1 12.282 Prec@5 35.901\n",
      " * Prec@1 12.284 Prec@5 35.920\n",
      " * Prec@1 12.216 Prec@5 35.938\n",
      " * Prec@1 12.219 Prec@5 36.025\n",
      " * Prec@1 12.153 Prec@5 35.972\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.703 (0.840)\n",
      "\n",
      "Loss 3.5504 (3.7570)\n",
      "\n",
      "Prec@1 18.750 (12.225)\n",
      "\n",
      "Prec@5 43.750 (36.058)\n",
      "\n",
      " * Prec@1 12.225 Prec@5 36.058\n",
      " * Prec@1 12.228 Prec@5 35.938\n",
      " * Prec@1 12.164 Prec@5 35.887\n",
      " * Prec@1 12.168 Prec@5 35.904\n",
      " * Prec@1 12.039 Prec@5 35.855\n",
      " * Prec@1 12.044 Prec@5 35.807\n",
      " * Prec@1 11.920 Prec@5 35.889\n",
      " * Prec@1 11.862 Prec@5 35.906\n",
      " * Prec@1 11.995 Prec@5 36.111\n",
      " * Prec@1 12.188 Prec@5 36.375\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.644 (0.826)\n",
      "\n",
      "Loss 3.7717 (3.7484)\n",
      "\n",
      "Prec@1 6.250 (12.129)\n",
      "\n",
      "Prec@5 37.500 (36.386)\n",
      "\n",
      " * Prec@1 12.129 Prec@5 36.386\n",
      " * Prec@1 12.316 Prec@5 36.520\n",
      " * Prec@1 12.318 Prec@5 36.529\n",
      " * Prec@1 12.320 Prec@5 36.478\n",
      " * Prec@1 12.381 Prec@5 36.607\n",
      " * Prec@1 12.500 Prec@5 36.675\n",
      " * Prec@1 12.442 Prec@5 36.741\n",
      " * Prec@1 12.442 Prec@5 36.690\n",
      " * Prec@1 12.385 Prec@5 36.869\n",
      " * Prec@1 12.386 Prec@5 36.818\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.659 (0.818)\n",
      "\n",
      "Loss 2.8694 (3.7394)\n",
      "\n",
      "Prec@1 18.750 (12.444)\n",
      "\n",
      "Prec@5 62.500 (37.050)\n",
      "\n",
      " * Prec@1 12.444 Prec@5 37.050\n",
      " * Prec@1 12.444 Prec@5 37.165\n",
      " * Prec@1 12.500 Prec@5 37.168\n",
      " * Prec@1 12.500 Prec@5 37.061\n",
      " * Prec@1 12.500 Prec@5 37.120\n",
      " * Prec@1 12.500 Prec@5 37.177\n",
      " * Prec@1 12.500 Prec@5 37.019\n",
      " * Prec@1 12.500 Prec@5 36.970\n",
      " * Prec@1 12.447 Prec@5 36.765\n",
      " * Prec@1 12.604 Prec@5 36.875\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.911 (0.814)\n",
      "\n",
      "Loss 4.1689 (3.7412)\n",
      "\n",
      "Prec@1 0.000 (12.500)\n",
      "\n",
      "Prec@5 12.500 (36.674)\n",
      "\n",
      " * Prec@1 12.500 Prec@5 36.674\n",
      " * Prec@1 12.602 Prec@5 36.578\n",
      " * Prec@1 12.602 Prec@5 36.535\n",
      " * Prec@1 12.500 Prec@5 36.492\n",
      " * Prec@1 12.450 Prec@5 36.250\n",
      " * Prec@1 12.401 Prec@5 36.310\n",
      " * Prec@1 12.451 Prec@5 36.270\n",
      " * Prec@1 12.451 Prec@5 36.182\n",
      " * Prec@1 12.403 Prec@5 36.095\n",
      " * Prec@1 12.548 Prec@5 36.250\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.689 (0.811)\n",
      "\n",
      "Loss 4.4399 (3.7572)\n",
      "\n",
      "Prec@1 6.250 (12.500)\n",
      "\n",
      "Prec@5 12.500 (36.069)\n",
      "\n",
      " * Prec@1 12.500 Prec@5 36.069\n",
      " * Prec@1 12.453 Prec@5 36.127\n",
      " * Prec@1 12.406 Prec@5 36.137\n",
      " * Prec@1 12.407 Prec@5 36.007\n",
      " * Prec@1 12.361 Prec@5 36.065\n",
      " * Prec@1 12.316 Prec@5 36.167\n",
      " * Prec@1 12.409 Prec@5 36.223\n",
      " * Prec@1 12.364 Prec@5 36.096\n",
      " * Prec@1 12.320 Prec@5 36.016\n",
      " * Prec@1 12.270 Prec@5 36.005\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/559]\t\\Time 0.493 (0.493)\tData 0.392 (0.392)\tLoss 3.9967 (3.9967)\tPrec@1 12.500 (12.500)\tPrec@5 25.000 (25.000)\n",
      "Epoch: [2][100/559]\t\\Time 0.553 (0.596)\tData 0.442 (0.497)\tLoss 3.4088 (3.3532)\tPrec@1 25.000 (16.337)\tPrec@5 37.500 (45.792)\n",
      "Epoch: [2][200/559]\t\\Time 0.449 (0.578)\tData 0.369 (0.479)\tLoss 2.9512 (3.3061)\tPrec@1 18.750 (17.879)\tPrec@5 62.500 (47.481)\n",
      "Epoch: [2][300/559]\t\\Time 0.973 (0.586)\tData 0.890 (0.486)\tLoss 3.1310 (3.2705)\tPrec@1 37.500 (19.248)\tPrec@5 56.250 (48.692)\n",
      "Epoch: [2][400/559]\t\\Time 0.561 (0.586)\tData 0.441 (0.486)\tLoss 3.2922 (3.2270)\tPrec@1 12.500 (20.168)\tPrec@5 31.250 (49.688)\n",
      "Epoch: [2][500/559]\t\\Time 0.579 (0.580)\tData 0.489 (0.480)\tLoss 2.8127 (3.1772)\tPrec@1 18.750 (20.858)\tPrec@5 56.250 (50.961)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.560 (0.560)\n",
      "\n",
      "Loss 5.4268 (5.4268)\n",
      "\n",
      "Prec@1 6.250 (6.250)\n",
      "\n",
      "Prec@5 37.500 (37.500)\n",
      "\n",
      " * Prec@1 6.250 Prec@5 37.500\n",
      " * Prec@1 6.250 Prec@5 43.750\n",
      " * Prec@1 4.167 Prec@5 33.333\n",
      " * Prec@1 4.688 Prec@5 34.375\n",
      " * Prec@1 5.000 Prec@5 32.500\n",
      " * Prec@1 4.167 Prec@5 28.125\n",
      " * Prec@1 4.464 Prec@5 25.893\n",
      " * Prec@1 6.250 Prec@5 25.781\n",
      " * Prec@1 5.556 Prec@5 25.000\n",
      " * Prec@1 5.000 Prec@5 25.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.550 (0.731)\n",
      "\n",
      "Loss 3.7162 (5.2934)\n",
      "\n",
      "Prec@1 12.500 (5.682)\n",
      "\n",
      "Prec@5 43.750 (27.273)\n",
      "\n",
      " * Prec@1 5.682 Prec@5 27.273\n",
      " * Prec@1 5.729 Prec@5 25.521\n",
      " * Prec@1 5.288 Prec@5 24.519\n",
      " * Prec@1 5.804 Prec@5 24.554\n",
      " * Prec@1 5.417 Prec@5 23.750\n",
      " * Prec@1 5.859 Prec@5 24.219\n",
      " * Prec@1 5.882 Prec@5 23.897\n",
      " * Prec@1 6.944 Prec@5 24.306\n",
      " * Prec@1 7.237 Prec@5 24.342\n",
      " * Prec@1 7.500 Prec@5 24.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.703 (0.726)\n",
      "\n",
      "Loss 5.0614 (5.4011)\n",
      "\n",
      "Prec@1 12.500 (7.738)\n",
      "\n",
      "Prec@5 37.500 (25.298)\n",
      "\n",
      " * Prec@1 7.738 Prec@5 25.298\n",
      " * Prec@1 7.955 Prec@5 25.568\n",
      " * Prec@1 8.696 Prec@5 25.815\n",
      " * Prec@1 8.333 Prec@5 26.042\n",
      " * Prec@1 8.500 Prec@5 25.750\n",
      " * Prec@1 8.413 Prec@5 26.202\n",
      " * Prec@1 8.102 Prec@5 25.463\n",
      " * Prec@1 8.482 Prec@5 25.893\n",
      " * Prec@1 8.836 Prec@5 26.293\n",
      " * Prec@1 9.167 Prec@5 27.083\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.725 (0.737)\n",
      "\n",
      "Loss 4.5404 (5.3772)\n",
      "\n",
      "Prec@1 18.750 (9.476)\n",
      "\n",
      "Prec@5 31.250 (27.218)\n",
      "\n",
      " * Prec@1 9.476 Prec@5 27.218\n",
      " * Prec@1 9.570 Prec@5 27.344\n",
      " * Prec@1 9.848 Prec@5 27.652\n",
      " * Prec@1 9.743 Prec@5 27.941\n",
      " * Prec@1 9.643 Prec@5 28.036\n",
      " * Prec@1 9.549 Prec@5 27.778\n",
      " * Prec@1 9.628 Prec@5 28.041\n",
      " * Prec@1 9.539 Prec@5 28.289\n",
      " * Prec@1 9.295 Prec@5 28.045\n",
      " * Prec@1 9.062 Prec@5 27.500\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.697 (0.749)\n",
      "\n",
      "Loss 5.1472 (5.3144)\n",
      "\n",
      "Prec@1 0.000 (8.841)\n",
      "\n",
      "Prec@5 25.000 (27.439)\n",
      "\n",
      " * Prec@1 8.841 Prec@5 27.439\n",
      " * Prec@1 8.780 Prec@5 27.381\n",
      " * Prec@1 8.721 Prec@5 27.471\n",
      " * Prec@1 8.523 Prec@5 27.131\n",
      " * Prec@1 8.333 Prec@5 26.806\n",
      " * Prec@1 8.424 Prec@5 26.902\n",
      " * Prec@1 8.245 Prec@5 26.596\n",
      " * Prec@1 8.203 Prec@5 26.562\n",
      " * Prec@1 8.036 Prec@5 26.148\n",
      " * Prec@1 7.875 Prec@5 26.000\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.687 (0.741)\n",
      "\n",
      "Loss 4.6684 (5.3097)\n",
      "\n",
      "Prec@1 12.500 (7.966)\n",
      "\n",
      "Prec@5 37.500 (26.225)\n",
      "\n",
      " * Prec@1 7.966 Prec@5 26.225\n",
      " * Prec@1 7.812 Prec@5 25.962\n",
      " * Prec@1 7.783 Prec@5 25.825\n",
      " * Prec@1 7.755 Prec@5 25.810\n",
      " * Prec@1 7.727 Prec@5 25.682\n",
      " * Prec@1 7.701 Prec@5 25.558\n",
      " * Prec@1 7.675 Prec@5 25.439\n",
      " * Prec@1 7.651 Prec@5 25.431\n",
      " * Prec@1 7.839 Prec@5 25.742\n",
      " * Prec@1 7.708 Prec@5 25.521\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.682 (0.739)\n",
      "\n",
      "Loss 5.2038 (5.3332)\n",
      "\n",
      "Prec@1 6.250 (7.684)\n",
      "\n",
      "Prec@5 12.500 (25.307)\n",
      "\n",
      " * Prec@1 7.684 Prec@5 25.307\n",
      " * Prec@1 7.661 Prec@5 25.403\n",
      " * Prec@1 7.540 Prec@5 25.198\n",
      " * Prec@1 7.520 Prec@5 25.098\n",
      " * Prec@1 7.500 Prec@5 25.000\n",
      " * Prec@1 7.576 Prec@5 25.189\n",
      " * Prec@1 7.556 Prec@5 25.280\n",
      " * Prec@1 7.537 Prec@5 25.368\n",
      " * Prec@1 7.609 Prec@5 25.362\n",
      " * Prec@1 7.589 Prec@5 25.268\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.795 (0.741)\n",
      "\n",
      "Loss 3.3224 (5.2976)\n",
      "\n",
      "Prec@1 12.500 (7.658)\n",
      "\n",
      "Prec@5 31.250 (25.352)\n",
      "\n",
      " * Prec@1 7.658 Prec@5 25.352\n",
      " * Prec@1 7.552 Prec@5 25.434\n",
      " * Prec@1 7.620 Prec@5 25.428\n",
      " * Prec@1 7.517 Prec@5 25.253\n",
      " * Prec@1 7.667 Prec@5 25.500\n",
      " * Prec@1 7.730 Prec@5 25.576\n",
      " * Prec@1 7.873 Prec@5 25.649\n",
      " * Prec@1 7.853 Prec@5 25.881\n",
      " * Prec@1 7.991 Prec@5 26.028\n",
      " * Prec@1 7.969 Prec@5 25.859\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.634 (0.742)\n",
      "\n",
      "Loss 6.2766 (5.2934)\n",
      "\n",
      "Prec@1 6.250 (7.948)\n",
      "\n",
      "Prec@5 25.000 (25.849)\n",
      "\n",
      " * Prec@1 7.948 Prec@5 25.849\n",
      " * Prec@1 7.851 Prec@5 25.915\n",
      " * Prec@1 7.756 Prec@5 25.904\n",
      " * Prec@1 7.812 Prec@5 26.190\n",
      " * Prec@1 7.794 Prec@5 26.324\n",
      " * Prec@1 7.849 Prec@5 26.381\n",
      " * Prec@1 7.902 Prec@5 26.365\n",
      " * Prec@1 7.955 Prec@5 26.562\n",
      " * Prec@1 7.935 Prec@5 26.475\n",
      " * Prec@1 7.847 Prec@5 26.250\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.689 (0.741)\n",
      "\n",
      "Loss 4.9808 (5.2654)\n",
      "\n",
      "Prec@1 6.250 (7.830)\n",
      "\n",
      "Prec@5 31.250 (26.305)\n",
      "\n",
      " * Prec@1 7.830 Prec@5 26.305\n",
      " * Prec@1 7.812 Prec@5 26.223\n",
      " * Prec@1 7.796 Prec@5 26.210\n",
      " * Prec@1 7.779 Prec@5 26.263\n",
      " * Prec@1 7.763 Prec@5 26.316\n",
      " * Prec@1 7.747 Prec@5 26.237\n",
      " * Prec@1 7.796 Prec@5 26.353\n",
      " * Prec@1 7.781 Prec@5 26.403\n",
      " * Prec@1 7.765 Prec@5 26.452\n",
      " * Prec@1 7.875 Prec@5 26.375\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.839 (0.746)\n",
      "\n",
      "Loss 5.3648 (5.2579)\n",
      "\n",
      "Prec@1 6.250 (7.859)\n",
      "\n",
      "Prec@5 18.750 (26.300)\n",
      "\n",
      " * Prec@1 7.859 Prec@5 26.300\n",
      " * Prec@1 7.843 Prec@5 26.409\n",
      " * Prec@1 7.828 Prec@5 26.456\n",
      " * Prec@1 7.812 Prec@5 26.442\n",
      " * Prec@1 7.917 Prec@5 26.369\n",
      " * Prec@1 8.019 Prec@5 26.474\n",
      " * Prec@1 8.002 Prec@5 26.577\n",
      " * Prec@1 8.044 Prec@5 26.562\n",
      " * Prec@1 8.028 Prec@5 26.720\n",
      " * Prec@1 8.125 Prec@5 26.761\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.665 (0.744)\n",
      "\n",
      "Loss 4.9605 (5.2321)\n",
      "\n",
      "Prec@1 12.500 (8.164)\n",
      "\n",
      "Prec@5 31.250 (26.802)\n",
      "\n",
      " * Prec@1 8.164 Prec@5 26.802\n",
      " * Prec@1 8.315 Prec@5 26.897\n",
      " * Prec@1 8.352 Prec@5 27.046\n",
      " * Prec@1 8.333 Prec@5 26.864\n",
      " * Prec@1 8.315 Prec@5 27.011\n",
      " * Prec@1 8.297 Prec@5 26.994\n",
      " * Prec@1 8.280 Prec@5 26.923\n",
      " * Prec@1 8.263 Prec@5 26.854\n",
      " * Prec@1 8.246 Prec@5 26.838\n",
      " * Prec@1 8.229 Prec@5 26.823\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.739 (0.742)\n",
      "\n",
      "Loss 6.3806 (5.2280)\n",
      "\n",
      "Prec@1 12.500 (8.264)\n",
      "\n",
      "Prec@5 18.750 (26.756)\n",
      "\n",
      " * Prec@1 8.264 Prec@5 26.756\n",
      " * Prec@1 8.350 Prec@5 26.793\n",
      " * Prec@1 8.283 Prec@5 26.728\n",
      " * Prec@1 8.367 Prec@5 26.714\n",
      " * Prec@1 8.350 Prec@5 26.700\n",
      " * Prec@1 8.333 Prec@5 26.687\n",
      " * Prec@1 8.415 Prec@5 26.673\n",
      " * Prec@1 8.447 Prec@5 26.562\n",
      " * Prec@1 8.479 Prec@5 26.599\n",
      " * Prec@1 8.413 Prec@5 26.635\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.699 (0.742)\n",
      "\n",
      "Loss 5.5216 (5.2258)\n",
      "\n",
      "Prec@1 6.250 (8.397)\n",
      "\n",
      "Prec@5 25.000 (26.622)\n",
      "\n",
      " * Prec@1 8.397 Prec@5 26.622\n",
      " * Prec@1 8.428 Prec@5 26.705\n",
      " * Prec@1 8.459 Prec@5 26.786\n",
      " * Prec@1 8.442 Prec@5 26.726\n",
      " * Prec@1 8.426 Prec@5 26.667\n",
      " * Prec@1 8.456 Prec@5 26.700\n",
      " * Prec@1 8.485 Prec@5 26.642\n",
      " * Prec@1 8.514 Prec@5 26.630\n",
      " * Prec@1 8.453 Prec@5 26.664\n",
      " * Prec@1 8.419 Prec@5 26.601\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/559]\t\\Time 0.572 (0.572)\tData 0.464 (0.464)\tLoss 4.8702 (4.8702)\tPrec@1 12.500 (12.500)\tPrec@5 31.250 (31.250)\n",
      "Epoch: [3][100/559]\t\\Time 0.553 (0.548)\tData 0.473 (0.451)\tLoss 2.9490 (2.8198)\tPrec@1 31.250 (28.032)\tPrec@5 68.750 (61.448)\n",
      "Epoch: [3][200/559]\t\\Time 0.564 (0.548)\tData 0.454 (0.451)\tLoss 1.9101 (2.7686)\tPrec@1 56.250 (29.291)\tPrec@5 81.250 (61.878)\n",
      "Epoch: [3][300/559]\t\\Time 0.571 (0.548)\tData 0.453 (0.450)\tLoss 2.4065 (2.7620)\tPrec@1 43.750 (29.132)\tPrec@5 68.750 (62.189)\n",
      "Epoch: [3][400/559]\t\\Time 0.548 (0.551)\tData 0.467 (0.452)\tLoss 2.2498 (2.7187)\tPrec@1 37.500 (30.206)\tPrec@5 68.750 (63.186)\n",
      "Epoch: [3][500/559]\t\\Time 0.473 (0.551)\tData 0.365 (0.452)\tLoss 2.4445 (2.6828)\tPrec@1 31.250 (31.150)\tPrec@5 62.500 (63.760)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.583 (0.583)\n",
      "\n",
      "Loss 2.6744 (2.6744)\n",
      "\n",
      "Prec@1 31.250 (31.250)\n",
      "\n",
      "Prec@5 56.250 (56.250)\n",
      "\n",
      " * Prec@1 31.250 Prec@5 56.250\n",
      " * Prec@1 28.125 Prec@5 68.750\n",
      " * Prec@1 29.167 Prec@5 68.750\n",
      " * Prec@1 26.562 Prec@5 65.625\n",
      " * Prec@1 30.000 Prec@5 66.250\n",
      " * Prec@1 27.083 Prec@5 60.417\n",
      " * Prec@1 25.893 Prec@5 59.821\n",
      " * Prec@1 24.219 Prec@5 58.594\n",
      " * Prec@1 24.306 Prec@5 57.639\n",
      " * Prec@1 25.000 Prec@5 58.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.560 (0.712)\n",
      "\n",
      "Loss 2.3219 (2.9933)\n",
      "\n",
      "Prec@1 43.750 (26.705)\n",
      "\n",
      "Prec@5 56.250 (57.955)\n",
      "\n",
      " * Prec@1 26.705 Prec@5 57.955\n",
      " * Prec@1 25.521 Prec@5 58.854\n",
      " * Prec@1 25.962 Prec@5 59.135\n",
      " * Prec@1 25.446 Prec@5 58.482\n",
      " * Prec@1 25.000 Prec@5 59.167\n",
      " * Prec@1 25.781 Prec@5 59.766\n",
      " * Prec@1 26.103 Prec@5 59.559\n",
      " * Prec@1 28.125 Prec@5 61.111\n",
      " * Prec@1 29.276 Prec@5 61.184\n",
      " * Prec@1 30.000 Prec@5 61.875\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.677 (0.705)\n",
      "\n",
      "Loss 2.4046 (2.8363)\n",
      "\n",
      "Prec@1 43.750 (30.655)\n",
      "\n",
      "Prec@5 68.750 (62.202)\n",
      "\n",
      " * Prec@1 30.655 Prec@5 62.202\n",
      " * Prec@1 30.114 Prec@5 62.216\n",
      " * Prec@1 30.978 Prec@5 62.772\n",
      " * Prec@1 30.729 Prec@5 63.281\n",
      " * Prec@1 30.500 Prec@5 63.500\n",
      " * Prec@1 29.808 Prec@5 62.981\n",
      " * Prec@1 29.861 Prec@5 62.500\n",
      " * Prec@1 30.134 Prec@5 62.946\n",
      " * Prec@1 30.172 Prec@5 62.500\n",
      " * Prec@1 30.208 Prec@5 62.917\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.681 (0.716)\n",
      "\n",
      "Loss 2.2478 (2.7514)\n",
      "\n",
      "Prec@1 43.750 (30.645)\n",
      "\n",
      "Prec@5 75.000 (63.306)\n",
      "\n",
      " * Prec@1 30.645 Prec@5 63.306\n",
      " * Prec@1 30.859 Prec@5 63.281\n",
      " * Prec@1 31.061 Prec@5 63.826\n",
      " * Prec@1 30.699 Prec@5 63.971\n",
      " * Prec@1 30.893 Prec@5 63.929\n",
      " * Prec@1 30.729 Prec@5 63.715\n",
      " * Prec@1 30.912 Prec@5 64.189\n",
      " * Prec@1 31.250 Prec@5 64.638\n",
      " * Prec@1 30.929 Prec@5 64.583\n",
      " * Prec@1 30.469 Prec@5 64.219\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.671 (0.716)\n",
      "\n",
      "Loss 2.9209 (2.7128)\n",
      "\n",
      "Prec@1 43.750 (30.793)\n",
      "\n",
      "Prec@5 56.250 (64.024)\n",
      "\n",
      " * Prec@1 30.793 Prec@5 64.024\n",
      " * Prec@1 30.506 Prec@5 63.690\n",
      " * Prec@1 30.814 Prec@5 64.099\n",
      " * Prec@1 30.682 Prec@5 64.205\n",
      " * Prec@1 30.417 Prec@5 63.889\n",
      " * Prec@1 30.299 Prec@5 64.130\n",
      " * Prec@1 30.186 Prec@5 63.830\n",
      " * Prec@1 30.469 Prec@5 63.932\n",
      " * Prec@1 30.740 Prec@5 64.158\n",
      " * Prec@1 31.000 Prec@5 64.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.662 (0.716)\n",
      "\n",
      "Loss 2.4399 (2.6830)\n",
      "\n",
      "Prec@1 43.750 (31.250)\n",
      "\n",
      "Prec@5 68.750 (64.461)\n",
      "\n",
      " * Prec@1 31.250 Prec@5 64.461\n",
      " * Prec@1 31.250 Prec@5 64.303\n",
      " * Prec@1 31.368 Prec@5 64.269\n",
      " * Prec@1 31.597 Prec@5 64.236\n",
      " * Prec@1 31.818 Prec@5 64.318\n",
      " * Prec@1 31.696 Prec@5 64.286\n",
      " * Prec@1 31.579 Prec@5 63.925\n",
      " * Prec@1 31.466 Prec@5 63.793\n",
      " * Prec@1 31.992 Prec@5 63.877\n",
      " * Prec@1 31.875 Prec@5 64.062\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.661 (0.713)\n",
      "\n",
      "Loss 2.5351 (2.6935)\n",
      "\n",
      "Prec@1 50.000 (32.172)\n",
      "\n",
      "Prec@5 62.500 (64.037)\n",
      "\n",
      " * Prec@1 32.172 Prec@5 64.037\n",
      " * Prec@1 32.460 Prec@5 64.113\n",
      " * Prec@1 32.440 Prec@5 63.988\n",
      " * Prec@1 32.422 Prec@5 64.160\n",
      " * Prec@1 32.500 Prec@5 64.327\n",
      " * Prec@1 32.576 Prec@5 64.299\n",
      " * Prec@1 32.369 Prec@5 64.086\n",
      " * Prec@1 32.537 Prec@5 64.338\n",
      " * Prec@1 32.428 Prec@5 64.312\n",
      " * Prec@1 32.232 Prec@5 64.464\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.656 (0.710)\n",
      "\n",
      "Loss 1.6631 (2.6708)\n",
      "\n",
      "Prec@1 50.000 (32.482)\n",
      "\n",
      "Prec@5 81.250 (64.701)\n",
      "\n",
      " * Prec@1 32.482 Prec@5 64.701\n",
      " * Prec@1 32.465 Prec@5 64.670\n",
      " * Prec@1 32.192 Prec@5 64.555\n",
      " * Prec@1 31.841 Prec@5 64.527\n",
      " * Prec@1 32.083 Prec@5 64.750\n",
      " * Prec@1 31.990 Prec@5 64.638\n",
      " * Prec@1 31.981 Prec@5 64.935\n",
      " * Prec@1 32.051 Prec@5 64.984\n",
      " * Prec@1 32.120 Prec@5 64.794\n",
      " * Prec@1 31.953 Prec@5 64.531\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.601 (0.707)\n",
      "\n",
      "Loss 3.0355 (2.6727)\n",
      "\n",
      "Prec@1 18.750 (31.790)\n",
      "\n",
      "Prec@5 62.500 (64.506)\n",
      "\n",
      " * Prec@1 31.790 Prec@5 64.506\n",
      " * Prec@1 32.165 Prec@5 64.634\n",
      " * Prec@1 32.304 Prec@5 64.834\n",
      " * Prec@1 32.440 Prec@5 64.955\n",
      " * Prec@1 32.500 Prec@5 64.926\n",
      " * Prec@1 32.558 Prec@5 64.826\n",
      " * Prec@1 32.615 Prec@5 65.014\n",
      " * Prec@1 32.457 Prec@5 64.986\n",
      " * Prec@1 32.303 Prec@5 64.888\n",
      " * Prec@1 32.222 Prec@5 64.931\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.721 (0.707)\n",
      "\n",
      "Loss 2.3063 (2.6486)\n",
      "\n",
      "Prec@1 43.750 (32.349)\n",
      "\n",
      "Prec@5 75.000 (65.041)\n",
      "\n",
      " * Prec@1 32.349 Prec@5 65.041\n",
      " * Prec@1 32.405 Prec@5 65.014\n",
      " * Prec@1 32.191 Prec@5 64.785\n",
      " * Prec@1 32.181 Prec@5 64.628\n",
      " * Prec@1 32.368 Prec@5 64.605\n",
      " * Prec@1 32.292 Prec@5 64.648\n",
      " * Prec@1 32.410 Prec@5 64.691\n",
      " * Prec@1 32.398 Prec@5 64.732\n",
      " * Prec@1 32.386 Prec@5 64.836\n",
      " * Prec@1 32.500 Prec@5 65.000\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.611 (0.707)\n",
      "\n",
      "Loss 2.4126 (2.6527)\n",
      "\n",
      "Prec@1 37.500 (32.550)\n",
      "\n",
      "Prec@5 68.750 (65.037)\n",
      "\n",
      " * Prec@1 32.550 Prec@5 65.037\n",
      " * Prec@1 32.475 Prec@5 65.074\n",
      " * Prec@1 32.524 Prec@5 65.109\n",
      " * Prec@1 32.572 Prec@5 65.024\n",
      " * Prec@1 32.560 Prec@5 65.119\n",
      " * Prec@1 32.429 Prec@5 64.976\n",
      " * Prec@1 32.477 Prec@5 65.070\n",
      " * Prec@1 32.350 Prec@5 65.104\n",
      " * Prec@1 32.397 Prec@5 65.138\n",
      " * Prec@1 32.330 Prec@5 64.943\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.641 (0.705)\n",
      "\n",
      "Loss 2.2243 (2.6511)\n",
      "\n",
      "Prec@1 25.000 (32.264)\n",
      "\n",
      "Prec@5 75.000 (65.034)\n",
      "\n",
      " * Prec@1 32.264 Prec@5 65.034\n",
      " * Prec@1 32.310 Prec@5 65.067\n",
      " * Prec@1 32.301 Prec@5 65.044\n",
      " * Prec@1 32.292 Prec@5 65.132\n",
      " * Prec@1 32.228 Prec@5 65.163\n",
      " * Prec@1 32.166 Prec@5 65.194\n",
      " * Prec@1 32.105 Prec@5 65.171\n",
      " * Prec@1 31.992 Prec@5 65.042\n",
      " * Prec@1 31.933 Prec@5 64.863\n",
      " * Prec@1 31.875 Prec@5 64.896\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.745 (0.705)\n",
      "\n",
      "Loss 3.1050 (2.6675)\n",
      "\n",
      "Prec@1 43.750 (31.973)\n",
      "\n",
      "Prec@5 56.250 (64.824)\n",
      "\n",
      " * Prec@1 31.973 Prec@5 64.824\n",
      " * Prec@1 31.967 Prec@5 64.703\n",
      " * Prec@1 31.860 Prec@5 64.837\n",
      " * Prec@1 31.704 Prec@5 64.667\n",
      " * Prec@1 31.650 Prec@5 64.550\n",
      " * Prec@1 31.796 Prec@5 64.633\n",
      " * Prec@1 31.890 Prec@5 64.665\n",
      " * Prec@1 31.836 Prec@5 64.648\n",
      " * Prec@1 31.831 Prec@5 64.632\n",
      " * Prec@1 32.019 Prec@5 64.760\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.703 (0.705)\n",
      "\n",
      "Loss 3.0310 (2.6804)\n",
      "\n",
      "Prec@1 31.250 (32.013)\n",
      "\n",
      "Prec@5 68.750 (64.790)\n",
      "\n",
      " * Prec@1 32.013 Prec@5 64.790\n",
      " * Prec@1 32.150 Prec@5 64.820\n",
      " * Prec@1 32.237 Prec@5 64.850\n",
      " * Prec@1 32.183 Prec@5 64.739\n",
      " * Prec@1 32.130 Prec@5 64.907\n",
      " * Prec@1 32.261 Prec@5 64.982\n",
      " * Prec@1 32.162 Prec@5 65.009\n",
      " * Prec@1 32.246 Prec@5 65.082\n",
      " * Prec@1 32.239 Prec@5 65.198\n",
      " * Prec@1 32.244 Prec@5 65.159\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/559]\t\\Time 0.506 (0.506)\tData 0.393 (0.393)\tLoss 2.1462 (2.1462)\tPrec@1 37.500 (37.500)\tPrec@5 75.000 (75.000)\n",
      "Epoch: [4][100/559]\t\\Time 0.552 (0.545)\tData 0.434 (0.447)\tLoss 2.8367 (2.3099)\tPrec@1 18.750 (40.285)\tPrec@5 62.500 (72.958)\n",
      "Epoch: [4][200/559]\t\\Time 0.506 (0.547)\tData 0.425 (0.448)\tLoss 2.7270 (2.3086)\tPrec@1 31.250 (39.335)\tPrec@5 50.000 (72.170)\n",
      "Epoch: [4][300/559]\t\\Time 0.520 (0.547)\tData 0.410 (0.448)\tLoss 1.6063 (2.3022)\tPrec@1 56.250 (39.867)\tPrec@5 93.750 (72.093)\n",
      "Epoch: [4][400/559]\t\\Time 0.549 (0.547)\tData 0.439 (0.447)\tLoss 2.0709 (2.2730)\tPrec@1 37.500 (40.118)\tPrec@5 75.000 (72.569)\n",
      "Epoch: [4][500/559]\t\\Time 0.550 (0.548)\tData 0.450 (0.447)\tLoss 1.8806 (2.2591)\tPrec@1 56.250 (40.544)\tPrec@5 75.000 (72.817)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.534 (0.534)\n",
      "\n",
      "Loss 2.0735 (2.0735)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 50.000 Prec@5 81.250\n",
      " * Prec@1 43.750 Prec@5 78.125\n",
      " * Prec@1 43.750 Prec@5 79.167\n",
      " * Prec@1 42.188 Prec@5 75.000\n",
      " * Prec@1 42.500 Prec@5 77.500\n",
      " * Prec@1 38.542 Prec@5 69.792\n",
      " * Prec@1 39.286 Prec@5 69.643\n",
      " * Prec@1 37.500 Prec@5 69.531\n",
      " * Prec@1 35.417 Prec@5 67.361\n",
      " * Prec@1 35.625 Prec@5 65.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.531 (0.692)\n",
      "\n",
      "Loss 1.5698 (2.6851)\n",
      "\n",
      "Prec@1 50.000 (36.932)\n",
      "\n",
      "Prec@5 75.000 (66.477)\n",
      "\n",
      " * Prec@1 36.932 Prec@5 66.477\n",
      " * Prec@1 36.458 Prec@5 66.667\n",
      " * Prec@1 36.058 Prec@5 67.308\n",
      " * Prec@1 35.268 Prec@5 66.518\n",
      " * Prec@1 34.583 Prec@5 65.833\n",
      " * Prec@1 34.766 Prec@5 64.453\n",
      " * Prec@1 34.926 Prec@5 65.074\n",
      " * Prec@1 34.722 Prec@5 65.972\n",
      " * Prec@1 34.868 Prec@5 66.447\n",
      " * Prec@1 34.688 Prec@5 67.500\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.634 (0.702)\n",
      "\n",
      "Loss 2.4482 (2.6307)\n",
      "\n",
      "Prec@1 43.750 (35.119)\n",
      "\n",
      "Prec@5 62.500 (67.262)\n",
      "\n",
      " * Prec@1 35.119 Prec@5 67.262\n",
      " * Prec@1 35.227 Prec@5 67.614\n",
      " * Prec@1 35.870 Prec@5 67.663\n",
      " * Prec@1 35.677 Prec@5 67.708\n",
      " * Prec@1 36.250 Prec@5 68.000\n",
      " * Prec@1 36.298 Prec@5 68.029\n",
      " * Prec@1 35.417 Prec@5 68.056\n",
      " * Prec@1 36.384 Prec@5 68.304\n",
      " * Prec@1 36.207 Prec@5 67.888\n",
      " * Prec@1 36.458 Prec@5 68.333\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.664 (0.705)\n",
      "\n",
      "Loss 2.4101 (2.5416)\n",
      "\n",
      "Prec@1 37.500 (36.492)\n",
      "\n",
      "Prec@5 68.750 (68.347)\n",
      "\n",
      " * Prec@1 36.492 Prec@5 68.347\n",
      " * Prec@1 36.523 Prec@5 68.555\n",
      " * Prec@1 36.742 Prec@5 68.939\n",
      " * Prec@1 36.581 Prec@5 69.118\n",
      " * Prec@1 36.786 Prec@5 69.107\n",
      " * Prec@1 36.285 Prec@5 68.229\n",
      " * Prec@1 36.318 Prec@5 68.750\n",
      " * Prec@1 36.678 Prec@5 68.914\n",
      " * Prec@1 36.859 Prec@5 68.910\n",
      " * Prec@1 36.250 Prec@5 68.594\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.662 (0.712)\n",
      "\n",
      "Loss 2.5608 (2.5427)\n",
      "\n",
      "Prec@1 25.000 (35.976)\n",
      "\n",
      "Prec@5 75.000 (68.750)\n",
      "\n",
      " * Prec@1 35.976 Prec@5 68.750\n",
      " * Prec@1 35.565 Prec@5 68.452\n",
      " * Prec@1 35.901 Prec@5 68.750\n",
      " * Prec@1 35.653 Prec@5 69.034\n",
      " * Prec@1 35.417 Prec@5 68.889\n",
      " * Prec@1 35.462 Prec@5 69.158\n",
      " * Prec@1 35.372 Prec@5 68.883\n",
      " * Prec@1 35.547 Prec@5 68.750\n",
      " * Prec@1 35.842 Prec@5 69.005\n",
      " * Prec@1 36.000 Prec@5 69.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.681 (0.709)\n",
      "\n",
      "Loss 2.1203 (2.5251)\n",
      "\n",
      "Prec@1 50.000 (36.275)\n",
      "\n",
      "Prec@5 75.000 (69.485)\n",
      "\n",
      " * Prec@1 36.275 Prec@5 69.485\n",
      " * Prec@1 36.538 Prec@5 69.351\n",
      " * Prec@1 36.675 Prec@5 69.458\n",
      " * Prec@1 36.806 Prec@5 69.560\n",
      " * Prec@1 37.159 Prec@5 69.659\n",
      " * Prec@1 37.388 Prec@5 69.643\n",
      " * Prec@1 36.732 Prec@5 69.189\n",
      " * Prec@1 37.069 Prec@5 69.181\n",
      " * Prec@1 37.182 Prec@5 68.962\n",
      " * Prec@1 37.188 Prec@5 68.958\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.662 (0.711)\n",
      "\n",
      "Loss 1.7012 (2.5129)\n",
      "\n",
      "Prec@1 50.000 (37.398)\n",
      "\n",
      "Prec@5 75.000 (69.057)\n",
      "\n",
      " * Prec@1 37.398 Prec@5 69.057\n",
      " * Prec@1 37.601 Prec@5 69.254\n",
      " * Prec@1 37.599 Prec@5 69.246\n",
      " * Prec@1 37.500 Prec@5 69.336\n",
      " * Prec@1 37.692 Prec@5 69.423\n",
      " * Prec@1 37.784 Prec@5 69.318\n",
      " * Prec@1 37.687 Prec@5 69.216\n",
      " * Prec@1 37.592 Prec@5 69.210\n",
      " * Prec@1 37.409 Prec@5 69.384\n",
      " * Prec@1 37.143 Prec@5 69.464\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.683 (0.709)\n",
      "\n",
      "Loss 1.7190 (2.5051)\n",
      "\n",
      "Prec@1 56.250 (37.412)\n",
      "\n",
      "Prec@5 81.250 (69.630)\n",
      "\n",
      " * Prec@1 37.412 Prec@5 69.630\n",
      " * Prec@1 37.413 Prec@5 69.618\n",
      " * Prec@1 37.414 Prec@5 69.606\n",
      " * Prec@1 37.500 Prec@5 69.426\n",
      " * Prec@1 37.667 Prec@5 69.500\n",
      " * Prec@1 37.418 Prec@5 69.655\n",
      " * Prec@1 37.662 Prec@5 69.805\n",
      " * Prec@1 37.821 Prec@5 69.952\n",
      " * Prec@1 37.658 Prec@5 69.620\n",
      " * Prec@1 37.578 Prec@5 69.297\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.644 (0.708)\n",
      "\n",
      "Loss 2.3675 (2.4942)\n",
      "\n",
      "Prec@1 31.250 (37.500)\n",
      "\n",
      "Prec@5 87.500 (69.522)\n",
      "\n",
      " * Prec@1 37.500 Prec@5 69.522\n",
      " * Prec@1 37.652 Prec@5 69.588\n",
      " * Prec@1 37.500 Prec@5 69.955\n",
      " * Prec@1 37.277 Prec@5 69.792\n",
      " * Prec@1 37.353 Prec@5 69.853\n",
      " * Prec@1 37.282 Prec@5 69.695\n",
      " * Prec@1 37.284 Prec@5 69.612\n",
      " * Prec@1 37.358 Prec@5 69.602\n",
      " * Prec@1 37.079 Prec@5 69.663\n",
      " * Prec@1 37.222 Prec@5 69.653\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.690 (0.709)\n",
      "\n",
      "Loss 1.6343 (2.4882)\n",
      "\n",
      "Prec@1 50.000 (37.363)\n",
      "\n",
      "Prec@5 81.250 (69.780)\n",
      "\n",
      " * Prec@1 37.363 Prec@5 69.780\n",
      " * Prec@1 37.296 Prec@5 69.905\n",
      " * Prec@1 37.231 Prec@5 69.892\n",
      " * Prec@1 37.234 Prec@5 69.880\n",
      " * Prec@1 37.105 Prec@5 69.868\n",
      " * Prec@1 37.109 Prec@5 69.857\n",
      " * Prec@1 37.113 Prec@5 69.716\n",
      " * Prec@1 37.117 Prec@5 69.770\n",
      " * Prec@1 37.247 Prec@5 69.697\n",
      " * Prec@1 37.500 Prec@5 69.812\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.644 (0.707)\n",
      "\n",
      "Loss 2.3985 (2.4739)\n",
      "\n",
      "Prec@1 31.250 (37.438)\n",
      "\n",
      "Prec@5 75.000 (69.864)\n",
      "\n",
      " * Prec@1 37.438 Prec@5 69.864\n",
      " * Prec@1 37.439 Prec@5 69.792\n",
      " * Prec@1 37.379 Prec@5 69.782\n",
      " * Prec@1 37.440 Prec@5 69.772\n",
      " * Prec@1 37.262 Prec@5 69.643\n",
      " * Prec@1 37.205 Prec@5 69.693\n",
      " * Prec@1 37.208 Prec@5 69.626\n",
      " * Prec@1 37.384 Prec@5 69.676\n",
      " * Prec@1 37.385 Prec@5 69.667\n",
      " * Prec@1 37.273 Prec@5 69.432\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.683 (0.707)\n",
      "\n",
      "Loss 2.2062 (2.4802)\n",
      "\n",
      "Prec@1 43.750 (37.331)\n",
      "\n",
      "Prec@5 56.250 (69.313)\n",
      "\n",
      " * Prec@1 37.331 Prec@5 69.313\n",
      " * Prec@1 37.444 Prec@5 69.364\n",
      " * Prec@1 37.500 Prec@5 69.358\n",
      " * Prec@1 37.445 Prec@5 69.353\n",
      " * Prec@1 37.554 Prec@5 69.511\n",
      " * Prec@1 37.554 Prec@5 69.343\n",
      " * Prec@1 37.500 Prec@5 69.391\n",
      " * Prec@1 37.341 Prec@5 69.227\n",
      " * Prec@1 37.290 Prec@5 69.170\n",
      " * Prec@1 37.344 Prec@5 69.323\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.721 (0.707)\n",
      "\n",
      "Loss 2.8649 (2.4924)\n",
      "\n",
      "Prec@1 43.750 (37.397)\n",
      "\n",
      "Prec@5 62.500 (69.267)\n",
      "\n",
      " * Prec@1 37.397 Prec@5 69.267\n",
      " * Prec@1 37.398 Prec@5 69.211\n",
      " * Prec@1 37.449 Prec@5 69.207\n",
      " * Prec@1 37.399 Prec@5 69.204\n",
      " * Prec@1 37.400 Prec@5 69.100\n",
      " * Prec@1 37.450 Prec@5 69.296\n",
      " * Prec@1 37.451 Prec@5 69.291\n",
      " * Prec@1 37.549 Prec@5 69.238\n",
      " * Prec@1 37.548 Prec@5 69.138\n",
      " * Prec@1 37.692 Prec@5 69.279\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.730 (0.707)\n",
      "\n",
      "Loss 3.2291 (2.4964)\n",
      "\n",
      "Prec@1 31.250 (37.643)\n",
      "\n",
      "Prec@5 56.250 (69.179)\n",
      "\n",
      " * Prec@1 37.643 Prec@5 69.179\n",
      " * Prec@1 37.642 Prec@5 69.271\n",
      " * Prec@1 37.782 Prec@5 69.314\n",
      " * Prec@1 37.687 Prec@5 69.263\n",
      " * Prec@1 37.685 Prec@5 69.352\n",
      " * Prec@1 37.776 Prec@5 69.393\n",
      " * Prec@1 37.774 Prec@5 69.434\n",
      " * Prec@1 37.772 Prec@5 69.429\n",
      " * Prec@1 37.680 Prec@5 69.290\n",
      " * Prec@1 37.573 Prec@5 69.279\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/559]\t\\Time 0.556 (0.556)\tData 0.452 (0.452)\tLoss 1.5206 (1.5206)\tPrec@1 56.250 (56.250)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [5][100/559]\t\\Time 0.576 (0.544)\tData 0.470 (0.443)\tLoss 1.6705 (1.8780)\tPrec@1 62.500 (48.515)\tPrec@5 81.250 (80.012)\n",
      "Epoch: [5][200/559]\t\\Time 0.585 (0.547)\tData 0.482 (0.445)\tLoss 1.5470 (1.8535)\tPrec@1 43.750 (49.907)\tPrec@5 93.750 (80.784)\n",
      "Epoch: [5][300/559]\t\\Time 0.565 (0.550)\tData 0.495 (0.448)\tLoss 1.7559 (1.8861)\tPrec@1 56.250 (49.232)\tPrec@5 81.250 (80.087)\n",
      "Epoch: [5][400/559]\t\\Time 0.514 (0.551)\tData 0.443 (0.449)\tLoss 1.7172 (1.8844)\tPrec@1 56.250 (49.314)\tPrec@5 81.250 (79.910)\n",
      "Epoch: [5][500/559]\t\\Time 0.483 (0.552)\tData 0.400 (0.450)\tLoss 1.5666 (1.8721)\tPrec@1 68.750 (49.663)\tPrec@5 81.250 (80.027)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.572 (0.572)\n",
      "\n",
      "Loss 1.7116 (1.7116)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 75.000\n",
      " * Prec@1 59.375 Prec@5 81.250\n",
      " * Prec@1 54.167 Prec@5 79.167\n",
      " * Prec@1 53.125 Prec@5 79.688\n",
      " * Prec@1 51.250 Prec@5 78.750\n",
      " * Prec@1 46.875 Prec@5 77.083\n",
      " * Prec@1 47.321 Prec@5 75.893\n",
      " * Prec@1 45.312 Prec@5 74.219\n",
      " * Prec@1 45.139 Prec@5 73.611\n",
      " * Prec@1 44.375 Prec@5 73.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.565 (0.721)\n",
      "\n",
      "Loss 1.2589 (2.3284)\n",
      "\n",
      "Prec@1 68.750 (46.591)\n",
      "\n",
      "Prec@5 87.500 (74.432)\n",
      "\n",
      " * Prec@1 46.591 Prec@5 74.432\n",
      " * Prec@1 47.396 Prec@5 75.000\n",
      " * Prec@1 46.154 Prec@5 74.038\n",
      " * Prec@1 44.643 Prec@5 74.554\n",
      " * Prec@1 44.167 Prec@5 75.000\n",
      " * Prec@1 44.141 Prec@5 75.000\n",
      " * Prec@1 43.750 Prec@5 75.735\n",
      " * Prec@1 44.444 Prec@5 76.389\n",
      " * Prec@1 45.066 Prec@5 76.645\n",
      " * Prec@1 45.625 Prec@5 76.875\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.611 (0.700)\n",
      "\n",
      "Loss 2.8617 (2.2096)\n",
      "\n",
      "Prec@1 31.250 (44.940)\n",
      "\n",
      "Prec@5 75.000 (76.786)\n",
      "\n",
      " * Prec@1 44.940 Prec@5 76.786\n",
      " * Prec@1 45.170 Prec@5 76.989\n",
      " * Prec@1 45.924 Prec@5 77.446\n",
      " * Prec@1 45.833 Prec@5 76.823\n",
      " * Prec@1 46.000 Prec@5 77.000\n",
      " * Prec@1 45.913 Prec@5 77.163\n",
      " * Prec@1 45.833 Prec@5 76.852\n",
      " * Prec@1 45.982 Prec@5 77.009\n",
      " * Prec@1 45.474 Prec@5 76.509\n",
      " * Prec@1 45.833 Prec@5 76.875\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.721 (0.707)\n",
      "\n",
      "Loss 1.6238 (2.1798)\n",
      "\n",
      "Prec@1 43.750 (45.766)\n",
      "\n",
      "Prec@5 87.500 (77.218)\n",
      "\n",
      " * Prec@1 45.766 Prec@5 77.218\n",
      " * Prec@1 45.508 Prec@5 76.953\n",
      " * Prec@1 46.023 Prec@5 77.462\n",
      " * Prec@1 45.588 Prec@5 77.757\n",
      " * Prec@1 45.893 Prec@5 77.500\n",
      " * Prec@1 45.660 Prec@5 77.083\n",
      " * Prec@1 46.115 Prec@5 77.027\n",
      " * Prec@1 46.053 Prec@5 77.138\n",
      " * Prec@1 45.513 Prec@5 76.763\n",
      " * Prec@1 44.844 Prec@5 76.250\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.672 (0.713)\n",
      "\n",
      "Loss 2.9440 (2.1998)\n",
      "\n",
      "Prec@1 25.000 (44.360)\n",
      "\n",
      "Prec@5 56.250 (75.762)\n",
      "\n",
      " * Prec@1 44.360 Prec@5 75.762\n",
      " * Prec@1 43.750 Prec@5 75.298\n",
      " * Prec@1 44.331 Prec@5 75.436\n",
      " * Prec@1 44.318 Prec@5 75.284\n",
      " * Prec@1 44.583 Prec@5 75.000\n",
      " * Prec@1 44.565 Prec@5 75.272\n",
      " * Prec@1 44.548 Prec@5 75.133\n",
      " * Prec@1 44.401 Prec@5 75.260\n",
      " * Prec@1 44.388 Prec@5 75.128\n",
      " * Prec@1 44.375 Prec@5 75.250\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.636 (0.708)\n",
      "\n",
      "Loss 2.0957 (2.1912)\n",
      "\n",
      "Prec@1 37.500 (44.240)\n",
      "\n",
      "Prec@5 81.250 (75.368)\n",
      "\n",
      " * Prec@1 44.240 Prec@5 75.368\n",
      " * Prec@1 44.111 Prec@5 75.240\n",
      " * Prec@1 43.868 Prec@5 75.236\n",
      " * Prec@1 44.097 Prec@5 75.231\n",
      " * Prec@1 44.432 Prec@5 75.341\n",
      " * Prec@1 44.420 Prec@5 75.335\n",
      " * Prec@1 44.627 Prec@5 75.329\n",
      " * Prec@1 44.828 Prec@5 75.323\n",
      " * Prec@1 44.703 Prec@5 75.212\n",
      " * Prec@1 44.583 Prec@5 75.312\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.702 (0.709)\n",
      "\n",
      "Loss 1.4254 (2.1816)\n",
      "\n",
      "Prec@1 68.750 (44.980)\n",
      "\n",
      "Prec@5 87.500 (75.512)\n",
      "\n",
      " * Prec@1 44.980 Prec@5 75.512\n",
      " * Prec@1 45.060 Prec@5 75.504\n",
      " * Prec@1 44.841 Prec@5 75.397\n",
      " * Prec@1 44.922 Prec@5 75.391\n",
      " * Prec@1 45.000 Prec@5 75.385\n",
      " * Prec@1 45.170 Prec@5 75.473\n",
      " * Prec@1 45.149 Prec@5 75.280\n",
      " * Prec@1 45.496 Prec@5 75.460\n",
      " * Prec@1 45.471 Prec@5 75.362\n",
      " * Prec@1 45.357 Prec@5 75.446\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.674 (0.707)\n",
      "\n",
      "Loss 2.0632 (2.1674)\n",
      "\n",
      "Prec@1 37.500 (45.246)\n",
      "\n",
      "Prec@5 75.000 (75.440)\n",
      "\n",
      " * Prec@1 45.246 Prec@5 75.440\n",
      " * Prec@1 45.139 Prec@5 75.434\n",
      " * Prec@1 45.205 Prec@5 75.428\n",
      " * Prec@1 45.017 Prec@5 75.169\n",
      " * Prec@1 45.000 Prec@5 75.167\n",
      " * Prec@1 44.984 Prec@5 75.082\n",
      " * Prec@1 45.049 Prec@5 75.000\n",
      " * Prec@1 44.952 Prec@5 75.080\n",
      " * Prec@1 44.937 Prec@5 74.842\n",
      " * Prec@1 44.844 Prec@5 74.688\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.661 (0.707)\n",
      "\n",
      "Loss 1.7187 (2.1649)\n",
      "\n",
      "Prec@1 50.000 (44.907)\n",
      "\n",
      "Prec@5 87.500 (74.846)\n",
      "\n",
      " * Prec@1 44.907 Prec@5 74.846\n",
      " * Prec@1 45.046 Prec@5 74.924\n",
      " * Prec@1 45.181 Prec@5 75.226\n",
      " * Prec@1 45.164 Prec@5 75.298\n",
      " * Prec@1 45.368 Prec@5 75.441\n",
      " * Prec@1 45.203 Prec@5 75.145\n",
      " * Prec@1 45.187 Prec@5 75.144\n",
      " * Prec@1 45.099 Prec@5 75.284\n",
      " * Prec@1 45.014 Prec@5 75.281\n",
      " * Prec@1 45.000 Prec@5 75.347\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.685 (0.708)\n",
      "\n",
      "Loss 1.3607 (2.1326)\n",
      "\n",
      "Prec@1 62.500 (45.192)\n",
      "\n",
      "Prec@5 81.250 (75.412)\n",
      "\n",
      " * Prec@1 45.192 Prec@5 75.412\n",
      " * Prec@1 45.177 Prec@5 75.408\n",
      " * Prec@1 45.094 Prec@5 75.470\n",
      " * Prec@1 44.947 Prec@5 75.399\n",
      " * Prec@1 44.868 Prec@5 75.329\n",
      " * Prec@1 44.922 Prec@5 75.195\n",
      " * Prec@1 44.781 Prec@5 75.129\n",
      " * Prec@1 44.643 Prec@5 75.128\n",
      " * Prec@1 44.760 Prec@5 75.063\n",
      " * Prec@1 44.750 Prec@5 75.000\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.636 (0.706)\n",
      "\n",
      "Loss 2.6184 (2.1452)\n",
      "\n",
      "Prec@1 43.750 (44.740)\n",
      "\n",
      "Prec@5 62.500 (74.876)\n",
      "\n",
      " * Prec@1 44.740 Prec@5 74.876\n",
      " * Prec@1 44.792 Prec@5 74.877\n",
      " * Prec@1 45.085 Prec@5 75.061\n",
      " * Prec@1 45.252 Prec@5 75.120\n",
      " * Prec@1 45.119 Prec@5 74.821\n",
      " * Prec@1 45.047 Prec@5 74.823\n",
      " * Prec@1 45.152 Prec@5 74.942\n",
      " * Prec@1 45.197 Prec@5 75.000\n",
      " * Prec@1 45.183 Prec@5 74.885\n",
      " * Prec@1 45.000 Prec@5 74.830\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.654 (0.706)\n",
      "\n",
      "Loss 2.6388 (2.1429)\n",
      "\n",
      "Prec@1 37.500 (44.932)\n",
      "\n",
      "Prec@5 62.500 (74.718)\n",
      "\n",
      " * Prec@1 44.932 Prec@5 74.718\n",
      " * Prec@1 44.978 Prec@5 74.665\n",
      " * Prec@1 45.022 Prec@5 74.723\n",
      " * Prec@1 44.956 Prec@5 74.671\n",
      " * Prec@1 45.000 Prec@5 74.837\n",
      " * Prec@1 44.935 Prec@5 74.784\n",
      " * Prec@1 44.925 Prec@5 74.733\n",
      " * Prec@1 44.915 Prec@5 74.788\n",
      " * Prec@1 44.800 Prec@5 74.632\n",
      " * Prec@1 44.844 Prec@5 74.583\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.702 (0.705)\n",
      "\n",
      "Loss 3.3790 (2.1601)\n",
      "\n",
      "Prec@1 43.750 (44.835)\n",
      "\n",
      "Prec@5 56.250 (74.432)\n",
      "\n",
      " * Prec@1 44.835 Prec@5 74.432\n",
      " * Prec@1 44.775 Prec@5 74.334\n",
      " * Prec@1 44.817 Prec@5 74.289\n",
      " * Prec@1 44.708 Prec@5 74.194\n",
      " * Prec@1 44.700 Prec@5 74.200\n",
      " * Prec@1 44.692 Prec@5 74.256\n",
      " * Prec@1 44.783 Prec@5 74.213\n",
      " * Prec@1 44.873 Prec@5 74.268\n",
      " * Prec@1 44.913 Prec@5 74.176\n",
      " * Prec@1 45.000 Prec@5 74.183\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.690 (0.708)\n",
      "\n",
      "Loss 2.9168 (2.1811)\n",
      "\n",
      "Prec@1 31.250 (44.895)\n",
      "\n",
      "Prec@5 62.500 (74.094)\n",
      "\n",
      " * Prec@1 44.895 Prec@5 74.094\n",
      " * Prec@1 45.076 Prec@5 74.100\n",
      " * Prec@1 45.113 Prec@5 74.201\n",
      " * Prec@1 45.103 Prec@5 74.160\n",
      " * Prec@1 45.231 Prec@5 74.213\n",
      " * Prec@1 45.358 Prec@5 74.311\n",
      " * Prec@1 45.438 Prec@5 74.407\n",
      " * Prec@1 45.335 Prec@5 74.411\n",
      " * Prec@1 45.324 Prec@5 74.371\n",
      " * Prec@1 45.365 Prec@5 74.384\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/559]\t\\Time 0.702 (0.702)\tData 0.434 (0.434)\tLoss 1.2832 (1.2832)\tPrec@1 62.500 (62.500)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [6][100/559]\t\\Time 0.562 (0.542)\tData 0.451 (0.440)\tLoss 1.4372 (1.4421)\tPrec@1 62.500 (59.777)\tPrec@5 87.500 (87.314)\n",
      "Epoch: [6][200/559]\t\\Time 0.564 (0.540)\tData 0.502 (0.440)\tLoss 1.1261 (1.4697)\tPrec@1 68.750 (59.266)\tPrec@5 87.500 (87.438)\n",
      "Epoch: [6][300/559]\t\\Time 0.582 (0.541)\tData 0.502 (0.442)\tLoss 1.5015 (1.4807)\tPrec@1 43.750 (58.866)\tPrec@5 93.750 (87.002)\n",
      "Epoch: [6][400/559]\t\\Time 0.481 (0.539)\tData 0.401 (0.442)\tLoss 1.4588 (1.4747)\tPrec@1 56.250 (59.492)\tPrec@5 81.250 (86.596)\n",
      "Epoch: [6][500/559]\t\\Time 0.564 (0.540)\tData 0.483 (0.443)\tLoss 1.3440 (1.4777)\tPrec@1 68.750 (59.394)\tPrec@5 87.500 (86.539)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.582 (0.582)\n",
      "\n",
      "Loss 2.1109 (2.1109)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      " * Prec@1 50.000 Prec@5 75.000\n",
      " * Prec@1 53.125 Prec@5 78.125\n",
      " * Prec@1 52.083 Prec@5 70.833\n",
      " * Prec@1 50.000 Prec@5 71.875\n",
      " * Prec@1 47.500 Prec@5 73.750\n",
      " * Prec@1 43.750 Prec@5 67.708\n",
      " * Prec@1 43.750 Prec@5 66.964\n",
      " * Prec@1 42.188 Prec@5 67.188\n",
      " * Prec@1 38.889 Prec@5 64.583\n",
      " * Prec@1 37.500 Prec@5 63.750\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.582 (0.718)\n",
      "\n",
      "Loss 1.9762 (2.7683)\n",
      "\n",
      "Prec@1 43.750 (38.068)\n",
      "\n",
      "Prec@5 75.000 (64.773)\n",
      "\n",
      " * Prec@1 38.068 Prec@5 64.773\n",
      " * Prec@1 38.542 Prec@5 66.146\n",
      " * Prec@1 37.981 Prec@5 66.827\n",
      " * Prec@1 38.393 Prec@5 66.964\n",
      " * Prec@1 37.500 Prec@5 66.250\n",
      " * Prec@1 38.672 Prec@5 66.797\n",
      " * Prec@1 38.971 Prec@5 68.015\n",
      " * Prec@1 39.583 Prec@5 69.097\n",
      " * Prec@1 40.132 Prec@5 70.066\n",
      " * Prec@1 40.312 Prec@5 70.000\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.633 (0.709)\n",
      "\n",
      "Loss 2.4851 (2.5442)\n",
      "\n",
      "Prec@1 50.000 (40.774)\n",
      "\n",
      "Prec@5 75.000 (70.238)\n",
      "\n",
      " * Prec@1 40.774 Prec@5 70.238\n",
      " * Prec@1 40.341 Prec@5 70.455\n",
      " * Prec@1 41.304 Prec@5 71.196\n",
      " * Prec@1 41.146 Prec@5 71.354\n",
      " * Prec@1 41.750 Prec@5 72.000\n",
      " * Prec@1 40.865 Prec@5 71.154\n",
      " * Prec@1 40.509 Prec@5 70.602\n",
      " * Prec@1 41.295 Prec@5 71.205\n",
      " * Prec@1 41.379 Prec@5 71.121\n",
      " * Prec@1 41.667 Prec@5 71.667\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.723 (0.720)\n",
      "\n",
      "Loss 2.0601 (2.4723)\n",
      "\n",
      "Prec@1 56.250 (42.137)\n",
      "\n",
      "Prec@5 75.000 (71.774)\n",
      "\n",
      " * Prec@1 42.137 Prec@5 71.774\n",
      " * Prec@1 42.188 Prec@5 71.484\n",
      " * Prec@1 42.803 Prec@5 71.970\n",
      " * Prec@1 42.831 Prec@5 71.691\n",
      " * Prec@1 43.036 Prec@5 71.429\n",
      " * Prec@1 42.708 Prec@5 71.007\n",
      " * Prec@1 43.074 Prec@5 71.622\n",
      " * Prec@1 43.586 Prec@5 72.039\n",
      " * Prec@1 43.109 Prec@5 71.955\n",
      " * Prec@1 42.969 Prec@5 71.562\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.671 (0.723)\n",
      "\n",
      "Loss 3.0022 (2.4306)\n",
      "\n",
      "Prec@1 31.250 (42.683)\n",
      "\n",
      "Prec@5 75.000 (71.646)\n",
      "\n",
      " * Prec@1 42.683 Prec@5 71.646\n",
      " * Prec@1 42.113 Prec@5 71.429\n",
      " * Prec@1 42.442 Prec@5 71.657\n",
      " * Prec@1 42.614 Prec@5 71.733\n",
      " * Prec@1 42.361 Prec@5 71.806\n",
      " * Prec@1 42.255 Prec@5 72.011\n",
      " * Prec@1 42.154 Prec@5 72.074\n",
      " * Prec@1 42.318 Prec@5 72.135\n",
      " * Prec@1 42.347 Prec@5 72.066\n",
      " * Prec@1 42.625 Prec@5 72.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.670 (0.718)\n",
      "\n",
      "Loss 1.1656 (2.3584)\n",
      "\n",
      "Prec@1 62.500 (43.015)\n",
      "\n",
      "Prec@5 93.750 (72.794)\n",
      "\n",
      " * Prec@1 43.015 Prec@5 72.794\n",
      " * Prec@1 42.909 Prec@5 72.837\n",
      " * Prec@1 43.278 Prec@5 73.113\n",
      " * Prec@1 43.287 Prec@5 73.264\n",
      " * Prec@1 43.409 Prec@5 73.523\n",
      " * Prec@1 43.527 Prec@5 73.438\n",
      " * Prec@1 43.202 Prec@5 73.026\n",
      " * Prec@1 43.534 Prec@5 73.060\n",
      " * Prec@1 43.538 Prec@5 73.093\n",
      " * Prec@1 43.542 Prec@5 73.229\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.655 (0.715)\n",
      "\n",
      "Loss 1.5985 (2.3472)\n",
      "\n",
      "Prec@1 50.000 (43.648)\n",
      "\n",
      "Prec@5 81.250 (73.361)\n",
      "\n",
      " * Prec@1 43.648 Prec@5 73.361\n",
      " * Prec@1 43.952 Prec@5 73.488\n",
      " * Prec@1 43.651 Prec@5 73.214\n",
      " * Prec@1 43.457 Prec@5 73.242\n",
      " * Prec@1 43.462 Prec@5 73.173\n",
      " * Prec@1 43.371 Prec@5 73.201\n",
      " * Prec@1 43.284 Prec@5 73.134\n",
      " * Prec@1 43.750 Prec@5 73.438\n",
      " * Prec@1 43.569 Prec@5 73.370\n",
      " * Prec@1 43.214 Prec@5 73.304\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.706 (0.712)\n",
      "\n",
      "Loss 1.3449 (2.3273)\n",
      "\n",
      "Prec@1 68.750 (43.574)\n",
      "\n",
      "Prec@5 87.500 (73.504)\n",
      "\n",
      " * Prec@1 43.574 Prec@5 73.504\n",
      " * Prec@1 43.663 Prec@5 73.611\n",
      " * Prec@1 43.664 Prec@5 73.630\n",
      " * Prec@1 43.497 Prec@5 73.649\n",
      " * Prec@1 43.667 Prec@5 73.750\n",
      " * Prec@1 43.750 Prec@5 73.602\n",
      " * Prec@1 43.506 Prec@5 73.377\n",
      " * Prec@1 43.590 Prec@5 73.478\n",
      " * Prec@1 43.592 Prec@5 73.497\n",
      " * Prec@1 43.359 Prec@5 73.438\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.620 (0.711)\n",
      "\n",
      "Loss 2.5436 (2.3432)\n",
      "\n",
      "Prec@1 18.750 (43.056)\n",
      "\n",
      "Prec@5 68.750 (73.380)\n",
      "\n",
      " * Prec@1 43.056 Prec@5 73.380\n",
      " * Prec@1 43.140 Prec@5 73.399\n",
      " * Prec@1 42.997 Prec@5 73.419\n",
      " * Prec@1 43.080 Prec@5 73.512\n",
      " * Prec@1 43.309 Prec@5 73.603\n",
      " * Prec@1 43.096 Prec@5 73.474\n",
      " * Prec@1 43.247 Prec@5 73.491\n",
      " * Prec@1 42.969 Prec@5 73.438\n",
      " * Prec@1 42.907 Prec@5 73.315\n",
      " * Prec@1 42.986 Prec@5 73.333\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.715 (0.710)\n",
      "\n",
      "Loss 1.8919 (2.3358)\n",
      "\n",
      "Prec@1 43.750 (42.995)\n",
      "\n",
      "Prec@5 75.000 (73.352)\n",
      "\n",
      " * Prec@1 42.995 Prec@5 73.352\n",
      " * Prec@1 42.935 Prec@5 73.370\n",
      " * Prec@1 42.876 Prec@5 73.253\n",
      " * Prec@1 42.753 Prec@5 73.271\n",
      " * Prec@1 42.566 Prec@5 73.224\n",
      " * Prec@1 42.578 Prec@5 73.177\n",
      " * Prec@1 42.655 Prec@5 73.131\n",
      " * Prec@1 42.730 Prec@5 73.151\n",
      " * Prec@1 42.929 Prec@5 73.295\n",
      " * Prec@1 43.062 Prec@5 73.188\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.664 (0.710)\n",
      "\n",
      "Loss 1.7501 (2.3214)\n",
      "\n",
      "Prec@1 56.250 (43.193)\n",
      "\n",
      "Prec@5 81.250 (73.267)\n",
      "\n",
      " * Prec@1 43.193 Prec@5 73.267\n",
      " * Prec@1 43.260 Prec@5 73.284\n",
      " * Prec@1 43.204 Prec@5 73.240\n",
      " * Prec@1 43.450 Prec@5 73.377\n",
      " * Prec@1 43.274 Prec@5 73.333\n",
      " * Prec@1 43.101 Prec@5 73.172\n",
      " * Prec@1 43.049 Prec@5 73.131\n",
      " * Prec@1 43.056 Prec@5 73.264\n",
      " * Prec@1 43.005 Prec@5 73.280\n",
      " * Prec@1 42.955 Prec@5 73.239\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.650 (0.707)\n",
      "\n",
      "Loss 2.6468 (2.3307)\n",
      "\n",
      "Prec@1 43.750 (42.962)\n",
      "\n",
      "Prec@5 62.500 (73.142)\n",
      "\n",
      " * Prec@1 42.962 Prec@5 73.142\n",
      " * Prec@1 42.969 Prec@5 73.158\n",
      " * Prec@1 43.142 Prec@5 73.175\n",
      " * Prec@1 43.092 Prec@5 73.191\n",
      " * Prec@1 43.207 Prec@5 73.261\n",
      " * Prec@1 43.157 Prec@5 73.222\n",
      " * Prec@1 43.056 Prec@5 73.237\n",
      " * Prec@1 42.850 Prec@5 73.305\n",
      " * Prec@1 42.805 Prec@5 73.109\n",
      " * Prec@1 42.812 Prec@5 73.125\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.730 (0.706)\n",
      "\n",
      "Loss 2.5990 (2.3498)\n",
      "\n",
      "Prec@1 37.500 (42.769)\n",
      "\n",
      "Prec@5 75.000 (73.140)\n",
      "\n",
      " * Prec@1 42.769 Prec@5 73.140\n",
      " * Prec@1 42.777 Prec@5 73.002\n",
      " * Prec@1 42.632 Prec@5 72.815\n",
      " * Prec@1 42.490 Prec@5 72.631\n",
      " * Prec@1 42.400 Prec@5 72.500\n",
      " * Prec@1 42.659 Prec@5 72.619\n",
      " * Prec@1 42.864 Prec@5 72.687\n",
      " * Prec@1 42.920 Prec@5 72.656\n",
      " * Prec@1 43.023 Prec@5 72.674\n",
      " * Prec@1 43.077 Prec@5 72.692\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.683 (0.705)\n",
      "\n",
      "Loss 3.4411 (2.3684)\n",
      "\n",
      "Prec@1 43.750 (43.082)\n",
      "\n",
      "Prec@5 50.000 (72.519)\n",
      "\n",
      " * Prec@1 43.082 Prec@5 72.519\n",
      " * Prec@1 43.087 Prec@5 72.538\n",
      " * Prec@1 43.139 Prec@5 72.650\n",
      " * Prec@1 43.004 Prec@5 72.621\n",
      " * Prec@1 43.056 Prec@5 72.731\n",
      " * Prec@1 43.199 Prec@5 72.748\n",
      " * Prec@1 43.203 Prec@5 72.856\n",
      " * Prec@1 43.161 Prec@5 72.781\n",
      " * Prec@1 43.121 Prec@5 72.752\n",
      " * Prec@1 43.171 Prec@5 72.862\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/559]\t\\Time 0.508 (0.508)\tData 0.400 (0.400)\tLoss 0.9808 (0.9808)\tPrec@1 68.750 (68.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/559]\t\\Time 0.522 (0.533)\tData 0.412 (0.437)\tLoss 1.4071 (1.1456)\tPrec@1 68.750 (67.389)\tPrec@5 81.250 (90.965)\n",
      "Epoch: [7][200/559]\t\\Time 0.540 (0.533)\tData 0.440 (0.437)\tLoss 1.1298 (1.1240)\tPrec@1 68.750 (67.848)\tPrec@5 87.500 (90.983)\n",
      "Epoch: [7][300/559]\t\\Time 0.614 (0.536)\tData 0.494 (0.439)\tLoss 1.1190 (1.1331)\tPrec@1 50.000 (67.691)\tPrec@5 100.000 (91.383)\n",
      "Epoch: [7][400/559]\t\\Time 0.482 (0.540)\tData 0.400 (0.443)\tLoss 1.5826 (1.1596)\tPrec@1 75.000 (67.347)\tPrec@5 81.250 (90.835)\n",
      "Epoch: [7][500/559]\t\\Time 0.593 (0.539)\tData 0.485 (0.441)\tLoss 1.6250 (1.1526)\tPrec@1 56.250 (67.789)\tPrec@5 75.000 (90.856)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.535 (0.535)\n",
      "\n",
      "Loss 2.0782 (2.0782)\n",
      "\n",
      "Prec@1 43.750 (43.750)\n",
      "\n",
      "Prec@5 68.750 (68.750)\n",
      "\n",
      " * Prec@1 43.750 Prec@5 68.750\n",
      " * Prec@1 53.125 Prec@5 78.125\n",
      " * Prec@1 56.250 Prec@5 81.250\n",
      " * Prec@1 56.250 Prec@5 81.250\n",
      " * Prec@1 53.750 Prec@5 80.000\n",
      " * Prec@1 52.083 Prec@5 79.167\n",
      " * Prec@1 50.000 Prec@5 78.571\n",
      " * Prec@1 47.656 Prec@5 77.344\n",
      " * Prec@1 45.833 Prec@5 77.083\n",
      " * Prec@1 45.000 Prec@5 76.250\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.562 (0.698)\n",
      "\n",
      "Loss 1.4900 (2.3084)\n",
      "\n",
      "Prec@1 56.250 (46.023)\n",
      "\n",
      "Prec@5 87.500 (77.273)\n",
      "\n",
      " * Prec@1 46.023 Prec@5 77.273\n",
      " * Prec@1 45.833 Prec@5 78.125\n",
      " * Prec@1 44.712 Prec@5 78.365\n",
      " * Prec@1 44.643 Prec@5 78.125\n",
      " * Prec@1 45.000 Prec@5 77.500\n",
      " * Prec@1 44.922 Prec@5 77.734\n",
      " * Prec@1 45.588 Prec@5 78.676\n",
      " * Prec@1 46.875 Prec@5 79.514\n",
      " * Prec@1 47.368 Prec@5 79.934\n",
      " * Prec@1 47.500 Prec@5 80.625\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.635 (0.694)\n",
      "\n",
      "Loss 2.6587 (2.1479)\n",
      "\n",
      "Prec@1 37.500 (47.024)\n",
      "\n",
      "Prec@5 68.750 (80.060)\n",
      "\n",
      " * Prec@1 47.024 Prec@5 80.060\n",
      " * Prec@1 46.875 Prec@5 79.830\n",
      " * Prec@1 48.370 Prec@5 80.163\n",
      " * Prec@1 48.698 Prec@5 80.469\n",
      " * Prec@1 49.250 Prec@5 80.500\n",
      " * Prec@1 48.798 Prec@5 80.288\n",
      " * Prec@1 48.611 Prec@5 79.861\n",
      " * Prec@1 49.330 Prec@5 80.134\n",
      " * Prec@1 49.353 Prec@5 79.741\n",
      " * Prec@1 49.167 Prec@5 79.792\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.736 (0.709)\n",
      "\n",
      "Loss 1.1216 (2.0743)\n",
      "\n",
      "Prec@1 68.750 (49.798)\n",
      "\n",
      "Prec@5 100.000 (80.444)\n",
      "\n",
      " * Prec@1 49.798 Prec@5 80.444\n",
      " * Prec@1 49.609 Prec@5 80.273\n",
      " * Prec@1 50.000 Prec@5 80.114\n",
      " * Prec@1 50.000 Prec@5 80.147\n",
      " * Prec@1 50.000 Prec@5 80.000\n",
      " * Prec@1 49.306 Prec@5 79.167\n",
      " * Prec@1 49.662 Prec@5 79.730\n",
      " * Prec@1 50.000 Prec@5 80.099\n",
      " * Prec@1 50.321 Prec@5 80.128\n",
      " * Prec@1 50.625 Prec@5 80.156\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.632 (0.712)\n",
      "\n",
      "Loss 2.8291 (2.0443)\n",
      "\n",
      "Prec@1 37.500 (50.305)\n",
      "\n",
      "Prec@5 75.000 (80.030)\n",
      "\n",
      " * Prec@1 50.305 Prec@5 80.030\n",
      " * Prec@1 49.702 Prec@5 79.762\n",
      " * Prec@1 50.145 Prec@5 80.087\n",
      " * Prec@1 49.716 Prec@5 79.972\n",
      " * Prec@1 49.444 Prec@5 79.861\n",
      " * Prec@1 49.592 Prec@5 80.027\n",
      " * Prec@1 49.468 Prec@5 80.186\n",
      " * Prec@1 49.740 Prec@5 79.948\n",
      " * Prec@1 49.872 Prec@5 79.847\n",
      " * Prec@1 49.875 Prec@5 80.125\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.705 (0.713)\n",
      "\n",
      "Loss 2.1356 (2.0305)\n",
      "\n",
      "Prec@1 43.750 (49.755)\n",
      "\n",
      "Prec@5 81.250 (80.147)\n",
      "\n",
      " * Prec@1 49.755 Prec@5 80.147\n",
      " * Prec@1 49.880 Prec@5 80.168\n",
      " * Prec@1 49.882 Prec@5 80.542\n",
      " * Prec@1 49.769 Prec@5 80.556\n",
      " * Prec@1 50.000 Prec@5 80.568\n",
      " * Prec@1 49.777 Prec@5 80.357\n",
      " * Prec@1 49.452 Prec@5 80.373\n",
      " * Prec@1 49.246 Prec@5 80.280\n",
      " * Prec@1 49.470 Prec@5 80.297\n",
      " * Prec@1 49.375 Prec@5 80.521\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.660 (0.712)\n",
      "\n",
      "Loss 1.4809 (2.0440)\n",
      "\n",
      "Prec@1 56.250 (49.488)\n",
      "\n",
      "Prec@5 87.500 (80.635)\n",
      "\n",
      " * Prec@1 49.488 Prec@5 80.635\n",
      " * Prec@1 49.294 Prec@5 80.645\n",
      " * Prec@1 49.405 Prec@5 80.754\n",
      " * Prec@1 49.512 Prec@5 80.957\n",
      " * Prec@1 49.519 Prec@5 80.865\n",
      " * Prec@1 49.337 Prec@5 80.777\n",
      " * Prec@1 49.534 Prec@5 80.877\n",
      " * Prec@1 49.724 Prec@5 80.974\n",
      " * Prec@1 49.909 Prec@5 80.797\n",
      " * Prec@1 49.643 Prec@5 80.714\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.694 (0.710)\n",
      "\n",
      "Loss 1.5656 (2.0295)\n",
      "\n",
      "Prec@1 68.750 (49.912)\n",
      "\n",
      "Prec@5 93.750 (80.898)\n",
      "\n",
      " * Prec@1 49.912 Prec@5 80.898\n",
      " * Prec@1 49.913 Prec@5 80.990\n",
      " * Prec@1 50.000 Prec@5 80.993\n",
      " * Prec@1 50.084 Prec@5 80.997\n",
      " * Prec@1 50.333 Prec@5 81.083\n",
      " * Prec@1 50.411 Prec@5 81.003\n",
      " * Prec@1 50.325 Prec@5 80.601\n",
      " * Prec@1 50.481 Prec@5 80.609\n",
      " * Prec@1 50.475 Prec@5 80.459\n",
      " * Prec@1 50.625 Prec@5 80.547\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.620 (0.708)\n",
      "\n",
      "Loss 1.6300 (2.0272)\n",
      "\n",
      "Prec@1 50.000 (50.617)\n",
      "\n",
      "Prec@5 87.500 (80.633)\n",
      "\n",
      " * Prec@1 50.617 Prec@5 80.633\n",
      " * Prec@1 50.686 Prec@5 80.640\n",
      " * Prec@1 50.828 Prec@5 80.798\n",
      " * Prec@1 50.967 Prec@5 80.952\n",
      " * Prec@1 51.250 Prec@5 81.029\n",
      " * Prec@1 51.163 Prec@5 81.032\n",
      " * Prec@1 51.365 Prec@5 81.106\n",
      " * Prec@1 51.278 Prec@5 81.037\n",
      " * Prec@1 51.194 Prec@5 80.899\n",
      " * Prec@1 51.319 Prec@5 81.111\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.695 (0.707)\n",
      "\n",
      "Loss 1.3796 (1.9892)\n",
      "\n",
      "Prec@1 62.500 (51.442)\n",
      "\n",
      "Prec@5 87.500 (81.181)\n",
      "\n",
      " * Prec@1 51.442 Prec@5 81.181\n",
      " * Prec@1 51.359 Prec@5 81.046\n",
      " * Prec@1 50.941 Prec@5 80.981\n",
      " * Prec@1 50.931 Prec@5 80.785\n",
      " * Prec@1 50.921 Prec@5 80.724\n",
      " * Prec@1 50.977 Prec@5 80.599\n",
      " * Prec@1 50.902 Prec@5 80.412\n",
      " * Prec@1 51.020 Prec@5 80.357\n",
      " * Prec@1 51.073 Prec@5 80.366\n",
      " * Prec@1 51.062 Prec@5 80.438\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.636 (0.706)\n",
      "\n",
      "Loss 2.1782 (2.0083)\n",
      "\n",
      "Prec@1 50.000 (51.052)\n",
      "\n",
      "Prec@5 81.250 (80.446)\n",
      "\n",
      " * Prec@1 51.052 Prec@5 80.446\n",
      " * Prec@1 51.103 Prec@5 80.576\n",
      " * Prec@1 51.214 Prec@5 80.522\n",
      " * Prec@1 51.262 Prec@5 80.589\n",
      " * Prec@1 51.310 Prec@5 80.655\n",
      " * Prec@1 51.238 Prec@5 80.601\n",
      " * Prec@1 51.227 Prec@5 80.666\n",
      " * Prec@1 51.157 Prec@5 80.729\n",
      " * Prec@1 51.204 Prec@5 80.619\n",
      " * Prec@1 51.080 Prec@5 80.625\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.692 (0.705)\n",
      "\n",
      "Loss 2.6651 (2.0104)\n",
      "\n",
      "Prec@1 37.500 (50.957)\n",
      "\n",
      "Prec@5 81.250 (80.631)\n",
      "\n",
      " * Prec@1 50.957 Prec@5 80.631\n",
      " * Prec@1 50.949 Prec@5 80.580\n",
      " * Prec@1 50.940 Prec@5 80.531\n",
      " * Prec@1 51.042 Prec@5 80.592\n",
      " * Prec@1 51.033 Prec@5 80.652\n",
      " * Prec@1 51.078 Prec@5 80.603\n",
      " * Prec@1 51.175 Prec@5 80.716\n",
      " * Prec@1 51.059 Prec@5 80.773\n",
      " * Prec@1 51.208 Prec@5 80.882\n",
      " * Prec@1 51.198 Prec@5 80.990\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.724 (0.706)\n",
      "\n",
      "Loss 1.6925 (1.9909)\n",
      "\n",
      "Prec@1 62.500 (51.291)\n",
      "\n",
      "Prec@5 75.000 (80.940)\n",
      "\n",
      " * Prec@1 51.291 Prec@5 80.940\n",
      " * Prec@1 51.281 Prec@5 80.943\n",
      " * Prec@1 51.118 Prec@5 80.843\n",
      " * Prec@1 50.907 Prec@5 80.796\n",
      " * Prec@1 50.750 Prec@5 80.700\n",
      " * Prec@1 50.893 Prec@5 80.754\n",
      " * Prec@1 50.984 Prec@5 80.758\n",
      " * Prec@1 50.977 Prec@5 80.762\n",
      " * Prec@1 50.921 Prec@5 80.620\n",
      " * Prec@1 51.058 Prec@5 80.673\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.702 (0.707)\n",
      "\n",
      "Loss 3.3064 (2.0208)\n",
      "\n",
      "Prec@1 31.250 (50.906)\n",
      "\n",
      "Prec@5 50.000 (80.439)\n",
      "\n",
      " * Prec@1 50.906 Prec@5 80.439\n",
      " * Prec@1 50.805 Prec@5 80.445\n",
      " * Prec@1 50.846 Prec@5 80.592\n",
      " * Prec@1 50.746 Prec@5 80.550\n",
      " * Prec@1 50.787 Prec@5 80.648\n",
      " * Prec@1 50.781 Prec@5 80.790\n",
      " * Prec@1 50.684 Prec@5 80.839\n",
      " * Prec@1 50.634 Prec@5 80.752\n",
      " * Prec@1 50.585 Prec@5 80.710\n",
      " * Prec@1 50.560 Prec@5 80.699\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/559]\t\\Time 0.522 (0.522)\tData 0.416 (0.416)\tLoss 1.4307 (1.4307)\tPrec@1 56.250 (56.250)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/559]\t\\Time 0.567 (0.535)\tData 0.457 (0.437)\tLoss 0.4265 (0.9588)\tPrec@1 87.500 (72.834)\tPrec@5 100.000 (93.688)\n",
      "Epoch: [8][200/559]\t\\Time 0.524 (0.538)\tData 0.438 (0.441)\tLoss 1.0527 (0.9103)\tPrec@1 81.250 (74.192)\tPrec@5 87.500 (94.030)\n",
      "Epoch: [8][300/559]\t\\Time 0.534 (0.544)\tData 0.464 (0.445)\tLoss 1.0488 (0.9128)\tPrec@1 68.750 (74.149)\tPrec@5 100.000 (93.875)\n",
      "Epoch: [8][400/559]\t\\Time 0.531 (0.550)\tData 0.431 (0.451)\tLoss 0.6446 (0.8911)\tPrec@1 93.750 (74.610)\tPrec@5 93.750 (94.031)\n",
      "Epoch: [8][500/559]\t\\Time 0.573 (0.551)\tData 0.463 (0.452)\tLoss 1.7151 (0.9018)\tPrec@1 56.250 (74.451)\tPrec@5 81.250 (93.875)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.575 (0.575)\n",
      "\n",
      "Loss 1.8604 (1.8604)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 75.000\n",
      " * Prec@1 65.625 Prec@5 81.250\n",
      " * Prec@1 68.750 Prec@5 85.417\n",
      " * Prec@1 64.062 Prec@5 85.938\n",
      " * Prec@1 65.000 Prec@5 85.000\n",
      " * Prec@1 62.500 Prec@5 83.333\n",
      " * Prec@1 59.821 Prec@5 82.143\n",
      " * Prec@1 58.594 Prec@5 80.469\n",
      " * Prec@1 56.944 Prec@5 80.556\n",
      " * Prec@1 55.625 Prec@5 79.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.573 (0.714)\n",
      "\n",
      "Loss 1.6152 (1.8939)\n",
      "\n",
      "Prec@1 50.000 (55.114)\n",
      "\n",
      "Prec@5 81.250 (79.545)\n",
      "\n",
      " * Prec@1 55.114 Prec@5 79.545\n",
      " * Prec@1 56.771 Prec@5 80.729\n",
      " * Prec@1 55.288 Prec@5 81.250\n",
      " * Prec@1 55.804 Prec@5 82.143\n",
      " * Prec@1 55.000 Prec@5 81.250\n",
      " * Prec@1 54.688 Prec@5 82.031\n",
      " * Prec@1 54.779 Prec@5 82.721\n",
      " * Prec@1 56.250 Prec@5 83.681\n",
      " * Prec@1 56.579 Prec@5 83.553\n",
      " * Prec@1 57.188 Prec@5 83.750\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.620 (0.706)\n",
      "\n",
      "Loss 1.9972 (1.7366)\n",
      "\n",
      "Prec@1 56.250 (57.143)\n",
      "\n",
      "Prec@5 75.000 (83.333)\n",
      "\n",
      " * Prec@1 57.143 Prec@5 83.333\n",
      " * Prec@1 57.102 Prec@5 83.523\n",
      " * Prec@1 58.152 Prec@5 83.967\n",
      " * Prec@1 59.115 Prec@5 84.635\n",
      " * Prec@1 59.250 Prec@5 84.750\n",
      " * Prec@1 59.375 Prec@5 84.375\n",
      " * Prec@1 59.491 Prec@5 84.259\n",
      " * Prec@1 59.821 Prec@5 84.375\n",
      " * Prec@1 59.483 Prec@5 83.836\n",
      " * Prec@1 60.417 Prec@5 83.958\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.670 (0.707)\n",
      "\n",
      "Loss 0.4347 (1.6296)\n",
      "\n",
      "Prec@1 93.750 (61.492)\n",
      "\n",
      "Prec@5 100.000 (84.476)\n",
      "\n",
      " * Prec@1 61.492 Prec@5 84.476\n",
      " * Prec@1 61.719 Prec@5 84.180\n",
      " * Prec@1 62.121 Prec@5 84.470\n",
      " * Prec@1 62.132 Prec@5 84.559\n",
      " * Prec@1 62.500 Prec@5 84.643\n",
      " * Prec@1 61.979 Prec@5 84.028\n",
      " * Prec@1 62.162 Prec@5 84.291\n",
      " * Prec@1 62.336 Prec@5 84.539\n",
      " * Prec@1 62.340 Prec@5 84.455\n",
      " * Prec@1 62.500 Prec@5 84.375\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.715 (0.714)\n",
      "\n",
      "Loss 2.5207 (1.6119)\n",
      "\n",
      "Prec@1 50.000 (62.195)\n",
      "\n",
      "Prec@5 75.000 (84.146)\n",
      "\n",
      " * Prec@1 62.195 Prec@5 84.146\n",
      " * Prec@1 61.607 Prec@5 83.929\n",
      " * Prec@1 62.209 Prec@5 84.157\n",
      " * Prec@1 61.932 Prec@5 83.807\n",
      " * Prec@1 61.389 Prec@5 83.750\n",
      " * Prec@1 61.277 Prec@5 83.832\n",
      " * Prec@1 61.303 Prec@5 83.644\n",
      " * Prec@1 61.198 Prec@5 83.594\n",
      " * Prec@1 61.224 Prec@5 83.418\n",
      " * Prec@1 61.000 Prec@5 83.500\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.648 (0.710)\n",
      "\n",
      "Loss 1.1701 (1.6500)\n",
      "\n",
      "Prec@1 62.500 (61.029)\n",
      "\n",
      "Prec@5 87.500 (83.578)\n",
      "\n",
      " * Prec@1 61.029 Prec@5 83.578\n",
      " * Prec@1 60.938 Prec@5 83.293\n",
      " * Prec@1 60.967 Prec@5 83.255\n",
      " * Prec@1 60.995 Prec@5 83.218\n",
      " * Prec@1 61.136 Prec@5 83.182\n",
      " * Prec@1 61.272 Prec@5 83.259\n",
      " * Prec@1 61.075 Prec@5 83.114\n",
      " * Prec@1 60.991 Prec@5 82.974\n",
      " * Prec@1 60.911 Prec@5 82.945\n",
      " * Prec@1 61.042 Prec@5 83.229\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.701 (0.708)\n",
      "\n",
      "Loss 1.5006 (1.6514)\n",
      "\n",
      "Prec@1 68.750 (61.168)\n",
      "\n",
      "Prec@5 87.500 (83.299)\n",
      "\n",
      " * Prec@1 61.168 Prec@5 83.299\n",
      " * Prec@1 61.391 Prec@5 83.468\n",
      " * Prec@1 61.607 Prec@5 83.433\n",
      " * Prec@1 61.621 Prec@5 83.594\n",
      " * Prec@1 61.923 Prec@5 83.654\n",
      " * Prec@1 61.742 Prec@5 83.428\n",
      " * Prec@1 61.754 Prec@5 83.396\n",
      " * Prec@1 62.040 Prec@5 83.456\n",
      " * Prec@1 61.957 Prec@5 83.333\n",
      " * Prec@1 61.875 Prec@5 83.393\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.687 (0.706)\n",
      "\n",
      "Loss 1.0973 (1.6395)\n",
      "\n",
      "Prec@1 81.250 (62.148)\n",
      "\n",
      "Prec@5 87.500 (83.451)\n",
      "\n",
      " * Prec@1 62.148 Prec@5 83.451\n",
      " * Prec@1 62.326 Prec@5 83.594\n",
      " * Prec@1 62.329 Prec@5 83.476\n",
      " * Prec@1 62.247 Prec@5 83.530\n",
      " * Prec@1 62.500 Prec@5 83.583\n",
      " * Prec@1 62.336 Prec@5 83.388\n",
      " * Prec@1 62.094 Prec@5 83.360\n",
      " * Prec@1 62.099 Prec@5 83.494\n",
      " * Prec@1 61.788 Prec@5 83.465\n",
      " * Prec@1 61.875 Prec@5 83.516\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.648 (0.705)\n",
      "\n",
      "Loss 1.2555 (1.6451)\n",
      "\n",
      "Prec@1 75.000 (62.037)\n",
      "\n",
      "Prec@5 87.500 (83.565)\n",
      "\n",
      " * Prec@1 62.037 Prec@5 83.565\n",
      " * Prec@1 62.195 Prec@5 83.537\n",
      " * Prec@1 62.425 Prec@5 83.735\n",
      " * Prec@1 62.426 Prec@5 83.854\n",
      " * Prec@1 62.574 Prec@5 83.971\n",
      " * Prec@1 62.718 Prec@5 84.012\n",
      " * Prec@1 62.859 Prec@5 84.124\n",
      " * Prec@1 62.642 Prec@5 84.091\n",
      " * Prec@1 62.640 Prec@5 84.129\n",
      " * Prec@1 62.847 Prec@5 84.167\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.704 (0.707)\n",
      "\n",
      "Loss 1.8303 (1.6153)\n",
      "\n",
      "Prec@1 50.000 (62.706)\n",
      "\n",
      "Prec@5 75.000 (84.066)\n",
      "\n",
      " * Prec@1 62.706 Prec@5 84.066\n",
      " * Prec@1 62.500 Prec@5 83.899\n",
      " * Prec@1 62.500 Prec@5 83.871\n",
      " * Prec@1 62.566 Prec@5 83.777\n",
      " * Prec@1 62.434 Prec@5 83.684\n",
      " * Prec@1 62.500 Prec@5 83.659\n",
      " * Prec@1 62.436 Prec@5 83.634\n",
      " * Prec@1 62.372 Prec@5 83.737\n",
      " * Prec@1 62.374 Prec@5 83.586\n",
      " * Prec@1 62.500 Prec@5 83.500\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.611 (0.706)\n",
      "\n",
      "Loss 1.7798 (1.6257)\n",
      "\n",
      "Prec@1 68.750 (62.562)\n",
      "\n",
      "Prec@5 81.250 (83.478)\n",
      "\n",
      " * Prec@1 62.562 Prec@5 83.478\n",
      " * Prec@1 62.745 Prec@5 83.640\n",
      " * Prec@1 62.985 Prec@5 83.799\n",
      " * Prec@1 62.981 Prec@5 83.894\n",
      " * Prec@1 63.036 Prec@5 83.988\n",
      " * Prec@1 62.854 Prec@5 83.903\n",
      " * Prec@1 63.026 Prec@5 83.995\n",
      " * Prec@1 63.137 Prec@5 83.912\n",
      " * Prec@1 63.131 Prec@5 83.888\n",
      " * Prec@1 62.955 Prec@5 83.807\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.684 (0.705)\n",
      "\n",
      "Loss 3.2012 (1.6204)\n",
      "\n",
      "Prec@1 37.500 (62.725)\n",
      "\n",
      "Prec@5 62.500 (83.615)\n",
      "\n",
      " * Prec@1 62.725 Prec@5 83.615\n",
      " * Prec@1 62.723 Prec@5 83.538\n",
      " * Prec@1 62.777 Prec@5 83.628\n",
      " * Prec@1 62.664 Prec@5 83.717\n",
      " * Prec@1 62.717 Prec@5 83.696\n",
      " * Prec@1 62.769 Prec@5 83.675\n",
      " * Prec@1 62.607 Prec@5 83.707\n",
      " * Prec@1 62.553 Prec@5 83.686\n",
      " * Prec@1 62.553 Prec@5 83.613\n",
      " * Prec@1 62.604 Prec@5 83.646\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.732 (0.704)\n",
      "\n",
      "Loss 2.3067 (1.6232)\n",
      "\n",
      "Prec@1 62.500 (62.603)\n",
      "\n",
      "Prec@5 75.000 (83.574)\n",
      "\n",
      " * Prec@1 62.603 Prec@5 83.574\n",
      " * Prec@1 62.551 Prec@5 83.555\n",
      " * Prec@1 62.348 Prec@5 83.333\n",
      " * Prec@1 62.198 Prec@5 83.266\n",
      " * Prec@1 62.150 Prec@5 83.150\n",
      " * Prec@1 62.103 Prec@5 83.185\n",
      " * Prec@1 62.106 Prec@5 83.120\n",
      " * Prec@1 62.207 Prec@5 83.105\n",
      " * Prec@1 62.064 Prec@5 82.946\n",
      " * Prec@1 62.019 Prec@5 82.885\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.680 (0.703)\n",
      "\n",
      "Loss 2.1075 (1.6615)\n",
      "\n",
      "Prec@1 56.250 (61.975)\n",
      "\n",
      "Prec@5 75.000 (82.824)\n",
      "\n",
      " * Prec@1 61.975 Prec@5 82.824\n",
      " * Prec@1 61.979 Prec@5 82.812\n",
      " * Prec@1 62.124 Prec@5 82.895\n",
      " * Prec@1 62.220 Prec@5 82.882\n",
      " * Prec@1 62.130 Prec@5 82.917\n",
      " * Prec@1 62.316 Prec@5 82.996\n",
      " * Prec@1 62.181 Prec@5 82.984\n",
      " * Prec@1 62.138 Prec@5 82.971\n",
      " * Prec@1 62.050 Prec@5 82.959\n",
      " * Prec@1 62.069 Prec@5 82.938\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/559]\t\\Time 0.523 (0.523)\tData 0.453 (0.453)\tLoss 0.4164 (0.4164)\tPrec@1 93.750 (93.750)\tPrec@5 93.750 (93.750)\n",
      "Epoch: [9][100/559]\t\\Time 0.622 (0.539)\tData 0.501 (0.438)\tLoss 0.4365 (0.5765)\tPrec@1 81.250 (83.230)\tPrec@5 100.000 (97.092)\n",
      "Epoch: [9][200/559]\t\\Time 0.589 (0.543)\tData 0.469 (0.443)\tLoss 1.0129 (0.6001)\tPrec@1 68.750 (82.276)\tPrec@5 87.500 (97.201)\n",
      "Epoch: [9][300/559]\t\\Time 0.623 (0.546)\tData 0.513 (0.445)\tLoss 0.3971 (0.6223)\tPrec@1 87.500 (81.728)\tPrec@5 100.000 (96.948)\n",
      "Epoch: [9][400/559]\t\\Time 0.525 (0.545)\tData 0.414 (0.445)\tLoss 1.0598 (0.6414)\tPrec@1 81.250 (81.515)\tPrec@5 93.750 (96.789)\n",
      "Epoch: [9][500/559]\t\\Time 0.541 (0.544)\tData 0.430 (0.444)\tLoss 0.2624 (0.6526)\tPrec@1 93.750 (81.325)\tPrec@5 100.000 (96.657)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.555 (0.555)\n",
      "\n",
      "Loss 1.7406 (1.7406)\n",
      "\n",
      "Prec@1 68.750 (68.750)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 62.500 Prec@5 87.500\n",
      " * Prec@1 64.583 Prec@5 85.417\n",
      " * Prec@1 64.062 Prec@5 84.375\n",
      " * Prec@1 65.000 Prec@5 83.750\n",
      " * Prec@1 61.458 Prec@5 81.250\n",
      " * Prec@1 58.036 Prec@5 80.357\n",
      " * Prec@1 56.250 Prec@5 79.688\n",
      " * Prec@1 55.556 Prec@5 79.861\n",
      " * Prec@1 54.375 Prec@5 78.750\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.551 (0.710)\n",
      "\n",
      "Loss 1.7251 (2.1858)\n",
      "\n",
      "Prec@1 56.250 (54.545)\n",
      "\n",
      "Prec@5 81.250 (78.977)\n",
      "\n",
      " * Prec@1 54.545 Prec@5 78.977\n",
      " * Prec@1 56.250 Prec@5 80.208\n",
      " * Prec@1 56.250 Prec@5 80.288\n",
      " * Prec@1 56.250 Prec@5 80.804\n",
      " * Prec@1 56.667 Prec@5 80.833\n",
      " * Prec@1 56.250 Prec@5 81.641\n",
      " * Prec@1 57.353 Prec@5 82.721\n",
      " * Prec@1 57.986 Prec@5 83.333\n",
      " * Prec@1 58.224 Prec@5 83.553\n",
      " * Prec@1 59.062 Prec@5 83.750\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.627 (0.717)\n",
      "\n",
      "Loss 2.3425 (1.9093)\n",
      "\n",
      "Prec@1 62.500 (59.226)\n",
      "\n",
      "Prec@5 87.500 (83.929)\n",
      "\n",
      " * Prec@1 59.226 Prec@5 83.929\n",
      " * Prec@1 58.807 Prec@5 83.239\n",
      " * Prec@1 59.783 Prec@5 83.424\n",
      " * Prec@1 60.156 Prec@5 83.854\n",
      " * Prec@1 60.250 Prec@5 83.750\n",
      " * Prec@1 59.135 Prec@5 83.654\n",
      " * Prec@1 59.028 Prec@5 83.102\n",
      " * Prec@1 58.929 Prec@5 83.036\n",
      " * Prec@1 58.836 Prec@5 82.759\n",
      " * Prec@1 59.167 Prec@5 82.917\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.693 (0.714)\n",
      "\n",
      "Loss 0.4185 (1.8474)\n",
      "\n",
      "Prec@1 87.500 (60.081)\n",
      "\n",
      "Prec@5 100.000 (83.468)\n",
      "\n",
      " * Prec@1 60.081 Prec@5 83.468\n",
      " * Prec@1 59.766 Prec@5 83.398\n",
      " * Prec@1 59.848 Prec@5 83.523\n",
      " * Prec@1 59.559 Prec@5 83.456\n",
      " * Prec@1 59.464 Prec@5 83.214\n",
      " * Prec@1 59.201 Prec@5 82.639\n",
      " * Prec@1 59.459 Prec@5 82.939\n",
      " * Prec@1 59.539 Prec@5 83.059\n",
      " * Prec@1 59.936 Prec@5 83.013\n",
      " * Prec@1 60.000 Prec@5 82.812\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.670 (0.719)\n",
      "\n",
      "Loss 2.7006 (1.8537)\n",
      "\n",
      "Prec@1 43.750 (59.604)\n",
      "\n",
      "Prec@5 75.000 (82.622)\n",
      "\n",
      " * Prec@1 59.604 Prec@5 82.622\n",
      " * Prec@1 59.226 Prec@5 82.738\n",
      " * Prec@1 60.029 Prec@5 82.994\n",
      " * Prec@1 59.943 Prec@5 82.812\n",
      " * Prec@1 60.000 Prec@5 82.639\n",
      " * Prec@1 60.190 Prec@5 82.880\n",
      " * Prec@1 60.106 Prec@5 82.979\n",
      " * Prec@1 59.896 Prec@5 83.073\n",
      " * Prec@1 59.949 Prec@5 83.163\n",
      " * Prec@1 60.375 Prec@5 83.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.671 (0.715)\n",
      "\n",
      "Loss 1.2236 (1.7952)\n",
      "\n",
      "Prec@1 68.750 (60.539)\n",
      "\n",
      "Prec@5 87.500 (83.456)\n",
      "\n",
      " * Prec@1 60.539 Prec@5 83.456\n",
      " * Prec@1 60.577 Prec@5 83.413\n",
      " * Prec@1 60.613 Prec@5 83.491\n",
      " * Prec@1 60.764 Prec@5 83.449\n",
      " * Prec@1 61.023 Prec@5 83.636\n",
      " * Prec@1 61.161 Prec@5 83.594\n",
      " * Prec@1 60.746 Prec@5 83.443\n",
      " * Prec@1 60.560 Prec@5 83.405\n",
      " * Prec@1 60.487 Prec@5 83.263\n",
      " * Prec@1 60.729 Prec@5 83.542\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.713 (0.712)\n",
      "\n",
      "Loss 1.6322 (1.7810)\n",
      "\n",
      "Prec@1 75.000 (60.963)\n",
      "\n",
      "Prec@5 87.500 (83.607)\n",
      "\n",
      " * Prec@1 60.963 Prec@5 83.607\n",
      " * Prec@1 61.290 Prec@5 83.770\n",
      " * Prec@1 61.210 Prec@5 83.730\n",
      " * Prec@1 61.328 Prec@5 83.691\n",
      " * Prec@1 61.346 Prec@5 83.750\n",
      " * Prec@1 61.174 Prec@5 83.523\n",
      " * Prec@1 60.914 Prec@5 83.396\n",
      " * Prec@1 61.121 Prec@5 83.456\n",
      " * Prec@1 60.870 Prec@5 83.243\n",
      " * Prec@1 60.893 Prec@5 83.214\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.683 (0.710)\n",
      "\n",
      "Loss 0.9547 (1.7897)\n",
      "\n",
      "Prec@1 68.750 (61.004)\n",
      "\n",
      "Prec@5 93.750 (83.363)\n",
      "\n",
      " * Prec@1 61.004 Prec@5 83.363\n",
      " * Prec@1 60.938 Prec@5 83.507\n",
      " * Prec@1 60.959 Prec@5 83.562\n",
      " * Prec@1 60.811 Prec@5 83.530\n",
      " * Prec@1 61.000 Prec@5 83.500\n",
      " * Prec@1 61.102 Prec@5 83.388\n",
      " * Prec@1 60.958 Prec@5 83.279\n",
      " * Prec@1 61.138 Prec@5 83.413\n",
      " * Prec@1 61.076 Prec@5 83.307\n",
      " * Prec@1 61.250 Prec@5 83.438\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.665 (0.709)\n",
      "\n",
      "Loss 1.8769 (1.7760)\n",
      "\n",
      "Prec@1 75.000 (61.420)\n",
      "\n",
      "Prec@5 75.000 (83.333)\n",
      "\n",
      " * Prec@1 61.420 Prec@5 83.333\n",
      " * Prec@1 61.509 Prec@5 83.384\n",
      " * Prec@1 61.672 Prec@5 83.584\n",
      " * Prec@1 61.756 Prec@5 83.705\n",
      " * Prec@1 61.912 Prec@5 83.897\n",
      " * Prec@1 61.991 Prec@5 83.866\n",
      " * Prec@1 61.997 Prec@5 83.908\n",
      " * Prec@1 61.932 Prec@5 83.878\n",
      " * Prec@1 62.008 Prec@5 83.848\n",
      " * Prec@1 62.083 Prec@5 83.958\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.681 (0.708)\n",
      "\n",
      "Loss 1.8842 (1.7426)\n",
      "\n",
      "Prec@1 50.000 (61.951)\n",
      "\n",
      "Prec@5 87.500 (83.997)\n",
      "\n",
      " * Prec@1 61.951 Prec@5 83.997\n",
      " * Prec@1 61.957 Prec@5 84.035\n",
      " * Prec@1 62.164 Prec@5 84.140\n",
      " * Prec@1 61.902 Prec@5 83.976\n",
      " * Prec@1 61.711 Prec@5 83.882\n",
      " * Prec@1 61.914 Prec@5 83.854\n",
      " * Prec@1 61.791 Prec@5 83.827\n",
      " * Prec@1 61.926 Prec@5 83.929\n",
      " * Prec@1 62.058 Prec@5 84.091\n",
      " * Prec@1 62.250 Prec@5 84.062\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.622 (0.708)\n",
      "\n",
      "Loss 1.9301 (1.7340)\n",
      "\n",
      "Prec@1 62.500 (62.252)\n",
      "\n",
      "Prec@5 75.000 (83.973)\n",
      "\n",
      " * Prec@1 62.252 Prec@5 83.973\n",
      " * Prec@1 62.439 Prec@5 84.130\n",
      " * Prec@1 62.682 Prec@5 84.284\n",
      " * Prec@1 62.680 Prec@5 84.375\n",
      " * Prec@1 62.619 Prec@5 84.286\n",
      " * Prec@1 62.382 Prec@5 84.257\n",
      " * Prec@1 62.558 Prec@5 84.346\n",
      " * Prec@1 62.616 Prec@5 84.317\n",
      " * Prec@1 62.557 Prec@5 84.232\n",
      " * Prec@1 62.557 Prec@5 84.148\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.660 (0.707)\n",
      "\n",
      "Loss 3.1789 (1.7234)\n",
      "\n",
      "Prec@1 37.500 (62.331)\n",
      "\n",
      "Prec@5 68.750 (84.009)\n",
      "\n",
      " * Prec@1 62.331 Prec@5 84.009\n",
      " * Prec@1 62.221 Prec@5 83.929\n",
      " * Prec@1 62.279 Prec@5 84.015\n",
      " * Prec@1 62.390 Prec@5 83.991\n",
      " * Prec@1 62.554 Prec@5 84.076\n",
      " * Prec@1 62.554 Prec@5 83.998\n",
      " * Prec@1 62.340 Prec@5 84.028\n",
      " * Prec@1 62.341 Prec@5 84.163\n",
      " * Prec@1 62.290 Prec@5 84.139\n",
      " * Prec@1 62.292 Prec@5 84.115\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.723 (0.706)\n",
      "\n",
      "Loss 2.0930 (1.7169)\n",
      "\n",
      "Prec@1 62.500 (62.293)\n",
      "\n",
      "Prec@5 75.000 (84.039)\n",
      "\n",
      " * Prec@1 62.293 Prec@5 84.039\n",
      " * Prec@1 62.295 Prec@5 84.119\n",
      " * Prec@1 62.246 Prec@5 83.994\n",
      " * Prec@1 62.198 Prec@5 83.921\n",
      " * Prec@1 62.200 Prec@5 83.750\n",
      " * Prec@1 62.351 Prec@5 83.780\n",
      " * Prec@1 62.451 Prec@5 83.760\n",
      " * Prec@1 62.451 Prec@5 83.740\n",
      " * Prec@1 62.403 Prec@5 83.672\n",
      " * Prec@1 62.404 Prec@5 83.702\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.709 (0.705)\n",
      "\n",
      "Loss 3.0862 (1.7475)\n",
      "\n",
      "Prec@1 37.500 (62.214)\n",
      "\n",
      "Prec@5 62.500 (83.540)\n",
      "\n",
      " * Prec@1 62.214 Prec@5 83.540\n",
      " * Prec@1 62.263 Prec@5 83.523\n",
      " * Prec@1 62.453 Prec@5 83.647\n",
      " * Prec@1 62.500 Prec@5 83.675\n",
      " * Prec@1 62.500 Prec@5 83.750\n",
      " * Prec@1 62.684 Prec@5 83.869\n",
      " * Prec@1 62.637 Prec@5 83.896\n",
      " * Prec@1 62.636 Prec@5 83.877\n",
      " * Prec@1 62.635 Prec@5 83.903\n",
      " * Prec@1 62.517 Prec@5 83.968\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [10][0/559]\t\\Time 0.560 (0.560)\tData 0.452 (0.452)\tLoss 0.1482 (0.1482)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/559]\t\\Time 0.471 (0.551)\tData 0.403 (0.452)\tLoss 0.1434 (0.3536)\tPrec@1 100.000 (89.480)\tPrec@5 100.000 (99.072)\n",
      "Epoch: [10][200/559]\t\\Time 0.562 (0.552)\tData 0.450 (0.453)\tLoss 0.4429 (0.3549)\tPrec@1 81.250 (89.428)\tPrec@5 100.000 (99.098)\n",
      "Epoch: [10][300/559]\t\\Time 0.580 (0.550)\tData 0.472 (0.451)\tLoss 0.2374 (0.3804)\tPrec@1 93.750 (88.580)\tPrec@5 100.000 (99.045)\n",
      "Epoch: [10][400/559]\t\\Time 0.580 (0.551)\tData 0.470 (0.452)\tLoss 0.1510 (0.4036)\tPrec@1 100.000 (87.890)\tPrec@5 100.000 (98.971)\n",
      "Epoch: [10][500/559]\t\\Time 0.548 (0.550)\tData 0.447 (0.450)\tLoss 0.7967 (0.4362)\tPrec@1 75.000 (86.926)\tPrec@5 100.000 (98.678)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.582 (0.582)\n",
      "\n",
      "Loss 2.0550 (2.0550)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 81.250\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 68.750 Prec@5 85.417\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 66.250 Prec@5 83.750\n",
      " * Prec@1 62.500 Prec@5 83.333\n",
      " * Prec@1 63.393 Prec@5 83.929\n",
      " * Prec@1 60.938 Prec@5 82.031\n",
      " * Prec@1 59.028 Prec@5 81.250\n",
      " * Prec@1 56.875 Prec@5 80.000\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.562 (0.730)\n",
      "\n",
      "Loss 1.7443 (2.1172)\n",
      "\n",
      "Prec@1 56.250 (56.818)\n",
      "\n",
      "Prec@5 81.250 (80.114)\n",
      "\n",
      " * Prec@1 56.818 Prec@5 80.114\n",
      " * Prec@1 57.292 Prec@5 81.250\n",
      " * Prec@1 56.731 Prec@5 81.250\n",
      " * Prec@1 56.250 Prec@5 80.804\n",
      " * Prec@1 56.250 Prec@5 80.000\n",
      " * Prec@1 56.250 Prec@5 80.078\n",
      " * Prec@1 57.353 Prec@5 80.882\n",
      " * Prec@1 59.375 Prec@5 81.944\n",
      " * Prec@1 59.868 Prec@5 82.237\n",
      " * Prec@1 59.375 Prec@5 82.812\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.651 (0.711)\n",
      "\n",
      "Loss 2.6949 (1.9163)\n",
      "\n",
      "Prec@1 56.250 (59.226)\n",
      "\n",
      "Prec@5 68.750 (82.143)\n",
      "\n",
      " * Prec@1 59.226 Prec@5 82.143\n",
      " * Prec@1 59.659 Prec@5 82.102\n",
      " * Prec@1 60.326 Prec@5 82.609\n",
      " * Prec@1 61.198 Prec@5 83.333\n",
      " * Prec@1 61.750 Prec@5 83.500\n",
      " * Prec@1 61.538 Prec@5 83.654\n",
      " * Prec@1 61.574 Prec@5 83.565\n",
      " * Prec@1 62.277 Prec@5 83.705\n",
      " * Prec@1 62.069 Prec@5 83.405\n",
      " * Prec@1 62.292 Prec@5 83.542\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.685 (0.716)\n",
      "\n",
      "Loss 0.2850 (1.7166)\n",
      "\n",
      "Prec@1 93.750 (63.306)\n",
      "\n",
      "Prec@5 100.000 (84.073)\n",
      "\n",
      " * Prec@1 63.306 Prec@5 84.073\n",
      " * Prec@1 62.695 Prec@5 83.789\n",
      " * Prec@1 62.689 Prec@5 83.902\n",
      " * Prec@1 62.684 Prec@5 83.824\n",
      " * Prec@1 62.857 Prec@5 83.750\n",
      " * Prec@1 62.674 Prec@5 83.160\n",
      " * Prec@1 63.007 Prec@5 83.446\n",
      " * Prec@1 63.487 Prec@5 83.717\n",
      " * Prec@1 63.942 Prec@5 83.654\n",
      " * Prec@1 64.062 Prec@5 83.906\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.682 (0.719)\n",
      "\n",
      "Loss 2.3491 (1.7245)\n",
      "\n",
      "Prec@1 62.500 (64.024)\n",
      "\n",
      "Prec@5 87.500 (83.994)\n",
      "\n",
      " * Prec@1 64.024 Prec@5 83.994\n",
      " * Prec@1 63.690 Prec@5 83.780\n",
      " * Prec@1 63.663 Prec@5 83.866\n",
      " * Prec@1 63.494 Prec@5 83.665\n",
      " * Prec@1 63.472 Prec@5 83.611\n",
      " * Prec@1 63.995 Prec@5 83.967\n",
      " * Prec@1 64.096 Prec@5 84.043\n",
      " * Prec@1 63.932 Prec@5 84.115\n",
      " * Prec@1 64.031 Prec@5 84.056\n",
      " * Prec@1 64.000 Prec@5 84.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.671 (0.714)\n",
      "\n",
      "Loss 1.3926 (1.6896)\n",
      "\n",
      "Prec@1 62.500 (63.971)\n",
      "\n",
      "Prec@5 87.500 (84.436)\n",
      "\n",
      " * Prec@1 63.971 Prec@5 84.436\n",
      " * Prec@1 63.702 Prec@5 84.135\n",
      " * Prec@1 63.915 Prec@5 84.316\n",
      " * Prec@1 64.236 Prec@5 84.259\n",
      " * Prec@1 64.318 Prec@5 84.318\n",
      " * Prec@1 64.509 Prec@5 84.375\n",
      " * Prec@1 64.145 Prec@5 84.211\n",
      " * Prec@1 63.901 Prec@5 84.159\n",
      " * Prec@1 64.089 Prec@5 84.004\n",
      " * Prec@1 64.271 Prec@5 84.062\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.652 (0.712)\n",
      "\n",
      "Loss 1.3432 (1.7013)\n",
      "\n",
      "Prec@1 81.250 (64.549)\n",
      "\n",
      "Prec@5 81.250 (84.016)\n",
      "\n",
      " * Prec@1 64.549 Prec@5 84.016\n",
      " * Prec@1 64.617 Prec@5 84.173\n",
      " * Prec@1 64.583 Prec@5 84.325\n",
      " * Prec@1 64.551 Prec@5 84.473\n",
      " * Prec@1 64.808 Prec@5 84.423\n",
      " * Prec@1 64.867 Prec@5 84.375\n",
      " * Prec@1 64.925 Prec@5 84.328\n",
      " * Prec@1 65.074 Prec@5 84.467\n",
      " * Prec@1 64.946 Prec@5 84.239\n",
      " * Prec@1 65.268 Prec@5 84.286\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.681 (0.711)\n",
      "\n",
      "Loss 1.6479 (1.6858)\n",
      "\n",
      "Prec@1 50.000 (65.053)\n",
      "\n",
      "Prec@5 87.500 (84.331)\n",
      "\n",
      " * Prec@1 65.053 Prec@5 84.331\n",
      " * Prec@1 65.017 Prec@5 84.462\n",
      " * Prec@1 64.897 Prec@5 84.503\n",
      " * Prec@1 64.780 Prec@5 84.544\n",
      " * Prec@1 65.083 Prec@5 84.583\n",
      " * Prec@1 64.885 Prec@5 84.457\n",
      " * Prec@1 64.773 Prec@5 84.416\n",
      " * Prec@1 64.904 Prec@5 84.455\n",
      " * Prec@1 64.636 Prec@5 84.415\n",
      " * Prec@1 64.688 Prec@5 84.531\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.614 (0.708)\n",
      "\n",
      "Loss 1.2326 (1.6842)\n",
      "\n",
      "Prec@1 75.000 (64.815)\n",
      "\n",
      "Prec@5 93.750 (84.645)\n",
      "\n",
      " * Prec@1 64.815 Prec@5 84.645\n",
      " * Prec@1 64.939 Prec@5 84.756\n",
      " * Prec@1 65.060 Prec@5 84.940\n",
      " * Prec@1 65.179 Prec@5 84.970\n",
      " * Prec@1 65.294 Prec@5 85.000\n",
      " * Prec@1 65.262 Prec@5 84.956\n",
      " * Prec@1 65.374 Prec@5 85.057\n",
      " * Prec@1 65.128 Prec@5 84.943\n",
      " * Prec@1 65.098 Prec@5 84.902\n",
      " * Prec@1 65.278 Prec@5 85.000\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.692 (0.707)\n",
      "\n",
      "Loss 1.6466 (1.6554)\n",
      "\n",
      "Prec@1 56.250 (65.179)\n",
      "\n",
      "Prec@5 87.500 (85.027)\n",
      "\n",
      " * Prec@1 65.179 Prec@5 85.027\n",
      " * Prec@1 65.082 Prec@5 84.918\n",
      " * Prec@1 65.121 Prec@5 84.946\n",
      " * Prec@1 64.960 Prec@5 84.774\n",
      " * Prec@1 64.803 Prec@5 84.671\n",
      " * Prec@1 64.844 Prec@5 84.635\n",
      " * Prec@1 64.626 Prec@5 84.601\n",
      " * Prec@1 64.668 Prec@5 84.694\n",
      " * Prec@1 64.836 Prec@5 84.722\n",
      " * Prec@1 64.938 Prec@5 84.688\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.672 (0.706)\n",
      "\n",
      "Loss 2.4457 (1.6776)\n",
      "\n",
      "Prec@1 68.750 (64.975)\n",
      "\n",
      "Prec@5 81.250 (84.653)\n",
      "\n",
      " * Prec@1 64.975 Prec@5 84.653\n",
      " * Prec@1 65.135 Prec@5 84.743\n",
      " * Prec@1 65.291 Prec@5 84.891\n",
      " * Prec@1 65.325 Prec@5 84.976\n",
      " * Prec@1 65.417 Prec@5 85.060\n",
      " * Prec@1 65.212 Prec@5 85.024\n",
      " * Prec@1 65.304 Prec@5 85.105\n",
      " * Prec@1 65.220 Prec@5 85.069\n",
      " * Prec@1 65.252 Prec@5 84.977\n",
      " * Prec@1 65.227 Prec@5 84.830\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.661 (0.705)\n",
      "\n",
      "Loss 4.0611 (1.6882)\n",
      "\n",
      "Prec@1 50.000 (65.090)\n",
      "\n",
      "Prec@5 62.500 (84.628)\n",
      "\n",
      " * Prec@1 65.090 Prec@5 84.628\n",
      " * Prec@1 65.123 Prec@5 84.654\n",
      " * Prec@1 65.321 Prec@5 84.735\n",
      " * Prec@1 65.296 Prec@5 84.814\n",
      " * Prec@1 65.380 Prec@5 84.837\n",
      " * Prec@1 65.409 Prec@5 84.806\n",
      " * Prec@1 65.385 Prec@5 84.669\n",
      " * Prec@1 65.360 Prec@5 84.640\n",
      " * Prec@1 65.441 Prec@5 84.611\n",
      " * Prec@1 65.417 Prec@5 84.531\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.722 (0.705)\n",
      "\n",
      "Loss 1.7448 (1.6981)\n",
      "\n",
      "Prec@1 75.000 (65.496)\n",
      "\n",
      "Prec@5 87.500 (84.556)\n",
      "\n",
      " * Prec@1 65.496 Prec@5 84.556\n",
      " * Prec@1 65.574 Prec@5 84.631\n",
      " * Prec@1 65.396 Prec@5 84.502\n",
      " * Prec@1 65.323 Prec@5 84.375\n",
      " * Prec@1 65.200 Prec@5 84.250\n",
      " * Prec@1 65.327 Prec@5 84.276\n",
      " * Prec@1 65.354 Prec@5 84.252\n",
      " * Prec@1 65.332 Prec@5 84.229\n",
      " * Prec@1 65.262 Prec@5 84.157\n",
      " * Prec@1 65.337 Prec@5 84.183\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.689 (0.705)\n",
      "\n",
      "Loss 2.6940 (1.7387)\n",
      "\n",
      "Prec@1 56.250 (65.267)\n",
      "\n",
      "Prec@5 81.250 (84.160)\n",
      "\n",
      " * Prec@1 65.267 Prec@5 84.160\n",
      " * Prec@1 65.341 Prec@5 84.138\n",
      " * Prec@1 65.508 Prec@5 84.258\n",
      " * Prec@1 65.485 Prec@5 84.142\n",
      " * Prec@1 65.556 Prec@5 84.213\n",
      " * Prec@1 65.533 Prec@5 84.237\n",
      " * Prec@1 65.420 Prec@5 84.307\n",
      " * Prec@1 65.399 Prec@5 84.194\n",
      " * Prec@1 65.513 Prec@5 84.218\n",
      " * Prec@1 65.562 Prec@5 84.236\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [11][0/559]\t\\Time 0.503 (0.503)\tData 0.395 (0.395)\tLoss 0.4017 (0.4017)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/559]\t\\Time 0.601 (0.547)\tData 0.495 (0.448)\tLoss 0.0809 (0.2930)\tPrec@1 100.000 (91.646)\tPrec@5 100.000 (99.257)\n",
      "Epoch: [11][200/559]\t\\Time 0.553 (0.550)\tData 0.441 (0.451)\tLoss 0.4815 (0.2826)\tPrec@1 81.250 (91.511)\tPrec@5 100.000 (99.285)\n",
      "Epoch: [11][300/559]\t\\Time 0.483 (0.552)\tData 0.379 (0.454)\tLoss 0.2228 (0.3053)\tPrec@1 93.750 (90.760)\tPrec@5 100.000 (99.252)\n",
      "Epoch: [11][400/559]\t\\Time 0.493 (0.551)\tData 0.387 (0.452)\tLoss 0.2157 (0.3185)\tPrec@1 93.750 (90.259)\tPrec@5 100.000 (99.190)\n",
      "Epoch: [11][500/559]\t\\Time 0.626 (0.551)\tData 0.513 (0.452)\tLoss 0.1779 (0.3356)\tPrec@1 100.000 (89.795)\tPrec@5 100.000 (99.114)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.542 (0.542)\n",
      "\n",
      "Loss 1.7966 (1.7966)\n",
      "\n",
      "Prec@1 62.500 (62.500)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 62.500 Prec@5 81.250\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 85.417\n",
      " * Prec@1 65.625 Prec@5 82.812\n",
      " * Prec@1 65.000 Prec@5 82.500\n",
      " * Prec@1 63.542 Prec@5 80.208\n",
      " * Prec@1 61.607 Prec@5 81.250\n",
      " * Prec@1 58.594 Prec@5 79.688\n",
      " * Prec@1 58.333 Prec@5 79.167\n",
      " * Prec@1 56.875 Prec@5 78.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.572 (0.702)\n",
      "\n",
      "Loss 2.4706 (2.5197)\n",
      "\n",
      "Prec@1 50.000 (56.250)\n",
      "\n",
      "Prec@5 81.250 (78.409)\n",
      "\n",
      " * Prec@1 56.250 Prec@5 78.409\n",
      " * Prec@1 57.292 Prec@5 78.646\n",
      " * Prec@1 56.731 Prec@5 78.846\n",
      " * Prec@1 57.143 Prec@5 79.464\n",
      " * Prec@1 57.500 Prec@5 79.167\n",
      " * Prec@1 58.594 Prec@5 79.297\n",
      " * Prec@1 59.191 Prec@5 80.147\n",
      " * Prec@1 60.069 Prec@5 81.250\n",
      " * Prec@1 60.855 Prec@5 81.908\n",
      " * Prec@1 61.875 Prec@5 82.500\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.620 (0.705)\n",
      "\n",
      "Loss 2.2219 (2.1410)\n",
      "\n",
      "Prec@1 62.500 (61.905)\n",
      "\n",
      "Prec@5 75.000 (82.143)\n",
      "\n",
      " * Prec@1 61.905 Prec@5 82.143\n",
      " * Prec@1 61.648 Prec@5 81.818\n",
      " * Prec@1 62.228 Prec@5 82.065\n",
      " * Prec@1 63.542 Prec@5 82.552\n",
      " * Prec@1 64.250 Prec@5 82.750\n",
      " * Prec@1 64.423 Prec@5 82.933\n",
      " * Prec@1 65.046 Prec@5 82.870\n",
      " * Prec@1 64.955 Prec@5 82.812\n",
      " * Prec@1 64.224 Prec@5 82.543\n",
      " * Prec@1 63.958 Prec@5 82.708\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.662 (0.708)\n",
      "\n",
      "Loss 0.2264 (1.9142)\n",
      "\n",
      "Prec@1 93.750 (64.919)\n",
      "\n",
      "Prec@5 100.000 (83.266)\n",
      "\n",
      " * Prec@1 64.919 Prec@5 83.266\n",
      " * Prec@1 64.258 Prec@5 83.203\n",
      " * Prec@1 64.773 Prec@5 83.523\n",
      " * Prec@1 65.074 Prec@5 83.640\n",
      " * Prec@1 65.357 Prec@5 83.571\n",
      " * Prec@1 65.278 Prec@5 83.507\n",
      " * Prec@1 65.541 Prec@5 83.615\n",
      " * Prec@1 65.789 Prec@5 83.882\n",
      " * Prec@1 65.865 Prec@5 83.974\n",
      " * Prec@1 66.250 Prec@5 84.062\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.663 (0.711)\n",
      "\n",
      "Loss 2.7551 (1.8268)\n",
      "\n",
      "Prec@1 62.500 (66.159)\n",
      "\n",
      "Prec@5 81.250 (83.994)\n",
      "\n",
      " * Prec@1 66.159 Prec@5 83.994\n",
      " * Prec@1 66.220 Prec@5 83.929\n",
      " * Prec@1 66.860 Prec@5 84.157\n",
      " * Prec@1 66.903 Prec@5 84.233\n",
      " * Prec@1 66.667 Prec@5 84.306\n",
      " * Prec@1 66.576 Prec@5 84.511\n",
      " * Prec@1 66.888 Prec@5 84.707\n",
      " * Prec@1 66.927 Prec@5 84.635\n",
      " * Prec@1 66.709 Prec@5 84.821\n",
      " * Prec@1 66.750 Prec@5 85.000\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.643 (0.708)\n",
      "\n",
      "Loss 1.4164 (1.7634)\n",
      "\n",
      "Prec@1 62.500 (66.667)\n",
      "\n",
      "Prec@5 87.500 (85.049)\n",
      "\n",
      " * Prec@1 66.667 Prec@5 85.049\n",
      " * Prec@1 66.707 Prec@5 84.976\n",
      " * Prec@1 66.863 Prec@5 85.142\n",
      " * Prec@1 67.014 Prec@5 85.069\n",
      " * Prec@1 67.159 Prec@5 85.114\n",
      " * Prec@1 67.299 Prec@5 85.156\n",
      " * Prec@1 67.215 Prec@5 85.197\n",
      " * Prec@1 67.134 Prec@5 85.129\n",
      " * Prec@1 67.161 Prec@5 84.958\n",
      " * Prec@1 67.292 Prec@5 85.104\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.665 (0.707)\n",
      "\n",
      "Loss 1.9447 (1.7487)\n",
      "\n",
      "Prec@1 62.500 (67.213)\n",
      "\n",
      "Prec@5 81.250 (85.041)\n",
      "\n",
      " * Prec@1 67.213 Prec@5 85.041\n",
      " * Prec@1 67.137 Prec@5 85.181\n",
      " * Prec@1 67.262 Prec@5 85.317\n",
      " * Prec@1 67.480 Prec@5 85.449\n",
      " * Prec@1 67.308 Prec@5 85.481\n",
      " * Prec@1 66.951 Prec@5 85.322\n",
      " * Prec@1 66.698 Prec@5 85.354\n",
      " * Prec@1 67.004 Prec@5 85.478\n",
      " * Prec@1 66.848 Prec@5 85.326\n",
      " * Prec@1 67.054 Prec@5 85.357\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.673 (0.709)\n",
      "\n",
      "Loss 2.2498 (1.7500)\n",
      "\n",
      "Prec@1 62.500 (66.989)\n",
      "\n",
      "Prec@5 81.250 (85.299)\n",
      "\n",
      " * Prec@1 66.989 Prec@5 85.299\n",
      " * Prec@1 67.014 Prec@5 85.417\n",
      " * Prec@1 66.952 Prec@5 85.531\n",
      " * Prec@1 66.976 Prec@5 85.557\n",
      " * Prec@1 67.167 Prec@5 85.750\n",
      " * Prec@1 67.188 Prec@5 85.691\n",
      " * Prec@1 67.127 Prec@5 85.633\n",
      " * Prec@1 67.228 Prec@5 85.577\n",
      " * Prec@1 67.168 Prec@5 85.443\n",
      " * Prec@1 67.500 Prec@5 85.547\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.621 (0.705)\n",
      "\n",
      "Loss 1.3749 (1.7194)\n",
      "\n",
      "Prec@1 62.500 (67.438)\n",
      "\n",
      "Prec@5 87.500 (85.571)\n",
      "\n",
      " * Prec@1 67.438 Prec@5 85.571\n",
      " * Prec@1 67.607 Prec@5 85.671\n",
      " * Prec@1 67.696 Prec@5 85.843\n",
      " * Prec@1 67.634 Prec@5 85.863\n",
      " * Prec@1 67.647 Prec@5 85.956\n",
      " * Prec@1 67.587 Prec@5 85.901\n",
      " * Prec@1 67.601 Prec@5 85.991\n",
      " * Prec@1 67.330 Prec@5 85.866\n",
      " * Prec@1 67.275 Prec@5 85.815\n",
      " * Prec@1 67.500 Prec@5 85.903\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.733 (0.705)\n",
      "\n",
      "Loss 1.5658 (1.6996)\n",
      "\n",
      "Prec@1 62.500 (67.445)\n",
      "\n",
      "Prec@5 81.250 (85.852)\n",
      "\n",
      " * Prec@1 67.445 Prec@5 85.852\n",
      " * Prec@1 67.391 Prec@5 85.802\n",
      " * Prec@1 67.540 Prec@5 85.954\n",
      " * Prec@1 67.354 Prec@5 85.838\n",
      " * Prec@1 67.368 Prec@5 85.855\n",
      " * Prec@1 67.513 Prec@5 85.807\n",
      " * Prec@1 67.526 Prec@5 85.696\n",
      " * Prec@1 67.474 Prec@5 85.651\n",
      " * Prec@1 67.361 Prec@5 85.669\n",
      " * Prec@1 67.375 Prec@5 85.750\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.612 (0.704)\n",
      "\n",
      "Loss 1.9920 (1.7101)\n",
      "\n",
      "Prec@1 75.000 (67.450)\n",
      "\n",
      "Prec@5 87.500 (85.767)\n",
      "\n",
      " * Prec@1 67.450 Prec@5 85.767\n",
      " * Prec@1 67.525 Prec@5 85.907\n",
      " * Prec@1 67.597 Prec@5 85.983\n",
      " * Prec@1 67.608 Prec@5 86.058\n",
      " * Prec@1 67.679 Prec@5 86.131\n",
      " * Prec@1 67.512 Prec@5 85.967\n",
      " * Prec@1 67.699 Prec@5 86.098\n",
      " * Prec@1 67.593 Prec@5 86.111\n",
      " * Prec@1 67.431 Prec@5 86.009\n",
      " * Prec@1 67.386 Prec@5 85.966\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.659 (0.702)\n",
      "\n",
      "Loss 3.2088 (1.7149)\n",
      "\n",
      "Prec@1 31.250 (67.061)\n",
      "\n",
      "Prec@5 68.750 (85.811)\n",
      "\n",
      " * Prec@1 67.061 Prec@5 85.811\n",
      " * Prec@1 67.132 Prec@5 85.770\n",
      " * Prec@1 67.201 Prec@5 85.841\n",
      " * Prec@1 67.050 Prec@5 85.910\n",
      " * Prec@1 67.174 Prec@5 85.924\n",
      " * Prec@1 67.080 Prec@5 85.830\n",
      " * Prec@1 66.987 Prec@5 85.844\n",
      " * Prec@1 66.896 Prec@5 85.805\n",
      " * Prec@1 66.912 Prec@5 85.767\n",
      " * Prec@1 67.031 Prec@5 85.781\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.741 (0.702)\n",
      "\n",
      "Loss 1.5619 (1.7166)\n",
      "\n",
      "Prec@1 81.250 (67.149)\n",
      "\n",
      "Prec@5 81.250 (85.744)\n",
      "\n",
      " * Prec@1 67.149 Prec@5 85.744\n",
      " * Prec@1 67.316 Prec@5 85.809\n",
      " * Prec@1 67.124 Prec@5 85.620\n",
      " * Prec@1 67.087 Prec@5 85.534\n",
      " * Prec@1 66.950 Prec@5 85.450\n",
      " * Prec@1 67.014 Prec@5 85.466\n",
      " * Prec@1 67.028 Prec@5 85.433\n",
      " * Prec@1 67.041 Prec@5 85.352\n",
      " * Prec@1 66.909 Prec@5 85.320\n",
      " * Prec@1 66.875 Prec@5 85.433\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.690 (0.702)\n",
      "\n",
      "Loss 2.4835 (1.7512)\n",
      "\n",
      "Prec@1 56.250 (66.794)\n",
      "\n",
      "Prec@5 81.250 (85.401)\n",
      "\n",
      " * Prec@1 66.794 Prec@5 85.401\n",
      " * Prec@1 66.856 Prec@5 85.322\n",
      " * Prec@1 66.870 Prec@5 85.291\n",
      " * Prec@1 66.791 Prec@5 85.215\n",
      " * Prec@1 66.898 Prec@5 85.278\n",
      " * Prec@1 67.004 Prec@5 85.386\n",
      " * Prec@1 66.925 Prec@5 85.356\n",
      " * Prec@1 66.984 Prec@5 85.281\n",
      " * Prec@1 66.862 Prec@5 85.252\n",
      " * Prec@1 66.816 Prec@5 85.311\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [12][0/559]\t\\Time 0.450 (0.450)\tData 0.381 (0.381)\tLoss 0.2786 (0.2786)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/559]\t\\Time 0.492 (0.540)\tData 0.382 (0.441)\tLoss 0.0295 (0.2239)\tPrec@1 100.000 (93.007)\tPrec@5 100.000 (99.629)\n",
      "Epoch: [12][200/559]\t\\Time 0.566 (0.538)\tData 0.455 (0.439)\tLoss 0.2868 (0.2176)\tPrec@1 93.750 (93.408)\tPrec@5 100.000 (99.689)\n",
      "Epoch: [12][300/559]\t\\Time 0.566 (0.542)\tData 0.456 (0.442)\tLoss 0.6476 (0.2287)\tPrec@1 81.250 (93.210)\tPrec@5 100.000 (99.585)\n",
      "Epoch: [12][400/559]\t\\Time 0.543 (0.543)\tData 0.463 (0.443)\tLoss 0.5358 (0.2360)\tPrec@1 81.250 (93.080)\tPrec@5 100.000 (99.517)\n",
      "Epoch: [12][500/559]\t\\Time 0.561 (0.545)\tData 0.431 (0.444)\tLoss 0.0645 (0.2476)\tPrec@1 100.000 (92.577)\tPrec@5 100.000 (99.476)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.547 (0.547)\n",
      "\n",
      "Loss 1.5101 (1.5101)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 81.250\n",
      " * Prec@1 71.875 Prec@5 84.375\n",
      " * Prec@1 70.833 Prec@5 87.500\n",
      " * Prec@1 68.750 Prec@5 87.500\n",
      " * Prec@1 70.000 Prec@5 86.250\n",
      " * Prec@1 68.750 Prec@5 82.292\n",
      " * Prec@1 68.750 Prec@5 82.143\n",
      " * Prec@1 66.406 Prec@5 81.250\n",
      " * Prec@1 65.972 Prec@5 81.944\n",
      " * Prec@1 66.250 Prec@5 80.625\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.603 (0.715)\n",
      "\n",
      "Loss 1.8732 (2.2874)\n",
      "\n",
      "Prec@1 50.000 (64.773)\n",
      "\n",
      "Prec@5 81.250 (80.682)\n",
      "\n",
      " * Prec@1 64.773 Prec@5 80.682\n",
      " * Prec@1 64.583 Prec@5 81.250\n",
      " * Prec@1 64.423 Prec@5 81.250\n",
      " * Prec@1 64.286 Prec@5 81.250\n",
      " * Prec@1 64.583 Prec@5 80.417\n",
      " * Prec@1 65.234 Prec@5 81.250\n",
      " * Prec@1 65.441 Prec@5 81.985\n",
      " * Prec@1 66.667 Prec@5 82.986\n",
      " * Prec@1 67.763 Prec@5 83.224\n",
      " * Prec@1 68.750 Prec@5 83.750\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.622 (0.713)\n",
      "\n",
      "Loss 2.1895 (1.9805)\n",
      "\n",
      "Prec@1 56.250 (68.155)\n",
      "\n",
      "Prec@5 93.750 (84.226)\n",
      "\n",
      " * Prec@1 68.155 Prec@5 84.226\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      " * Prec@1 69.293 Prec@5 84.511\n",
      " * Prec@1 69.792 Prec@5 85.156\n",
      " * Prec@1 70.250 Prec@5 85.000\n",
      " * Prec@1 70.192 Prec@5 85.096\n",
      " * Prec@1 70.139 Prec@5 84.722\n",
      " * Prec@1 70.089 Prec@5 84.821\n",
      " * Prec@1 69.397 Prec@5 84.052\n",
      " * Prec@1 69.792 Prec@5 84.375\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.701 (0.720)\n",
      "\n",
      "Loss 0.1694 (1.7929)\n",
      "\n",
      "Prec@1 87.500 (70.363)\n",
      "\n",
      "Prec@5 100.000 (84.879)\n",
      "\n",
      " * Prec@1 70.363 Prec@5 84.879\n",
      " * Prec@1 70.117 Prec@5 84.570\n",
      " * Prec@1 70.265 Prec@5 85.038\n",
      " * Prec@1 70.404 Prec@5 85.110\n",
      " * Prec@1 70.357 Prec@5 85.000\n",
      " * Prec@1 70.139 Prec@5 84.896\n",
      " * Prec@1 70.101 Prec@5 85.304\n",
      " * Prec@1 70.395 Prec@5 85.526\n",
      " * Prec@1 70.353 Prec@5 85.577\n",
      " * Prec@1 70.469 Prec@5 85.625\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.692 (0.727)\n",
      "\n",
      "Loss 2.5123 (1.7642)\n",
      "\n",
      "Prec@1 56.250 (70.122)\n",
      "\n",
      "Prec@5 68.750 (85.213)\n",
      "\n",
      " * Prec@1 70.122 Prec@5 85.213\n",
      " * Prec@1 69.792 Prec@5 84.970\n",
      " * Prec@1 70.203 Prec@5 85.174\n",
      " * Prec@1 70.170 Prec@5 85.227\n",
      " * Prec@1 70.278 Prec@5 85.417\n",
      " * Prec@1 70.109 Prec@5 85.598\n",
      " * Prec@1 70.080 Prec@5 85.638\n",
      " * Prec@1 70.312 Prec@5 85.547\n",
      " * Prec@1 70.408 Prec@5 85.587\n",
      " * Prec@1 70.625 Prec@5 85.625\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.661 (0.721)\n",
      "\n",
      "Loss 1.5566 (1.7019)\n",
      "\n",
      "Prec@1 62.500 (70.466)\n",
      "\n",
      "Prec@5 93.750 (85.784)\n",
      "\n",
      " * Prec@1 70.466 Prec@5 85.784\n",
      " * Prec@1 70.673 Prec@5 85.697\n",
      " * Prec@1 70.873 Prec@5 85.967\n",
      " * Prec@1 70.949 Prec@5 85.880\n",
      " * Prec@1 70.795 Prec@5 85.909\n",
      " * Prec@1 70.871 Prec@5 85.938\n",
      " * Prec@1 70.724 Prec@5 85.855\n",
      " * Prec@1 70.690 Prec@5 85.884\n",
      " * Prec@1 70.657 Prec@5 85.699\n",
      " * Prec@1 70.625 Prec@5 85.729\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.681 (0.718)\n",
      "\n",
      "Loss 1.3373 (1.6918)\n",
      "\n",
      "Prec@1 75.000 (70.697)\n",
      "\n",
      "Prec@5 93.750 (85.861)\n",
      "\n",
      " * Prec@1 70.697 Prec@5 85.861\n",
      " * Prec@1 70.766 Prec@5 86.089\n",
      " * Prec@1 70.635 Prec@5 86.012\n",
      " * Prec@1 70.703 Prec@5 86.230\n",
      " * Prec@1 70.962 Prec@5 86.250\n",
      " * Prec@1 70.739 Prec@5 86.174\n",
      " * Prec@1 70.709 Prec@5 86.007\n",
      " * Prec@1 70.956 Prec@5 86.213\n",
      " * Prec@1 70.924 Prec@5 86.051\n",
      " * Prec@1 71.071 Prec@5 85.982\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.670 (0.715)\n",
      "\n",
      "Loss 1.8984 (1.6971)\n",
      "\n",
      "Prec@1 56.250 (70.863)\n",
      "\n",
      "Prec@5 81.250 (85.915)\n",
      "\n",
      " * Prec@1 70.863 Prec@5 85.915\n",
      " * Prec@1 70.833 Prec@5 85.938\n",
      " * Prec@1 70.976 Prec@5 86.045\n",
      " * Prec@1 70.946 Prec@5 86.064\n",
      " * Prec@1 71.083 Prec@5 86.083\n",
      " * Prec@1 71.135 Prec@5 86.020\n",
      " * Prec@1 71.104 Prec@5 86.039\n",
      " * Prec@1 71.154 Prec@5 86.058\n",
      " * Prec@1 71.044 Prec@5 85.839\n",
      " * Prec@1 71.328 Prec@5 85.938\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.633 (0.712)\n",
      "\n",
      "Loss 1.5977 (1.6891)\n",
      "\n",
      "Prec@1 75.000 (71.373)\n",
      "\n",
      "Prec@5 87.500 (85.957)\n",
      "\n",
      " * Prec@1 71.373 Prec@5 85.957\n",
      " * Prec@1 71.418 Prec@5 85.976\n",
      " * Prec@1 71.536 Prec@5 86.145\n",
      " * Prec@1 71.652 Prec@5 86.235\n",
      " * Prec@1 71.985 Prec@5 86.397\n",
      " * Prec@1 72.020 Prec@5 86.337\n",
      " * Prec@1 71.983 Prec@5 86.422\n",
      " * Prec@1 71.946 Prec@5 86.364\n",
      " * Prec@1 71.980 Prec@5 86.447\n",
      " * Prec@1 72.153 Prec@5 86.528\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.732 (0.711)\n",
      "\n",
      "Loss 1.2676 (1.6375)\n",
      "\n",
      "Prec@1 62.500 (72.047)\n",
      "\n",
      "Prec@5 93.750 (86.607)\n",
      "\n",
      " * Prec@1 72.047 Prec@5 86.607\n",
      " * Prec@1 72.011 Prec@5 86.481\n",
      " * Prec@1 71.976 Prec@5 86.559\n",
      " * Prec@1 71.809 Prec@5 86.436\n",
      " * Prec@1 71.711 Prec@5 86.382\n",
      " * Prec@1 71.810 Prec@5 86.328\n",
      " * Prec@1 71.907 Prec@5 86.276\n",
      " * Prec@1 72.003 Prec@5 86.352\n",
      " * Prec@1 71.970 Prec@5 86.237\n",
      " * Prec@1 72.125 Prec@5 86.250\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.642 (0.712)\n",
      "\n",
      "Loss 1.4773 (1.6507)\n",
      "\n",
      "Prec@1 81.250 (72.215)\n",
      "\n",
      "Prec@5 87.500 (86.262)\n",
      "\n",
      " * Prec@1 72.215 Prec@5 86.262\n",
      " * Prec@1 72.365 Prec@5 86.397\n",
      " * Prec@1 72.451 Prec@5 86.529\n",
      " * Prec@1 72.476 Prec@5 86.599\n",
      " * Prec@1 72.321 Prec@5 86.607\n",
      " * Prec@1 72.111 Prec@5 86.380\n",
      " * Prec@1 72.313 Prec@5 86.507\n",
      " * Prec@1 72.222 Prec@5 86.458\n",
      " * Prec@1 72.248 Prec@5 86.411\n",
      " * Prec@1 72.216 Prec@5 86.364\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.641 (0.711)\n",
      "\n",
      "Loss 3.6479 (1.6435)\n",
      "\n",
      "Prec@1 43.750 (71.959)\n",
      "\n",
      "Prec@5 68.750 (86.205)\n",
      "\n",
      " * Prec@1 71.959 Prec@5 86.205\n",
      " * Prec@1 71.987 Prec@5 86.161\n",
      " * Prec@1 72.069 Prec@5 86.173\n",
      " * Prec@1 71.930 Prec@5 86.239\n",
      " * Prec@1 72.011 Prec@5 86.304\n",
      " * Prec@1 71.983 Prec@5 86.207\n",
      " * Prec@1 71.848 Prec@5 86.218\n",
      " * Prec@1 71.769 Prec@5 86.229\n",
      " * Prec@1 71.796 Prec@5 86.187\n",
      " * Prec@1 71.875 Prec@5 86.250\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.721 (0.710)\n",
      "\n",
      "Loss 1.4106 (1.6416)\n",
      "\n",
      "Prec@1 62.500 (71.798)\n",
      "\n",
      "Prec@5 87.500 (86.260)\n",
      "\n",
      " * Prec@1 71.798 Prec@5 86.260\n",
      " * Prec@1 71.875 Prec@5 86.270\n",
      " * Prec@1 71.646 Prec@5 86.230\n",
      " * Prec@1 71.522 Prec@5 86.139\n",
      " * Prec@1 71.500 Prec@5 86.000\n",
      " * Prec@1 71.528 Prec@5 86.012\n",
      " * Prec@1 71.555 Prec@5 86.024\n",
      " * Prec@1 71.533 Prec@5 85.986\n",
      " * Prec@1 71.366 Prec@5 85.853\n",
      " * Prec@1 71.346 Prec@5 85.865\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.720 (0.710)\n",
      "\n",
      "Loss 2.5809 (1.6939)\n",
      "\n",
      "Prec@1 62.500 (71.279)\n",
      "\n",
      "Prec@5 81.250 (85.830)\n",
      "\n",
      " * Prec@1 71.279 Prec@5 85.830\n",
      " * Prec@1 71.307 Prec@5 85.843\n",
      " * Prec@1 71.335 Prec@5 85.949\n",
      " * Prec@1 71.362 Prec@5 85.868\n",
      " * Prec@1 71.481 Prec@5 85.926\n",
      " * Prec@1 71.553 Prec@5 86.029\n",
      " * Prec@1 71.442 Prec@5 85.995\n",
      " * Prec@1 71.467 Prec@5 85.915\n",
      " * Prec@1 71.448 Prec@5 85.926\n",
      " * Prec@1 71.518 Prec@5 85.938\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [13][0/559]\t\\Time 0.511 (0.511)\tData 0.411 (0.411)\tLoss 0.1281 (0.1281)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/559]\t\\Time 0.490 (0.532)\tData 0.410 (0.432)\tLoss 0.0530 (0.1712)\tPrec@1 100.000 (94.493)\tPrec@5 100.000 (99.814)\n",
      "Epoch: [13][200/559]\t\\Time 0.541 (0.538)\tData 0.441 (0.438)\tLoss 0.1428 (0.1515)\tPrec@1 93.750 (95.274)\tPrec@5 100.000 (99.876)\n",
      "Epoch: [13][300/559]\t\\Time 0.460 (0.540)\tData 0.360 (0.440)\tLoss 0.2282 (0.1494)\tPrec@1 87.500 (95.556)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [13][400/559]\t\\Time 0.529 (0.544)\tData 0.429 (0.443)\tLoss 0.1125 (0.1508)\tPrec@1 100.000 (95.527)\tPrec@5 100.000 (99.813)\n",
      "Epoch: [13][500/559]\t\\Time 0.580 (0.547)\tData 0.450 (0.446)\tLoss 0.0317 (0.1570)\tPrec@1 100.000 (95.359)\tPrec@5 100.000 (99.800)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.538 (0.538)\n",
      "\n",
      "Loss 1.8822 (1.8822)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 81.250\n",
      " * Prec@1 75.000 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 85.417\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 71.250 Prec@5 86.250\n",
      " * Prec@1 67.708 Prec@5 85.417\n",
      " * Prec@1 67.857 Prec@5 85.714\n",
      " * Prec@1 66.406 Prec@5 84.375\n",
      " * Prec@1 65.972 Prec@5 84.028\n",
      " * Prec@1 64.375 Prec@5 82.500\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.560 (0.702)\n",
      "\n",
      "Loss 2.1679 (2.3870)\n",
      "\n",
      "Prec@1 75.000 (65.341)\n",
      "\n",
      "Prec@5 75.000 (81.818)\n",
      "\n",
      " * Prec@1 65.341 Prec@5 81.818\n",
      " * Prec@1 66.146 Prec@5 81.771\n",
      " * Prec@1 65.865 Prec@5 81.731\n",
      " * Prec@1 66.071 Prec@5 82.143\n",
      " * Prec@1 65.833 Prec@5 82.500\n",
      " * Prec@1 66.016 Prec@5 82.422\n",
      " * Prec@1 66.544 Prec@5 83.088\n",
      " * Prec@1 67.708 Prec@5 84.028\n",
      " * Prec@1 68.750 Prec@5 84.211\n",
      " * Prec@1 69.375 Prec@5 84.688\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.570 (0.698)\n",
      "\n",
      "Loss 3.2032 (2.0311)\n",
      "\n",
      "Prec@1 62.500 (69.048)\n",
      "\n",
      "Prec@5 68.750 (83.929)\n",
      "\n",
      " * Prec@1 69.048 Prec@5 83.929\n",
      " * Prec@1 69.034 Prec@5 84.091\n",
      " * Prec@1 69.837 Prec@5 84.511\n",
      " * Prec@1 70.833 Prec@5 84.896\n",
      " * Prec@1 71.000 Prec@5 85.000\n",
      " * Prec@1 70.673 Prec@5 85.096\n",
      " * Prec@1 70.602 Prec@5 85.185\n",
      " * Prec@1 70.536 Prec@5 85.268\n",
      " * Prec@1 70.043 Prec@5 84.914\n",
      " * Prec@1 70.417 Prec@5 85.208\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.644 (0.706)\n",
      "\n",
      "Loss 0.1203 (1.7818)\n",
      "\n",
      "Prec@1 100.000 (71.371)\n",
      "\n",
      "Prec@5 100.000 (85.685)\n",
      "\n",
      " * Prec@1 71.371 Prec@5 85.685\n",
      " * Prec@1 71.289 Prec@5 85.742\n",
      " * Prec@1 71.780 Prec@5 86.174\n",
      " * Prec@1 71.507 Prec@5 86.397\n",
      " * Prec@1 71.429 Prec@5 86.071\n",
      " * Prec@1 71.007 Prec@5 85.764\n",
      " * Prec@1 71.115 Prec@5 85.980\n",
      " * Prec@1 71.217 Prec@5 86.184\n",
      " * Prec@1 71.474 Prec@5 86.218\n",
      " * Prec@1 71.719 Prec@5 86.094\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.670 (0.711)\n",
      "\n",
      "Loss 2.6003 (1.7579)\n",
      "\n",
      "Prec@1 68.750 (71.646)\n",
      "\n",
      "Prec@5 87.500 (86.128)\n",
      "\n",
      " * Prec@1 71.646 Prec@5 86.128\n",
      " * Prec@1 71.280 Prec@5 85.863\n",
      " * Prec@1 71.512 Prec@5 86.047\n",
      " * Prec@1 71.449 Prec@5 85.938\n",
      " * Prec@1 71.528 Prec@5 86.111\n",
      " * Prec@1 71.603 Prec@5 86.141\n",
      " * Prec@1 71.543 Prec@5 86.303\n",
      " * Prec@1 71.615 Prec@5 86.328\n",
      " * Prec@1 71.556 Prec@5 86.480\n",
      " * Prec@1 71.500 Prec@5 86.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.701 (0.708)\n",
      "\n",
      "Loss 1.8866 (1.7320)\n",
      "\n",
      "Prec@1 56.250 (71.201)\n",
      "\n",
      "Prec@5 87.500 (86.397)\n",
      "\n",
      " * Prec@1 71.201 Prec@5 86.397\n",
      " * Prec@1 71.274 Prec@5 86.298\n",
      " * Prec@1 71.462 Prec@5 86.439\n",
      " * Prec@1 71.412 Prec@5 86.343\n",
      " * Prec@1 71.364 Prec@5 86.477\n",
      " * Prec@1 71.429 Prec@5 86.719\n",
      " * Prec@1 71.382 Prec@5 86.623\n",
      " * Prec@1 71.444 Prec@5 86.638\n",
      " * Prec@1 71.398 Prec@5 86.441\n",
      " * Prec@1 71.458 Prec@5 86.562\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.653 (0.708)\n",
      "\n",
      "Loss 1.1236 (1.7168)\n",
      "\n",
      "Prec@1 81.250 (71.619)\n",
      "\n",
      "Prec@5 93.750 (86.680)\n",
      "\n",
      " * Prec@1 71.619 Prec@5 86.680\n",
      " * Prec@1 71.673 Prec@5 86.694\n",
      " * Prec@1 71.429 Prec@5 86.706\n",
      " * Prec@1 71.484 Prec@5 86.914\n",
      " * Prec@1 71.635 Prec@5 86.923\n",
      " * Prec@1 71.591 Prec@5 86.837\n",
      " * Prec@1 71.549 Prec@5 86.754\n",
      " * Prec@1 71.875 Prec@5 86.949\n",
      " * Prec@1 71.830 Prec@5 86.775\n",
      " * Prec@1 71.875 Prec@5 86.786\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.680 (0.707)\n",
      "\n",
      "Loss 1.9316 (1.7053)\n",
      "\n",
      "Prec@1 75.000 (71.919)\n",
      "\n",
      "Prec@5 75.000 (86.620)\n",
      "\n",
      " * Prec@1 71.919 Prec@5 86.620\n",
      " * Prec@1 71.875 Prec@5 86.719\n",
      " * Prec@1 72.003 Prec@5 86.729\n",
      " * Prec@1 72.044 Prec@5 86.655\n",
      " * Prec@1 72.167 Prec@5 86.750\n",
      " * Prec@1 72.204 Prec@5 86.595\n",
      " * Prec@1 72.159 Prec@5 86.526\n",
      " * Prec@1 72.276 Prec@5 86.538\n",
      " * Prec@1 72.073 Prec@5 86.392\n",
      " * Prec@1 72.344 Prec@5 86.562\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.610 (0.704)\n",
      "\n",
      "Loss 1.5627 (1.6951)\n",
      "\n",
      "Prec@1 68.750 (72.299)\n",
      "\n",
      "Prec@5 81.250 (86.497)\n",
      "\n",
      " * Prec@1 72.299 Prec@5 86.497\n",
      " * Prec@1 72.485 Prec@5 86.585\n",
      " * Prec@1 72.590 Prec@5 86.747\n",
      " * Prec@1 72.768 Prec@5 86.905\n",
      " * Prec@1 72.868 Prec@5 86.985\n",
      " * Prec@1 72.820 Prec@5 86.991\n",
      " * Prec@1 72.917 Prec@5 87.069\n",
      " * Prec@1 72.798 Prec@5 87.003\n",
      " * Prec@1 72.683 Prec@5 86.938\n",
      " * Prec@1 72.847 Prec@5 87.014\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.695 (0.703)\n",
      "\n",
      "Loss 1.4149 (1.6488)\n",
      "\n",
      "Prec@1 75.000 (72.871)\n",
      "\n",
      "Prec@5 87.500 (87.019)\n",
      "\n",
      " * Prec@1 72.871 Prec@5 87.019\n",
      " * Prec@1 72.826 Prec@5 86.957\n",
      " * Prec@1 72.917 Prec@5 87.030\n",
      " * Prec@1 72.673 Prec@5 86.769\n",
      " * Prec@1 72.632 Prec@5 86.645\n",
      " * Prec@1 72.721 Prec@5 86.589\n",
      " * Prec@1 72.680 Prec@5 86.469\n",
      " * Prec@1 72.768 Prec@5 86.480\n",
      " * Prec@1 72.664 Prec@5 86.553\n",
      " * Prec@1 72.750 Prec@5 86.500\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.662 (0.701)\n",
      "\n",
      "Loss 1.7240 (1.6722)\n",
      "\n",
      "Prec@1 81.250 (72.834)\n",
      "\n",
      "Prec@5 87.500 (86.510)\n",
      "\n",
      " * Prec@1 72.834 Prec@5 86.510\n",
      " * Prec@1 72.978 Prec@5 86.642\n",
      " * Prec@1 73.119 Prec@5 86.772\n",
      " * Prec@1 73.137 Prec@5 86.839\n",
      " * Prec@1 73.155 Prec@5 86.905\n",
      " * Prec@1 72.877 Prec@5 86.851\n",
      " * Prec@1 73.014 Prec@5 86.916\n",
      " * Prec@1 72.975 Prec@5 86.806\n",
      " * Prec@1 72.993 Prec@5 86.755\n",
      " * Prec@1 73.011 Prec@5 86.705\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.661 (0.701)\n",
      "\n",
      "Loss 3.3160 (1.6716)\n",
      "\n",
      "Prec@1 50.000 (72.804)\n",
      "\n",
      "Prec@5 81.250 (86.655)\n",
      "\n",
      " * Prec@1 72.804 Prec@5 86.655\n",
      " * Prec@1 72.768 Prec@5 86.607\n",
      " * Prec@1 72.788 Prec@5 86.615\n",
      " * Prec@1 72.697 Prec@5 86.568\n",
      " * Prec@1 72.826 Prec@5 86.685\n",
      " * Prec@1 72.845 Prec@5 86.638\n",
      " * Prec@1 72.596 Prec@5 86.645\n",
      " * Prec@1 72.405 Prec@5 86.547\n",
      " * Prec@1 72.426 Prec@5 86.555\n",
      " * Prec@1 72.500 Prec@5 86.615\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.724 (0.701)\n",
      "\n",
      "Loss 1.7133 (1.6762)\n",
      "\n",
      "Prec@1 75.000 (72.521)\n",
      "\n",
      "Prec@5 81.250 (86.570)\n",
      "\n",
      " * Prec@1 72.521 Prec@5 86.570\n",
      " * Prec@1 72.541 Prec@5 86.578\n",
      " * Prec@1 72.409 Prec@5 86.382\n",
      " * Prec@1 72.278 Prec@5 86.290\n",
      " * Prec@1 72.200 Prec@5 86.200\n",
      " * Prec@1 72.272 Prec@5 86.210\n",
      " * Prec@1 72.293 Prec@5 86.171\n",
      " * Prec@1 72.314 Prec@5 86.084\n",
      " * Prec@1 72.238 Prec@5 85.998\n",
      " * Prec@1 72.260 Prec@5 86.058\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.704 (0.702)\n",
      "\n",
      "Loss 3.5096 (1.7290)\n",
      "\n",
      "Prec@1 56.250 (72.137)\n",
      "\n",
      "Prec@5 81.250 (86.021)\n",
      "\n",
      " * Prec@1 72.137 Prec@5 86.021\n",
      " * Prec@1 72.206 Prec@5 86.032\n",
      " * Prec@1 72.227 Prec@5 86.137\n",
      " * Prec@1 72.201 Prec@5 86.054\n",
      " * Prec@1 72.269 Prec@5 86.065\n",
      " * Prec@1 72.426 Prec@5 86.121\n",
      " * Prec@1 72.308 Prec@5 86.131\n",
      " * Prec@1 72.283 Prec@5 86.051\n",
      " * Prec@1 72.302 Prec@5 86.061\n",
      " * Prec@1 72.324 Prec@5 86.117\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [14][0/559]\t\\Time 0.492 (0.492)\tData 0.432 (0.432)\tLoss 0.1310 (0.1310)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/559]\t\\Time 0.516 (0.546)\tData 0.392 (0.448)\tLoss 0.0292 (0.0925)\tPrec@1 100.000 (97.277)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/559]\t\\Time 0.496 (0.546)\tData 0.415 (0.447)\tLoss 0.0162 (0.0849)\tPrec@1 100.000 (97.606)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [14][300/559]\t\\Time 0.634 (0.546)\tData 0.512 (0.446)\tLoss 0.0201 (0.0881)\tPrec@1 100.000 (97.571)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [14][400/559]\t\\Time 0.530 (0.546)\tData 0.423 (0.446)\tLoss 0.0493 (0.0937)\tPrec@1 100.000 (97.444)\tPrec@5 100.000 (99.891)\n",
      "Epoch: [14][500/559]\t\\Time 0.482 (0.546)\tData 0.412 (0.446)\tLoss 0.1888 (0.1017)\tPrec@1 87.500 (97.243)\tPrec@5 100.000 (99.888)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.529 (0.529)\n",
      "\n",
      "Loss 1.7179 (1.7179)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 81.250\n",
      " * Prec@1 78.125 Prec@5 84.375\n",
      " * Prec@1 79.167 Prec@5 85.417\n",
      " * Prec@1 76.562 Prec@5 85.938\n",
      " * Prec@1 76.250 Prec@5 83.750\n",
      " * Prec@1 76.042 Prec@5 83.333\n",
      " * Prec@1 75.000 Prec@5 83.036\n",
      " * Prec@1 71.875 Prec@5 81.250\n",
      " * Prec@1 70.833 Prec@5 80.556\n",
      " * Prec@1 69.375 Prec@5 79.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.550 (0.695)\n",
      "\n",
      "Loss 2.1349 (2.1656)\n",
      "\n",
      "Prec@1 62.500 (68.750)\n",
      "\n",
      "Prec@5 81.250 (79.545)\n",
      "\n",
      " * Prec@1 68.750 Prec@5 79.545\n",
      " * Prec@1 69.271 Prec@5 79.688\n",
      " * Prec@1 68.269 Prec@5 80.288\n",
      " * Prec@1 69.196 Prec@5 80.357\n",
      " * Prec@1 69.167 Prec@5 80.417\n",
      " * Prec@1 69.141 Prec@5 80.859\n",
      " * Prec@1 69.485 Prec@5 81.985\n",
      " * Prec@1 70.139 Prec@5 82.986\n",
      " * Prec@1 71.053 Prec@5 83.553\n",
      " * Prec@1 72.188 Prec@5 84.062\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.613 (0.695)\n",
      "\n",
      "Loss 1.9805 (1.8541)\n",
      "\n",
      "Prec@1 81.250 (72.619)\n",
      "\n",
      "Prec@5 81.250 (83.929)\n",
      "\n",
      " * Prec@1 72.619 Prec@5 83.929\n",
      " * Prec@1 73.011 Prec@5 84.091\n",
      " * Prec@1 73.913 Prec@5 84.511\n",
      " * Prec@1 75.000 Prec@5 85.156\n",
      " * Prec@1 75.000 Prec@5 85.250\n",
      " * Prec@1 74.279 Prec@5 85.096\n",
      " * Prec@1 74.306 Prec@5 85.185\n",
      " * Prec@1 74.107 Prec@5 85.268\n",
      " * Prec@1 73.491 Prec@5 84.698\n",
      " * Prec@1 73.542 Prec@5 84.792\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.688 (0.701)\n",
      "\n",
      "Loss 0.0411 (1.6612)\n",
      "\n",
      "Prec@1 100.000 (74.395)\n",
      "\n",
      "Prec@5 100.000 (85.282)\n",
      "\n",
      " * Prec@1 74.395 Prec@5 85.282\n",
      " * Prec@1 74.414 Prec@5 85.156\n",
      " * Prec@1 74.811 Prec@5 85.227\n",
      " * Prec@1 75.000 Prec@5 85.110\n",
      " * Prec@1 75.000 Prec@5 85.000\n",
      " * Prec@1 74.479 Prec@5 84.722\n",
      " * Prec@1 74.662 Prec@5 84.797\n",
      " * Prec@1 74.671 Prec@5 85.033\n",
      " * Prec@1 74.679 Prec@5 84.936\n",
      " * Prec@1 75.000 Prec@5 85.156\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.664 (0.706)\n",
      "\n",
      "Loss 2.5371 (1.6722)\n",
      "\n",
      "Prec@1 62.500 (74.695)\n",
      "\n",
      "Prec@5 87.500 (85.213)\n",
      "\n",
      " * Prec@1 74.695 Prec@5 85.213\n",
      " * Prec@1 74.554 Prec@5 84.970\n",
      " * Prec@1 74.855 Prec@5 85.174\n",
      " * Prec@1 74.290 Prec@5 85.227\n",
      " * Prec@1 74.306 Prec@5 85.417\n",
      " * Prec@1 74.185 Prec@5 85.598\n",
      " * Prec@1 74.335 Prec@5 85.638\n",
      " * Prec@1 74.479 Prec@5 85.677\n",
      " * Prec@1 74.490 Prec@5 85.714\n",
      " * Prec@1 74.625 Prec@5 85.750\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.662 (0.703)\n",
      "\n",
      "Loss 1.3593 (1.6170)\n",
      "\n",
      "Prec@1 62.500 (74.387)\n",
      "\n",
      "Prec@5 93.750 (85.907)\n",
      "\n",
      " * Prec@1 74.387 Prec@5 85.907\n",
      " * Prec@1 74.519 Prec@5 85.817\n",
      " * Prec@1 74.764 Prec@5 86.085\n",
      " * Prec@1 74.769 Prec@5 85.995\n",
      " * Prec@1 74.773 Prec@5 86.023\n",
      " * Prec@1 74.888 Prec@5 86.161\n",
      " * Prec@1 74.561 Prec@5 85.965\n",
      " * Prec@1 74.461 Prec@5 85.884\n",
      " * Prec@1 74.470 Prec@5 85.805\n",
      " * Prec@1 74.583 Prec@5 85.938\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.663 (0.702)\n",
      "\n",
      "Loss 1.3393 (1.6163)\n",
      "\n",
      "Prec@1 81.250 (74.693)\n",
      "\n",
      "Prec@5 93.750 (86.066)\n",
      "\n",
      " * Prec@1 74.693 Prec@5 86.066\n",
      " * Prec@1 74.798 Prec@5 86.089\n",
      " * Prec@1 74.901 Prec@5 86.111\n",
      " * Prec@1 74.902 Prec@5 86.230\n",
      " * Prec@1 75.000 Prec@5 86.250\n",
      " * Prec@1 74.811 Prec@5 86.364\n",
      " * Prec@1 74.627 Prec@5 86.474\n",
      " * Prec@1 74.816 Prec@5 86.673\n",
      " * Prec@1 74.638 Prec@5 86.413\n",
      " * Prec@1 74.732 Prec@5 86.429\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.680 (0.703)\n",
      "\n",
      "Loss 1.7503 (1.5964)\n",
      "\n",
      "Prec@1 75.000 (74.736)\n",
      "\n",
      "Prec@5 87.500 (86.444)\n",
      "\n",
      " * Prec@1 74.736 Prec@5 86.444\n",
      " * Prec@1 74.653 Prec@5 86.458\n",
      " * Prec@1 74.658 Prec@5 86.473\n",
      " * Prec@1 74.662 Prec@5 86.402\n",
      " * Prec@1 74.750 Prec@5 86.500\n",
      " * Prec@1 74.753 Prec@5 86.349\n",
      " * Prec@1 74.756 Prec@5 86.201\n",
      " * Prec@1 74.840 Prec@5 86.218\n",
      " * Prec@1 74.763 Prec@5 85.997\n",
      " * Prec@1 74.922 Prec@5 86.094\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.628 (0.703)\n",
      "\n",
      "Loss 1.9863 (1.6066)\n",
      "\n",
      "Prec@1 62.500 (74.769)\n",
      "\n",
      "Prec@5 81.250 (86.034)\n",
      "\n",
      " * Prec@1 74.769 Prec@5 86.034\n",
      " * Prec@1 74.924 Prec@5 86.128\n",
      " * Prec@1 75.000 Prec@5 86.295\n",
      " * Prec@1 75.223 Prec@5 86.458\n",
      " * Prec@1 75.368 Prec@5 86.618\n",
      " * Prec@1 75.436 Prec@5 86.555\n",
      " * Prec@1 75.431 Prec@5 86.638\n",
      " * Prec@1 75.284 Prec@5 86.719\n",
      " * Prec@1 75.070 Prec@5 86.657\n",
      " * Prec@1 75.139 Prec@5 86.736\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.710 (0.704)\n",
      "\n",
      "Loss 1.6844 (1.5543)\n",
      "\n",
      "Prec@1 75.000 (75.137)\n",
      "\n",
      "Prec@5 93.750 (86.813)\n",
      "\n",
      " * Prec@1 75.137 Prec@5 86.813\n",
      " * Prec@1 75.068 Prec@5 86.821\n",
      " * Prec@1 75.202 Prec@5 86.895\n",
      " * Prec@1 75.000 Prec@5 86.769\n",
      " * Prec@1 74.934 Prec@5 86.645\n",
      " * Prec@1 74.935 Prec@5 86.654\n",
      " * Prec@1 74.807 Prec@5 86.598\n",
      " * Prec@1 74.872 Prec@5 86.607\n",
      " * Prec@1 74.874 Prec@5 86.616\n",
      " * Prec@1 74.812 Prec@5 86.562\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.652 (0.704)\n",
      "\n",
      "Loss 1.9664 (1.5733)\n",
      "\n",
      "Prec@1 75.000 (74.814)\n",
      "\n",
      "Prec@5 87.500 (86.572)\n",
      "\n",
      " * Prec@1 74.814 Prec@5 86.572\n",
      " * Prec@1 74.939 Prec@5 86.642\n",
      " * Prec@1 75.121 Prec@5 86.772\n",
      " * Prec@1 75.240 Prec@5 86.839\n",
      " * Prec@1 75.179 Prec@5 86.786\n",
      " * Prec@1 74.882 Prec@5 86.557\n",
      " * Prec@1 75.000 Prec@5 86.624\n",
      " * Prec@1 74.942 Prec@5 86.574\n",
      " * Prec@1 74.885 Prec@5 86.468\n",
      " * Prec@1 74.943 Prec@5 86.420\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.650 (0.703)\n",
      "\n",
      "Loss 3.6165 (1.5856)\n",
      "\n",
      "Prec@1 43.750 (74.662)\n",
      "\n",
      "Prec@5 75.000 (86.318)\n",
      "\n",
      " * Prec@1 74.662 Prec@5 86.318\n",
      " * Prec@1 74.554 Prec@5 86.272\n",
      " * Prec@1 74.613 Prec@5 86.338\n",
      " * Prec@1 74.561 Prec@5 86.404\n",
      " * Prec@1 74.620 Prec@5 86.467\n",
      " * Prec@1 74.569 Prec@5 86.476\n",
      " * Prec@1 74.466 Prec@5 86.538\n",
      " * Prec@1 74.311 Prec@5 86.494\n",
      " * Prec@1 74.370 Prec@5 86.450\n",
      " * Prec@1 74.427 Prec@5 86.458\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.722 (0.703)\n",
      "\n",
      "Loss 1.2884 (1.5792)\n",
      "\n",
      "Prec@1 81.250 (74.483)\n",
      "\n",
      "Prec@5 87.500 (86.467)\n",
      "\n",
      " * Prec@1 74.483 Prec@5 86.467\n",
      " * Prec@1 74.590 Prec@5 86.527\n",
      " * Prec@1 74.390 Prec@5 86.382\n",
      " * Prec@1 74.345 Prec@5 86.290\n",
      " * Prec@1 74.300 Prec@5 86.200\n",
      " * Prec@1 74.355 Prec@5 86.210\n",
      " * Prec@1 74.409 Prec@5 86.171\n",
      " * Prec@1 74.316 Prec@5 86.133\n",
      " * Prec@1 74.128 Prec@5 85.998\n",
      " * Prec@1 74.135 Prec@5 86.010\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.703 (0.702)\n",
      "\n",
      "Loss 2.0764 (1.6279)\n",
      "\n",
      "Prec@1 62.500 (74.046)\n",
      "\n",
      "Prec@5 81.250 (85.973)\n",
      "\n",
      " * Prec@1 74.046 Prec@5 85.973\n",
      " * Prec@1 74.100 Prec@5 85.985\n",
      " * Prec@1 74.107 Prec@5 86.043\n",
      " * Prec@1 74.067 Prec@5 86.054\n",
      " * Prec@1 74.167 Prec@5 86.111\n",
      " * Prec@1 74.173 Prec@5 86.167\n",
      " * Prec@1 74.042 Prec@5 86.223\n",
      " * Prec@1 74.049 Prec@5 86.141\n",
      " * Prec@1 74.056 Prec@5 86.196\n",
      " * Prec@1 74.116 Prec@5 86.207\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [15][0/559]\t\\Time 0.586 (0.586)\tData 0.476 (0.476)\tLoss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/559]\t\\Time 0.552 (0.549)\tData 0.480 (0.450)\tLoss 0.0071 (0.0339)\tPrec@1 100.000 (99.257)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/559]\t\\Time 0.571 (0.545)\tData 0.453 (0.446)\tLoss 0.0042 (0.0289)\tPrec@1 100.000 (99.471)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/559]\t\\Time 0.471 (0.546)\tData 0.401 (0.447)\tLoss 0.0016 (0.0279)\tPrec@1 100.000 (99.481)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][400/559]\t\\Time 0.633 (0.546)\tData 0.525 (0.447)\tLoss 0.0031 (0.0281)\tPrec@1 100.000 (99.486)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][500/559]\t\\Time 0.526 (0.547)\tData 0.397 (0.448)\tLoss 0.0014 (0.0314)\tPrec@1 100.000 (99.414)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.582 (0.582)\n",
      "\n",
      "Loss 1.0298 (1.0298)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 81.250\n",
      " * Prec@1 81.250 Prec@5 84.375\n",
      " * Prec@1 79.167 Prec@5 85.417\n",
      " * Prec@1 76.562 Prec@5 87.500\n",
      " * Prec@1 76.250 Prec@5 86.250\n",
      " * Prec@1 73.958 Prec@5 85.417\n",
      " * Prec@1 73.214 Prec@5 85.714\n",
      " * Prec@1 71.094 Prec@5 85.156\n",
      " * Prec@1 69.444 Prec@5 85.417\n",
      " * Prec@1 68.750 Prec@5 84.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.550 (0.714)\n",
      "\n",
      "Loss 2.4054 (2.0167)\n",
      "\n",
      "Prec@1 50.000 (67.045)\n",
      "\n",
      "Prec@5 75.000 (83.523)\n",
      "\n",
      " * Prec@1 67.045 Prec@5 83.523\n",
      " * Prec@1 67.708 Prec@5 83.333\n",
      " * Prec@1 67.308 Prec@5 84.135\n",
      " * Prec@1 67.857 Prec@5 84.375\n",
      " * Prec@1 68.333 Prec@5 84.167\n",
      " * Prec@1 68.750 Prec@5 84.766\n",
      " * Prec@1 69.853 Prec@5 84.926\n",
      " * Prec@1 71.528 Prec@5 85.764\n",
      " * Prec@1 72.368 Prec@5 85.855\n",
      " * Prec@1 73.438 Prec@5 86.250\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.639 (0.707)\n",
      "\n",
      "Loss 1.8288 (1.6707)\n",
      "\n",
      "Prec@1 75.000 (73.512)\n",
      "\n",
      "Prec@5 87.500 (86.310)\n",
      "\n",
      " * Prec@1 73.512 Prec@5 86.310\n",
      " * Prec@1 73.580 Prec@5 86.080\n",
      " * Prec@1 74.457 Prec@5 86.685\n",
      " * Prec@1 75.521 Prec@5 87.240\n",
      " * Prec@1 76.000 Prec@5 87.250\n",
      " * Prec@1 75.721 Prec@5 87.019\n",
      " * Prec@1 75.694 Prec@5 87.037\n",
      " * Prec@1 75.670 Prec@5 87.054\n",
      " * Prec@1 75.431 Prec@5 86.638\n",
      " * Prec@1 75.625 Prec@5 86.875\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.691 (0.721)\n",
      "\n",
      "Loss 0.2072 (1.5063)\n",
      "\n",
      "Prec@1 87.500 (76.008)\n",
      "\n",
      "Prec@5 100.000 (87.298)\n",
      "\n",
      " * Prec@1 76.008 Prec@5 87.298\n",
      " * Prec@1 75.781 Prec@5 87.109\n",
      " * Prec@1 75.947 Prec@5 87.500\n",
      " * Prec@1 75.919 Prec@5 87.500\n",
      " * Prec@1 75.893 Prec@5 87.321\n",
      " * Prec@1 75.521 Prec@5 87.153\n",
      " * Prec@1 75.676 Prec@5 87.331\n",
      " * Prec@1 75.987 Prec@5 87.500\n",
      " * Prec@1 75.962 Prec@5 87.500\n",
      " * Prec@1 76.406 Prec@5 87.656\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.676 (0.730)\n",
      "\n",
      "Loss 2.7024 (1.4911)\n",
      "\n",
      "Prec@1 68.750 (76.220)\n",
      "\n",
      "Prec@5 87.500 (87.652)\n",
      "\n",
      " * Prec@1 76.220 Prec@5 87.652\n",
      " * Prec@1 76.042 Prec@5 87.351\n",
      " * Prec@1 76.308 Prec@5 87.500\n",
      " * Prec@1 75.994 Prec@5 87.358\n",
      " * Prec@1 75.972 Prec@5 87.222\n",
      " * Prec@1 75.951 Prec@5 87.228\n",
      " * Prec@1 75.931 Prec@5 87.367\n",
      " * Prec@1 76.042 Prec@5 87.240\n",
      " * Prec@1 75.893 Prec@5 87.245\n",
      " * Prec@1 76.000 Prec@5 87.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.691 (0.729)\n",
      "\n",
      "Loss 1.7451 (1.4903)\n",
      "\n",
      "Prec@1 56.250 (75.613)\n",
      "\n",
      "Prec@5 87.500 (87.377)\n",
      "\n",
      " * Prec@1 75.613 Prec@5 87.377\n",
      " * Prec@1 75.721 Prec@5 87.380\n",
      " * Prec@1 75.943 Prec@5 87.618\n",
      " * Prec@1 75.926 Prec@5 87.500\n",
      " * Prec@1 76.023 Prec@5 87.500\n",
      " * Prec@1 76.228 Prec@5 87.500\n",
      " * Prec@1 76.096 Prec@5 87.390\n",
      " * Prec@1 76.078 Prec@5 87.284\n",
      " * Prec@1 76.059 Prec@5 87.076\n",
      " * Prec@1 76.146 Prec@5 87.188\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.701 (0.728)\n",
      "\n",
      "Loss 1.4241 (1.4991)\n",
      "\n",
      "Prec@1 68.750 (76.025)\n",
      "\n",
      "Prec@5 93.750 (87.295)\n",
      "\n",
      " * Prec@1 76.025 Prec@5 87.295\n",
      " * Prec@1 76.109 Prec@5 87.399\n",
      " * Prec@1 75.992 Prec@5 87.401\n",
      " * Prec@1 75.977 Prec@5 87.598\n",
      " * Prec@1 76.154 Prec@5 87.596\n",
      " * Prec@1 76.042 Prec@5 87.500\n",
      " * Prec@1 76.026 Prec@5 87.407\n",
      " * Prec@1 76.287 Prec@5 87.592\n",
      " * Prec@1 76.087 Prec@5 87.500\n",
      " * Prec@1 76.071 Prec@5 87.500\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.693 (0.728)\n",
      "\n",
      "Loss 1.7974 (1.4919)\n",
      "\n",
      "Prec@1 75.000 (76.056)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 76.056 Prec@5 87.500\n",
      " * Prec@1 75.955 Prec@5 87.587\n",
      " * Prec@1 76.027 Prec@5 87.671\n",
      " * Prec@1 75.929 Prec@5 87.584\n",
      " * Prec@1 76.083 Prec@5 87.667\n",
      " * Prec@1 76.069 Prec@5 87.500\n",
      " * Prec@1 75.893 Prec@5 87.500\n",
      " * Prec@1 75.962 Prec@5 87.500\n",
      " * Prec@1 75.870 Prec@5 87.342\n",
      " * Prec@1 76.094 Prec@5 87.422\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.660 (0.727)\n",
      "\n",
      "Loss 1.1909 (1.4915)\n",
      "\n",
      "Prec@1 68.750 (76.003)\n",
      "\n",
      "Prec@5 81.250 (87.346)\n",
      "\n",
      " * Prec@1 76.003 Prec@5 87.346\n",
      " * Prec@1 76.143 Prec@5 87.424\n",
      " * Prec@1 76.280 Prec@5 87.575\n",
      " * Prec@1 76.414 Prec@5 87.723\n",
      " * Prec@1 76.544 Prec@5 87.868\n",
      " * Prec@1 76.526 Prec@5 87.863\n",
      " * Prec@1 76.509 Prec@5 87.931\n",
      " * Prec@1 76.420 Prec@5 87.926\n",
      " * Prec@1 76.334 Prec@5 87.921\n",
      " * Prec@1 76.458 Prec@5 87.986\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.720 (0.726)\n",
      "\n",
      "Loss 0.8768 (1.4484)\n",
      "\n",
      "Prec@1 81.250 (76.511)\n",
      "\n",
      "Prec@5 93.750 (88.049)\n",
      "\n",
      " * Prec@1 76.511 Prec@5 88.049\n",
      " * Prec@1 76.495 Prec@5 87.976\n",
      " * Prec@1 76.680 Prec@5 88.038\n",
      " * Prec@1 76.463 Prec@5 87.832\n",
      " * Prec@1 76.382 Prec@5 87.763\n",
      " * Prec@1 76.432 Prec@5 87.695\n",
      " * Prec@1 76.224 Prec@5 87.564\n",
      " * Prec@1 76.276 Prec@5 87.564\n",
      " * Prec@1 76.263 Prec@5 87.626\n",
      " * Prec@1 76.312 Prec@5 87.562\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.632 (0.725)\n",
      "\n",
      "Loss 1.7520 (1.4680)\n",
      "\n",
      "Prec@1 81.250 (76.361)\n",
      "\n",
      "Prec@5 87.500 (87.562)\n",
      "\n",
      " * Prec@1 76.361 Prec@5 87.562\n",
      " * Prec@1 76.532 Prec@5 87.684\n",
      " * Prec@1 76.638 Prec@5 87.803\n",
      " * Prec@1 76.743 Prec@5 87.861\n",
      " * Prec@1 76.726 Prec@5 87.857\n",
      " * Prec@1 76.474 Prec@5 87.677\n",
      " * Prec@1 76.636 Prec@5 87.792\n",
      " * Prec@1 76.620 Prec@5 87.789\n",
      " * Prec@1 76.606 Prec@5 87.729\n",
      " * Prec@1 76.648 Prec@5 87.670\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.673 (0.725)\n",
      "\n",
      "Loss 3.4563 (1.4672)\n",
      "\n",
      "Prec@1 50.000 (76.408)\n",
      "\n",
      "Prec@5 75.000 (87.556)\n",
      "\n",
      " * Prec@1 76.408 Prec@5 87.556\n",
      " * Prec@1 76.339 Prec@5 87.556\n",
      " * Prec@1 76.438 Prec@5 87.555\n",
      " * Prec@1 76.425 Prec@5 87.610\n",
      " * Prec@1 76.413 Prec@5 87.663\n",
      " * Prec@1 76.401 Prec@5 87.608\n",
      " * Prec@1 76.335 Prec@5 87.660\n",
      " * Prec@1 76.218 Prec@5 87.712\n",
      " * Prec@1 76.261 Prec@5 87.658\n",
      " * Prec@1 76.354 Prec@5 87.656\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.720 (0.723)\n",
      "\n",
      "Loss 1.5244 (1.4565)\n",
      "\n",
      "Prec@1 81.250 (76.395)\n",
      "\n",
      "Prec@5 81.250 (87.603)\n",
      "\n",
      " * Prec@1 76.395 Prec@5 87.603\n",
      " * Prec@1 76.434 Prec@5 87.602\n",
      " * Prec@1 76.169 Prec@5 87.500\n",
      " * Prec@1 76.109 Prec@5 87.450\n",
      " * Prec@1 76.050 Prec@5 87.350\n",
      " * Prec@1 76.042 Prec@5 87.351\n",
      " * Prec@1 76.083 Prec@5 87.303\n",
      " * Prec@1 76.025 Prec@5 87.256\n",
      " * Prec@1 75.872 Prec@5 87.161\n",
      " * Prec@1 75.865 Prec@5 87.260\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.730 (0.722)\n",
      "\n",
      "Loss 2.2253 (1.5080)\n",
      "\n",
      "Prec@1 68.750 (75.811)\n",
      "\n",
      "Prec@5 81.250 (87.214)\n",
      "\n",
      " * Prec@1 75.811 Prec@5 87.214\n",
      " * Prec@1 75.852 Prec@5 87.263\n",
      " * Prec@1 75.893 Prec@5 87.312\n",
      " * Prec@1 75.840 Prec@5 87.267\n",
      " * Prec@1 75.972 Prec@5 87.315\n",
      " * Prec@1 76.057 Prec@5 87.408\n",
      " * Prec@1 75.912 Prec@5 87.363\n",
      " * Prec@1 75.906 Prec@5 87.274\n",
      " * Prec@1 75.899 Prec@5 87.275\n",
      " * Prec@1 75.862 Prec@5 87.326\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [16][0/559]\t\\Time 0.546 (0.546)\tData 0.446 (0.446)\tLoss 0.0044 (0.0044)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/559]\t\\Time 0.550 (0.546)\tData 0.450 (0.446)\tLoss 0.0015 (0.0091)\tPrec@1 100.000 (99.876)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/559]\t\\Time 0.524 (0.547)\tData 0.404 (0.448)\tLoss 0.0177 (0.0207)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][300/559]\t\\Time 0.580 (0.548)\tData 0.476 (0.449)\tLoss 0.0033 (0.0178)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][400/559]\t\\Time 0.531 (0.551)\tData 0.461 (0.452)\tLoss 0.0038 (0.0168)\tPrec@1 100.000 (99.719)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][500/559]\t\\Time 0.562 (0.552)\tData 0.461 (0.452)\tLoss 0.0024 (0.0180)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.484 (0.484)\n",
      "\n",
      "Loss 1.1684 (1.1684)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 81.250\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 79.167 Prec@5 87.500\n",
      " * Prec@1 76.562 Prec@5 85.938\n",
      " * Prec@1 76.250 Prec@5 86.250\n",
      " * Prec@1 75.000 Prec@5 85.417\n",
      " * Prec@1 75.000 Prec@5 85.714\n",
      " * Prec@1 74.219 Prec@5 85.156\n",
      " * Prec@1 72.917 Prec@5 84.722\n",
      " * Prec@1 72.500 Prec@5 83.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.592 (0.696)\n",
      "\n",
      "Loss 2.0750 (2.0084)\n",
      "\n",
      "Prec@1 56.250 (71.023)\n",
      "\n",
      "Prec@5 68.750 (81.818)\n",
      "\n",
      " * Prec@1 71.023 Prec@5 81.818\n",
      " * Prec@1 71.354 Prec@5 81.771\n",
      " * Prec@1 70.673 Prec@5 82.212\n",
      " * Prec@1 70.982 Prec@5 82.143\n",
      " * Prec@1 71.250 Prec@5 82.500\n",
      " * Prec@1 71.484 Prec@5 83.203\n",
      " * Prec@1 72.059 Prec@5 83.824\n",
      " * Prec@1 73.611 Prec@5 84.722\n",
      " * Prec@1 74.342 Prec@5 84.868\n",
      " * Prec@1 75.312 Prec@5 85.312\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.632 (0.696)\n",
      "\n",
      "Loss 1.7875 (1.6404)\n",
      "\n",
      "Prec@1 75.000 (75.298)\n",
      "\n",
      "Prec@5 87.500 (85.417)\n",
      "\n",
      " * Prec@1 75.298 Prec@5 85.417\n",
      " * Prec@1 75.568 Prec@5 85.511\n",
      " * Prec@1 76.359 Prec@5 86.141\n",
      " * Prec@1 77.344 Prec@5 86.719\n",
      " * Prec@1 77.500 Prec@5 86.750\n",
      " * Prec@1 77.163 Prec@5 86.779\n",
      " * Prec@1 77.083 Prec@5 86.806\n",
      " * Prec@1 77.009 Prec@5 86.830\n",
      " * Prec@1 76.509 Prec@5 86.638\n",
      " * Prec@1 76.667 Prec@5 86.875\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.737 (0.719)\n",
      "\n",
      "Loss 0.0034 (1.4575)\n",
      "\n",
      "Prec@1 100.000 (77.419)\n",
      "\n",
      "Prec@5 100.000 (87.298)\n",
      "\n",
      " * Prec@1 77.419 Prec@5 87.298\n",
      " * Prec@1 77.344 Prec@5 87.109\n",
      " * Prec@1 77.652 Prec@5 87.311\n",
      " * Prec@1 77.574 Prec@5 87.316\n",
      " * Prec@1 77.500 Prec@5 87.143\n",
      " * Prec@1 77.257 Prec@5 86.806\n",
      " * Prec@1 77.365 Prec@5 86.993\n",
      " * Prec@1 77.632 Prec@5 87.171\n",
      " * Prec@1 77.724 Prec@5 87.179\n",
      " * Prec@1 78.125 Prec@5 87.344\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.655 (0.717)\n",
      "\n",
      "Loss 2.4348 (1.4612)\n",
      "\n",
      "Prec@1 68.750 (77.896)\n",
      "\n",
      "Prec@5 81.250 (87.195)\n",
      "\n",
      " * Prec@1 77.896 Prec@5 87.195\n",
      " * Prec@1 77.679 Prec@5 87.054\n",
      " * Prec@1 78.052 Prec@5 87.209\n",
      " * Prec@1 77.699 Prec@5 87.216\n",
      " * Prec@1 77.639 Prec@5 87.083\n",
      " * Prec@1 77.717 Prec@5 87.228\n",
      " * Prec@1 77.793 Prec@5 87.367\n",
      " * Prec@1 77.734 Prec@5 87.240\n",
      " * Prec@1 77.806 Prec@5 87.245\n",
      " * Prec@1 77.750 Prec@5 87.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.682 (0.714)\n",
      "\n",
      "Loss 1.4997 (1.4708)\n",
      "\n",
      "Prec@1 62.500 (77.451)\n",
      "\n",
      "Prec@5 93.750 (87.500)\n",
      "\n",
      " * Prec@1 77.451 Prec@5 87.500\n",
      " * Prec@1 77.524 Prec@5 87.500\n",
      " * Prec@1 77.594 Prec@5 87.736\n",
      " * Prec@1 77.546 Prec@5 87.616\n",
      " * Prec@1 77.614 Prec@5 87.614\n",
      " * Prec@1 77.790 Prec@5 87.612\n",
      " * Prec@1 77.522 Prec@5 87.390\n",
      " * Prec@1 77.478 Prec@5 87.284\n",
      " * Prec@1 77.436 Prec@5 87.182\n",
      " * Prec@1 77.500 Prec@5 87.292\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.682 (0.714)\n",
      "\n",
      "Loss 1.2884 (1.4717)\n",
      "\n",
      "Prec@1 81.250 (77.561)\n",
      "\n",
      "Prec@5 93.750 (87.398)\n",
      "\n",
      " * Prec@1 77.561 Prec@5 87.398\n",
      " * Prec@1 77.621 Prec@5 87.399\n",
      " * Prec@1 77.579 Prec@5 87.401\n",
      " * Prec@1 77.539 Prec@5 87.598\n",
      " * Prec@1 77.596 Prec@5 87.596\n",
      " * Prec@1 77.462 Prec@5 87.500\n",
      " * Prec@1 77.425 Prec@5 87.313\n",
      " * Prec@1 77.574 Prec@5 87.500\n",
      " * Prec@1 77.355 Prec@5 87.228\n",
      " * Prec@1 77.411 Prec@5 87.232\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.720 (0.716)\n",
      "\n",
      "Loss 1.4424 (1.4677)\n",
      "\n",
      "Prec@1 68.750 (77.289)\n",
      "\n",
      "Prec@5 87.500 (87.236)\n",
      "\n",
      " * Prec@1 77.289 Prec@5 87.236\n",
      " * Prec@1 77.257 Prec@5 87.326\n",
      " * Prec@1 77.312 Prec@5 87.414\n",
      " * Prec@1 77.280 Prec@5 87.331\n",
      " * Prec@1 77.417 Prec@5 87.417\n",
      " * Prec@1 77.385 Prec@5 87.253\n",
      " * Prec@1 77.192 Prec@5 87.256\n",
      " * Prec@1 77.244 Prec@5 87.260\n",
      " * Prec@1 77.136 Prec@5 87.184\n",
      " * Prec@1 77.344 Prec@5 87.266\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.642 (0.715)\n",
      "\n",
      "Loss 1.4803 (1.4699)\n",
      "\n",
      "Prec@1 68.750 (77.238)\n",
      "\n",
      "Prec@5 81.250 (87.191)\n",
      "\n",
      " * Prec@1 77.238 Prec@5 87.191\n",
      " * Prec@1 77.287 Prec@5 87.271\n",
      " * Prec@1 77.410 Prec@5 87.425\n",
      " * Prec@1 77.604 Prec@5 87.574\n",
      " * Prec@1 77.721 Prec@5 87.721\n",
      " * Prec@1 77.762 Prec@5 87.718\n",
      " * Prec@1 77.802 Prec@5 87.787\n",
      " * Prec@1 77.699 Prec@5 87.784\n",
      " * Prec@1 77.598 Prec@5 87.711\n",
      " * Prec@1 77.778 Prec@5 87.778\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.694 (0.713)\n",
      "\n",
      "Loss 0.9889 (1.4267)\n",
      "\n",
      "Prec@1 75.000 (77.747)\n",
      "\n",
      "Prec@5 93.750 (87.843)\n",
      "\n",
      " * Prec@1 77.747 Prec@5 87.843\n",
      " * Prec@1 77.717 Prec@5 87.772\n",
      " * Prec@1 77.823 Prec@5 87.836\n",
      " * Prec@1 77.593 Prec@5 87.633\n",
      " * Prec@1 77.566 Prec@5 87.566\n",
      " * Prec@1 77.604 Prec@5 87.500\n",
      " * Prec@1 77.513 Prec@5 87.564\n",
      " * Prec@1 77.551 Prec@5 87.628\n",
      " * Prec@1 77.525 Prec@5 87.689\n",
      " * Prec@1 77.562 Prec@5 87.688\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.668 (0.713)\n",
      "\n",
      "Loss 1.6550 (1.4306)\n",
      "\n",
      "Prec@1 81.250 (77.599)\n",
      "\n",
      "Prec@5 87.500 (87.686)\n",
      "\n",
      " * Prec@1 77.599 Prec@5 87.686\n",
      " * Prec@1 77.757 Prec@5 87.745\n",
      " * Prec@1 77.852 Prec@5 87.864\n",
      " * Prec@1 77.945 Prec@5 87.921\n",
      " * Prec@1 77.857 Prec@5 87.976\n",
      " * Prec@1 77.594 Prec@5 87.795\n",
      " * Prec@1 77.687 Prec@5 87.850\n",
      " * Prec@1 77.604 Prec@5 87.789\n",
      " * Prec@1 77.523 Prec@5 87.729\n",
      " * Prec@1 77.557 Prec@5 87.670\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.665 (0.712)\n",
      "\n",
      "Loss 3.4431 (1.4351)\n",
      "\n",
      "Prec@1 50.000 (77.309)\n",
      "\n",
      "Prec@5 81.250 (87.613)\n",
      "\n",
      " * Prec@1 77.309 Prec@5 87.613\n",
      " * Prec@1 77.232 Prec@5 87.667\n",
      " * Prec@1 77.323 Prec@5 87.666\n",
      " * Prec@1 77.303 Prec@5 87.719\n",
      " * Prec@1 77.337 Prec@5 87.772\n",
      " * Prec@1 77.263 Prec@5 87.769\n",
      " * Prec@1 77.190 Prec@5 87.821\n",
      " * Prec@1 77.066 Prec@5 87.871\n",
      " * Prec@1 77.101 Prec@5 87.815\n",
      " * Prec@1 77.135 Prec@5 87.812\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.765 (0.710)\n",
      "\n",
      "Loss 1.3931 (1.4229)\n",
      "\n",
      "Prec@1 81.250 (77.169)\n",
      "\n",
      "Prec@5 87.500 (87.810)\n",
      "\n",
      " * Prec@1 77.169 Prec@5 87.810\n",
      " * Prec@1 77.254 Prec@5 87.807\n",
      " * Prec@1 77.083 Prec@5 87.703\n",
      " * Prec@1 77.016 Prec@5 87.651\n",
      " * Prec@1 77.000 Prec@5 87.550\n",
      " * Prec@1 77.034 Prec@5 87.550\n",
      " * Prec@1 77.067 Prec@5 87.500\n",
      " * Prec@1 77.002 Prec@5 87.451\n",
      " * Prec@1 76.841 Prec@5 87.403\n",
      " * Prec@1 76.827 Prec@5 87.500\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.723 (0.709)\n",
      "\n",
      "Loss 2.1656 (1.4689)\n",
      "\n",
      "Prec@1 68.750 (76.765)\n",
      "\n",
      "Prec@5 81.250 (87.452)\n",
      "\n",
      " * Prec@1 76.765 Prec@5 87.452\n",
      " * Prec@1 76.799 Prec@5 87.500\n",
      " * Prec@1 76.833 Prec@5 87.594\n",
      " * Prec@1 76.819 Prec@5 87.593\n",
      " * Prec@1 76.944 Prec@5 87.639\n",
      " * Prec@1 76.976 Prec@5 87.730\n",
      " * Prec@1 76.825 Prec@5 87.682\n",
      " * Prec@1 76.812 Prec@5 87.636\n",
      " * Prec@1 76.754 Prec@5 87.680\n",
      " * Prec@1 76.758 Prec@5 87.730\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [17][0/559]\t\\Time 0.570 (0.570)\tData 0.460 (0.460)\tLoss 0.0010 (0.0010)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/559]\t\\Time 0.500 (0.536)\tData 0.420 (0.440)\tLoss 0.0020 (0.0118)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][200/559]\t\\Time 0.568 (0.541)\tData 0.460 (0.443)\tLoss 0.0014 (0.0083)\tPrec@1 100.000 (99.813)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][300/559]\t\\Time 0.592 (0.544)\tData 0.472 (0.446)\tLoss 0.0091 (0.0155)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][400/559]\t\\Time 0.511 (0.546)\tData 0.441 (0.447)\tLoss 0.1921 (0.0173)\tPrec@1 93.750 (99.626)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][500/559]\t\\Time 0.584 (0.547)\tData 0.482 (0.448)\tLoss 0.0099 (0.0164)\tPrec@1 100.000 (99.613)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.569 (0.569)\n",
      "\n",
      "Loss 1.3469 (1.3469)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 81.250\n",
      " * Prec@1 78.125 Prec@5 87.500\n",
      " * Prec@1 77.083 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 85.938\n",
      " * Prec@1 75.000 Prec@5 85.000\n",
      " * Prec@1 76.042 Prec@5 84.375\n",
      " * Prec@1 75.000 Prec@5 85.714\n",
      " * Prec@1 73.438 Prec@5 85.156\n",
      " * Prec@1 71.528 Prec@5 85.417\n",
      " * Prec@1 71.250 Prec@5 83.750\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.574 (0.726)\n",
      "\n",
      "Loss 1.8490 (1.9927)\n",
      "\n",
      "Prec@1 62.500 (70.455)\n",
      "\n",
      "Prec@5 81.250 (83.523)\n",
      "\n",
      " * Prec@1 70.455 Prec@5 83.523\n",
      " * Prec@1 70.833 Prec@5 83.854\n",
      " * Prec@1 69.712 Prec@5 84.135\n",
      " * Prec@1 70.089 Prec@5 84.375\n",
      " * Prec@1 70.417 Prec@5 84.583\n",
      " * Prec@1 70.312 Prec@5 85.156\n",
      " * Prec@1 70.956 Prec@5 85.662\n",
      " * Prec@1 72.569 Prec@5 86.458\n",
      " * Prec@1 73.355 Prec@5 86.513\n",
      " * Prec@1 74.375 Prec@5 86.875\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.632 (0.720)\n",
      "\n",
      "Loss 1.7464 (1.6183)\n",
      "\n",
      "Prec@1 75.000 (74.405)\n",
      "\n",
      "Prec@5 87.500 (86.905)\n",
      "\n",
      " * Prec@1 74.405 Prec@5 86.905\n",
      " * Prec@1 74.716 Prec@5 86.932\n",
      " * Prec@1 75.543 Prec@5 87.500\n",
      " * Prec@1 76.562 Prec@5 88.021\n",
      " * Prec@1 76.750 Prec@5 88.000\n",
      " * Prec@1 76.442 Prec@5 87.981\n",
      " * Prec@1 76.389 Prec@5 87.963\n",
      " * Prec@1 76.339 Prec@5 87.946\n",
      " * Prec@1 75.862 Prec@5 87.716\n",
      " * Prec@1 76.042 Prec@5 87.917\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.693 (0.723)\n",
      "\n",
      "Loss 0.0050 (1.4421)\n",
      "\n",
      "Prec@1 100.000 (76.815)\n",
      "\n",
      "Prec@5 100.000 (88.306)\n",
      "\n",
      " * Prec@1 76.815 Prec@5 88.306\n",
      " * Prec@1 76.562 Prec@5 88.086\n",
      " * Prec@1 77.083 Prec@5 88.258\n",
      " * Prec@1 76.838 Prec@5 88.235\n",
      " * Prec@1 76.607 Prec@5 87.857\n",
      " * Prec@1 76.215 Prec@5 87.500\n",
      " * Prec@1 76.520 Prec@5 87.669\n",
      " * Prec@1 76.809 Prec@5 87.829\n",
      " * Prec@1 76.763 Prec@5 87.821\n",
      " * Prec@1 76.875 Prec@5 87.969\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.650 (0.724)\n",
      "\n",
      "Loss 2.6319 (1.4543)\n",
      "\n",
      "Prec@1 68.750 (76.677)\n",
      "\n",
      "Prec@5 81.250 (87.805)\n",
      "\n",
      " * Prec@1 76.677 Prec@5 87.805\n",
      " * Prec@1 76.339 Prec@5 87.649\n",
      " * Prec@1 76.744 Prec@5 87.791\n",
      " * Prec@1 76.420 Prec@5 87.784\n",
      " * Prec@1 76.389 Prec@5 87.639\n",
      " * Prec@1 76.495 Prec@5 87.636\n",
      " * Prec@1 76.463 Prec@5 87.766\n",
      " * Prec@1 76.432 Prec@5 87.630\n",
      " * Prec@1 76.531 Prec@5 87.628\n",
      " * Prec@1 76.375 Prec@5 87.750\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.662 (0.720)\n",
      "\n",
      "Loss 1.6507 (1.4602)\n",
      "\n",
      "Prec@1 62.500 (76.103)\n",
      "\n",
      "Prec@5 93.750 (87.868)\n",
      "\n",
      " * Prec@1 76.103 Prec@5 87.868\n",
      " * Prec@1 76.202 Prec@5 87.861\n",
      " * Prec@1 76.415 Prec@5 88.090\n",
      " * Prec@1 76.505 Prec@5 87.963\n",
      " * Prec@1 76.705 Prec@5 87.955\n",
      " * Prec@1 76.897 Prec@5 88.058\n",
      " * Prec@1 76.754 Prec@5 87.939\n",
      " * Prec@1 76.724 Prec@5 87.823\n",
      " * Prec@1 76.695 Prec@5 87.712\n",
      " * Prec@1 76.771 Prec@5 87.812\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.689 (0.717)\n",
      "\n",
      "Loss 1.1989 (1.4564)\n",
      "\n",
      "Prec@1 81.250 (76.844)\n",
      "\n",
      "Prec@5 93.750 (87.910)\n",
      "\n",
      " * Prec@1 76.844 Prec@5 87.910\n",
      " * Prec@1 76.915 Prec@5 87.903\n",
      " * Prec@1 76.885 Prec@5 87.897\n",
      " * Prec@1 76.953 Prec@5 88.086\n",
      " * Prec@1 77.019 Prec@5 88.077\n",
      " * Prec@1 76.894 Prec@5 87.879\n",
      " * Prec@1 76.866 Prec@5 87.780\n",
      " * Prec@1 77.022 Prec@5 87.960\n",
      " * Prec@1 76.812 Prec@5 87.681\n",
      " * Prec@1 76.875 Prec@5 87.679\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.669 (0.717)\n",
      "\n",
      "Loss 1.3333 (1.4597)\n",
      "\n",
      "Prec@1 75.000 (76.849)\n",
      "\n",
      "Prec@5 87.500 (87.676)\n",
      "\n",
      " * Prec@1 76.849 Prec@5 87.676\n",
      " * Prec@1 76.736 Prec@5 87.674\n",
      " * Prec@1 76.798 Prec@5 87.757\n",
      " * Prec@1 76.774 Prec@5 87.669\n",
      " * Prec@1 76.917 Prec@5 87.750\n",
      " * Prec@1 76.891 Prec@5 87.664\n",
      " * Prec@1 76.705 Prec@5 87.662\n",
      " * Prec@1 76.763 Prec@5 87.660\n",
      " * Prec@1 76.661 Prec@5 87.579\n",
      " * Prec@1 76.875 Prec@5 87.656\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.651 (0.714)\n",
      "\n",
      "Loss 1.6122 (1.4607)\n",
      "\n",
      "Prec@1 68.750 (76.775)\n",
      "\n",
      "Prec@5 81.250 (87.577)\n",
      "\n",
      " * Prec@1 76.775 Prec@5 87.577\n",
      " * Prec@1 76.905 Prec@5 87.652\n",
      " * Prec@1 76.958 Prec@5 87.801\n",
      " * Prec@1 77.083 Prec@5 87.946\n",
      " * Prec@1 77.279 Prec@5 88.088\n",
      " * Prec@1 77.253 Prec@5 88.081\n",
      " * Prec@1 77.299 Prec@5 88.147\n",
      " * Prec@1 77.202 Prec@5 88.068\n",
      " * Prec@1 77.107 Prec@5 87.992\n",
      " * Prec@1 77.292 Prec@5 88.056\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.736 (0.715)\n",
      "\n",
      "Loss 0.9964 (1.4181)\n",
      "\n",
      "Prec@1 81.250 (77.335)\n",
      "\n",
      "Prec@5 93.750 (88.118)\n",
      "\n",
      " * Prec@1 77.335 Prec@5 88.118\n",
      " * Prec@1 77.310 Prec@5 88.043\n",
      " * Prec@1 77.419 Prec@5 88.172\n",
      " * Prec@1 77.194 Prec@5 87.965\n",
      " * Prec@1 77.105 Prec@5 87.895\n",
      " * Prec@1 77.148 Prec@5 87.826\n",
      " * Prec@1 76.933 Prec@5 87.758\n",
      " * Prec@1 76.977 Prec@5 87.819\n",
      " * Prec@1 76.957 Prec@5 87.879\n",
      " * Prec@1 77.000 Prec@5 87.875\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.638 (0.714)\n",
      "\n",
      "Loss 1.5323 (1.4238)\n",
      "\n",
      "Prec@1 81.250 (77.042)\n",
      "\n",
      "Prec@5 87.500 (87.871)\n",
      "\n",
      " * Prec@1 77.042 Prec@5 87.871\n",
      " * Prec@1 77.206 Prec@5 87.990\n",
      " * Prec@1 77.306 Prec@5 88.107\n",
      " * Prec@1 77.464 Prec@5 88.161\n",
      " * Prec@1 77.381 Prec@5 88.214\n",
      " * Prec@1 77.123 Prec@5 88.090\n",
      " * Prec@1 77.278 Prec@5 88.201\n",
      " * Prec@1 77.199 Prec@5 88.194\n",
      " * Prec@1 77.179 Prec@5 88.131\n",
      " * Prec@1 77.159 Prec@5 88.068\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.641 (0.712)\n",
      "\n",
      "Loss 3.1641 (1.4252)\n",
      "\n",
      "Prec@1 50.000 (76.914)\n",
      "\n",
      "Prec@5 81.250 (88.007)\n",
      "\n",
      " * Prec@1 76.914 Prec@5 88.007\n",
      " * Prec@1 76.842 Prec@5 88.058\n",
      " * Prec@1 76.936 Prec@5 88.053\n",
      " * Prec@1 76.974 Prec@5 88.103\n",
      " * Prec@1 77.011 Prec@5 88.152\n",
      " * Prec@1 76.940 Prec@5 88.093\n",
      " * Prec@1 76.870 Prec@5 88.141\n",
      " * Prec@1 76.748 Prec@5 88.136\n",
      " * Prec@1 76.786 Prec@5 88.078\n",
      " * Prec@1 76.875 Prec@5 88.125\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.700 (0.711)\n",
      "\n",
      "Loss 1.5086 (1.4141)\n",
      "\n",
      "Prec@1 81.250 (76.911)\n",
      "\n",
      "Prec@5 81.250 (88.068)\n",
      "\n",
      " * Prec@1 76.911 Prec@5 88.068\n",
      " * Prec@1 76.947 Prec@5 88.115\n",
      " * Prec@1 76.728 Prec@5 87.957\n",
      " * Prec@1 76.663 Prec@5 87.903\n",
      " * Prec@1 76.650 Prec@5 87.800\n",
      " * Prec@1 76.687 Prec@5 87.798\n",
      " * Prec@1 76.722 Prec@5 87.746\n",
      " * Prec@1 76.660 Prec@5 87.695\n",
      " * Prec@1 76.502 Prec@5 87.645\n",
      " * Prec@1 76.490 Prec@5 87.692\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.691 (0.710)\n",
      "\n",
      "Loss 2.1954 (1.4674)\n",
      "\n",
      "Prec@1 68.750 (76.431)\n",
      "\n",
      "Prec@5 81.250 (87.643)\n",
      "\n",
      " * Prec@1 76.431 Prec@5 87.643\n",
      " * Prec@1 76.468 Prec@5 87.642\n",
      " * Prec@1 76.504 Prec@5 87.688\n",
      " * Prec@1 76.446 Prec@5 87.687\n",
      " * Prec@1 76.574 Prec@5 87.731\n",
      " * Prec@1 76.608 Prec@5 87.822\n",
      " * Prec@1 76.460 Prec@5 87.819\n",
      " * Prec@1 76.449 Prec@5 87.772\n",
      " * Prec@1 76.439 Prec@5 87.770\n",
      " * Prec@1 76.444 Prec@5 87.819\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [18][0/559]\t\\Time 0.511 (0.511)\tData 0.411 (0.411)\tLoss 0.0006 (0.0006)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/559]\t\\Time 0.504 (0.528)\tData 0.384 (0.428)\tLoss 0.0005 (0.0097)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][200/559]\t\\Time 0.566 (0.528)\tData 0.467 (0.429)\tLoss 0.0009 (0.0115)\tPrec@1 100.000 (99.720)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][300/559]\t\\Time 0.497 (0.530)\tData 0.423 (0.430)\tLoss 0.4571 (0.0134)\tPrec@1 93.750 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][400/559]\t\\Time 0.553 (0.529)\tData 0.446 (0.431)\tLoss 0.0044 (0.0124)\tPrec@1 100.000 (99.704)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][500/559]\t\\Time 0.535 (0.532)\tData 0.473 (0.434)\tLoss 0.0010 (0.0124)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.574 (0.574)\n",
      "\n",
      "Loss 1.3855 (1.3855)\n",
      "\n",
      "Prec@1 81.250 (81.250)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 81.250 Prec@5 81.250\n",
      " * Prec@1 81.250 Prec@5 87.500\n",
      " * Prec@1 79.167 Prec@5 87.500\n",
      " * Prec@1 76.562 Prec@5 85.938\n",
      " * Prec@1 76.250 Prec@5 86.250\n",
      " * Prec@1 76.042 Prec@5 86.458\n",
      " * Prec@1 74.107 Prec@5 87.500\n",
      " * Prec@1 72.656 Prec@5 85.938\n",
      " * Prec@1 70.833 Prec@5 86.111\n",
      " * Prec@1 70.625 Prec@5 84.375\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.562 (0.727)\n",
      "\n",
      "Loss 1.8282 (2.0247)\n",
      "\n",
      "Prec@1 56.250 (69.318)\n",
      "\n",
      "Prec@5 87.500 (84.659)\n",
      "\n",
      " * Prec@1 69.318 Prec@5 84.659\n",
      " * Prec@1 69.792 Prec@5 84.375\n",
      " * Prec@1 68.750 Prec@5 85.096\n",
      " * Prec@1 69.196 Prec@5 85.268\n",
      " * Prec@1 69.583 Prec@5 85.417\n",
      " * Prec@1 69.531 Prec@5 85.938\n",
      " * Prec@1 70.221 Prec@5 86.397\n",
      " * Prec@1 71.875 Prec@5 87.153\n",
      " * Prec@1 72.697 Prec@5 87.171\n",
      " * Prec@1 73.750 Prec@5 87.500\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.590 (0.707)\n",
      "\n",
      "Loss 1.7867 (1.6393)\n",
      "\n",
      "Prec@1 75.000 (73.810)\n",
      "\n",
      "Prec@5 87.500 (87.500)\n",
      "\n",
      " * Prec@1 73.810 Prec@5 87.500\n",
      " * Prec@1 74.148 Prec@5 87.500\n",
      " * Prec@1 75.000 Prec@5 88.043\n",
      " * Prec@1 76.042 Prec@5 88.542\n",
      " * Prec@1 76.250 Prec@5 88.500\n",
      " * Prec@1 75.962 Prec@5 88.462\n",
      " * Prec@1 75.926 Prec@5 88.426\n",
      " * Prec@1 75.893 Prec@5 88.393\n",
      " * Prec@1 75.216 Prec@5 87.931\n",
      " * Prec@1 75.417 Prec@5 88.125\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.683 (0.711)\n",
      "\n",
      "Loss 0.0056 (1.4539)\n",
      "\n",
      "Prec@1 100.000 (76.210)\n",
      "\n",
      "Prec@5 100.000 (88.508)\n",
      "\n",
      " * Prec@1 76.210 Prec@5 88.508\n",
      " * Prec@1 76.172 Prec@5 88.281\n",
      " * Prec@1 76.705 Prec@5 88.447\n",
      " * Prec@1 76.471 Prec@5 88.419\n",
      " * Prec@1 76.429 Prec@5 88.036\n",
      " * Prec@1 76.042 Prec@5 87.674\n",
      " * Prec@1 76.182 Prec@5 87.838\n",
      " * Prec@1 76.480 Prec@5 87.993\n",
      " * Prec@1 76.442 Prec@5 87.981\n",
      " * Prec@1 76.719 Prec@5 88.125\n",
      "Test: [40/140]\n",
      "\n",
      "Time 0.660 (0.717)\n",
      "\n",
      "Loss 2.5605 (1.4454)\n",
      "\n",
      "Prec@1 68.750 (76.524)\n",
      "\n",
      "Prec@5 81.250 (87.957)\n",
      "\n",
      " * Prec@1 76.524 Prec@5 87.957\n",
      " * Prec@1 76.190 Prec@5 87.649\n",
      " * Prec@1 76.599 Prec@5 87.791\n",
      " * Prec@1 76.278 Prec@5 87.784\n",
      " * Prec@1 76.250 Prec@5 87.639\n",
      " * Prec@1 76.359 Prec@5 87.636\n",
      " * Prec@1 76.330 Prec@5 87.766\n",
      " * Prec@1 76.302 Prec@5 87.630\n",
      " * Prec@1 76.403 Prec@5 87.628\n",
      " * Prec@1 76.250 Prec@5 87.750\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.660 (0.715)\n",
      "\n",
      "Loss 1.5050 (1.4471)\n",
      "\n",
      "Prec@1 62.500 (75.980)\n",
      "\n",
      "Prec@5 93.750 (87.868)\n",
      "\n",
      " * Prec@1 75.980 Prec@5 87.868\n",
      " * Prec@1 76.082 Prec@5 87.861\n",
      " * Prec@1 76.297 Prec@5 88.090\n",
      " * Prec@1 76.389 Prec@5 87.963\n",
      " * Prec@1 76.477 Prec@5 87.955\n",
      " * Prec@1 76.674 Prec@5 88.058\n",
      " * Prec@1 76.535 Prec@5 87.829\n",
      " * Prec@1 76.509 Prec@5 87.716\n",
      " * Prec@1 76.483 Prec@5 87.606\n",
      " * Prec@1 76.562 Prec@5 87.708\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.681 (0.713)\n",
      "\n",
      "Loss 1.1957 (1.4536)\n",
      "\n",
      "Prec@1 75.000 (76.537)\n",
      "\n",
      "Prec@5 93.750 (87.807)\n",
      "\n",
      " * Prec@1 76.537 Prec@5 87.807\n",
      " * Prec@1 76.613 Prec@5 87.802\n",
      " * Prec@1 76.587 Prec@5 87.798\n",
      " * Prec@1 76.660 Prec@5 87.988\n",
      " * Prec@1 76.731 Prec@5 87.981\n",
      " * Prec@1 76.610 Prec@5 87.784\n",
      " * Prec@1 76.586 Prec@5 87.687\n",
      " * Prec@1 76.746 Prec@5 87.868\n",
      " * Prec@1 76.540 Prec@5 87.591\n",
      " * Prec@1 76.607 Prec@5 87.589\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.743 (0.712)\n",
      "\n",
      "Loss 1.3625 (1.4527)\n",
      "\n",
      "Prec@1 75.000 (76.585)\n",
      "\n",
      "Prec@5 87.500 (87.588)\n",
      "\n",
      " * Prec@1 76.585 Prec@5 87.588\n",
      " * Prec@1 76.476 Prec@5 87.674\n",
      " * Prec@1 76.541 Prec@5 87.757\n",
      " * Prec@1 76.436 Prec@5 87.669\n",
      " * Prec@1 76.583 Prec@5 87.750\n",
      " * Prec@1 76.562 Prec@5 87.582\n",
      " * Prec@1 76.461 Prec@5 87.581\n",
      " * Prec@1 76.522 Prec@5 87.580\n",
      " * Prec@1 76.424 Prec@5 87.500\n",
      " * Prec@1 76.641 Prec@5 87.578\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.611 (0.708)\n",
      "\n",
      "Loss 1.5428 (1.4526)\n",
      "\n",
      "Prec@1 68.750 (76.543)\n",
      "\n",
      "Prec@5 81.250 (87.500)\n",
      "\n",
      " * Prec@1 76.543 Prec@5 87.500\n",
      " * Prec@1 76.677 Prec@5 87.576\n",
      " * Prec@1 76.732 Prec@5 87.726\n",
      " * Prec@1 76.786 Prec@5 87.872\n",
      " * Prec@1 76.985 Prec@5 88.015\n",
      " * Prec@1 76.962 Prec@5 88.009\n",
      " * Prec@1 77.011 Prec@5 88.075\n",
      " * Prec@1 76.918 Prec@5 87.997\n",
      " * Prec@1 76.826 Prec@5 87.921\n",
      " * Prec@1 77.014 Prec@5 87.986\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.684 (0.707)\n",
      "\n",
      "Loss 0.8397 (1.4099)\n",
      "\n",
      "Prec@1 87.500 (77.129)\n",
      "\n",
      "Prec@5 93.750 (88.049)\n",
      "\n",
      " * Prec@1 77.129 Prec@5 88.049\n",
      " * Prec@1 77.106 Prec@5 87.976\n",
      " * Prec@1 77.218 Prec@5 88.038\n",
      " * Prec@1 76.995 Prec@5 87.832\n",
      " * Prec@1 76.974 Prec@5 87.763\n",
      " * Prec@1 77.018 Prec@5 87.695\n",
      " * Prec@1 76.869 Prec@5 87.629\n",
      " * Prec@1 76.913 Prec@5 87.628\n",
      " * Prec@1 76.894 Prec@5 87.689\n",
      " * Prec@1 76.938 Prec@5 87.688\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.645 (0.706)\n",
      "\n",
      "Loss 1.5263 (1.4185)\n",
      "\n",
      "Prec@1 81.250 (76.980)\n",
      "\n",
      "Prec@5 87.500 (87.686)\n",
      "\n",
      " * Prec@1 76.980 Prec@5 87.686\n",
      " * Prec@1 77.145 Prec@5 87.745\n",
      " * Prec@1 77.245 Prec@5 87.864\n",
      " * Prec@1 77.404 Prec@5 87.921\n",
      " * Prec@1 77.321 Prec@5 87.976\n",
      " * Prec@1 77.064 Prec@5 87.795\n",
      " * Prec@1 77.220 Prec@5 87.909\n",
      " * Prec@1 77.141 Prec@5 87.847\n",
      " * Prec@1 77.122 Prec@5 87.787\n",
      " * Prec@1 77.102 Prec@5 87.727\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.643 (0.704)\n",
      "\n",
      "Loss 3.1299 (1.4248)\n",
      "\n",
      "Prec@1 43.750 (76.802)\n",
      "\n",
      "Prec@5 81.250 (87.669)\n",
      "\n",
      " * Prec@1 76.802 Prec@5 87.669\n",
      " * Prec@1 76.730 Prec@5 87.723\n",
      " * Prec@1 76.770 Prec@5 87.721\n",
      " * Prec@1 76.809 Prec@5 87.774\n",
      " * Prec@1 76.848 Prec@5 87.826\n",
      " * Prec@1 76.778 Prec@5 87.769\n",
      " * Prec@1 76.763 Prec@5 87.821\n",
      " * Prec@1 76.642 Prec@5 87.871\n",
      " * Prec@1 76.681 Prec@5 87.815\n",
      " * Prec@1 76.771 Prec@5 87.812\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.730 (0.704)\n",
      "\n",
      "Loss 1.7181 (1.4170)\n",
      "\n",
      "Prec@1 81.250 (76.808)\n",
      "\n",
      "Prec@5 81.250 (87.758)\n",
      "\n",
      " * Prec@1 76.808 Prec@5 87.758\n",
      " * Prec@1 76.844 Prec@5 87.756\n",
      " * Prec@1 76.626 Prec@5 87.602\n",
      " * Prec@1 76.562 Prec@5 87.550\n",
      " * Prec@1 76.550 Prec@5 87.450\n",
      " * Prec@1 76.587 Prec@5 87.450\n",
      " * Prec@1 76.624 Prec@5 87.402\n",
      " * Prec@1 76.562 Prec@5 87.354\n",
      " * Prec@1 76.405 Prec@5 87.258\n",
      " * Prec@1 76.394 Prec@5 87.308\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.681 (0.703)\n",
      "\n",
      "Loss 2.1601 (1.4693)\n",
      "\n",
      "Prec@1 68.750 (76.336)\n",
      "\n",
      "Prec@5 81.250 (87.261)\n",
      "\n",
      " * Prec@1 76.336 Prec@5 87.261\n",
      " * Prec@1 76.373 Prec@5 87.311\n",
      " * Prec@1 76.410 Prec@5 87.406\n",
      " * Prec@1 76.353 Prec@5 87.407\n",
      " * Prec@1 76.481 Prec@5 87.454\n",
      " * Prec@1 76.517 Prec@5 87.546\n",
      " * Prec@1 76.369 Prec@5 87.546\n",
      " * Prec@1 76.359 Prec@5 87.455\n",
      " * Prec@1 76.349 Prec@5 87.455\n",
      " * Prec@1 76.355 Prec@5 87.506\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [19][0/559]\t\\Time 0.612 (0.612)\tData 0.502 (0.502)\tLoss 0.0009 (0.0009)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][100/559]\t\\Time 0.559 (0.523)\tData 0.450 (0.425)\tLoss 0.0053 (0.0120)\tPrec@1 100.000 (99.567)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][200/559]\t\\Time 0.497 (0.527)\tData 0.421 (0.429)\tLoss 0.0005 (0.0099)\tPrec@1 100.000 (99.689)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][300/559]\t\\Time 0.609 (0.555)\tData 0.491 (0.455)\tLoss 0.0007 (0.0082)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][400/559]\t\\Time 1.114 (0.558)\tData 0.987 (0.458)\tLoss 0.0009 (0.0079)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [19][500/559]\t\\Time 0.523 (0.574)\tData 0.452 (0.473)\tLoss 0.0053 (0.0086)\tPrec@1 100.000 (99.738)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/140]\n",
      "\n",
      "Time 0.627 (0.627)\n",
      "\n",
      "Loss 1.4865 (1.4865)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 81.250 (81.250)\n",
      "\n",
      " * Prec@1 75.000 Prec@5 81.250\n",
      " * Prec@1 71.875 Prec@5 87.500\n",
      " * Prec@1 72.917 Prec@5 87.500\n",
      " * Prec@1 71.875 Prec@5 85.938\n",
      " * Prec@1 72.500 Prec@5 85.000\n",
      " * Prec@1 72.917 Prec@5 85.417\n",
      " * Prec@1 72.321 Prec@5 86.607\n",
      " * Prec@1 71.094 Prec@5 84.375\n",
      " * Prec@1 70.139 Prec@5 84.722\n",
      " * Prec@1 70.000 Prec@5 83.125\n",
      "Test: [10/140]\n",
      "\n",
      "Time 0.616 (0.803)\n",
      "\n",
      "Loss 1.8780 (2.0356)\n",
      "\n",
      "Prec@1 62.500 (69.318)\n",
      "\n",
      "Prec@5 81.250 (82.955)\n",
      "\n",
      " * Prec@1 69.318 Prec@5 82.955\n",
      " * Prec@1 69.792 Prec@5 83.333\n",
      " * Prec@1 69.231 Prec@5 83.654\n",
      " * Prec@1 69.643 Prec@5 83.929\n",
      " * Prec@1 70.000 Prec@5 84.167\n",
      " * Prec@1 69.922 Prec@5 84.766\n",
      " * Prec@1 70.588 Prec@5 85.294\n",
      " * Prec@1 72.222 Prec@5 86.111\n",
      " * Prec@1 72.697 Prec@5 86.184\n",
      " * Prec@1 73.750 Prec@5 86.562\n",
      "Test: [20/140]\n",
      "\n",
      "Time 0.641 (0.785)\n",
      "\n",
      "Loss 1.8612 (1.6464)\n",
      "\n",
      "Prec@1 75.000 (73.810)\n",
      "\n",
      "Prec@5 87.500 (86.607)\n",
      "\n",
      " * Prec@1 73.810 Prec@5 86.607\n",
      " * Prec@1 74.148 Prec@5 86.648\n",
      " * Prec@1 75.272 Prec@5 87.228\n",
      " * Prec@1 76.302 Prec@5 87.760\n",
      " * Prec@1 76.500 Prec@5 87.750\n",
      " * Prec@1 75.962 Prec@5 87.740\n",
      " * Prec@1 75.926 Prec@5 87.731\n",
      " * Prec@1 75.670 Prec@5 87.723\n",
      " * Prec@1 75.000 Prec@5 87.284\n",
      " * Prec@1 75.208 Prec@5 87.500\n",
      "Test: [30/140]\n",
      "\n",
      "Time 0.726 (0.775)\n",
      "\n",
      "Loss 0.0040 (1.4534)\n",
      "\n",
      "Prec@1 100.000 (76.008)\n",
      "\n",
      "Prec@5 100.000 (87.903)\n",
      "\n",
      " * Prec@1 76.008 Prec@5 87.903\n",
      " * Prec@1 75.977 Prec@5 87.695\n",
      " * Prec@1 76.515 Prec@5 87.879\n",
      " * Prec@1 76.471 Prec@5 87.868\n",
      " * Prec@1 76.429 Prec@5 87.679\n",
      " * Prec@1 76.042 Prec@5 87.326\n",
      " * Prec@1 76.351 Prec@5 87.331\n",
      " * Prec@1 76.480 Prec@5 87.500\n",
      " * Prec@1 76.442 Prec@5 87.500\n",
      " * Prec@1 76.875 Prec@5 87.656\n",
      "Test: [40/140]\n",
      "\n",
      "Time 1.174 (0.786)\n",
      "\n",
      "Loss 2.5501 (1.4477)\n",
      "\n",
      "Prec@1 68.750 (76.677)\n",
      "\n",
      "Prec@5 81.250 (87.500)\n",
      "\n",
      " * Prec@1 76.677 Prec@5 87.500\n",
      " * Prec@1 76.339 Prec@5 87.202\n",
      " * Prec@1 76.744 Prec@5 87.355\n",
      " * Prec@1 76.420 Prec@5 87.358\n",
      " * Prec@1 76.389 Prec@5 87.361\n",
      " * Prec@1 76.223 Prec@5 87.364\n",
      " * Prec@1 76.330 Prec@5 87.367\n",
      " * Prec@1 76.432 Prec@5 87.240\n",
      " * Prec@1 76.531 Prec@5 87.245\n",
      " * Prec@1 76.375 Prec@5 87.375\n",
      "Test: [50/140]\n",
      "\n",
      "Time 0.706 (0.773)\n",
      "\n",
      "Loss 1.2758 (1.4475)\n",
      "\n",
      "Prec@1 62.500 (76.103)\n",
      "\n",
      "Prec@5 93.750 (87.500)\n",
      "\n",
      " * Prec@1 76.103 Prec@5 87.500\n",
      " * Prec@1 76.202 Prec@5 87.500\n",
      " * Prec@1 76.415 Prec@5 87.618\n",
      " * Prec@1 76.389 Prec@5 87.500\n",
      " * Prec@1 76.591 Prec@5 87.500\n",
      " * Prec@1 76.786 Prec@5 87.500\n",
      " * Prec@1 76.535 Prec@5 87.390\n",
      " * Prec@1 76.509 Prec@5 87.284\n",
      " * Prec@1 76.483 Prec@5 87.182\n",
      " * Prec@1 76.562 Prec@5 87.292\n",
      "Test: [60/140]\n",
      "\n",
      "Time 0.691 (0.766)\n",
      "\n",
      "Loss 1.0751 (1.4557)\n",
      "\n",
      "Prec@1 87.500 (76.742)\n",
      "\n",
      "Prec@5 93.750 (87.398)\n",
      "\n",
      " * Prec@1 76.742 Prec@5 87.398\n",
      " * Prec@1 76.815 Prec@5 87.399\n",
      " * Prec@1 76.786 Prec@5 87.401\n",
      " * Prec@1 76.953 Prec@5 87.598\n",
      " * Prec@1 77.019 Prec@5 87.596\n",
      " * Prec@1 76.894 Prec@5 87.500\n",
      " * Prec@1 76.866 Prec@5 87.407\n",
      " * Prec@1 77.022 Prec@5 87.592\n",
      " * Prec@1 76.812 Prec@5 87.409\n",
      " * Prec@1 76.875 Prec@5 87.411\n",
      "Test: [70/140]\n",
      "\n",
      "Time 0.704 (0.762)\n",
      "\n",
      "Loss 1.4895 (1.4566)\n",
      "\n",
      "Prec@1 68.750 (76.761)\n",
      "\n",
      "Prec@5 87.500 (87.412)\n",
      "\n",
      " * Prec@1 76.761 Prec@5 87.412\n",
      " * Prec@1 76.736 Prec@5 87.500\n",
      " * Prec@1 76.798 Prec@5 87.586\n",
      " * Prec@1 76.774 Prec@5 87.500\n",
      " * Prec@1 76.917 Prec@5 87.583\n",
      " * Prec@1 76.891 Prec@5 87.500\n",
      " * Prec@1 76.705 Prec@5 87.500\n",
      " * Prec@1 76.763 Prec@5 87.500\n",
      " * Prec@1 76.661 Prec@5 87.421\n",
      " * Prec@1 76.875 Prec@5 87.500\n",
      "Test: [80/140]\n",
      "\n",
      "Time 0.633 (0.753)\n",
      "\n",
      "Loss 1.7686 (1.4569)\n",
      "\n",
      "Prec@1 68.750 (76.775)\n",
      "\n",
      "Prec@5 81.250 (87.423)\n",
      "\n",
      " * Prec@1 76.775 Prec@5 87.423\n",
      " * Prec@1 76.829 Prec@5 87.500\n",
      " * Prec@1 76.883 Prec@5 87.651\n",
      " * Prec@1 77.009 Prec@5 87.798\n",
      " * Prec@1 77.206 Prec@5 87.941\n",
      " * Prec@1 77.326 Prec@5 87.936\n",
      " * Prec@1 77.371 Prec@5 88.003\n",
      " * Prec@1 77.273 Prec@5 87.926\n",
      " * Prec@1 77.177 Prec@5 87.851\n",
      " * Prec@1 77.361 Prec@5 87.917\n",
      "Test: [90/140]\n",
      "\n",
      "Time 0.718 (0.753)\n",
      "\n",
      "Loss 0.8718 (1.4111)\n",
      "\n",
      "Prec@1 81.250 (77.404)\n",
      "\n",
      "Prec@5 93.750 (87.981)\n",
      "\n",
      " * Prec@1 77.404 Prec@5 87.981\n",
      " * Prec@1 77.378 Prec@5 87.908\n",
      " * Prec@1 77.487 Prec@5 88.038\n",
      " * Prec@1 77.261 Prec@5 87.899\n",
      " * Prec@1 77.237 Prec@5 87.763\n",
      " * Prec@1 77.279 Prec@5 87.695\n",
      " * Prec@1 77.062 Prec@5 87.629\n",
      " * Prec@1 77.105 Prec@5 87.691\n",
      " * Prec@1 77.083 Prec@5 87.689\n",
      " * Prec@1 77.125 Prec@5 87.750\n",
      "Test: [100/140]\n",
      "\n",
      "Time 0.649 (0.748)\n",
      "\n",
      "Loss 1.5053 (1.4177)\n",
      "\n",
      "Prec@1 81.250 (77.166)\n",
      "\n",
      "Prec@5 87.500 (87.748)\n",
      "\n",
      " * Prec@1 77.166 Prec@5 87.748\n",
      " * Prec@1 77.328 Prec@5 87.868\n",
      " * Prec@1 77.427 Prec@5 87.985\n",
      " * Prec@1 77.524 Prec@5 88.041\n",
      " * Prec@1 77.440 Prec@5 88.095\n",
      " * Prec@1 77.123 Prec@5 87.972\n",
      " * Prec@1 77.278 Prec@5 88.084\n",
      " * Prec@1 77.199 Prec@5 88.079\n",
      " * Prec@1 77.122 Prec@5 88.016\n",
      " * Prec@1 77.102 Prec@5 87.955\n",
      "Test: [110/140]\n",
      "\n",
      "Time 0.636 (0.743)\n",
      "\n",
      "Loss 3.1024 (1.4212)\n",
      "\n",
      "Prec@1 43.750 (76.802)\n",
      "\n",
      "Prec@5 81.250 (87.894)\n",
      "\n",
      " * Prec@1 76.802 Prec@5 87.894\n",
      " * Prec@1 76.786 Prec@5 87.946\n",
      " * Prec@1 76.825 Prec@5 87.942\n",
      " * Prec@1 76.864 Prec@5 87.993\n",
      " * Prec@1 76.957 Prec@5 88.043\n",
      " * Prec@1 76.886 Prec@5 88.039\n",
      " * Prec@1 76.763 Prec@5 88.034\n",
      " * Prec@1 76.748 Prec@5 88.083\n",
      " * Prec@1 76.786 Prec@5 88.078\n",
      " * Prec@1 76.875 Prec@5 88.073\n",
      "Test: [120/140]\n",
      "\n",
      "Time 0.740 (0.740)\n",
      "\n",
      "Loss 1.5626 (1.4101)\n",
      "\n",
      "Prec@1 81.250 (76.911)\n",
      "\n",
      "Prec@5 87.500 (88.068)\n",
      "\n",
      " * Prec@1 76.911 Prec@5 88.068\n",
      " * Prec@1 76.947 Prec@5 88.115\n",
      " * Prec@1 76.728 Prec@5 87.907\n",
      " * Prec@1 76.714 Prec@5 87.853\n",
      " * Prec@1 76.650 Prec@5 87.750\n",
      " * Prec@1 76.687 Prec@5 87.748\n",
      " * Prec@1 76.722 Prec@5 87.697\n",
      " * Prec@1 76.660 Prec@5 87.646\n",
      " * Prec@1 76.502 Prec@5 87.548\n",
      " * Prec@1 76.490 Prec@5 87.548\n",
      "Test: [130/140]\n",
      "\n",
      "Time 0.672 (0.737)\n",
      "\n",
      "Loss 2.2620 (1.4604)\n",
      "\n",
      "Prec@1 68.750 (76.431)\n",
      "\n",
      "Prec@5 81.250 (87.500)\n",
      "\n",
      " * Prec@1 76.431 Prec@5 87.500\n",
      " * Prec@1 76.468 Prec@5 87.547\n",
      " * Prec@1 76.504 Prec@5 87.594\n",
      " * Prec@1 76.493 Prec@5 87.547\n",
      " * Prec@1 76.620 Prec@5 87.593\n",
      " * Prec@1 76.654 Prec@5 87.684\n",
      " * Prec@1 76.505 Prec@5 87.637\n",
      " * Prec@1 76.495 Prec@5 87.591\n",
      " * Prec@1 76.484 Prec@5 87.590\n",
      " * Prec@1 76.489 Prec@5 87.640\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "\n",
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 100, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_100targets_weights_seed211_split8020'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('combined_location_image_df_top100.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(211)\n",
    "train_size = int(0.8 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6976298-b66f-4b06-9862-ff9dad42e17e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_6172\\1204856281.py:1: DtypeWarning: Columns (40,56,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  comb = pd.read_csv('top_200_images_with_location_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = pd.read_csv('top_200_images_with_location_data.csv')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "non_existng_files = []\n",
    "\n",
    "for i in comb['path']:\n",
    "    # print(i)\n",
    "    if not os.path.isfile(i):\n",
    "        non_existng_files.append(i)\n",
    "    # Using cv2.imshow() method \n",
    "    # Displaying the image \n",
    "\n",
    "    # except:\n",
    "        \n",
    "non_existng_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b64e8724-ea9f-4a0b-9ddc-054fcc7f83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\vjosv\\AppData\\Local\\Temp\\ipykernel_6172\\3414169806.py:13: DtypeWarning: Columns (40,56,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.location_dataframe = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvit_b_16_artsobservasjoner224_200targets_weights_seed311_split8020\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m image_dataset \u001b[38;5;241m=\u001b[39m ImagesWithLocationDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_200_images_with_location_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m,transform\u001b[38;5;241m=\u001b[39mcomposed)\n\u001b[1;32m---> 14\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m311\u001b[39m)\n\u001b[0;32m     15\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(image_dataset))\n\u001b[0;32m     16\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(image_dataset) \u001b[38;5;241m-\u001b[39m train_size\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:401\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[1;32m---> 40\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\cuda\\random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    121\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m    122\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m--> 124\u001b[0m _lazy_call(cb, seed_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 229\u001b[0m         \u001b[38;5;28mcallable\u001b[39m()\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\cuda\\random.py:122\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[0;32m    121\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m--> 122\u001b[0m     default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "\n",
    "model = torchvision.models.vit_b_16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.heads[0] = nn.Linear(768 , 100, bias = True)\n",
    "model.name = 'vit_b_16_artsobservasjoner224_200targets_weights_seed311_split8020'\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset('top_200_images_with_location_data.csv','s',transform=composed)\n",
    "\n",
    "torch.manual_seed(311)\n",
    "train_size = int(0.8 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size\n",
    "data_train, data_val = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd7f70-97a3-4e00-946e-4b95eb6c9c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
