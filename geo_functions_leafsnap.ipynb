{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25186759-5663-43c9-85c4-c4ccf616186e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85be9381-4b25-4dd2-807d-77b393f639fb",
   "metadata": {},
   "source": [
    "### Create geo samples for testing on the leafsnap predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d96110-ccc3-4b9c-9058-785a4f2bdb7d",
   "metadata": {},
   "source": [
    "### IMPORTANT Run half of train_test_geo_leafsnap.ipynb first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedb2693-c5d0-421a-b822-84f321028304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import pandas as pd\n",
    "import os\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import imblearn\n",
    "import re\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "#copied from Kevin Barnes/kbarnes3: https://gist.github.com/kbarnes3/3fb7d353e9bdd3efccd5\n",
    "\n",
    "import ctypes\n",
    "import platform\n",
    "\n",
    "ES_CONTINUOUS = 0x80000000\n",
    "ES_SYSTEM_REQUIRED = 0x00000001\n",
    "\n",
    "\n",
    "def _set_thread_execution(state):\n",
    "    ctypes.windll.kernel32.SetThreadExecutionState(state)\n",
    "\n",
    "\n",
    "def prevent_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS | ES_SYSTEM_REQUIRED)\n",
    "\n",
    "\n",
    "def allow_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS)\n",
    "\n",
    "\n",
    "def long_running(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        prevent_standby()\n",
    "        result = func(*args, **kwargs)\n",
    "        allow_standby()\n",
    "        return result\n",
    "    return inner\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc756b-1c5c-42e2-b0c6-9178deaa306a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"resnet18_pretrained2911\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f1a41-0d34-46d4-b1b2-8d004a83491f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_utm_to_latlon(df, zone_number, zone_letter):\n",
    "    utm_proj = Proj(proj='utm', zone=zone_number, ellps='WGS84', south=(zone_letter < 'N'))\n",
    "    lonlat_proj = Proj(proj='latlong', datum='WGS84')\n",
    "    lon, lat = transform(utm_proj, lonlat_proj, df['Østkoordinat'].values, df['Nordkoordinat'].values)\n",
    "    \n",
    "    return pd.DataFrame({'Longitude': lon, 'Latitude': lat})\n",
    "\n",
    "df_latlon = convert_utm_to_latlon(dat, 33, 'N') \n",
    "\n",
    "\n",
    "\n",
    "dat = pd.read_csv('dataset/location_data/location_top_185.csv')\n",
    "dat = dat[['Id','Østkoordinat','Nordkoordinat','Vitenskapelig navn']]\n",
    "\n",
    "\n",
    "dat['points']= [[i,j] for i, j in zip(dat.Østkoordinat, dat.Nordkoordinat)]\n",
    "\n",
    "df_latlon = convert_utm_to_latlon(dat, 33, 'N') \n",
    "\n",
    "\n",
    "dat['lat']=df_latlon['Latitude']\n",
    "dat['long']=df_latlon['Longitude']\n",
    "\n",
    "\n",
    "\n",
    "lat_long_oslo = [(58.998141, 9.574585), (60.351413, 9.574585), (60.351413, 12.540894),(58.998141,12.540894)]\n",
    "\n",
    "\n",
    "\n",
    "dat = dat.loc[(dat['lat']>lat_long_oslo[0][0])  & (dat['lat']<lat_long_oslo[1][0]) & (dat['long']>lat_long_oslo[0][1 ]) & (dat['long']<lat_long_oslo[2][1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dat.to_csv('dataset/top185_in_oslo_area.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#oslo area:\n",
    "#lowerleft, upperleft, upper right, lower right,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "points = dat[['Østkoordinat','Nordkoordinat']].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "point_tree = spatial.cKDTree(points)\n",
    "\n",
    "\n",
    "science_names = dat['Vitenskapelig navn'].unique()\n",
    "indexes = [i for i in range(len(dat['Vitenskapelig navn'].unique()))]\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "random.shuffle(indexes)\n",
    "\n",
    "\n",
    "names_mapping = {science_name : index for (science_name,index) in zip(science_names,indexes)}\n",
    "index_mapping = {index : science_name for (science_name,index) in zip(science_names,indexes)}\n",
    "\n",
    "def distance_between_points(point, list_of_points):\n",
    "    return [np.sqrt(np.power(point[0]-lop[0],2)+np.power(point[1]-lop[1],2)) for lop in list_of_points]\n",
    "\n",
    "\n",
    "\n",
    "def get_points_within(df_row, distance=1000):\n",
    "    id = int(df_row['Id'].iloc[0])\n",
    "    return_list = point_tree.query_ball_point([[int(df_row['Østkoordinat'].iloc[0]),int(df_row['Nordkoordinat'].iloc[0])]], distance)[0]\n",
    "    return_dat = dat.iloc[return_list]\n",
    "    return_list = list(return_dat['Id'])\n",
    "    return_list.remove(id)\n",
    "    return return_list\n",
    "    \n",
    "def sample_plant_position(plant,df):\n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[plant]].sample(1)\n",
    "\n",
    "def kernel_density_estimate_value(point_row,dat,bandwidth = 500):\n",
    "    # print(point_row)\n",
    "    # print(dat)\n",
    "    if point_row.index[0] in list(dat.index):\n",
    "        np_dat_lat_long = dat.drop(point_row.index[0])[['Østkoordinat','Nordkoordinat']].to_numpy()\n",
    "    else:\n",
    "        np_dat_lat_long = dat[['Østkoordinat','Nordkoordinat']].to_numpy()\n",
    "    kde = KernelDensity(bandwidth=bandwidth)\n",
    "    # print(np_dat_lat_long)\n",
    "    if len(np_dat_lat_long)==0:\n",
    "        return 0\n",
    "    kde.fit(np_dat_lat_long)\n",
    "    np_point = np.array([[point_row['Østkoordinat'].iloc[0],point_row['Nordkoordinat'].iloc[0]]])\n",
    "    return np.exp(kde.score_samples(np_point))[0]\n",
    "\n",
    "def get_points_within_square(point, dat,side_length = 3000):\n",
    "    return_dat = dat[dat['Østkoordinat']>point['Østkoordinat'].iloc[0]-side_length]\n",
    "    return_dat = return_dat[return_dat['Østkoordinat']<point['Østkoordinat'].iloc[0]+ side_length]\n",
    "    return_dat = return_dat[return_dat['Nordkoordinat']>point['Nordkoordinat'].iloc[0]- side_length]\n",
    "    return_dat = return_dat[return_dat['Nordkoordinat']<point['Nordkoordinat'].iloc[0]+ side_length]\n",
    "    return return_dat\n",
    "\n",
    "# within_square =get_points_within_square(v,dat)\n",
    "\n",
    "# within_square\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_points_within(df_row, distance=1000):\n",
    "    id = int(df_row['Id'].iloc[0])\n",
    "    return_list = point_tree.query_ball_point([[int(df_row['Østkoordinat'].iloc[0]),int(df_row['Nordkoordinat'].iloc[0])]], distance)[0]\n",
    "    return_dat = dat.iloc[return_list]\n",
    "    return_list = list(return_dat['Id'])\n",
    "    return_list.remove(id)\n",
    "    return return_list\n",
    "    \n",
    "def sample_plant_position(plant,df):\n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[plant]].sample(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_knn_classifier(samples_pos_list,dat,n=1000):\n",
    "    sample_pos_indexes = [sp.index[0] for sp in samples_pos_list if sp.index[0] in list(dat.index)]\n",
    "    \n",
    "    dat_removed_samples = dat.drop(index=sample_pos_indexes)\n",
    "    category = []\n",
    "    for k in dat_removed_samples['Vitenskapelig navn']:\n",
    "        category.append(names_mapping[k])\n",
    "        \n",
    "    category = np.array(category)\n",
    "    points_np= np.array(list(dat_removed_samples['points']))\n",
    "    oversample = imblearn.over_sampling.KMeansSMOTE()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = oversample.fit_resample(points_np, category) \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "    neigh.fit(X, y)\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cea36-259d-4dd3-a4cd-0682c18660a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment_output(output, augment):\n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    output_aug = output_aug * augment\n",
    "    output_aug = output_aug * 1/torch.sum(output_aug) \n",
    "    return torch.log(output_aug)\n",
    "\n",
    "def augment_output2(output, augment, zero_tensor_kde001):\n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    augment = augment + zero_tensor_kde001*augment.min()\n",
    "    output_aug = output_aug + augment\n",
    "    output_aug = output_aug * 1/torch.sum(output_aug) \n",
    "    \n",
    "    return torch.log(output_aug)\n",
    "\n",
    "def kde_augmentet_output(sample_pos_list,output, dat, bandwidth):\n",
    "    \n",
    "    weight_tensor_kde = np.zeros((output.size(0),185))\n",
    "    zero_tensor_kde = np.ones((output.size(0),185))\n",
    "    for j, sample_pos in enumerate(sample_pos_list):\n",
    "        within_square =get_points_within_square(sample_pos,dat)\n",
    "        for plant_name in within_square.value_counts('Vitenskapelig navn').index:\n",
    "            within_square_ = within_square[within_square['Vitenskapelig navn']==plant_name]\n",
    "        \n",
    "            pj = names_mapping[plant_name]\n",
    "            pj_value = kernel_density_estimate_value(sample_pos,within_square_,bandwidth = bandwidth)\n",
    "            weight_tensor_kde[j][pj] = pj_value\n",
    "            zero_tensor_kde[j][pj] = 0\n",
    "    weight_tensor_kde = torch.tensor(weight_tensor_kde)\n",
    "    zero_tensor_kde = torch.tensor(zero_tensor_kde)\n",
    "    \n",
    "    output_aug_kde = augment_output2(output,weight_tensor_kde,zero_tensor_kde)\n",
    "\n",
    "    return output_aug_kde\n",
    "    \n",
    "stats_distance1 = norm(\n",
    "    loc=0, \n",
    "    scale=250\n",
    ")\n",
    "\n",
    "stats_distance2 = norm(\n",
    "    loc=0, \n",
    "    scale=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecb96c-470e-430a-91e2-07c6db59a3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##making random index mix\n",
    "\n",
    "random.seed(10)\n",
    "names_mapping = []\n",
    "index_mapping = []\n",
    "for i in range(20):\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    names_mapping.append({science_name : index for (science_name,index) in zip(science_names,indexes)})\n",
    "    index_mapping.append({index : science_name for (science_name,index) in zip(science_names,indexes)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689289d9-fa3c-42a2-a60b-7e285f46114f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_files = [ i for i in os.listdir(f'saved_output/{model_name}_validating_output/') if 'output' in i]\n",
    "output_files\n",
    "max_b=0\n",
    "max_e = 0\n",
    "for output_file in output_files:\n",
    "    of = re.findall('\\d+$',output_file)\n",
    "    if int(of[0]) > max_b:\n",
    "        max_b = int(of[0])\n",
    "    a= output_file.split('_')\n",
    "    if int(a[1][1:]) >= max_e:\n",
    "        max_e = int(a[1][1:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61135ab9-ce64-4451-8d22-7f15a084f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample_plant_position(plant,df,index):\n",
    " \n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[index][plant]].sample(1)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "names_mapping = []\n",
    "index_mapping = []\n",
    "for i in range(20):\n",
    "    random.shuffle(indexes)\n",
    "    names_mapping.append({science_name : index for (science_name,index) in zip(science_names,indexes)})\n",
    "    index_mapping.append({index : science_name for (science_name,index) in zip(science_names,indexes)})\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def create_samples_and_points_around(start_batch):\n",
    "    for e in range(1):#max_e+1):\n",
    "        for b in tqdm(range(max_b+1)):\n",
    "            output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "            target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "            sample_pos_list=[]\n",
    "            weight_tensors = [] \n",
    "            if b >=start_batch:\n",
    "                for i in tqdm(range(20)):\n",
    "\n",
    "                    for meter in [2000]:#500,600,700,800,900,1000,1100,1200,1300,1400,1500]:\n",
    "                        random.seed(11)\n",
    "                        weight_tensor = np.ones((output.size(0),185))*0.1\n",
    "                        sample_pos_list = []\n",
    "                        for j in range(output.size(0)):\n",
    "\n",
    "                            sample_pos = sample_plant_position(int(target[j]),dat,i)\n",
    "\n",
    "                            sample_pos_list.append(sample_pos)\n",
    "\n",
    "\n",
    "                        for sample_pos in sample_pos_list:\n",
    "                            points_in_area_list = get_points_within(sample_pos,meter)\n",
    "                            points_in_area = dat[dat['Id'].isin(points_in_area_list)]\n",
    "\n",
    "                            indexes_in_area = [ names_mapping[i][ii] for ii in list(points_in_area['Vitenskapelig navn'].unique())]\n",
    "\n",
    "                            for k in indexes_in_area:\n",
    "                                weight_tensor[j][k]=1\n",
    "\n",
    "                        \n",
    "                        weight_tensor = torch.from_numpy(weight_tensor)\n",
    "\n",
    "                        torch.save(weight_tensor,f'saved_output/geo_functions/sampled_{meter}m_batch{b}_cofiguration{i}')\n",
    "\n",
    "                            # print(weight_tensors)\n",
    "        # kde_augmentet_output()\n",
    "        \n",
    "create_samples_and_points_around(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e52c3-0211-4809-adb3-2d5dc4aa6b54",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "def get_points_within_square(point, dat,side_length = 3000):\n",
    "    return_dat = dat[dat['Østkoordinat']>point['Østkoordinat'].iloc[0]-side_length]\n",
    "    return_dat = return_dat[return_dat['Østkoordinat']<point['Østkoordinat'].iloc[0]+ side_length]\n",
    "    return_dat = return_dat[return_dat['Nordkoordinat']>point['Nordkoordinat'].iloc[0]- side_length]\n",
    "    return_dat = return_dat[return_dat['Nordkoordinat']<point['Nordkoordinat'].iloc[0]+ side_length]\n",
    "    return return_dat\n",
    "\n",
    "random.seed(10)\n",
    "names_mapping = []\n",
    "index_mapping = []\n",
    "for i in range(3):\n",
    "    random.shuffle(indexes)\n",
    "    names_mapping.append({science_name : index for (science_name,index) in zip(science_names,indexes)})\n",
    "    index_mapping.append({index : science_name for (science_name,index) in zip(science_names,indexes)})\n",
    "    \n",
    "@long_running\n",
    "def kde_samples_output(batch,configuration):\n",
    "    for e in range(1):#max_e+1):\n",
    "        for b in tqdm(range(max_b+1)):\n",
    "            output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "            target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "            sample_pos_list=[]\n",
    "            weight_tensors = [] \n",
    "\n",
    "            for i in tqdm(range(3)):\n",
    "                random.seed(11)\n",
    "                sample_pos_list = []\n",
    "                if b>=batch :\n",
    "                    for j in range(output.size(0)):\n",
    "                        sample_pos = sample_plant_position(int(target[j]),dat,i)\n",
    "\n",
    "                        sample_pos_list.append(sample_pos)\n",
    "                    for side_len in [1000,2000,3000,4000]:\n",
    "                        within_square =get_points_within_square(sample_pos,dat,side_length = side_len)\n",
    "                        within_square = within_square[within_square.Id != sample_pos['Id'].iloc[0]]\n",
    "                        \n",
    "                        for bandwidth in [3000,4000]:\n",
    "                            \n",
    "                            weight_tensor_kde = np.zeros((output.size(0),185))\n",
    "                            for j, sample_pos in enumerate(sample_pos_list):\n",
    "\n",
    "                                for plant_name in within_square.value_counts('Vitenskapelig navn').index:\n",
    "\n",
    "                                    within_square_ = within_square[within_square['Vitenskapelig navn']==plant_name]\n",
    "\n",
    "                                    pj = names_mapping[i][plant_name]\n",
    "                                    pj_value = kernel_density_estimate_value(sample_pos,within_square_,bandwidth = bandwidth)\n",
    "                                    weight_tensor_kde[j][pj] = pj_value\n",
    "\n",
    "                            weight_tensor_kde = torch.from_numpy(weight_tensor_kde)\n",
    "                            print(f'geo_functions_validating_output/kde_side_len{side_len}m_bandwitdth{bandwidth}_batch{b}_cofiguration{i}')\n",
    "                            torch.save(weight_tensor_kde,f'saved_output/geo_functions/kde_side_len{side_len}m_bandwitdth{bandwidth}_batch{b}_cofiguration{i}')\n",
    "                            \n",
    "# kde_samples_output(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2f049-23e5-4e91-a3b3-54570c0c3d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_knn_classifier(samples_pos_list,dat,n=1000):\n",
    "    sample_pos_indexes = [sp.index[0] for sp in samples_pos_list if sp.index[0] in list(dat.index)]\n",
    "    \n",
    "    dat_removed_samples = dat.drop(index=sample_pos_indexes)\n",
    "    category = []\n",
    "    for k in dat_removed_samples['Vitenskapelig navn']:\n",
    "        category.append(names_mapping[k])\n",
    "        \n",
    "    category = np.array(category)\n",
    "    points_np= np.array(list(dat_removed_samples['points']))\n",
    "    oversample = imblearn.over_sampling.KMeansSMOTE()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = oversample.fit_resample(points_np, category) \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "    neigh.fit(X, y)\n",
    "    return neigh\n",
    "\n",
    "def get_knn_classifier_smote(samples_pos_list,dat,n_list,configuration):\n",
    "    i = configuration\n",
    "    sample_pos_indexes = [sp.index[0] for sp in samples_pos_list if sp.index[0] in list(dat.index)]\n",
    "    \n",
    "    dat_removed_samples = dat.drop(index=sample_pos_indexes)\n",
    "    category = []\n",
    "    for k in dat_removed_samples['Vitenskapelig navn']:\n",
    "        category.append(names_mapping[i][k])\n",
    "        \n",
    "    category = np.array(category)\n",
    "    points_np= np.array(list(dat_removed_samples['points']))\n",
    "    oversample = imblearn.over_sampling.KMeansSMOTE()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = oversample.fit_resample(points_np, category) \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    neigh=[]\n",
    "    for n in n_list:\n",
    "        neigh.append(KNeighborsClassifier(n_neighbors=n))\n",
    "    for knn in neigh:\n",
    "        knn.fit(X, y)\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0212e79-605f-4748-ad4b-496ad18ac671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3429319-6ce1-49f2-af71-9eda42e62015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_pos = sample_plant_position(0,dat,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a5030-87d9-46ea-b9d9-88c2beea501d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_list = [10,15,20]#25,50,75]#[100,200,500,1000,1500,2000,2500,3000]\n",
    "\n",
    "# n_list = [1000\n",
    "\n",
    "random.seed(10)\n",
    "names_mapping = []\n",
    "index_mapping = []\n",
    "for i in range(3):\n",
    "    random.shuffle(indexes)\n",
    "    names_mapping.append({science_name : index for (science_name,index) in zip(science_names,indexes)})\n",
    "    index_mapping.append({index : science_name for (science_name,index) in zip(science_names,indexes)})\n",
    "    \n",
    "@long_running\n",
    "def knn_smote_samples_output(batch,n_list):\n",
    "    for e in range(1):#max_e+1):\n",
    "        for b in tqdm(range(max_b+1)):\n",
    "            output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "            target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "            sample_pos_list=[]\n",
    "            weight_tensors = [] \n",
    "            if b >= batch: \n",
    "                for i in tqdm(range(3)):\n",
    "                    random.seed(11)\n",
    "                    sample_pos_list = []\n",
    "                    # if b>=batch and i !=configuration:\n",
    "\n",
    "                    for j in range(output.size(0)):\n",
    "                        sample_pos = sample_plant_position(int(target[j]),dat,i)\n",
    "\n",
    "                        sample_pos_list.append(sample_pos)\n",
    "\n",
    "                    knns = get_knn_classifier_smote(sample_pos_list,dat,n_list,i)\n",
    "                    weight_tensor_knn = np.zeros((output.size(0),185))\n",
    "\n",
    "                    for n in range(len(n_list)):\n",
    "                        weight_tensor_knn = np.zeros((output.size(0),185))\n",
    "                        for j, sample_pos in enumerate(sample_pos_list):\n",
    "                            weight_tensor_knn[j]=knns[0].predict_proba(list(sample_pos['points']))\n",
    "\n",
    "                        weight_tensor_knn = torch.from_numpy(weight_tensor_knn)\n",
    "                        print(f'saved_output/{model_name}_validating_output/knn_smote_n_{n_list[n]}_batch{b}_cofiguration{i}')\n",
    "                        torch.save(weight_tensor_knn,f'saved_output/geo_functions/knn_smote_n_{n_list[n]}_batch{b}_cofiguration{i}')\n",
    "\n",
    "knn_smote_samples_output(14,n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f0d16-e233-451a-b31e-bc885eae4a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#multinomial logistic regression:\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def sample_plant_position(plant,df):\n",
    "    if type(plant) == str:\n",
    "        return dat[dat['Vitenskapelig navn'] == plant].sample(1)\n",
    "    elif type(plant) == int:\n",
    "        return dat[dat['Vitenskapelig navn'] == index_mapping[plant]].sample(1)\n",
    "\n",
    "def get_points_within_df(df_row, distance=1000):\n",
    "    id = int(df_row['Id'].iloc[0])\n",
    "    return_list = point_tree.query_ball_point([[int(df_row['Østkoordinat'].iloc[0]),int(df_row['Nordkoordinat'].iloc[0])]], distance)[0]\n",
    "    return_dat = dat.iloc[return_list]\n",
    "    \n",
    "    # return_list = list(return_dat['Id'])\n",
    "    # return_list.remove(id)\n",
    "    return return_dat[~return_dat['Id'].isin([id])]\n",
    "\n",
    "def relative_count_in_from_df(df_, name_to_index_dict):\n",
    "    list_science_names = list(df_['Vitenskapelig navn'])\n",
    "    count_list = [0 for i in range(185)]\n",
    "    sum_count = len(list_science_names)\n",
    "    for lsn in list_science_names:\n",
    "        count_list[name_to_index_dict[lsn]] += 1/sum_count\n",
    "\n",
    "    return count_list\n",
    "\n",
    "science_names = dat['Vitenskapelig navn'].unique()\n",
    "indexes = [i for i in range(len(dat['Vitenskapelig navn'].unique()))]\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "random.shuffle(indexes)\n",
    "\n",
    "\n",
    "names_mapping = {science_name : index for (science_name,index) in zip(science_names,indexes)}\n",
    "index_mapping = {index : science_name for (science_name,index) in zip(science_names,indexes)}\n",
    "    \n",
    "radius = 1000\n",
    "\n",
    "radius_list = [250,500,750,1000,2000]\n",
    "samples_per_species = 100\n",
    "\n",
    "@long_running\n",
    "def create_multinomial_logistic_regressions(radius_list,samples_per_species=100):\n",
    "    for radius in radius_list:\n",
    "        random.seed(1810)\n",
    "\n",
    "        sample_list = []\n",
    "        samples_from_areas = []\n",
    "        target_list = []\n",
    "        x_list = []\n",
    "        for i in tqdm(range(185)):\n",
    "            sample_list =[]\n",
    "            samples_from_areas = []\n",
    "            for j in range(samples_per_species):\n",
    "                target_list.append(i)\n",
    "                sample_list.append(sample_plant_position(i,dat))\n",
    "\n",
    "            for sample in sample_list:\n",
    "                samples_from_areas.append(get_points_within_df(sample,radius))\n",
    "\n",
    "        for sfa in samples_from_areas:\n",
    "            x_list.append(relative_count_in_from_df(sfa,names_mapping))\n",
    "\n",
    "        model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        model.fit(x_list, target_list)\n",
    "        np.save(f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/model_coefficients_r{radius}_shape{np.array(x_list).shape}', model.coef_)\n",
    "\n",
    "        np.save(f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/model_intercept_r{radius}_shape{np.array(x_list).shape}',model.intercept_)\n",
    "\n",
    "create_multinomial_logistic_regressions(radius_list)\n",
    "\n",
    "create_multinomial_logistic_regressions(radius_list,200)\n",
    "# for b in tqdm(range(max_b+1)):\n",
    "#     output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "#     target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "#     sample_pos_list=[]\n",
    "#     weight_tensors = [] \n",
    "#     if b >= batch: \n",
    "#         for i in tqdm(range(3)):\n",
    "#             random.seed(11)\n",
    "#             sample_pos_list = []\n",
    "#             # if b>=batch and i !=configuration:\n",
    "\n",
    "#             for j in range(output.size(0)):\n",
    "#                 sample_pos = sample_plant_position(int(target[j]),dat,i)\n",
    "\n",
    "#                 sample_pos_list.append(sample_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7124c57-4976-4dab-a62c-d4389f1bcee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2dc17-511e-49c0-a2bc-58f2bb19ff72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589f17c-5eb0-4128-b37b-431769f70f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93608f72-70b0-4dc8-a9cb-d904315256d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
