{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119ab6d8-c758-4429-a24b-b51af1ac2bb4",
   "metadata": {},
   "source": [
    "### training models on species observation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed47fa15-d61a-4016-b9f3-262a0e578e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_with_loc.csv'\n",
    "\n",
    "\n",
    "temp = 'C:/Users/vjosv/master/top_100_images_with_location_data.csv'\n",
    "import time\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "import ast\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from averagemeter import *\n",
    "from models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 150\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "best_prec1 = 0\n",
    "classes = []\n",
    "\n",
    "\n",
    "train_path ='dataset/image_data/csv/combined_location_top_100_images_csv_train.csv'\n",
    "test_path='dataset/image_data/csv/combined_location_top_100_images_csv_test.csv'\n",
    "validation_path = 'dataset/image_data/csv/combined_location_top_100_images_csv_validation.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c270da61-d502-44a7-b2fe-52e2c8efaa7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = [T.ToTensor(),T.Resize((INPUT_SIZE,INPUT_SIZE))]\n",
    "\n",
    "composed = T.Compose(transforms)\n",
    "\n",
    "\n",
    "class ImagesWithLocationDataset(Dataset):\n",
    "    \"\"\"Plant images with location data.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "    \n",
    "\n",
    "        self.location_dataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.location_dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.location_dataframe['path'].iloc[idx]\n",
    "        \n",
    "        image = io.imread(img_name)\n",
    "        # location_data = self.from_np_array(self.location_dataframe['count_in_1000'].iloc[idx])\n",
    "        target = np.array(self.location_dataframe['target'].iloc[idx])\n",
    "        # landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        # landmarks = np.array([landmarks], dtype=float).reshape(-1, 2)\n",
    "        sample = {'image': image, 'location_data': None, 'target':target}\n",
    "        sample = {'image': image, 'target':target}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            sample['target'] = torch.from_numpy(sample['target'])\n",
    "            # sample['location_data'] = torch.from_numpy(location_data).float()\n",
    "        return sample\n",
    "    \n",
    "    def from_np_array(self,array_string):\n",
    "        array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "        return np.array(ast.literal_eval(array_string))\n",
    "    \n",
    "    def name(self):\n",
    "        return 'ImagesWithLocationDataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be26d509-96f7-42ba-9e44-53a0f06ae9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import ctypes\n",
    "import platform\n",
    "\n",
    "ES_CONTINUOUS = 0x80000000\n",
    "ES_SYSTEM_REQUIRED = 0x00000001\n",
    "\n",
    "\n",
    "def _set_thread_execution(state):\n",
    "    ctypes.windll.kernel32.SetThreadExecutionState(state)\n",
    "\n",
    "\n",
    "def prevent_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS | ES_SYSTEM_REQUIRED)\n",
    "\n",
    "\n",
    "def allow_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS)\n",
    "\n",
    "\n",
    "def long_running(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        prevent_standby()\n",
    "        result = func(*args, **kwargs)\n",
    "        allow_standby()\n",
    "        return result\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe483d4-6528-44d7-ad52-ec4c69619e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3e600c-1e05-41a0-a007-c31a8736e16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        # print(input['image'].shape)\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "            \n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        \n",
    "        # compute output\n",
    "        # print(input_var.shape)\n",
    "        # print(output)\n",
    "\n",
    "        loss = criterion(output, target_var)\n",
    "        # print(loss)\n",
    "        # if i >10:\n",
    "        #     break\n",
    "        \n",
    "        save_output_target_train(model,output,target_var,epoch,i)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5,conf = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  '\\Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "def validate(val_loader, model, criterion,epoch,save_output=False):\n",
    "    # global output_aug_kde001, sample_pos, within_square, weight_tensor_kde001,zero_tensor_kde001,tt\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "\n",
    "    conf = AverageMeter()\n",
    "    class_correct = list(0. for i in range(200))\n",
    "    class_total = list(0. for i in range(200))\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, input in enumerate(val_loader):\n",
    "        \n",
    "\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        save_output_target_validate(model,output,target,epoch,i)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        \n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        \n",
    "\n",
    "        losses.update(loss.data.item(), image.size(0))\n",
    "        \n",
    "        top1.update(prec1.item(), image.size(0))\n",
    "        top5.update(prec5.item(), image.size(0))\n",
    "\n",
    "\n",
    "        conf.update(conf1,1)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            print('Test: [{0}/{1}]\\n'.format(i, len(val_loader)))\n",
    "            print('Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\n'.format(batch_time=batch_time))\n",
    "            print('Loss {loss.val:.4f} ({loss.avg:.4f})\\n'.format(loss=losses))\n",
    "            print('Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\n'.format(top1=top1))\n",
    "            print('Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\n'.format(top5=top5))\n",
    "\n",
    "        # print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "        #       .format(top1=top1, top5=top5))\n",
    "        \n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, adjust_now, LEARNING_RATE=LEARNING_RATE):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LEARNING_RATE\n",
    "    if (epoch-1) < 0:\n",
    "        former_lr=optimizer.param_groups[0]['lr']\n",
    "\n",
    "    former_lr = copy.copy(optimizer.param_groups[0]['lr'])\n",
    "    if adjust_now:\n",
    "        former_lr = copy.copy(optimizer.param_groups[0]['lr'])\n",
    "        LEARNING_RATE = LEARNING_RATE*0.1\n",
    "        lr = LEARNING_RATE\n",
    "    print('\\n[Learning Rate] {:0.6f}'.format(lr))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr != former_lr, LEARNING_RATE\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, model):\n",
    "    filename=f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        print('\\n[INFO] Saved Model to model_best.pth.tar')\n",
    "        shutil.copyfile(filename, f'saved_models/{model.name}_model_best.pth.tar')\n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = output.shape[1]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348541b4-ac24-487b-b492-51094a0c450a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a04e0b-940e-4ab6-84a8-29599d6306fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b8e1ad-3f9c-4307-a2c4-8c6953a70916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_epoch =0\n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS,init_learning_rate = None,load_best=False ):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    first_run = True \n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "        \n",
    "        if first_run and init_learning_rate:\n",
    "            LEARNING_RATE = init_learning_rate\n",
    "            print(LEARNING_RATE)\n",
    "            adjusted_rate= False\n",
    "        else:\n",
    "            adjusted_rate, LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE=LEARNING_RATE)\n",
    "            five_epochs_since_best = False\n",
    "        if adjusted_rate or (load_best and first_run):\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "        first_run = False\n",
    "\n",
    "def save_output_target_validate(model,output,target,epoch,batch):\n",
    "        torch.save(output,f'saved_output/{model.name}_validating_output/output_e{epoch}_b{batch}')\n",
    "        torch.save(target,f'saved_output/{model.name}_validating_output/target_b{batch}')\n",
    "        \n",
    "def save_output_target_train(model,output,target,epoch,batch):\n",
    "        torch.save(output,f'saved_output/{model.name}_training_output/output_e{epoch}_b{batch}')\n",
    "\n",
    "        torch.save(target,f'saved_output/{model.name}_training_output/target_e_{epoch}_b{batch}')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25f3ae-b480-4584-955c-ceb703aee337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4298f3e3-ac4a-4268-8560-c73f8725922b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "0.01\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\functional.py:5440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1334]\t\\Time 5.594 (5.594)\tData 4.562 (4.562)\tLoss 4.2932 (4.2932)\tPrec@1 0.000 (0.000)\tPrec@5 16.667 (16.667)\n",
      "Epoch: [0][100/1334]\t\\Time 0.311 (0.382)\tData 0.260 (0.297)\tLoss 4.6783 (4.7449)\tPrec@1 0.000 (0.825)\tPrec@5 0.000 (4.620)\n",
      "Epoch: [0][200/1334]\t\\Time 0.341 (0.359)\tData 0.291 (0.278)\tLoss 4.5183 (4.6967)\tPrec@1 0.000 (0.871)\tPrec@5 8.333 (4.768)\n",
      "Epoch: [0][300/1334]\t\\Time 0.357 (0.358)\tData 0.283 (0.278)\tLoss 4.4854 (4.6761)\tPrec@1 8.333 (1.135)\tPrec@5 16.667 (4.817)\n",
      "Epoch: [0][400/1334]\t\\Time 0.332 (0.358)\tData 0.271 (0.279)\tLoss 4.6430 (4.6579)\tPrec@1 0.000 (1.205)\tPrec@5 8.333 (5.320)\n",
      "Epoch: [0][500/1334]\t\\Time 0.342 (0.359)\tData 0.272 (0.281)\tLoss 4.4953 (4.6235)\tPrec@1 0.000 (1.480)\tPrec@5 8.333 (6.404)\n",
      "Epoch: [0][600/1334]\t\\Time 0.380 (0.358)\tData 0.310 (0.281)\tLoss 4.0866 (4.5667)\tPrec@1 8.333 (1.775)\tPrec@5 33.333 (7.903)\n",
      "Epoch: [0][700/1334]\t\\Time 0.433 (0.358)\tData 0.363 (0.281)\tLoss 4.0424 (4.5057)\tPrec@1 8.333 (2.294)\tPrec@5 16.667 (9.736)\n",
      "Epoch: [0][800/1334]\t\\Time 0.335 (0.359)\tData 0.244 (0.282)\tLoss 3.4065 (4.4398)\tPrec@1 16.667 (3.121)\tPrec@5 50.000 (11.819)\n",
      "Epoch: [0][900/1334]\t\\Time 0.395 (0.358)\tData 0.322 (0.281)\tLoss 3.6759 (4.3701)\tPrec@1 16.667 (3.940)\tPrec@5 41.667 (13.957)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.425 (0.357)\tData 0.355 (0.280)\tLoss 3.3523 (4.3021)\tPrec@1 16.667 (4.662)\tPrec@5 41.667 (15.951)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.357 (0.357)\tData 0.274 (0.280)\tLoss 3.6728 (4.2451)\tPrec@1 0.000 (5.298)\tPrec@5 41.667 (17.825)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.342 (0.358)\tData 0.272 (0.281)\tLoss 2.6651 (4.1905)\tPrec@1 8.333 (5.933)\tPrec@5 75.000 (19.643)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.385 (0.358)\tData 0.325 (0.282)\tLoss 3.6596 (4.1418)\tPrec@1 0.000 (6.476)\tPrec@5 41.667 (21.125)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.311 (0.311)\n",
      "\n",
      "Loss 3.6043 (3.6043)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 41.667 (41.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.457 (0.403)\n",
      "\n",
      "Loss 3.8032 (3.4894)\n",
      "\n",
      "Prec@1 16.667 (16.584)\n",
      "\n",
      "Prec@5 25.000 (40.512)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.165 (0.375)\n",
      "\n",
      "Loss 3.5580 (3.4439)\n",
      "\n",
      "Prec@1 0.000 (16.211)\n",
      "\n",
      "Prec@5 33.333 (42.164)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.122 (0.355)\n",
      "\n",
      "Loss 3.4020 (3.4365)\n",
      "\n",
      "Prec@1 8.333 (16.833)\n",
      "\n",
      "Prec@5 33.333 (42.940)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [1][0/1334]\t\\Time 0.343 (0.343)\tData 0.263 (0.263)\tLoss 4.2179 (4.2179)\tPrec@1 8.333 (8.333)\tPrec@5 25.000 (25.000)\n",
      "Epoch: [1][100/1334]\t\\Time 0.351 (0.354)\tData 0.289 (0.277)\tLoss 3.3208 (3.4329)\tPrec@1 8.333 (14.686)\tPrec@5 66.667 (44.389)\n",
      "Epoch: [1][200/1334]\t\\Time 0.323 (0.352)\tData 0.210 (0.276)\tLoss 2.9708 (3.4195)\tPrec@1 25.000 (14.925)\tPrec@5 50.000 (43.947)\n",
      "Epoch: [1][300/1334]\t\\Time 0.307 (0.351)\tData 0.215 (0.274)\tLoss 3.5380 (3.4033)\tPrec@1 8.333 (15.642)\tPrec@5 41.667 (44.684)\n",
      "Epoch: [1][400/1334]\t\\Time 0.317 (0.350)\tData 0.219 (0.273)\tLoss 3.3598 (3.3720)\tPrec@1 16.667 (16.168)\tPrec@5 66.667 (45.698)\n",
      "Epoch: [1][500/1334]\t\\Time 0.365 (0.352)\tData 0.285 (0.274)\tLoss 3.6620 (3.3524)\tPrec@1 0.000 (16.900)\tPrec@5 33.333 (46.324)\n",
      "Epoch: [1][600/1334]\t\\Time 0.416 (0.353)\tData 0.332 (0.275)\tLoss 3.1605 (3.3311)\tPrec@1 16.667 (17.457)\tPrec@5 66.667 (47.047)\n",
      "Epoch: [1][700/1334]\t\\Time 0.330 (0.353)\tData 0.243 (0.275)\tLoss 3.6826 (3.3205)\tPrec@1 8.333 (17.416)\tPrec@5 41.667 (47.266)\n",
      "Epoch: [1][800/1334]\t\\Time 0.322 (0.352)\tData 0.228 (0.274)\tLoss 3.0031 (3.3036)\tPrec@1 25.000 (17.769)\tPrec@5 41.667 (47.774)\n",
      "Epoch: [1][900/1334]\t\\Time 0.336 (0.353)\tData 0.236 (0.275)\tLoss 3.2010 (3.2848)\tPrec@1 33.333 (18.202)\tPrec@5 50.000 (48.298)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.384 (0.353)\tData 0.307 (0.274)\tLoss 2.7726 (3.2678)\tPrec@1 33.333 (18.565)\tPrec@5 50.000 (48.751)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.451 (0.353)\tData 0.371 (0.275)\tLoss 2.4144 (3.2448)\tPrec@1 58.333 (19.058)\tPrec@5 83.333 (49.402)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.338 (0.353)\tData 0.264 (0.275)\tLoss 3.0702 (3.2307)\tPrec@1 33.333 (19.484)\tPrec@5 41.667 (49.799)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.371 (0.353)\tData 0.290 (0.275)\tLoss 3.1351 (3.2119)\tPrec@1 16.667 (19.831)\tPrec@5 75.000 (50.256)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.325 (0.325)\n",
      "\n",
      "Loss 2.5911 (2.5911)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.421 (0.396)\n",
      "\n",
      "Loss 2.8202 (2.9789)\n",
      "\n",
      "Prec@1 25.000 (25.413)\n",
      "\n",
      "Prec@5 58.333 (54.620)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.159 (0.369)\n",
      "\n",
      "Loss 2.7449 (2.9725)\n",
      "\n",
      "Prec@1 25.000 (24.461)\n",
      "\n",
      "Prec@5 66.667 (55.307)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.134 (0.348)\n",
      "\n",
      "Loss 2.5355 (2.9850)\n",
      "\n",
      "Prec@1 25.000 (24.557)\n",
      "\n",
      "Prec@5 58.333 (55.399)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [2][0/1334]\t\\Time 0.342 (0.342)\tData 0.272 (0.272)\tLoss 2.4705 (2.4705)\tPrec@1 33.333 (33.333)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [2][100/1334]\t\\Time 0.320 (0.349)\tData 0.240 (0.271)\tLoss 2.6492 (2.9258)\tPrec@1 25.000 (26.568)\tPrec@5 75.000 (58.086)\n",
      "Epoch: [2][200/1334]\t\\Time 0.320 (0.351)\tData 0.250 (0.273)\tLoss 2.7351 (2.9262)\tPrec@1 25.000 (26.368)\tPrec@5 66.667 (58.416)\n",
      "Epoch: [2][300/1334]\t\\Time 0.321 (0.352)\tData 0.241 (0.274)\tLoss 2.3484 (2.8602)\tPrec@1 25.000 (26.883)\tPrec@5 83.333 (59.939)\n",
      "Epoch: [2][400/1334]\t\\Time 0.339 (0.353)\tData 0.251 (0.276)\tLoss 3.3219 (2.8510)\tPrec@1 25.000 (27.057)\tPrec@5 41.667 (60.100)\n",
      "Epoch: [2][500/1334]\t\\Time 0.332 (0.353)\tData 0.238 (0.276)\tLoss 4.1423 (2.8623)\tPrec@1 16.667 (26.730)\tPrec@5 41.667 (59.747)\n",
      "Epoch: [2][600/1334]\t\\Time 0.337 (0.353)\tData 0.264 (0.275)\tLoss 3.5119 (2.8525)\tPrec@1 16.667 (27.177)\tPrec@5 41.667 (59.664)\n",
      "Epoch: [2][700/1334]\t\\Time 0.340 (0.354)\tData 0.250 (0.276)\tLoss 3.3007 (2.8542)\tPrec@1 16.667 (27.247)\tPrec@5 41.667 (59.510)\n",
      "Epoch: [2][800/1334]\t\\Time 0.352 (0.354)\tData 0.280 (0.276)\tLoss 2.2199 (2.8438)\tPrec@1 33.333 (27.414)\tPrec@5 83.333 (59.748)\n",
      "Epoch: [2][900/1334]\t\\Time 0.321 (0.354)\tData 0.220 (0.277)\tLoss 3.3205 (2.8359)\tPrec@1 16.667 (27.701)\tPrec@5 50.000 (60.174)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.431 (0.355)\tData 0.374 (0.277)\tLoss 2.8927 (2.8260)\tPrec@1 16.667 (28.105)\tPrec@5 66.667 (60.373)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.410 (0.355)\tData 0.350 (0.278)\tLoss 2.1668 (2.8143)\tPrec@1 58.333 (28.323)\tPrec@5 75.000 (60.672)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.351 (0.355)\tData 0.251 (0.278)\tLoss 2.8749 (2.7978)\tPrec@1 25.000 (28.733)\tPrec@5 58.333 (60.949)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.340 (0.355)\tData 0.261 (0.277)\tLoss 2.0724 (2.7932)\tPrec@1 50.000 (28.850)\tPrec@5 75.000 (61.056)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 3.0296 (3.0296)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 41.667 (41.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.425 (0.397)\n",
      "\n",
      "Loss 2.5784 (2.7694)\n",
      "\n",
      "Prec@1 33.333 (27.970)\n",
      "\n",
      "Prec@5 66.667 (62.871)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.161 (0.370)\n",
      "\n",
      "Loss 2.0994 (2.7000)\n",
      "\n",
      "Prec@1 58.333 (30.390)\n",
      "\n",
      "Prec@5 75.000 (63.226)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.128 (0.350)\n",
      "\n",
      "Loss 2.2498 (2.6972)\n",
      "\n",
      "Prec@1 33.333 (30.869)\n",
      "\n",
      "Prec@5 75.000 (63.372)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [3][0/1334]\t\\Time 0.374 (0.374)\tData 0.282 (0.282)\tLoss 2.8078 (2.8078)\tPrec@1 16.667 (16.667)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [3][100/1334]\t\\Time 0.312 (0.342)\tData 0.220 (0.264)\tLoss 2.5851 (2.5023)\tPrec@1 33.333 (34.901)\tPrec@5 75.000 (67.244)\n",
      "Epoch: [3][200/1334]\t\\Time 0.383 (0.347)\tData 0.332 (0.268)\tLoss 2.4920 (2.4403)\tPrec@1 25.000 (36.650)\tPrec@5 66.667 (68.532)\n",
      "Epoch: [3][300/1334]\t\\Time 0.393 (0.348)\tData 0.312 (0.270)\tLoss 2.2288 (2.4395)\tPrec@1 66.667 (36.545)\tPrec@5 83.333 (68.383)\n",
      "Epoch: [3][400/1334]\t\\Time 0.369 (0.351)\tData 0.288 (0.272)\tLoss 2.9042 (2.4599)\tPrec@1 41.667 (36.180)\tPrec@5 50.000 (68.121)\n",
      "Epoch: [3][500/1334]\t\\Time 0.362 (0.353)\tData 0.301 (0.275)\tLoss 3.0390 (2.4679)\tPrec@1 16.667 (35.895)\tPrec@5 50.000 (68.081)\n",
      "Epoch: [3][600/1334]\t\\Time 0.358 (0.353)\tData 0.267 (0.274)\tLoss 2.4231 (2.4843)\tPrec@1 33.333 (35.496)\tPrec@5 66.667 (67.485)\n",
      "Epoch: [3][700/1334]\t\\Time 0.324 (0.353)\tData 0.216 (0.275)\tLoss 1.9605 (2.4756)\tPrec@1 41.667 (35.568)\tPrec@5 83.333 (67.475)\n",
      "Epoch: [3][800/1334]\t\\Time 0.318 (0.353)\tData 0.218 (0.275)\tLoss 2.9615 (2.4775)\tPrec@1 41.667 (35.799)\tPrec@5 66.667 (67.624)\n",
      "Epoch: [3][900/1334]\t\\Time 0.347 (0.353)\tData 0.256 (0.275)\tLoss 2.1656 (2.4808)\tPrec@1 50.000 (35.812)\tPrec@5 66.667 (67.601)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.370 (0.354)\tData 0.320 (0.276)\tLoss 1.1355 (2.4721)\tPrec@1 75.000 (35.856)\tPrec@5 83.333 (67.924)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.420 (0.354)\tData 0.371 (0.276)\tLoss 2.8554 (2.4711)\tPrec@1 25.000 (35.876)\tPrec@5 75.000 (68.021)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.341 (0.355)\tData 0.251 (0.276)\tLoss 3.2143 (2.4670)\tPrec@1 25.000 (35.797)\tPrec@5 58.333 (68.006)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.386 (0.355)\tData 0.303 (0.277)\tLoss 2.7440 (2.4651)\tPrec@1 33.333 (35.799)\tPrec@5 50.000 (67.967)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.320 (0.320)\n",
      "\n",
      "Loss 2.7737 (2.7737)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 50.000 (50.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.411 (0.397)\n",
      "\n",
      "Loss 2.7995 (2.4626)\n",
      "\n",
      "Prec@1 33.333 (37.046)\n",
      "\n",
      "Prec@5 66.667 (68.647)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.149 (0.369)\n",
      "\n",
      "Loss 2.0214 (2.4799)\n",
      "\n",
      "Prec@1 66.667 (35.738)\n",
      "\n",
      "Prec@5 66.667 (68.118)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.130 (0.349)\n",
      "\n",
      "Loss 2.0247 (2.4598)\n",
      "\n",
      "Prec@1 58.333 (36.240)\n",
      "\n",
      "Prec@5 83.333 (68.411)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [4][0/1334]\t\\Time 0.345 (0.345)\tData 0.273 (0.273)\tLoss 2.5160 (2.5160)\tPrec@1 41.667 (41.667)\tPrec@5 75.000 (75.000)\n",
      "Epoch: [4][100/1334]\t\\Time 0.386 (0.349)\tData 0.316 (0.273)\tLoss 3.4182 (2.1371)\tPrec@1 25.000 (42.409)\tPrec@5 58.333 (75.083)\n",
      "Epoch: [4][200/1334]\t\\Time 0.313 (0.350)\tData 0.225 (0.273)\tLoss 1.8519 (2.1729)\tPrec@1 50.000 (42.206)\tPrec@5 83.333 (74.046)\n",
      "Epoch: [4][300/1334]\t\\Time 0.384 (0.352)\tData 0.313 (0.276)\tLoss 1.8246 (2.1691)\tPrec@1 50.000 (41.916)\tPrec@5 75.000 (74.169)\n",
      "Epoch: [4][400/1334]\t\\Time 0.352 (0.353)\tData 0.292 (0.275)\tLoss 1.8444 (2.1484)\tPrec@1 33.333 (42.207)\tPrec@5 75.000 (74.564)\n",
      "Epoch: [4][500/1334]\t\\Time 0.333 (0.353)\tData 0.249 (0.276)\tLoss 2.9486 (2.1690)\tPrec@1 16.667 (42.166)\tPrec@5 58.333 (73.985)\n",
      "Epoch: [4][600/1334]\t\\Time 0.332 (0.354)\tData 0.232 (0.276)\tLoss 2.2449 (2.1659)\tPrec@1 50.000 (42.166)\tPrec@5 83.333 (74.002)\n",
      "Epoch: [4][700/1334]\t\\Time 0.364 (0.354)\tData 0.266 (0.276)\tLoss 1.6509 (2.1648)\tPrec@1 58.333 (42.083)\tPrec@5 83.333 (74.097)\n",
      "Epoch: [4][800/1334]\t\\Time 0.321 (0.354)\tData 0.224 (0.276)\tLoss 1.6419 (2.1765)\tPrec@1 50.000 (42.176)\tPrec@5 83.333 (74.043)\n",
      "Epoch: [4][900/1334]\t\\Time 0.340 (0.354)\tData 0.242 (0.276)\tLoss 2.5096 (2.1746)\tPrec@1 41.667 (42.231)\tPrec@5 75.000 (74.020)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.327 (0.354)\tData 0.257 (0.275)\tLoss 2.5946 (2.1783)\tPrec@1 25.000 (42.349)\tPrec@5 58.333 (73.868)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.442 (0.355)\tData 0.365 (0.276)\tLoss 1.7920 (2.1769)\tPrec@1 33.333 (42.204)\tPrec@5 91.667 (74.001)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.319 (0.355)\tData 0.223 (0.277)\tLoss 1.8397 (2.1721)\tPrec@1 50.000 (42.555)\tPrec@5 66.667 (74.070)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.312 (0.355)\tData 0.213 (0.277)\tLoss 1.6755 (2.1759)\tPrec@1 50.000 (42.589)\tPrec@5 83.333 (73.950)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.327 (0.327)\n",
      "\n",
      "Loss 2.9209 (2.9209)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.437 (0.393)\n",
      "\n",
      "Loss 1.8114 (2.5692)\n",
      "\n",
      "Prec@1 58.333 (34.818)\n",
      "\n",
      "Prec@5 75.000 (67.162)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.146 (0.368)\n",
      "\n",
      "Loss 2.4237 (2.5821)\n",
      "\n",
      "Prec@1 50.000 (34.619)\n",
      "\n",
      "Prec@5 58.333 (66.833)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.155 (0.349)\n",
      "\n",
      "Loss 1.4136 (2.5398)\n",
      "\n",
      "Prec@1 75.000 (36.296)\n",
      "\n",
      "Prec@5 83.333 (67.719)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [5][0/1334]\t\\Time 0.402 (0.402)\tData 0.322 (0.322)\tLoss 2.1085 (2.1085)\tPrec@1 50.000 (50.000)\tPrec@5 66.667 (66.667)\n",
      "Epoch: [5][100/1334]\t\\Time 0.337 (0.349)\tData 0.252 (0.272)\tLoss 1.9876 (1.8224)\tPrec@1 58.333 (49.917)\tPrec@5 58.333 (81.023)\n",
      "Epoch: [5][200/1334]\t\\Time 0.321 (0.351)\tData 0.240 (0.274)\tLoss 1.3924 (1.8255)\tPrec@1 58.333 (50.166)\tPrec@5 91.667 (81.468)\n",
      "Epoch: [5][300/1334]\t\\Time 0.360 (0.351)\tData 0.280 (0.274)\tLoss 1.0811 (1.8508)\tPrec@1 66.667 (49.197)\tPrec@5 91.667 (80.399)\n",
      "Epoch: [5][400/1334]\t\\Time 0.391 (0.352)\tData 0.301 (0.275)\tLoss 1.4272 (1.8775)\tPrec@1 66.667 (49.127)\tPrec@5 91.667 (79.717)\n",
      "Epoch: [5][500/1334]\t\\Time 0.321 (0.352)\tData 0.261 (0.275)\tLoss 1.8806 (1.8858)\tPrec@1 33.333 (48.703)\tPrec@5 91.667 (79.508)\n",
      "Epoch: [5][600/1334]\t\\Time 0.316 (0.354)\tData 0.219 (0.277)\tLoss 2.1182 (1.9064)\tPrec@1 58.333 (48.419)\tPrec@5 83.333 (79.160)\n",
      "Epoch: [5][700/1334]\t\\Time 0.372 (0.354)\tData 0.305 (0.276)\tLoss 0.9504 (1.9078)\tPrec@1 75.000 (48.371)\tPrec@5 91.667 (79.078)\n",
      "Epoch: [5][800/1334]\t\\Time 0.340 (0.354)\tData 0.260 (0.276)\tLoss 1.2682 (1.9085)\tPrec@1 58.333 (48.315)\tPrec@5 83.333 (79.078)\n",
      "Epoch: [5][900/1334]\t\\Time 0.393 (0.359)\tData 0.319 (0.281)\tLoss 1.5031 (1.9091)\tPrec@1 50.000 (48.215)\tPrec@5 83.333 (79.042)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.490 (0.372)\tData 0.416 (0.294)\tLoss 2.2421 (1.9218)\tPrec@1 25.000 (47.952)\tPrec@5 66.667 (78.846)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.370 (0.379)\tData 0.313 (0.302)\tLoss 1.8721 (1.9247)\tPrec@1 58.333 (48.032)\tPrec@5 66.667 (78.739)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.532 (0.386)\tData 0.464 (0.309)\tLoss 1.9251 (1.9236)\tPrec@1 58.333 (47.939)\tPrec@5 83.333 (78.740)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.428 (0.392)\tData 0.366 (0.314)\tLoss 2.3293 (1.9296)\tPrec@1 33.333 (47.829)\tPrec@5 75.000 (78.606)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.477 (0.477)\n",
      "\n",
      "Loss 2.1506 (2.1506)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.531 (0.518)\n",
      "\n",
      "Loss 2.8947 (2.4031)\n",
      "\n",
      "Prec@1 33.333 (37.541)\n",
      "\n",
      "Prec@5 50.000 (69.142)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.169 (0.474)\n",
      "\n",
      "Loss 2.1870 (2.3363)\n",
      "\n",
      "Prec@1 41.667 (39.345)\n",
      "\n",
      "Prec@5 75.000 (71.061)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.191 (0.446)\n",
      "\n",
      "Loss 2.0547 (2.3516)\n",
      "\n",
      "Prec@1 41.667 (39.092)\n",
      "\n",
      "Prec@5 83.333 (71.096)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [6][0/1334]\t\\Time 0.543 (0.543)\tData 0.424 (0.424)\tLoss 1.7811 (1.7811)\tPrec@1 33.333 (33.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [6][100/1334]\t\\Time 0.509 (0.622)\tData 0.427 (0.540)\tLoss 1.2416 (1.6724)\tPrec@1 66.667 (54.208)\tPrec@5 91.667 (84.323)\n",
      "Epoch: [6][200/1334]\t\\Time 0.369 (0.530)\tData 0.283 (0.453)\tLoss 2.0984 (1.6384)\tPrec@1 66.667 (55.556)\tPrec@5 75.000 (84.494)\n",
      "Epoch: [6][300/1334]\t\\Time 0.367 (0.511)\tData 0.286 (0.433)\tLoss 2.5895 (1.6487)\tPrec@1 50.000 (55.676)\tPrec@5 50.000 (83.610)\n",
      "Epoch: [6][400/1334]\t\\Time 0.373 (0.518)\tData 0.311 (0.440)\tLoss 2.4269 (1.6525)\tPrec@1 33.333 (55.424)\tPrec@5 75.000 (83.603)\n",
      "Epoch: [6][500/1334]\t\\Time 0.468 (0.522)\tData 0.399 (0.444)\tLoss 1.6663 (1.6674)\tPrec@1 50.000 (55.156)\tPrec@5 83.333 (83.217)\n",
      "Epoch: [6][600/1334]\t\\Time 0.516 (0.517)\tData 0.457 (0.439)\tLoss 2.2322 (1.6688)\tPrec@1 50.000 (55.019)\tPrec@5 75.000 (83.125)\n",
      "Epoch: [6][700/1334]\t\\Time 0.419 (0.525)\tData 0.363 (0.447)\tLoss 1.4961 (1.6738)\tPrec@1 58.333 (54.731)\tPrec@5 100.000 (83.048)\n",
      "Epoch: [6][800/1334]\t\\Time 0.329 (0.519)\tData 0.237 (0.441)\tLoss 1.7908 (1.6874)\tPrec@1 41.667 (54.432)\tPrec@5 83.333 (82.720)\n",
      "Epoch: [6][900/1334]\t\\Time 0.467 (0.516)\tData 0.372 (0.438)\tLoss 1.2547 (1.6926)\tPrec@1 58.333 (54.171)\tPrec@5 83.333 (82.584)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.434 (0.513)\tData 0.359 (0.435)\tLoss 2.3094 (1.6918)\tPrec@1 41.667 (54.196)\tPrec@5 75.000 (82.634)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.534 (0.510)\tData 0.459 (0.433)\tLoss 2.4545 (1.6962)\tPrec@1 33.333 (54.042)\tPrec@5 75.000 (82.539)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.579 (0.508)\tData 0.501 (0.430)\tLoss 2.2167 (1.6978)\tPrec@1 50.000 (53.920)\tPrec@5 75.000 (82.515)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.466 (0.505)\tData 0.389 (0.428)\tLoss 1.7732 (1.7057)\tPrec@1 50.000 (53.721)\tPrec@5 91.667 (82.353)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 1.337 (1.337)\n",
      "\n",
      "Loss 2.5465 (2.5465)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.451 (0.582)\n",
      "\n",
      "Loss 2.1233 (2.3130)\n",
      "\n",
      "Prec@1 50.000 (42.492)\n",
      "\n",
      "Prec@5 75.000 (72.195)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.127 (0.513)\n",
      "\n",
      "Loss 1.5034 (2.2898)\n",
      "\n",
      "Prec@1 66.667 (42.289)\n",
      "\n",
      "Prec@5 91.667 (71.849)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.143 (0.465)\n",
      "\n",
      "Loss 1.4466 (2.2411)\n",
      "\n",
      "Prec@1 50.000 (43.466)\n",
      "\n",
      "Prec@5 91.667 (73.477)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [7][0/1334]\t\\Time 0.318 (0.318)\tData 0.241 (0.241)\tLoss 2.0374 (2.0374)\tPrec@1 50.000 (50.000)\tPrec@5 66.667 (66.667)\n",
      "Epoch: [7][100/1334]\t\\Time 0.328 (0.369)\tData 0.264 (0.291)\tLoss 1.3892 (1.3240)\tPrec@1 50.000 (61.634)\tPrec@5 91.667 (88.036)\n",
      "Epoch: [7][200/1334]\t\\Time 0.371 (0.371)\tData 0.310 (0.293)\tLoss 1.6575 (1.3739)\tPrec@1 66.667 (60.572)\tPrec@5 83.333 (87.272)\n",
      "Epoch: [7][300/1334]\t\\Time 0.341 (0.376)\tData 0.257 (0.298)\tLoss 1.6220 (1.4045)\tPrec@1 58.333 (60.133)\tPrec@5 91.667 (86.573)\n",
      "Epoch: [7][400/1334]\t\\Time 0.367 (0.371)\tData 0.242 (0.292)\tLoss 2.1834 (1.4029)\tPrec@1 50.000 (60.266)\tPrec@5 66.667 (86.617)\n",
      "Epoch: [7][500/1334]\t\\Time 0.552 (0.374)\tData 0.479 (0.296)\tLoss 1.3460 (1.4210)\tPrec@1 66.667 (59.880)\tPrec@5 91.667 (86.593)\n",
      "Epoch: [7][600/1334]\t\\Time 0.476 (0.392)\tData 0.400 (0.314)\tLoss 0.7517 (1.4393)\tPrec@1 83.333 (59.262)\tPrec@5 100.000 (86.384)\n",
      "Epoch: [7][700/1334]\t\\Time 0.432 (0.402)\tData 0.372 (0.324)\tLoss 1.4142 (1.4485)\tPrec@1 66.667 (59.094)\tPrec@5 91.667 (86.365)\n",
      "Epoch: [7][800/1334]\t\\Time 0.416 (0.411)\tData 0.339 (0.333)\tLoss 1.2301 (1.4506)\tPrec@1 58.333 (58.895)\tPrec@5 100.000 (86.298)\n",
      "Epoch: [7][900/1334]\t\\Time 0.423 (0.432)\tData 0.367 (0.354)\tLoss 1.6769 (1.4619)\tPrec@1 33.333 (58.537)\tPrec@5 83.333 (86.016)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.338 (0.446)\tData 0.238 (0.368)\tLoss 1.4687 (1.4675)\tPrec@1 58.333 (58.433)\tPrec@5 91.667 (85.981)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.445 (0.448)\tData 0.360 (0.370)\tLoss 1.4630 (1.4826)\tPrec@1 66.667 (57.985)\tPrec@5 83.333 (85.929)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.361 (0.455)\tData 0.279 (0.376)\tLoss 1.5940 (1.4862)\tPrec@1 50.000 (57.945)\tPrec@5 75.000 (85.880)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.529 (0.466)\tData 0.472 (0.387)\tLoss 2.6956 (1.4913)\tPrec@1 16.667 (57.770)\tPrec@5 75.000 (85.863)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.446 (0.446)\n",
      "\n",
      "Loss 2.0133 (2.0133)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 1.760 (0.657)\n",
      "\n",
      "Loss 2.1191 (2.2810)\n",
      "\n",
      "Prec@1 33.333 (45.627)\n",
      "\n",
      "Prec@5 75.000 (72.525)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.196 (0.548)\n",
      "\n",
      "Loss 1.6269 (2.2693)\n",
      "\n",
      "Prec@1 50.000 (45.398)\n",
      "\n",
      "Prec@5 83.333 (72.720)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.162 (0.496)\n",
      "\n",
      "Loss 2.0957 (2.2325)\n",
      "\n",
      "Prec@1 25.000 (45.792)\n",
      "\n",
      "Prec@5 91.667 (73.699)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [8][0/1334]\t\\Time 0.446 (0.446)\tData 0.359 (0.359)\tLoss 1.1906 (1.1906)\tPrec@1 58.333 (58.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [8][100/1334]\t\\Time 0.423 (0.443)\tData 0.343 (0.365)\tLoss 0.7347 (1.0722)\tPrec@1 83.333 (67.739)\tPrec@5 100.000 (92.904)\n",
      "Epoch: [8][200/1334]\t\\Time 0.438 (0.452)\tData 0.361 (0.375)\tLoss 1.0506 (1.1012)\tPrec@1 66.667 (67.579)\tPrec@5 100.000 (91.957)\n",
      "Epoch: [8][300/1334]\t\\Time 0.439 (0.459)\tData 0.359 (0.383)\tLoss 1.0942 (1.1506)\tPrec@1 66.667 (66.445)\tPrec@5 83.333 (91.085)\n",
      "Epoch: [8][400/1334]\t\\Time 1.051 (0.482)\tData 0.842 (0.404)\tLoss 0.7353 (1.1650)\tPrec@1 66.667 (65.815)\tPrec@5 100.000 (91.209)\n",
      "Epoch: [8][500/1334]\t\\Time 0.406 (0.491)\tData 0.347 (0.413)\tLoss 0.9313 (1.1898)\tPrec@1 75.000 (65.336)\tPrec@5 83.333 (90.902)\n",
      "Epoch: [8][600/1334]\t\\Time 0.398 (0.487)\tData 0.324 (0.410)\tLoss 1.7602 (1.2333)\tPrec@1 50.000 (64.254)\tPrec@5 66.667 (90.211)\n",
      "Epoch: [8][700/1334]\t\\Time 0.376 (0.484)\tData 0.301 (0.407)\tLoss 0.9477 (1.2328)\tPrec@1 66.667 (64.301)\tPrec@5 100.000 (90.026)\n",
      "Epoch: [8][800/1334]\t\\Time 0.439 (0.483)\tData 0.354 (0.406)\tLoss 1.4155 (1.2476)\tPrec@1 75.000 (64.024)\tPrec@5 83.333 (89.846)\n",
      "Epoch: [8][900/1334]\t\\Time 0.444 (0.482)\tData 0.363 (0.406)\tLoss 0.8514 (1.2697)\tPrec@1 66.667 (63.485)\tPrec@5 91.667 (89.419)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.319 (0.481)\tData 0.223 (0.405)\tLoss 1.6085 (1.2784)\tPrec@1 41.667 (63.328)\tPrec@5 91.667 (89.252)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.368 (0.485)\tData 0.290 (0.407)\tLoss 1.1593 (1.2853)\tPrec@1 58.333 (63.132)\tPrec@5 91.667 (89.177)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.339 (0.478)\tData 0.274 (0.401)\tLoss 1.2075 (1.2858)\tPrec@1 66.667 (62.989)\tPrec@5 83.333 (89.210)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.377 (0.471)\tData 0.299 (0.394)\tLoss 1.4579 (1.2961)\tPrec@1 50.000 (62.721)\tPrec@5 75.000 (89.028)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.355 (0.355)\n",
      "\n",
      "Loss 2.6986 (2.6986)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.435 (0.443)\n",
      "\n",
      "Loss 2.3184 (2.3834)\n",
      "\n",
      "Prec@1 50.000 (43.729)\n",
      "\n",
      "Prec@5 75.000 (71.205)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.154 (0.419)\n",
      "\n",
      "Loss 2.1603 (2.3336)\n",
      "\n",
      "Prec@1 41.667 (44.113)\n",
      "\n",
      "Prec@5 66.667 (71.891)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.169 (0.399)\n",
      "\n",
      "Loss 1.8367 (2.2975)\n",
      "\n",
      "Prec@1 41.667 (45.072)\n",
      "\n",
      "Prec@5 91.667 (73.173)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "\n",
      "Epoch: [9][0/1334]\t\\Time 0.420 (0.420)\tData 0.306 (0.306)\tLoss 0.6862 (0.6862)\tPrec@1 83.333 (83.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [9][100/1334]\t\\Time 0.441 (0.444)\tData 0.366 (0.364)\tLoss 0.9808 (0.9175)\tPrec@1 75.000 (73.020)\tPrec@5 91.667 (93.564)\n",
      "Epoch: [9][200/1334]\t\\Time 0.377 (0.468)\tData 0.315 (0.388)\tLoss 1.1627 (0.9005)\tPrec@1 66.667 (73.881)\tPrec@5 91.667 (94.610)\n",
      "Epoch: [9][300/1334]\t\\Time 0.320 (0.435)\tData 0.220 (0.356)\tLoss 2.0142 (0.9304)\tPrec@1 50.000 (72.730)\tPrec@5 83.333 (94.269)\n",
      "Epoch: [9][400/1334]\t\\Time 0.351 (0.421)\tData 0.230 (0.342)\tLoss 0.7334 (0.9676)\tPrec@1 75.000 (71.800)\tPrec@5 91.667 (93.641)\n",
      "Epoch: [9][500/1334]\t\\Time 0.399 (0.414)\tData 0.336 (0.336)\tLoss 2.3224 (1.0027)\tPrec@1 50.000 (70.642)\tPrec@5 75.000 (93.097)\n",
      "Epoch: [9][600/1334]\t\\Time 0.339 (0.411)\tData 0.260 (0.333)\tLoss 1.0818 (1.0324)\tPrec@1 66.667 (69.634)\tPrec@5 91.667 (92.734)\n",
      "Epoch: [9][700/1334]\t\\Time 0.331 (0.418)\tData 0.265 (0.340)\tLoss 1.9930 (1.0565)\tPrec@1 58.333 (69.163)\tPrec@5 91.667 (92.475)\n",
      "Epoch: [9][800/1334]\t\\Time 0.334 (0.411)\tData 0.249 (0.332)\tLoss 0.8625 (1.0657)\tPrec@1 66.667 (68.955)\tPrec@5 100.000 (92.374)\n",
      "Epoch: [9][900/1334]\t\\Time 0.389 (0.414)\tData 0.322 (0.335)\tLoss 1.0726 (1.0767)\tPrec@1 75.000 (68.581)\tPrec@5 83.333 (92.194)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.363 (0.416)\tData 0.285 (0.336)\tLoss 1.0267 (1.0857)\tPrec@1 66.667 (68.340)\tPrec@5 100.000 (92.000)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.340 (0.415)\tData 0.266 (0.335)\tLoss 1.6936 (1.1018)\tPrec@1 58.333 (68.014)\tPrec@5 91.667 (91.742)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.356 (0.411)\tData 0.276 (0.332)\tLoss 1.4282 (1.1089)\tPrec@1 66.667 (67.874)\tPrec@5 91.667 (91.653)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.453 (0.410)\tData 0.348 (0.331)\tLoss 1.3498 (1.1162)\tPrec@1 58.333 (67.775)\tPrec@5 83.333 (91.436)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.340 (0.340)\n",
      "\n",
      "Loss 3.0296 (3.0296)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 41.667 (41.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.479 (0.495)\n",
      "\n",
      "Loss 2.5263 (2.4487)\n",
      "\n",
      "Prec@1 41.667 (43.317)\n",
      "\n",
      "Prec@5 75.000 (72.690)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.140 (0.416)\n",
      "\n",
      "Loss 1.9058 (2.4011)\n",
      "\n",
      "Prec@1 50.000 (44.030)\n",
      "\n",
      "Prec@5 83.333 (73.093)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.146 (0.393)\n",
      "\n",
      "Loss 1.6716 (2.3930)\n",
      "\n",
      "Prec@1 50.000 (43.854)\n",
      "\n",
      "Prec@5 83.333 (73.533)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "0.01\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 8)\n",
      "Epoch: [10][0/1334]\t\\Time 0.433 (0.433)\tData 0.349 (0.349)\tLoss 1.0484 (1.0484)\tPrec@1 75.000 (75.000)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [10][100/1334]\t\\Time 0.352 (0.350)\tData 0.282 (0.269)\tLoss 0.7653 (0.8953)\tPrec@1 91.667 (76.403)\tPrec@5 100.000 (94.142)\n",
      "Epoch: [10][200/1334]\t\\Time 0.390 (0.352)\tData 0.301 (0.273)\tLoss 0.5482 (0.8498)\tPrec@1 83.333 (76.327)\tPrec@5 100.000 (94.279)\n",
      "Epoch: [10][300/1334]\t\\Time 0.357 (0.352)\tData 0.294 (0.273)\tLoss 0.8737 (0.7889)\tPrec@1 75.000 (78.239)\tPrec@5 91.667 (94.961)\n",
      "Epoch: [10][400/1334]\t\\Time 0.360 (0.356)\tData 0.281 (0.277)\tLoss 0.5013 (0.7602)\tPrec@1 83.333 (79.073)\tPrec@5 100.000 (95.137)\n",
      "Epoch: [10][500/1334]\t\\Time 0.359 (0.358)\tData 0.278 (0.279)\tLoss 0.3028 (0.7495)\tPrec@1 83.333 (79.291)\tPrec@5 100.000 (95.126)\n",
      "Epoch: [10][600/1334]\t\\Time 0.385 (0.359)\tData 0.303 (0.280)\tLoss 0.7069 (0.7280)\tPrec@1 75.000 (79.603)\tPrec@5 100.000 (95.410)\n",
      "Epoch: [10][700/1334]\t\\Time 0.360 (0.360)\tData 0.280 (0.281)\tLoss 0.3477 (0.7186)\tPrec@1 91.667 (79.731)\tPrec@5 91.667 (95.471)\n",
      "Epoch: [10][800/1334]\t\\Time 0.351 (0.362)\tData 0.291 (0.283)\tLoss 0.7018 (0.7032)\tPrec@1 75.000 (80.160)\tPrec@5 91.667 (95.516)\n",
      "Epoch: [10][900/1334]\t\\Time 0.330 (0.361)\tData 0.260 (0.282)\tLoss 0.2734 (0.6840)\tPrec@1 91.667 (80.697)\tPrec@5 100.000 (95.727)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.341 (0.360)\tData 0.260 (0.281)\tLoss 1.0849 (0.6734)\tPrec@1 66.667 (80.911)\tPrec@5 91.667 (95.846)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.350 (0.360)\tData 0.270 (0.280)\tLoss 0.5143 (0.6570)\tPrec@1 91.667 (81.396)\tPrec@5 100.000 (96.011)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.351 (0.360)\tData 0.300 (0.281)\tLoss 0.3255 (0.6470)\tPrec@1 91.667 (81.599)\tPrec@5 100.000 (96.107)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.350 (0.360)\tData 0.290 (0.281)\tLoss 0.6780 (0.6343)\tPrec@1 83.333 (81.969)\tPrec@5 91.667 (96.189)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 2.2131 (2.2131)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.441 (0.397)\n",
      "\n",
      "Loss 2.1517 (2.3222)\n",
      "\n",
      "Prec@1 50.000 (52.145)\n",
      "\n",
      "Prec@5 75.000 (76.980)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.155 (0.369)\n",
      "\n",
      "Loss 2.0304 (2.2559)\n",
      "\n",
      "Prec@1 58.333 (51.534)\n",
      "\n",
      "Prec@5 75.000 (77.446)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.140 (0.349)\n",
      "\n",
      "Loss 1.0533 (2.2099)\n",
      "\n",
      "Prec@1 66.667 (52.436)\n",
      "\n",
      "Prec@5 91.667 (78.378)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "\n",
      "Epoch: [11][0/1334]\t\\Time 0.300 (0.300)\tData 0.220 (0.220)\tLoss 0.4239 (0.4239)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.410 (0.352)\tData 0.330 (0.277)\tLoss 0.2388 (0.3463)\tPrec@1 91.667 (91.254)\tPrec@5 100.000 (98.515)\n",
      "Epoch: [11][200/1334]\t\\Time 0.320 (0.355)\tData 0.220 (0.279)\tLoss 0.2948 (0.3322)\tPrec@1 91.667 (91.003)\tPrec@5 100.000 (98.673)\n",
      "Epoch: [11][300/1334]\t\\Time 0.361 (0.353)\tData 0.304 (0.276)\tLoss 0.1504 (0.3453)\tPrec@1 100.000 (90.919)\tPrec@5 100.000 (98.422)\n",
      "Epoch: [11][400/1334]\t\\Time 0.341 (0.351)\tData 0.251 (0.273)\tLoss 0.1571 (0.3445)\tPrec@1 91.667 (91.022)\tPrec@5 100.000 (98.421)\n",
      "Epoch: [11][500/1334]\t\\Time 0.400 (0.353)\tData 0.320 (0.275)\tLoss 0.2988 (0.3486)\tPrec@1 100.000 (90.818)\tPrec@5 100.000 (98.370)\n",
      "Epoch: [11][600/1334]\t\\Time 0.356 (0.353)\tData 0.271 (0.274)\tLoss 0.2415 (0.3492)\tPrec@1 91.667 (90.710)\tPrec@5 100.000 (98.433)\n",
      "Epoch: [11][700/1334]\t\\Time 0.301 (0.353)\tData 0.210 (0.274)\tLoss 0.4579 (0.3541)\tPrec@1 83.333 (90.490)\tPrec@5 100.000 (98.359)\n",
      "Epoch: [11][800/1334]\t\\Time 0.381 (0.352)\tData 0.322 (0.274)\tLoss 0.3995 (0.3565)\tPrec@1 91.667 (90.252)\tPrec@5 100.000 (98.377)\n",
      "Epoch: [11][900/1334]\t\\Time 0.340 (0.353)\tData 0.250 (0.274)\tLoss 0.2057 (0.3511)\tPrec@1 91.667 (90.418)\tPrec@5 100.000 (98.391)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.412 (0.353)\tData 0.352 (0.274)\tLoss 0.4301 (0.3509)\tPrec@1 91.667 (90.443)\tPrec@5 100.000 (98.402)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.381 (0.353)\tData 0.308 (0.274)\tLoss 0.0677 (0.3550)\tPrec@1 100.000 (90.251)\tPrec@5 100.000 (98.350)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.361 (0.353)\tData 0.293 (0.274)\tLoss 0.4271 (0.3548)\tPrec@1 91.667 (90.272)\tPrec@5 91.667 (98.328)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.352 (0.353)\tData 0.272 (0.274)\tLoss 0.6634 (0.3514)\tPrec@1 75.000 (90.379)\tPrec@5 100.000 (98.379)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.419 (0.419)\n",
      "\n",
      "Loss 2.0622 (2.0622)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.427 (0.399)\n",
      "\n",
      "Loss 2.3735 (2.4636)\n",
      "\n",
      "Prec@1 58.333 (52.063)\n",
      "\n",
      "Prec@5 66.667 (76.898)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.149 (0.371)\n",
      "\n",
      "Loss 2.2784 (2.3849)\n",
      "\n",
      "Prec@1 66.667 (51.907)\n",
      "\n",
      "Prec@5 75.000 (77.819)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.131 (0.351)\n",
      "\n",
      "Loss 1.2400 (2.3291)\n",
      "\n",
      "Prec@1 75.000 (52.658)\n",
      "\n",
      "Prec@5 91.667 (78.488)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "\n",
      "Epoch: [12][0/1334]\t\\Time 0.392 (0.392)\tData 0.310 (0.310)\tLoss 0.1226 (0.1226)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.346 (0.349)\tData 0.243 (0.271)\tLoss 0.2806 (0.2064)\tPrec@1 83.333 (95.215)\tPrec@5 100.000 (99.422)\n",
      "Epoch: [12][200/1334]\t\\Time 0.369 (0.354)\tData 0.277 (0.275)\tLoss 0.0478 (0.2035)\tPrec@1 100.000 (95.564)\tPrec@5 100.000 (99.420)\n",
      "Epoch: [12][300/1334]\t\\Time 0.318 (0.353)\tData 0.219 (0.274)\tLoss 0.1110 (0.1997)\tPrec@1 91.667 (95.570)\tPrec@5 100.000 (99.391)\n",
      "Epoch: [12][400/1334]\t\\Time 0.383 (0.354)\tData 0.306 (0.275)\tLoss 0.0653 (0.2003)\tPrec@1 100.000 (95.553)\tPrec@5 100.000 (99.335)\n",
      "Epoch: [12][500/1334]\t\\Time 0.335 (0.353)\tData 0.254 (0.275)\tLoss 0.0850 (0.1978)\tPrec@1 100.000 (95.642)\tPrec@5 100.000 (99.351)\n",
      "Epoch: [12][600/1334]\t\\Time 0.351 (0.353)\tData 0.271 (0.275)\tLoss 0.2247 (0.1975)\tPrec@1 91.667 (95.674)\tPrec@5 100.000 (99.334)\n",
      "Epoch: [12][700/1334]\t\\Time 0.335 (0.353)\tData 0.257 (0.275)\tLoss 0.0438 (0.1968)\tPrec@1 100.000 (95.709)\tPrec@5 100.000 (99.358)\n",
      "Epoch: [12][800/1334]\t\\Time 0.331 (0.354)\tData 0.231 (0.276)\tLoss 0.0749 (0.1985)\tPrec@1 100.000 (95.620)\tPrec@5 100.000 (99.345)\n",
      "Epoch: [12][900/1334]\t\\Time 0.375 (0.354)\tData 0.302 (0.276)\tLoss 0.4018 (0.2003)\tPrec@1 91.667 (95.542)\tPrec@5 100.000 (99.343)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.380 (0.355)\tData 0.292 (0.276)\tLoss 0.0377 (0.2022)\tPrec@1 100.000 (95.480)\tPrec@5 100.000 (99.326)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.397 (0.355)\tData 0.317 (0.276)\tLoss 0.2162 (0.2018)\tPrec@1 100.000 (95.459)\tPrec@5 100.000 (99.334)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.325 (0.355)\tData 0.267 (0.276)\tLoss 0.1674 (0.2023)\tPrec@1 100.000 (95.400)\tPrec@5 100.000 (99.320)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.381 (0.355)\tData 0.291 (0.276)\tLoss 0.0967 (0.2025)\tPrec@1 100.000 (95.369)\tPrec@5 100.000 (99.321)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.326 (0.326)\n",
      "\n",
      "Loss 2.4452 (2.4452)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.418 (0.385)\n",
      "\n",
      "Loss 2.5246 (2.5926)\n",
      "\n",
      "Prec@1 58.333 (51.650)\n",
      "\n",
      "Prec@5 75.000 (76.320)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.149 (0.364)\n",
      "\n",
      "Loss 2.0613 (2.4864)\n",
      "\n",
      "Prec@1 58.333 (51.575)\n",
      "\n",
      "Prec@5 75.000 (77.322)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.149 (0.347)\n",
      "\n",
      "Loss 1.4015 (2.4392)\n",
      "\n",
      "Prec@1 66.667 (52.602)\n",
      "\n",
      "Prec@5 91.667 (78.156)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "\n",
      "Epoch: [13][0/1334]\t\\Time 0.497 (0.497)\tData 0.382 (0.382)\tLoss 0.0575 (0.0575)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.350 (0.367)\tData 0.263 (0.289)\tLoss 0.1000 (0.1048)\tPrec@1 100.000 (99.092)\tPrec@5 100.000 (99.835)\n",
      "Epoch: [13][200/1334]\t\\Time 0.412 (0.364)\tData 0.323 (0.286)\tLoss 0.1213 (0.1140)\tPrec@1 100.000 (98.466)\tPrec@5 100.000 (99.710)\n",
      "Epoch: [13][300/1334]\t\\Time 0.327 (0.361)\tData 0.252 (0.282)\tLoss 0.0746 (0.1163)\tPrec@1 100.000 (98.339)\tPrec@5 100.000 (99.723)\n",
      "Epoch: [13][400/1334]\t\\Time 0.318 (0.360)\tData 0.218 (0.281)\tLoss 0.1151 (0.1118)\tPrec@1 91.667 (98.441)\tPrec@5 100.000 (99.771)\n",
      "Epoch: [13][500/1334]\t\\Time 0.348 (0.364)\tData 0.277 (0.286)\tLoss 0.0829 (0.1120)\tPrec@1 100.000 (98.420)\tPrec@5 100.000 (99.767)\n",
      "Epoch: [13][600/1334]\t\\Time 0.381 (0.383)\tData 0.311 (0.304)\tLoss 0.0597 (0.1111)\tPrec@1 100.000 (98.364)\tPrec@5 100.000 (99.778)\n",
      "Epoch: [13][700/1334]\t\\Time 1.322 (0.415)\tData 1.238 (0.336)\tLoss 0.1459 (0.1124)\tPrec@1 100.000 (98.336)\tPrec@5 100.000 (99.798)\n",
      "Epoch: [13][800/1334]\t\\Time 0.319 (0.420)\tData 0.225 (0.342)\tLoss 0.1073 (0.1126)\tPrec@1 100.000 (98.294)\tPrec@5 100.000 (99.792)\n",
      "Epoch: [13][900/1334]\t\\Time 0.369 (0.423)\tData 0.292 (0.344)\tLoss 0.1376 (0.1126)\tPrec@1 100.000 (98.307)\tPrec@5 100.000 (99.797)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.328 (0.416)\tData 0.243 (0.337)\tLoss 0.0640 (0.1119)\tPrec@1 100.000 (98.343)\tPrec@5 100.000 (99.800)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.441 (0.412)\tData 0.363 (0.333)\tLoss 0.0480 (0.1122)\tPrec@1 100.000 (98.312)\tPrec@5 100.000 (99.803)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.421 (0.409)\tData 0.330 (0.330)\tLoss 0.0605 (0.1145)\tPrec@1 100.000 (98.217)\tPrec@5 100.000 (99.806)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.389 (0.407)\tData 0.310 (0.329)\tLoss 0.0313 (0.1142)\tPrec@1 100.000 (98.226)\tPrec@5 100.000 (99.801)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.340 (0.340)\n",
      "\n",
      "Loss 2.3996 (2.3996)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.439 (0.406)\n",
      "\n",
      "Loss 2.5645 (2.6128)\n",
      "\n",
      "Prec@1 58.333 (52.723)\n",
      "\n",
      "Prec@5 75.000 (76.238)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.144 (0.381)\n",
      "\n",
      "Loss 2.1680 (2.5114)\n",
      "\n",
      "Prec@1 58.333 (52.405)\n",
      "\n",
      "Prec@5 75.000 (77.114)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.114 (0.356)\n",
      "\n",
      "Loss 1.2181 (2.4598)\n",
      "\n",
      "Prec@1 75.000 (52.990)\n",
      "\n",
      "Prec@5 91.667 (77.962)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "\n",
      "Epoch: [14][0/1334]\t\\Time 0.374 (0.374)\tData 0.304 (0.304)\tLoss 0.0742 (0.0742)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1334]\t\\Time 0.461 (0.359)\tData 0.391 (0.280)\tLoss 0.0365 (0.0631)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/1334]\t\\Time 0.336 (0.362)\tData 0.260 (0.284)\tLoss 0.0777 (0.0631)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [14][300/1334]\t\\Time 0.344 (0.360)\tData 0.264 (0.282)\tLoss 0.0792 (0.0645)\tPrec@1 100.000 (99.723)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [14][400/1334]\t\\Time 0.705 (0.374)\tData 0.622 (0.296)\tLoss 0.0386 (0.0647)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [14][500/1334]\t\\Time 0.721 (0.376)\tData 0.664 (0.298)\tLoss 0.1573 (0.0649)\tPrec@1 91.667 (99.634)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [14][600/1334]\t\\Time 1.902 (0.430)\tData 1.819 (0.349)\tLoss 0.0327 (0.0646)\tPrec@1 100.000 (99.598)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [14][700/1334]\t\\Time 0.670 (0.477)\tData 0.576 (0.394)\tLoss 0.1114 (0.0650)\tPrec@1 100.000 (99.572)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [14][800/1334]\t\\Time 0.481 (0.483)\tData 0.402 (0.400)\tLoss 0.0725 (0.0656)\tPrec@1 91.667 (99.542)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [14][900/1334]\t\\Time 0.380 (0.485)\tData 0.297 (0.402)\tLoss 0.0553 (0.0663)\tPrec@1 100.000 (99.519)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.360 (0.480)\tData 0.290 (0.397)\tLoss 0.0866 (0.0671)\tPrec@1 100.000 (99.509)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.359 (0.469)\tData 0.272 (0.386)\tLoss 0.2672 (0.0675)\tPrec@1 91.667 (99.500)\tPrec@5 100.000 (99.970)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.401 (0.463)\tData 0.321 (0.381)\tLoss 0.0212 (0.0678)\tPrec@1 100.000 (99.500)\tPrec@5 100.000 (99.965)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.662 (0.460)\tData 0.583 (0.377)\tLoss 0.0595 (0.0674)\tPrec@1 100.000 (99.520)\tPrec@5 100.000 (99.962)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.293 (0.293)\n",
      "\n",
      "Loss 2.5517 (2.5517)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.416 (0.459)\n",
      "\n",
      "Loss 2.6522 (2.6817)\n",
      "\n",
      "Prec@1 58.333 (51.898)\n",
      "\n",
      "Prec@5 75.000 (75.495)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.157 (0.418)\n",
      "\n",
      "Loss 2.0143 (2.5678)\n",
      "\n",
      "Prec@1 66.667 (51.907)\n",
      "\n",
      "Prec@5 75.000 (76.741)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.145 (0.400)\n",
      "\n",
      "Loss 1.1507 (2.5091)\n",
      "\n",
      "Prec@1 75.000 (52.658)\n",
      "\n",
      "Prec@5 91.667 (77.824)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "0.001\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 14)\n",
      "Epoch: [15][0/1334]\t\\Time 0.420 (0.420)\tData 0.337 (0.337)\tLoss 0.0778 (0.0778)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.438 (0.407)\tData 0.362 (0.327)\tLoss 0.0343 (0.0669)\tPrec@1 100.000 (99.670)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/1334]\t\\Time 0.365 (0.383)\tData 0.282 (0.302)\tLoss 0.0398 (0.0688)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [15][300/1334]\t\\Time 0.340 (0.374)\tData 0.254 (0.294)\tLoss 0.0951 (0.0694)\tPrec@1 100.000 (99.502)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [15][400/1334]\t\\Time 0.347 (0.374)\tData 0.273 (0.295)\tLoss 0.1139 (0.0672)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [15][500/1334]\t\\Time 0.361 (0.373)\tData 0.293 (0.294)\tLoss 0.0937 (0.0670)\tPrec@1 100.000 (99.534)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [15][600/1334]\t\\Time 0.337 (0.378)\tData 0.283 (0.299)\tLoss 0.0415 (0.0656)\tPrec@1 100.000 (99.598)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [15][700/1334]\t\\Time 0.331 (0.377)\tData 0.272 (0.298)\tLoss 0.1308 (0.0651)\tPrec@1 91.667 (99.608)\tPrec@5 100.000 (99.976)\n",
      "Epoch: [15][800/1334]\t\\Time 0.376 (0.375)\tData 0.295 (0.297)\tLoss 0.0891 (0.0645)\tPrec@1 100.000 (99.636)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [15][900/1334]\t\\Time 0.331 (0.378)\tData 0.249 (0.300)\tLoss 0.0300 (0.0642)\tPrec@1 100.000 (99.658)\tPrec@5 100.000 (99.982)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.320 (0.376)\tData 0.250 (0.298)\tLoss 0.0143 (0.0642)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.975)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.369 (0.379)\tData 0.300 (0.301)\tLoss 0.0552 (0.0639)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.970)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.349 (0.379)\tData 0.256 (0.301)\tLoss 0.0339 (0.0636)\tPrec@1 100.000 (99.674)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.346 (0.377)\tData 0.267 (0.299)\tLoss 0.0402 (0.0632)\tPrec@1 100.000 (99.673)\tPrec@5 100.000 (99.974)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.361 (0.361)\n",
      "\n",
      "Loss 2.4191 (2.4191)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.444 (0.413)\n",
      "\n",
      "Loss 2.5829 (2.6224)\n",
      "\n",
      "Prec@1 58.333 (52.805)\n",
      "\n",
      "Prec@5 75.000 (76.568)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.170 (0.382)\n",
      "\n",
      "Loss 2.1491 (2.5198)\n",
      "\n",
      "Prec@1 66.667 (52.363)\n",
      "\n",
      "Prec@5 75.000 (77.280)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.150 (0.362)\n",
      "\n",
      "Loss 1.1154 (2.4629)\n",
      "\n",
      "Prec@1 75.000 (53.212)\n",
      "\n",
      "Prec@5 91.667 (78.101)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "\n",
      "Epoch: [16][0/1334]\t\\Time 0.314 (0.314)\tData 0.244 (0.244)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.311 (0.359)\tData 0.220 (0.281)\tLoss 0.0388 (0.0588)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/1334]\t\\Time 0.388 (0.364)\tData 0.308 (0.288)\tLoss 0.0478 (0.0618)\tPrec@1 100.000 (99.710)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [16][300/1334]\t\\Time 0.324 (0.364)\tData 0.262 (0.287)\tLoss 0.0325 (0.0591)\tPrec@1 100.000 (99.806)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [16][400/1334]\t\\Time 0.475 (0.367)\tData 0.385 (0.290)\tLoss 0.0662 (0.0581)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][500/1334]\t\\Time 0.338 (0.463)\tData 0.264 (0.381)\tLoss 0.0614 (0.0579)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [16][600/1334]\t\\Time 0.450 (0.486)\tData 0.381 (0.404)\tLoss 0.0469 (0.0586)\tPrec@1 100.000 (99.723)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [16][700/1334]\t\\Time 0.390 (0.508)\tData 0.310 (0.425)\tLoss 0.0441 (0.0578)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (99.976)\n",
      "Epoch: [16][800/1334]\t\\Time 0.314 (0.490)\tData 0.216 (0.407)\tLoss 0.0363 (0.0576)\tPrec@1 100.000 (99.761)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][900/1334]\t\\Time 0.349 (0.475)\tData 0.267 (0.393)\tLoss 0.0494 (0.0579)\tPrec@1 100.000 (99.741)\tPrec@5 100.000 (99.982)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.329 (0.462)\tData 0.220 (0.380)\tLoss 0.0397 (0.0581)\tPrec@1 100.000 (99.717)\tPrec@5 100.000 (99.975)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.328 (0.454)\tData 0.236 (0.372)\tLoss 0.0504 (0.0582)\tPrec@1 100.000 (99.705)\tPrec@5 100.000 (99.977)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.311 (0.446)\tData 0.210 (0.365)\tLoss 0.0401 (0.0588)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.350 (0.440)\tData 0.270 (0.359)\tLoss 0.0443 (0.0585)\tPrec@1 100.000 (99.686)\tPrec@5 100.000 (99.974)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.340 (0.340)\n",
      "\n",
      "Loss 2.4169 (2.4169)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.422 (0.423)\n",
      "\n",
      "Loss 2.5821 (2.6305)\n",
      "\n",
      "Prec@1 58.333 (52.558)\n",
      "\n",
      "Prec@5 75.000 (76.568)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.283 (0.397)\n",
      "\n",
      "Loss 2.1564 (2.5275)\n",
      "\n",
      "Prec@1 66.667 (52.280)\n",
      "\n",
      "Prec@5 75.000 (77.322)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.150 (0.385)\n",
      "\n",
      "Loss 1.1117 (2.4701)\n",
      "\n",
      "Prec@1 75.000 (53.184)\n",
      "\n",
      "Prec@5 91.667 (78.184)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 17)\n",
      "\n",
      "[INFO] Training Started\n",
      "0.0001\n",
      "\n",
      "[Learning Rate] 0.000010\n",
      "\n",
      "=> loading checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vit_b_16_v7_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 16)\n",
      "Epoch: [17][0/1334]\t\\Time 0.395 (0.395)\tData 0.303 (0.303)\tLoss 0.0915 (0.0915)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/1334]\t\\Time 0.376 (0.360)\tData 0.320 (0.282)\tLoss 0.1247 (0.0551)\tPrec@1 91.667 (99.835)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][200/1334]\t\\Time 0.392 (0.360)\tData 0.320 (0.282)\tLoss 0.0414 (0.0584)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][300/1334]\t\\Time 0.389 (0.361)\tData 0.310 (0.282)\tLoss 0.0981 (0.0585)\tPrec@1 100.000 (99.779)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][400/1334]\t\\Time 0.372 (0.360)\tData 0.283 (0.282)\tLoss 0.1183 (0.0597)\tPrec@1 100.000 (99.730)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][500/1334]\t\\Time 0.340 (0.363)\tData 0.251 (0.285)\tLoss 0.0542 (0.0591)\tPrec@1 100.000 (99.717)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [17][600/1334]\t\\Time 0.402 (0.363)\tData 0.341 (0.285)\tLoss 0.0251 (0.0590)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [17][700/1334]\t\\Time 0.388 (0.363)\tData 0.302 (0.285)\tLoss 0.0374 (0.0597)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [17][800/1334]\t\\Time 0.343 (0.363)\tData 0.286 (0.285)\tLoss 0.0132 (0.0598)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [17][900/1334]\t\\Time 0.400 (0.363)\tData 0.324 (0.285)\tLoss 0.0274 (0.0600)\tPrec@1 100.000 (99.676)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [17][1000/1334]\t\\Time 0.322 (0.363)\tData 0.220 (0.285)\tLoss 0.0802 (0.0590)\tPrec@1 100.000 (99.684)\tPrec@5 100.000 (99.975)\n",
      "Epoch: [17][1100/1334]\t\\Time 0.396 (0.364)\tData 0.327 (0.286)\tLoss 0.0360 (0.0585)\tPrec@1 100.000 (99.682)\tPrec@5 100.000 (99.977)\n",
      "Epoch: [17][1200/1334]\t\\Time 0.329 (0.364)\tData 0.250 (0.286)\tLoss 0.1058 (0.0581)\tPrec@1 100.000 (99.688)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [17][1300/1334]\t\\Time 0.376 (0.364)\tData 0.290 (0.286)\tLoss 0.0355 (0.0583)\tPrec@1 100.000 (99.686)\tPrec@5 100.000 (99.974)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.349 (0.349)\n",
      "\n",
      "Loss 2.4185 (2.4185)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.431 (0.411)\n",
      "\n",
      "Loss 2.5832 (2.6229)\n",
      "\n",
      "Prec@1 58.333 (52.723)\n",
      "\n",
      "Prec@5 75.000 (76.568)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.146 (0.383)\n",
      "\n",
      "Loss 2.1500 (2.5200)\n",
      "\n",
      "Prec@1 66.667 (52.363)\n",
      "\n",
      "Prec@5 75.000 (77.363)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.143 (0.362)\n",
      "\n",
      "Loss 1.1143 (2.4633)\n",
      "\n",
      "Prec@1 75.000 (53.212)\n",
      "\n",
      "Prec@5 91.667 (78.184)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000010\n",
      "\n",
      "Epoch: [18][0/1334]\t\\Time 0.348 (0.348)\tData 0.265 (0.265)\tLoss 0.0551 (0.0551)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/1334]\t\\Time 0.369 (0.360)\tData 0.291 (0.285)\tLoss 0.0166 (0.0550)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][200/1334]\t\\Time 0.364 (0.361)\tData 0.284 (0.285)\tLoss 0.0351 (0.0565)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][300/1334]\t\\Time 0.436 (0.360)\tData 0.355 (0.284)\tLoss 0.0373 (0.0556)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][400/1334]\t\\Time 0.379 (0.362)\tData 0.324 (0.285)\tLoss 0.0760 (0.0545)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][500/1334]\t\\Time 0.332 (0.363)\tData 0.242 (0.285)\tLoss 0.0413 (0.0555)\tPrec@1 100.000 (99.701)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [18][600/1334]\t\\Time 0.400 (0.363)\tData 0.320 (0.285)\tLoss 0.0301 (0.0581)\tPrec@1 100.000 (99.667)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [18][700/1334]\t\\Time 0.333 (0.368)\tData 0.223 (0.290)\tLoss 0.0559 (0.0589)\tPrec@1 100.000 (99.655)\tPrec@5 100.000 (99.976)\n",
      "Epoch: [18][800/1334]\t\\Time 0.370 (0.368)\tData 0.310 (0.290)\tLoss 0.0289 (0.0579)\tPrec@1 100.000 (99.677)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [18][900/1334]\t\\Time 0.355 (0.367)\tData 0.265 (0.289)\tLoss 0.0323 (0.0575)\tPrec@1 100.000 (99.713)\tPrec@5 100.000 (99.982)\n",
      "Epoch: [18][1000/1334]\t\\Time 0.377 (0.367)\tData 0.295 (0.290)\tLoss 0.0860 (0.0568)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [18][1100/1334]\t\\Time 0.363 (0.368)\tData 0.286 (0.290)\tLoss 0.0938 (0.0573)\tPrec@1 100.000 (99.682)\tPrec@5 100.000 (99.985)\n",
      "Epoch: [18][1200/1334]\t\\Time 0.372 (0.368)\tData 0.306 (0.290)\tLoss 0.0708 (0.0579)\tPrec@1 100.000 (99.681)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [18][1300/1334]\t\\Time 1.826 (0.380)\tData 1.750 (0.301)\tLoss 0.0772 (0.0581)\tPrec@1 100.000 (99.680)\tPrec@5 100.000 (99.974)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.308 (0.308)\n",
      "\n",
      "Loss 2.4187 (2.4187)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.432 (0.456)\n",
      "\n",
      "Loss 2.5842 (2.6236)\n",
      "\n",
      "Prec@1 58.333 (52.723)\n",
      "\n",
      "Prec@5 75.000 (76.568)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.145 (0.407)\n",
      "\n",
      "Loss 2.1504 (2.5205)\n",
      "\n",
      "Prec@1 66.667 (52.322)\n",
      "\n",
      "Prec@5 75.000 (77.363)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.148 (0.391)\n",
      "\n",
      "Loss 1.1132 (2.4639)\n",
      "\n",
      "Prec@1 75.000 (53.184)\n",
      "\n",
      "Prec@5 91.667 (78.184)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = torchvision.models.vit_b_16(weights = 'ViT_B_16_Weights.IMAGENET1K_V1')\n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "model.heads[0] =nn.Linear(768 , 100, bias = True)\n",
    "\n",
    "\n",
    "model.name = f'vit_b_16_v7_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "seed= 1212\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        print()\n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "        # prec1 = top1.avg\n",
    "        # prec5 = top5.avg\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.location_fc2.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.location_fc.parameters():\n",
    "#     param.requires_grad = True   \n",
    "# for param in model.linear_add.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)\n",
    "train_model(model,LEARNING_RATE = 1e-5,NUM_EPOCHS = 19)\n",
    "\n",
    "# train_model(model,LEARNING_RATE = 1e-5,NUM_EPOCHS = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410490a7-a4a6-4b07-9fd0-e28320a7e174",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 2)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1334]\t\\Time 1.115 (1.115)\tData 0.675 (0.675)\tLoss 1.5380 (1.5380)\tPrec@1 33.333 (33.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [2][100/1334]\t\\Time 0.384 (0.634)\tData 0.347 (0.570)\tLoss 1.3338 (1.8650)\tPrec@1 58.333 (48.350)\tPrec@5 83.333 (79.868)\n",
      "Epoch: [2][200/1334]\t\\Time 0.236 (0.503)\tData 0.208 (0.453)\tLoss 2.0061 (1.8707)\tPrec@1 50.000 (48.798)\tPrec@5 66.667 (80.141)\n",
      "Epoch: [2][300/1334]\t\\Time 0.306 (0.476)\tData 0.274 (0.429)\tLoss 1.6923 (1.8769)\tPrec@1 50.000 (49.031)\tPrec@5 83.333 (80.260)\n",
      "Epoch: [2][400/1334]\t\\Time 0.332 (0.485)\tData 0.293 (0.438)\tLoss 1.6119 (1.8840)\tPrec@1 58.333 (48.649)\tPrec@5 91.667 (79.967)\n",
      "Epoch: [2][500/1334]\t\\Time 0.409 (0.455)\tData 0.378 (0.411)\tLoss 1.9450 (1.8801)\tPrec@1 41.667 (48.869)\tPrec@5 75.000 (79.890)\n",
      "Epoch: [2][600/1334]\t\\Time 0.270 (0.431)\tData 0.240 (0.388)\tLoss 1.7139 (1.8797)\tPrec@1 50.000 (48.988)\tPrec@5 91.667 (79.867)\n",
      "Epoch: [2][700/1334]\t\\Time 0.310 (0.410)\tData 0.278 (0.369)\tLoss 1.2043 (1.8808)\tPrec@1 66.667 (48.978)\tPrec@5 100.000 (79.791)\n",
      "Epoch: [2][800/1334]\t\\Time 0.350 (0.401)\tData 0.318 (0.361)\tLoss 1.7865 (1.8752)\tPrec@1 58.333 (49.147)\tPrec@5 75.000 (79.848)\n",
      "Epoch: [2][900/1334]\t\\Time 0.210 (0.400)\tData 0.184 (0.360)\tLoss 1.7456 (1.8710)\tPrec@1 41.667 (49.001)\tPrec@5 83.333 (79.994)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.280 (0.391)\tData 0.250 (0.352)\tLoss 2.2861 (1.8702)\tPrec@1 50.000 (49.118)\tPrec@5 75.000 (80.045)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.301 (0.384)\tData 0.271 (0.346)\tLoss 1.6467 (1.8564)\tPrec@1 66.667 (49.455)\tPrec@5 83.333 (80.200)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.343 (0.379)\tData 0.313 (0.341)\tLoss 2.1612 (1.8572)\tPrec@1 50.000 (49.396)\tPrec@5 66.667 (80.260)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.338 (0.381)\tData 0.308 (0.343)\tLoss 1.5082 (1.8467)\tPrec@1 41.667 (49.635)\tPrec@5 91.667 (80.393)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.295 (0.295)\n",
      "\n",
      "Loss 1.6449 (1.6449)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.562 (0.484)\n",
      "\n",
      "Loss 2.1447 (1.7945)\n",
      "\n",
      "Prec@1 66.667 (51.568)\n",
      "\n",
      "Prec@5 75.000 (82.426)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.105 (0.421)\n",
      "\n",
      "Loss 1.4690 (1.8252)\n",
      "\n",
      "Prec@1 58.333 (51.036)\n",
      "\n",
      "Prec@5 91.667 (81.302)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.118 (0.389)\n",
      "\n",
      "Loss 2.5181 (1.8179)\n",
      "\n",
      "Prec@1 41.667 (50.664)\n",
      "\n",
      "Prec@5 83.333 (81.368)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1334]\t\\Time 0.570 (0.570)\tData 0.308 (0.308)\tLoss 1.6693 (1.6693)\tPrec@1 50.000 (50.000)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [3][100/1334]\t\\Time 0.279 (0.325)\tData 0.249 (0.290)\tLoss 1.2908 (1.5326)\tPrec@1 50.000 (57.673)\tPrec@5 91.667 (84.488)\n",
      "Epoch: [3][200/1334]\t\\Time 0.236 (0.347)\tData 0.206 (0.311)\tLoss 0.9769 (1.4973)\tPrec@1 66.667 (58.748)\tPrec@5 91.667 (85.531)\n",
      "Epoch: [3][300/1334]\t\\Time 0.265 (0.359)\tData 0.235 (0.323)\tLoss 1.6673 (1.5099)\tPrec@1 41.667 (58.361)\tPrec@5 100.000 (85.604)\n",
      "Epoch: [3][400/1334]\t\\Time 0.260 (0.345)\tData 0.230 (0.309)\tLoss 0.8804 (1.5150)\tPrec@1 75.000 (57.772)\tPrec@5 91.667 (85.869)\n",
      "Epoch: [3][500/1334]\t\\Time 0.374 (0.342)\tData 0.341 (0.307)\tLoss 1.1016 (1.5091)\tPrec@1 66.667 (57.951)\tPrec@5 91.667 (86.028)\n",
      "Epoch: [3][600/1334]\t\\Time 0.318 (0.340)\tData 0.288 (0.306)\tLoss 1.5046 (1.5043)\tPrec@1 66.667 (58.361)\tPrec@5 83.333 (86.051)\n",
      "Epoch: [3][700/1334]\t\\Time 0.390 (0.339)\tData 0.362 (0.304)\tLoss 0.5800 (1.5053)\tPrec@1 91.667 (58.345)\tPrec@5 91.667 (85.972)\n",
      "Epoch: [3][800/1334]\t\\Time 0.283 (0.338)\tData 0.251 (0.304)\tLoss 0.8534 (1.4959)\tPrec@1 83.333 (58.469)\tPrec@5 91.667 (86.153)\n",
      "Epoch: [3][900/1334]\t\\Time 0.280 (0.341)\tData 0.248 (0.306)\tLoss 1.0830 (1.4874)\tPrec@1 83.333 (58.703)\tPrec@5 91.667 (86.191)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.305 (0.340)\tData 0.274 (0.306)\tLoss 2.1640 (1.4832)\tPrec@1 41.667 (58.833)\tPrec@5 58.333 (86.147)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.331 (0.340)\tData 0.297 (0.306)\tLoss 2.3302 (1.4828)\tPrec@1 50.000 (58.825)\tPrec@5 58.333 (86.172)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.338 (0.339)\tData 0.304 (0.305)\tLoss 0.8057 (1.4723)\tPrec@1 83.333 (58.993)\tPrec@5 91.667 (86.317)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.416 (0.338)\tData 0.384 (0.304)\tLoss 2.3295 (1.4729)\tPrec@1 50.000 (59.032)\tPrec@5 83.333 (86.344)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.308 (0.308)\n",
      "\n",
      "Loss 2.8672 (2.8672)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.400 (0.394)\n",
      "\n",
      "Loss 1.7844 (2.0119)\n",
      "\n",
      "Prec@1 58.333 (49.175)\n",
      "\n",
      "Prec@5 83.333 (79.208)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.127 (0.365)\n",
      "\n",
      "Loss 1.7900 (2.0383)\n",
      "\n",
      "Prec@1 58.333 (48.798)\n",
      "\n",
      "Prec@5 75.000 (78.690)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.135 (0.342)\n",
      "\n",
      "Loss 1.4680 (2.0039)\n",
      "\n",
      "Prec@1 66.667 (49.446)\n",
      "\n",
      "Prec@5 83.333 (79.790)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1334]\t\\Time 0.618 (0.618)\tData 0.548 (0.548)\tLoss 1.2364 (1.2364)\tPrec@1 66.667 (66.667)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [4][100/1334]\t\\Time 0.463 (0.362)\tData 0.431 (0.327)\tLoss 0.9621 (1.2404)\tPrec@1 83.333 (63.944)\tPrec@5 83.333 (89.769)\n",
      "Epoch: [4][200/1334]\t\\Time 0.316 (0.348)\tData 0.286 (0.314)\tLoss 1.0370 (1.2785)\tPrec@1 58.333 (63.101)\tPrec@5 91.667 (89.262)\n",
      "Epoch: [4][300/1334]\t\\Time 0.282 (0.337)\tData 0.249 (0.303)\tLoss 1.5899 (1.2932)\tPrec@1 50.000 (63.012)\tPrec@5 83.333 (89.120)\n",
      "Epoch: [4][400/1334]\t\\Time 0.247 (0.336)\tData 0.215 (0.302)\tLoss 1.4978 (1.2878)\tPrec@1 66.667 (63.300)\tPrec@5 91.667 (89.090)\n",
      "Epoch: [4][500/1334]\t\\Time 0.486 (0.340)\tData 0.458 (0.306)\tLoss 0.8531 (1.3032)\tPrec@1 91.667 (62.891)\tPrec@5 91.667 (88.889)\n",
      "Epoch: [4][600/1334]\t\\Time 0.348 (0.338)\tData 0.312 (0.304)\tLoss 1.0732 (1.3078)\tPrec@1 83.333 (62.812)\tPrec@5 91.667 (88.991)\n",
      "Epoch: [4][700/1334]\t\\Time 0.306 (0.345)\tData 0.272 (0.311)\tLoss 1.1728 (1.3138)\tPrec@1 50.000 (62.530)\tPrec@5 100.000 (89.099)\n",
      "Epoch: [4][800/1334]\t\\Time 0.317 (0.349)\tData 0.280 (0.315)\tLoss 1.0513 (1.3152)\tPrec@1 75.000 (62.724)\tPrec@5 91.667 (88.993)\n",
      "Epoch: [4][900/1334]\t\\Time 0.383 (0.346)\tData 0.350 (0.312)\tLoss 0.5591 (1.3073)\tPrec@1 83.333 (63.023)\tPrec@5 100.000 (89.049)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.307 (0.344)\tData 0.273 (0.310)\tLoss 1.3598 (1.3149)\tPrec@1 58.333 (62.779)\tPrec@5 83.333 (88.903)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.371 (0.342)\tData 0.338 (0.308)\tLoss 1.3251 (1.3108)\tPrec@1 75.000 (63.026)\tPrec@5 83.333 (88.912)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.285 (0.340)\tData 0.255 (0.306)\tLoss 1.5300 (1.3174)\tPrec@1 66.667 (62.802)\tPrec@5 83.333 (88.822)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.261 (0.342)\tData 0.223 (0.308)\tLoss 1.2848 (1.3218)\tPrec@1 58.333 (62.772)\tPrec@5 91.667 (88.746)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.287 (0.287)\n",
      "\n",
      "Loss 1.8234 (1.8234)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.437 (0.485)\n",
      "\n",
      "Loss 1.4460 (1.9505)\n",
      "\n",
      "Prec@1 75.000 (50.578)\n",
      "\n",
      "Prec@5 75.000 (79.868)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.125 (0.424)\n",
      "\n",
      "Loss 2.6135 (1.9474)\n",
      "\n",
      "Prec@1 41.667 (50.249)\n",
      "\n",
      "Prec@5 75.000 (80.141)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.101 (0.392)\n",
      "\n",
      "Loss 1.6454 (1.9145)\n",
      "\n",
      "Prec@1 41.667 (51.384)\n",
      "\n",
      "Prec@5 91.667 (80.343)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1334]\t\\Time 0.291 (0.291)\tData 0.240 (0.240)\tLoss 0.6032 (0.6032)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [5][100/1334]\t\\Time 0.421 (0.328)\tData 0.387 (0.295)\tLoss 1.3366 (1.0226)\tPrec@1 58.333 (72.277)\tPrec@5 83.333 (91.172)\n",
      "Epoch: [5][200/1334]\t\\Time 0.426 (0.350)\tData 0.393 (0.316)\tLoss 0.9757 (1.0062)\tPrec@1 75.000 (72.139)\tPrec@5 91.667 (91.625)\n",
      "Epoch: [5][300/1334]\t\\Time 0.302 (0.368)\tData 0.272 (0.333)\tLoss 1.2364 (1.0256)\tPrec@1 58.333 (71.512)\tPrec@5 91.667 (92.027)\n",
      "Epoch: [5][400/1334]\t\\Time 0.325 (0.390)\tData 0.279 (0.352)\tLoss 1.1881 (1.0875)\tPrec@1 50.000 (69.057)\tPrec@5 91.667 (91.397)\n",
      "Epoch: [5][500/1334]\t\\Time 0.268 (0.373)\tData 0.234 (0.337)\tLoss 0.8625 (1.1039)\tPrec@1 83.333 (68.696)\tPrec@5 91.667 (91.317)\n",
      "Epoch: [5][600/1334]\t\\Time 0.344 (0.359)\tData 0.306 (0.324)\tLoss 0.7057 (1.1126)\tPrec@1 75.000 (68.344)\tPrec@5 100.000 (91.334)\n",
      "Epoch: [5][700/1334]\t\\Time 0.363 (0.356)\tData 0.328 (0.320)\tLoss 0.9325 (1.1253)\tPrec@1 58.333 (67.915)\tPrec@5 91.667 (91.144)\n",
      "Epoch: [5][800/1334]\t\\Time 0.254 (0.348)\tData 0.223 (0.313)\tLoss 1.2205 (1.1416)\tPrec@1 58.333 (67.655)\tPrec@5 91.667 (90.886)\n",
      "Epoch: [5][900/1334]\t\\Time 0.224 (0.342)\tData 0.193 (0.307)\tLoss 1.0872 (1.1474)\tPrec@1 58.333 (67.481)\tPrec@5 83.333 (90.908)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.348 (0.346)\tData 0.313 (0.311)\tLoss 1.4922 (1.1515)\tPrec@1 50.000 (67.316)\tPrec@5 83.333 (90.876)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.226 (0.350)\tData 0.197 (0.314)\tLoss 1.4002 (1.1604)\tPrec@1 66.667 (67.128)\tPrec@5 83.333 (90.683)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.190 (0.346)\tData 0.158 (0.311)\tLoss 1.3985 (1.1566)\tPrec@1 66.667 (67.222)\tPrec@5 91.667 (90.674)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.279 (0.348)\tData 0.250 (0.313)\tLoss 1.6301 (1.1560)\tPrec@1 33.333 (67.269)\tPrec@5 83.333 (90.642)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.255 (0.255)\n",
      "\n",
      "Loss 1.1662 (1.1662)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.592 (0.419)\n",
      "\n",
      "Loss 2.5887 (2.0233)\n",
      "\n",
      "Prec@1 58.333 (50.660)\n",
      "\n",
      "Prec@5 75.000 (80.776)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.109 (0.389)\n",
      "\n",
      "Loss 1.8113 (1.9914)\n",
      "\n",
      "Prec@1 58.333 (51.824)\n",
      "\n",
      "Prec@5 75.000 (80.348)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.213 (0.378)\n",
      "\n",
      "Loss 1.4874 (1.9556)\n",
      "\n",
      "Prec@1 75.000 (52.215)\n",
      "\n",
      "Prec@5 83.333 (80.482)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1334]\t\\Time 0.513 (0.513)\tData 0.428 (0.428)\tLoss 0.4608 (0.4608)\tPrec@1 91.667 (91.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [6][100/1334]\t\\Time 0.278 (0.406)\tData 0.248 (0.366)\tLoss 0.2708 (0.9158)\tPrec@1 100.000 (72.937)\tPrec@5 100.000 (94.637)\n",
      "Epoch: [6][200/1334]\t\\Time 0.266 (0.360)\tData 0.236 (0.322)\tLoss 0.8220 (0.9102)\tPrec@1 75.000 (73.259)\tPrec@5 100.000 (93.864)\n",
      "Epoch: [6][300/1334]\t\\Time 0.325 (0.354)\tData 0.293 (0.318)\tLoss 1.3022 (0.8994)\tPrec@1 58.333 (73.671)\tPrec@5 100.000 (93.965)\n",
      "Epoch: [6][400/1334]\t\\Time 0.356 (0.341)\tData 0.317 (0.306)\tLoss 0.9052 (0.9075)\tPrec@1 75.000 (73.421)\tPrec@5 100.000 (94.015)\n",
      "Epoch: [6][500/1334]\t\\Time 0.361 (0.331)\tData 0.330 (0.297)\tLoss 1.0393 (0.9277)\tPrec@1 83.333 (72.821)\tPrec@5 91.667 (93.563)\n",
      "Epoch: [6][600/1334]\t\\Time 0.343 (0.327)\tData 0.310 (0.293)\tLoss 1.5490 (0.9347)\tPrec@1 50.000 (72.518)\tPrec@5 100.000 (93.483)\n",
      "Epoch: [6][700/1334]\t\\Time 0.286 (0.324)\tData 0.257 (0.290)\tLoss 1.0143 (0.9445)\tPrec@1 58.333 (72.159)\tPrec@5 100.000 (93.485)\n",
      "Epoch: [6][800/1334]\t\\Time 0.323 (0.322)\tData 0.292 (0.289)\tLoss 0.8961 (0.9525)\tPrec@1 75.000 (72.035)\tPrec@5 91.667 (93.373)\n",
      "Epoch: [6][900/1334]\t\\Time 0.205 (0.319)\tData 0.171 (0.286)\tLoss 0.8571 (0.9609)\tPrec@1 75.000 (71.707)\tPrec@5 91.667 (93.276)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.296 (0.317)\tData 0.260 (0.284)\tLoss 1.0240 (0.9700)\tPrec@1 66.667 (71.528)\tPrec@5 83.333 (93.124)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.268 (0.316)\tData 0.236 (0.282)\tLoss 1.9129 (0.9736)\tPrec@1 50.000 (71.427)\tPrec@5 75.000 (93.074)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.212 (0.314)\tData 0.189 (0.280)\tLoss 0.2961 (0.9772)\tPrec@1 100.000 (71.225)\tPrec@5 100.000 (93.110)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.278 (0.313)\tData 0.247 (0.280)\tLoss 0.8845 (0.9818)\tPrec@1 75.000 (71.259)\tPrec@5 83.333 (92.986)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.298 (0.298)\n",
      "\n",
      "Loss 1.2943 (1.2943)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.395 (0.363)\n",
      "\n",
      "Loss 1.5507 (1.6486)\n",
      "\n",
      "Prec@1 58.333 (57.756)\n",
      "\n",
      "Prec@5 91.667 (84.241)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.144 (0.374)\n",
      "\n",
      "Loss 2.0396 (1.6413)\n",
      "\n",
      "Prec@1 50.000 (57.711)\n",
      "\n",
      "Prec@5 83.333 (84.163)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.100 (0.368)\n",
      "\n",
      "Loss 1.9135 (1.6623)\n",
      "\n",
      "Prec@1 66.667 (57.697)\n",
      "\n",
      "Prec@5 91.667 (84.081)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1334]\t\\Time 0.358 (0.358)\tData 0.294 (0.294)\tLoss 1.3295 (1.3295)\tPrec@1 66.667 (66.667)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [7][100/1334]\t\\Time 0.428 (0.324)\tData 0.392 (0.291)\tLoss 0.4422 (0.7072)\tPrec@1 91.667 (80.033)\tPrec@5 100.000 (96.122)\n",
      "Epoch: [7][200/1334]\t\\Time 0.472 (0.356)\tData 0.412 (0.321)\tLoss 0.7680 (0.7000)\tPrec@1 83.333 (79.395)\tPrec@5 100.000 (96.434)\n",
      "Epoch: [7][300/1334]\t\\Time 0.381 (0.354)\tData 0.352 (0.318)\tLoss 0.6175 (0.7213)\tPrec@1 83.333 (78.239)\tPrec@5 100.000 (96.318)\n",
      "Epoch: [7][400/1334]\t\\Time 0.300 (0.352)\tData 0.267 (0.318)\tLoss 0.8749 (0.7403)\tPrec@1 75.000 (77.577)\tPrec@5 100.000 (96.093)\n",
      "Epoch: [7][500/1334]\t\\Time 0.329 (0.349)\tData 0.294 (0.314)\tLoss 0.8325 (0.7461)\tPrec@1 58.333 (77.512)\tPrec@5 100.000 (96.041)\n",
      "Epoch: [7][600/1334]\t\\Time 0.516 (0.356)\tData 0.482 (0.320)\tLoss 0.7373 (0.7490)\tPrec@1 75.000 (77.246)\tPrec@5 100.000 (96.062)\n",
      "Epoch: [7][700/1334]\t\\Time 0.338 (0.354)\tData 0.304 (0.319)\tLoss 0.9601 (0.7535)\tPrec@1 66.667 (77.306)\tPrec@5 91.667 (95.994)\n",
      "Epoch: [7][800/1334]\t\\Time 0.306 (0.346)\tData 0.275 (0.311)\tLoss 1.1914 (0.7555)\tPrec@1 75.000 (77.299)\tPrec@5 91.667 (95.974)\n",
      "Epoch: [7][900/1334]\t\\Time 0.296 (0.342)\tData 0.261 (0.308)\tLoss 1.3802 (0.7701)\tPrec@1 50.000 (77.016)\tPrec@5 91.667 (95.597)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.245 (0.338)\tData 0.210 (0.304)\tLoss 1.2859 (0.7786)\tPrec@1 66.667 (76.657)\tPrec@5 83.333 (95.521)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.236 (0.338)\tData 0.204 (0.304)\tLoss 0.4691 (0.7921)\tPrec@1 83.333 (76.241)\tPrec@5 100.000 (95.398)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.272 (0.335)\tData 0.248 (0.301)\tLoss 0.8243 (0.8014)\tPrec@1 75.000 (75.992)\tPrec@5 100.000 (95.205)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.357 (0.333)\tData 0.326 (0.299)\tLoss 1.1121 (0.7998)\tPrec@1 66.667 (76.095)\tPrec@5 100.000 (95.132)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.265 (0.265)\n",
      "\n",
      "Loss 1.0551 (1.0551)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.435 (0.368)\n",
      "\n",
      "Loss 2.0198 (1.6631)\n",
      "\n",
      "Prec@1 50.000 (57.508)\n",
      "\n",
      "Prec@5 83.333 (84.818)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.106 (0.341)\n",
      "\n",
      "Loss 2.0426 (1.6480)\n",
      "\n",
      "Prec@1 50.000 (58.126)\n",
      "\n",
      "Prec@5 66.667 (84.701)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.165 (0.317)\n",
      "\n",
      "Loss 1.3593 (1.6794)\n",
      "\n",
      "Prec@1 50.000 (57.641)\n",
      "\n",
      "Prec@5 91.667 (84.579)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1334]\t\\Time 0.718 (0.718)\tData 0.647 (0.647)\tLoss 0.1506 (0.1506)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/1334]\t\\Time 0.310 (0.406)\tData 0.275 (0.368)\tLoss 1.2830 (0.6248)\tPrec@1 58.333 (81.023)\tPrec@5 100.000 (97.030)\n",
      "Epoch: [8][200/1334]\t\\Time 0.383 (0.363)\tData 0.351 (0.328)\tLoss 0.5116 (0.5923)\tPrec@1 75.000 (82.090)\tPrec@5 100.000 (97.388)\n",
      "Epoch: [8][300/1334]\t\\Time 0.585 (0.370)\tData 0.551 (0.334)\tLoss 1.5381 (0.6234)\tPrec@1 66.667 (81.423)\tPrec@5 83.333 (97.231)\n",
      "Epoch: [8][400/1334]\t\\Time 0.259 (0.353)\tData 0.227 (0.317)\tLoss 0.3492 (0.6347)\tPrec@1 83.333 (81.089)\tPrec@5 100.000 (96.862)\n",
      "Epoch: [8][500/1334]\t\\Time 0.265 (0.349)\tData 0.235 (0.313)\tLoss 0.2722 (0.6427)\tPrec@1 91.667 (80.888)\tPrec@5 100.000 (96.823)\n",
      "Epoch: [8][600/1334]\t\\Time 0.359 (0.361)\tData 0.322 (0.324)\tLoss 1.0223 (0.6511)\tPrec@1 58.333 (80.699)\tPrec@5 91.667 (96.644)\n",
      "Epoch: [8][700/1334]\t\\Time 0.299 (0.358)\tData 0.262 (0.322)\tLoss 0.7674 (0.6608)\tPrec@1 75.000 (80.254)\tPrec@5 100.000 (96.588)\n",
      "Epoch: [8][800/1334]\t\\Time 0.333 (0.354)\tData 0.300 (0.318)\tLoss 0.5372 (0.6705)\tPrec@1 75.000 (79.900)\tPrec@5 100.000 (96.463)\n",
      "Epoch: [8][900/1334]\t\\Time 0.268 (0.354)\tData 0.232 (0.318)\tLoss 0.6012 (0.6743)\tPrec@1 91.667 (79.883)\tPrec@5 91.667 (96.430)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.238 (0.348)\tData 0.217 (0.312)\tLoss 0.7859 (0.6793)\tPrec@1 83.333 (79.745)\tPrec@5 91.667 (96.429)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.370 (0.345)\tData 0.338 (0.309)\tLoss 1.1548 (0.6883)\tPrec@1 83.333 (79.526)\tPrec@5 83.333 (96.306)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.302 (0.344)\tData 0.272 (0.309)\tLoss 0.7389 (0.6975)\tPrec@1 75.000 (79.191)\tPrec@5 91.667 (96.191)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.261 (0.345)\tData 0.230 (0.310)\tLoss 1.0943 (0.7064)\tPrec@1 75.000 (78.997)\tPrec@5 91.667 (96.067)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.251 (0.251)\n",
      "\n",
      "Loss 1.4065 (1.4065)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.392 (0.359)\n",
      "\n",
      "Loss 2.0887 (1.6363)\n",
      "\n",
      "Prec@1 58.333 (59.983)\n",
      "\n",
      "Prec@5 75.000 (85.644)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.105 (0.337)\n",
      "\n",
      "Loss 1.7813 (1.6683)\n",
      "\n",
      "Prec@1 58.333 (59.494)\n",
      "\n",
      "Prec@5 83.333 (84.909)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.116 (0.317)\n",
      "\n",
      "Loss 3.1246 (1.6952)\n",
      "\n",
      "Prec@1 41.667 (59.856)\n",
      "\n",
      "Prec@5 75.000 (84.801)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1334]\t\\Time 0.373 (0.373)\tData 0.292 (0.292)\tLoss 0.3581 (0.3581)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/1334]\t\\Time 0.354 (0.296)\tData 0.323 (0.264)\tLoss 0.2453 (0.4532)\tPrec@1 100.000 (85.809)\tPrec@5 100.000 (98.515)\n",
      "Epoch: [9][200/1334]\t\\Time 0.295 (0.296)\tData 0.264 (0.264)\tLoss 0.2308 (0.5176)\tPrec@1 100.000 (83.706)\tPrec@5 100.000 (97.927)\n",
      "Epoch: [9][300/1334]\t\\Time 0.254 (0.297)\tData 0.222 (0.265)\tLoss 0.3840 (0.5228)\tPrec@1 83.333 (83.804)\tPrec@5 100.000 (97.813)\n",
      "Epoch: [9][400/1334]\t\\Time 0.355 (0.298)\tData 0.322 (0.266)\tLoss 0.6891 (0.5424)\tPrec@1 75.000 (83.042)\tPrec@5 100.000 (97.797)\n",
      "Epoch: [9][500/1334]\t\\Time 0.315 (0.299)\tData 0.284 (0.267)\tLoss 0.3880 (0.5419)\tPrec@1 83.333 (83.084)\tPrec@5 100.000 (97.888)\n",
      "Epoch: [9][600/1334]\t\\Time 0.335 (0.298)\tData 0.309 (0.266)\tLoss 0.4646 (0.5493)\tPrec@1 91.667 (82.820)\tPrec@5 100.000 (97.837)\n",
      "Epoch: [9][700/1334]\t\\Time 0.297 (0.298)\tData 0.270 (0.267)\tLoss 0.4383 (0.5541)\tPrec@1 75.000 (82.620)\tPrec@5 100.000 (97.765)\n",
      "Epoch: [9][800/1334]\t\\Time 0.269 (0.299)\tData 0.238 (0.267)\tLoss 0.7171 (0.5582)\tPrec@1 83.333 (82.626)\tPrec@5 91.667 (97.732)\n",
      "Epoch: [9][900/1334]\t\\Time 0.317 (0.299)\tData 0.286 (0.267)\tLoss 0.0981 (0.5655)\tPrec@1 100.000 (82.445)\tPrec@5 100.000 (97.651)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.318 (0.298)\tData 0.283 (0.267)\tLoss 0.6057 (0.5743)\tPrec@1 75.000 (82.276)\tPrec@5 100.000 (97.602)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.320 (0.298)\tData 0.290 (0.266)\tLoss 1.2387 (0.5765)\tPrec@1 58.333 (82.206)\tPrec@5 83.333 (97.616)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.335 (0.298)\tData 0.295 (0.266)\tLoss 0.1681 (0.5854)\tPrec@1 100.000 (82.001)\tPrec@5 100.000 (97.502)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.322 (0.298)\tData 0.292 (0.266)\tLoss 0.9754 (0.5948)\tPrec@1 75.000 (81.674)\tPrec@5 91.667 (97.406)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.279 (0.279)\n",
      "\n",
      "Loss 0.6752 (0.6752)\n",
      "\n",
      "Prec@1 91.667 (91.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.384 (0.358)\n",
      "\n",
      "Loss 1.7522 (1.7731)\n",
      "\n",
      "Prec@1 75.000 (57.343)\n",
      "\n",
      "Prec@5 75.000 (83.086)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.104 (0.334)\n",
      "\n",
      "Loss 2.3807 (1.8240)\n",
      "\n",
      "Prec@1 50.000 (56.799)\n",
      "\n",
      "Prec@5 83.333 (82.255)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.107 (0.315)\n",
      "\n",
      "Loss 3.5868 (1.8919)\n",
      "\n",
      "Prec@1 58.333 (56.285)\n",
      "\n",
      "Prec@5 66.667 (81.949)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Adjusted Learning rate resume from best model\n",
      "=> loading checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 9)\n",
      "Epoch: [10][0/1334]\t\\Time 0.360 (0.360)\tData 0.310 (0.310)\tLoss 0.2520 (0.2520)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/1334]\t\\Time 0.402 (0.288)\tData 0.368 (0.255)\tLoss 0.3092 (0.4007)\tPrec@1 91.667 (87.624)\tPrec@5 100.000 (98.680)\n",
      "Epoch: [10][200/1334]\t\\Time 0.317 (0.290)\tData 0.289 (0.258)\tLoss 0.2565 (0.3602)\tPrec@1 91.667 (89.138)\tPrec@5 100.000 (98.881)\n",
      "Epoch: [10][300/1334]\t\\Time 0.305 (0.291)\tData 0.271 (0.259)\tLoss 0.3000 (0.3425)\tPrec@1 91.667 (89.618)\tPrec@5 100.000 (98.865)\n",
      "Epoch: [10][400/1334]\t\\Time 0.322 (0.291)\tData 0.292 (0.259)\tLoss 0.3299 (0.3157)\tPrec@1 91.667 (90.524)\tPrec@5 100.000 (98.940)\n",
      "Epoch: [10][500/1334]\t\\Time 0.351 (0.293)\tData 0.320 (0.261)\tLoss 0.4157 (0.2914)\tPrec@1 83.333 (91.334)\tPrec@5 100.000 (99.118)\n",
      "Epoch: [10][600/1334]\t\\Time 0.240 (0.293)\tData 0.210 (0.261)\tLoss 0.2281 (0.2766)\tPrec@1 91.667 (91.833)\tPrec@5 100.000 (99.140)\n",
      "Epoch: [10][700/1334]\t\\Time 0.232 (0.294)\tData 0.201 (0.261)\tLoss 0.1218 (0.2646)\tPrec@1 100.000 (92.154)\tPrec@5 100.000 (99.204)\n",
      "Epoch: [10][800/1334]\t\\Time 0.334 (0.294)\tData 0.301 (0.262)\tLoss 0.2858 (0.2520)\tPrec@1 91.667 (92.489)\tPrec@5 100.000 (99.261)\n",
      "Epoch: [10][900/1334]\t\\Time 0.311 (0.295)\tData 0.280 (0.263)\tLoss 1.3153 (0.2461)\tPrec@1 91.667 (92.703)\tPrec@5 91.667 (99.288)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.302 (0.295)\tData 0.274 (0.263)\tLoss 0.2352 (0.2400)\tPrec@1 91.667 (92.865)\tPrec@5 100.000 (99.284)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.297 (0.295)\tData 0.265 (0.262)\tLoss 0.4171 (0.2344)\tPrec@1 91.667 (93.052)\tPrec@5 91.667 (99.311)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.345 (0.295)\tData 0.310 (0.263)\tLoss 0.0952 (0.2325)\tPrec@1 100.000 (93.110)\tPrec@5 100.000 (99.313)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.308 (0.296)\tData 0.273 (0.264)\tLoss 0.5536 (0.2290)\tPrec@1 83.333 (93.198)\tPrec@5 100.000 (99.334)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.260 (0.260)\n",
      "\n",
      "Loss 0.9290 (0.9290)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.390 (0.355)\n",
      "\n",
      "Loss 1.7375 (1.2722)\n",
      "\n",
      "Prec@1 75.000 (71.122)\n",
      "\n",
      "Prec@5 83.333 (90.677)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.102 (0.342)\n",
      "\n",
      "Loss 1.4477 (1.3289)\n",
      "\n",
      "Prec@1 75.000 (70.232)\n",
      "\n",
      "Prec@5 83.333 (89.967)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.107 (0.322)\n",
      "\n",
      "Loss 1.0564 (1.3483)\n",
      "\n",
      "Prec@1 75.000 (69.684)\n",
      "\n",
      "Prec@5 91.667 (90.006)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [11][0/1334]\t\\Time 0.364 (0.364)\tData 0.296 (0.296)\tLoss 0.0655 (0.0655)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.227 (0.292)\tData 0.197 (0.259)\tLoss 0.0748 (0.1181)\tPrec@1 100.000 (96.452)\tPrec@5 100.000 (99.752)\n",
      "Epoch: [11][200/1334]\t\\Time 0.239 (0.292)\tData 0.206 (0.259)\tLoss 0.2393 (0.1277)\tPrec@1 91.667 (96.393)\tPrec@5 100.000 (99.627)\n",
      "Epoch: [11][300/1334]\t\\Time 0.288 (0.292)\tData 0.251 (0.260)\tLoss 0.2230 (0.1205)\tPrec@1 91.667 (96.622)\tPrec@5 100.000 (99.723)\n",
      "Epoch: [11][400/1334]\t\\Time 0.310 (0.294)\tData 0.280 (0.261)\tLoss 0.3147 (0.1200)\tPrec@1 91.667 (96.675)\tPrec@5 100.000 (99.730)\n",
      "Epoch: [11][500/1334]\t\\Time 0.289 (0.295)\tData 0.257 (0.263)\tLoss 0.0613 (0.1160)\tPrec@1 100.000 (96.773)\tPrec@5 100.000 (99.767)\n",
      "Epoch: [11][600/1334]\t\\Time 0.315 (0.296)\tData 0.283 (0.264)\tLoss 0.1341 (0.1127)\tPrec@1 100.000 (96.852)\tPrec@5 100.000 (99.778)\n",
      "Epoch: [11][700/1334]\t\\Time 0.276 (0.296)\tData 0.240 (0.264)\tLoss 0.0555 (0.1142)\tPrec@1 100.000 (96.802)\tPrec@5 100.000 (99.738)\n",
      "Epoch: [11][800/1334]\t\\Time 0.301 (0.296)\tData 0.270 (0.264)\tLoss 0.0027 (0.1122)\tPrec@1 100.000 (96.868)\tPrec@5 100.000 (99.761)\n",
      "Epoch: [11][900/1334]\t\\Time 0.252 (0.296)\tData 0.219 (0.264)\tLoss 0.2904 (0.1111)\tPrec@1 91.667 (96.957)\tPrec@5 100.000 (99.760)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.248 (0.297)\tData 0.216 (0.265)\tLoss 0.1305 (0.1145)\tPrec@1 91.667 (96.861)\tPrec@5 100.000 (99.742)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.383 (0.296)\tData 0.353 (0.264)\tLoss 0.0219 (0.1129)\tPrec@1 100.000 (96.942)\tPrec@5 100.000 (99.750)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.321 (0.297)\tData 0.289 (0.264)\tLoss 0.0582 (0.1119)\tPrec@1 100.000 (96.926)\tPrec@5 100.000 (99.750)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.331 (0.303)\tData 0.301 (0.271)\tLoss 0.0924 (0.1101)\tPrec@1 100.000 (96.996)\tPrec@5 100.000 (99.763)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.267 (0.267)\n",
      "\n",
      "Loss 0.6679 (0.6679)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.410 (0.351)\n",
      "\n",
      "Loss 2.1936 (1.3979)\n",
      "\n",
      "Prec@1 75.000 (70.875)\n",
      "\n",
      "Prec@5 83.333 (90.677)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.112 (0.336)\n",
      "\n",
      "Loss 1.4281 (1.4347)\n",
      "\n",
      "Prec@1 75.000 (70.439)\n",
      "\n",
      "Prec@5 100.000 (89.884)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.104 (0.328)\n",
      "\n",
      "Loss 1.2004 (1.4529)\n",
      "\n",
      "Prec@1 66.667 (69.684)\n",
      "\n",
      "Prec@5 91.667 (89.978)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [12][0/1334]\t\\Time 0.316 (0.316)\tData 0.267 (0.267)\tLoss 0.0264 (0.0264)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.344 (0.292)\tData 0.313 (0.260)\tLoss 0.0210 (0.0759)\tPrec@1 100.000 (97.855)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][200/1334]\t\\Time 0.262 (0.304)\tData 0.228 (0.272)\tLoss 0.0073 (0.0745)\tPrec@1 100.000 (97.927)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [12][300/1334]\t\\Time 0.308 (0.316)\tData 0.275 (0.283)\tLoss 0.0286 (0.0738)\tPrec@1 100.000 (97.979)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [12][400/1334]\t\\Time 0.311 (0.313)\tData 0.281 (0.280)\tLoss 0.0535 (0.0701)\tPrec@1 100.000 (98.171)\tPrec@5 100.000 (99.855)\n",
      "Epoch: [12][500/1334]\t\\Time 0.319 (0.329)\tData 0.289 (0.295)\tLoss 0.0274 (0.0689)\tPrec@1 100.000 (98.187)\tPrec@5 100.000 (99.884)\n",
      "Epoch: [12][600/1334]\t\\Time 0.351 (0.327)\tData 0.309 (0.293)\tLoss 0.0019 (0.0678)\tPrec@1 100.000 (98.170)\tPrec@5 100.000 (99.903)\n",
      "Epoch: [12][700/1334]\t\\Time 0.263 (0.331)\tData 0.226 (0.297)\tLoss 0.0176 (0.0682)\tPrec@1 100.000 (98.181)\tPrec@5 100.000 (99.905)\n",
      "Epoch: [12][800/1334]\t\\Time 0.316 (0.328)\tData 0.277 (0.295)\tLoss 0.0412 (0.0676)\tPrec@1 100.000 (98.242)\tPrec@5 100.000 (99.906)\n",
      "Epoch: [12][900/1334]\t\\Time 0.356 (0.325)\tData 0.322 (0.291)\tLoss 0.0201 (0.0669)\tPrec@1 100.000 (98.261)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.326 (0.323)\tData 0.287 (0.290)\tLoss 0.3185 (0.0657)\tPrec@1 91.667 (98.310)\tPrec@5 100.000 (99.925)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.297 (0.321)\tData 0.266 (0.287)\tLoss 0.3598 (0.0660)\tPrec@1 91.667 (98.274)\tPrec@5 100.000 (99.932)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.368 (0.318)\tData 0.336 (0.285)\tLoss 0.1357 (0.0655)\tPrec@1 91.667 (98.265)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.243 (0.317)\tData 0.214 (0.283)\tLoss 0.0464 (0.0654)\tPrec@1 100.000 (98.290)\tPrec@5 100.000 (99.930)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.280 (0.280)\n",
      "\n",
      "Loss 1.0411 (1.0411)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.400 (0.366)\n",
      "\n",
      "Loss 2.3271 (1.4545)\n",
      "\n",
      "Prec@1 66.667 (70.957)\n",
      "\n",
      "Prec@5 83.333 (90.677)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.099 (0.336)\n",
      "\n",
      "Loss 1.6669 (1.4876)\n",
      "\n",
      "Prec@1 75.000 (70.274)\n",
      "\n",
      "Prec@5 91.667 (90.174)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.104 (0.315)\n",
      "\n",
      "Loss 1.3311 (1.5192)\n",
      "\n",
      "Prec@1 75.000 (69.657)\n",
      "\n",
      "Prec@5 91.667 (90.255)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [13][0/1334]\t\\Time 0.334 (0.334)\tData 0.275 (0.275)\tLoss 0.0389 (0.0389)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.263 (0.293)\tData 0.231 (0.261)\tLoss 0.0119 (0.0464)\tPrec@1 100.000 (99.175)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][200/1334]\t\\Time 0.323 (0.300)\tData 0.299 (0.268)\tLoss 0.0206 (0.0435)\tPrec@1 100.000 (99.171)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][300/1334]\t\\Time 0.285 (0.294)\tData 0.253 (0.262)\tLoss 0.0057 (0.0466)\tPrec@1 100.000 (98.920)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [13][400/1334]\t\\Time 0.298 (0.291)\tData 0.267 (0.259)\tLoss 0.1317 (0.0452)\tPrec@1 91.667 (98.982)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [13][500/1334]\t\\Time 0.262 (0.294)\tData 0.232 (0.262)\tLoss 0.0176 (0.0448)\tPrec@1 100.000 (98.969)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [13][600/1334]\t\\Time 0.273 (0.299)\tData 0.230 (0.267)\tLoss 0.0010 (0.0448)\tPrec@1 100.000 (99.002)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [13][700/1334]\t\\Time 0.219 (0.300)\tData 0.188 (0.268)\tLoss 0.1031 (0.0446)\tPrec@1 100.000 (98.966)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [13][800/1334]\t\\Time 0.228 (0.299)\tData 0.194 (0.267)\tLoss 0.0980 (0.0445)\tPrec@1 100.000 (98.960)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [13][900/1334]\t\\Time 0.291 (0.299)\tData 0.258 (0.267)\tLoss 0.0494 (0.0471)\tPrec@1 100.000 (98.927)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.300 (0.301)\tData 0.268 (0.269)\tLoss 0.0500 (0.0473)\tPrec@1 100.000 (98.926)\tPrec@5 100.000 (99.975)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.327 (0.303)\tData 0.305 (0.271)\tLoss 0.0086 (0.0471)\tPrec@1 100.000 (98.918)\tPrec@5 100.000 (99.977)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.371 (0.306)\tData 0.347 (0.273)\tLoss 0.0071 (0.0487)\tPrec@1 100.000 (98.834)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.398 (0.309)\tData 0.365 (0.276)\tLoss 0.0380 (0.0484)\tPrec@1 100.000 (98.821)\tPrec@5 100.000 (99.981)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.323 (0.323)\n",
      "\n",
      "Loss 1.0041 (1.0041)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.425 (0.390)\n",
      "\n",
      "Loss 2.4174 (1.4505)\n",
      "\n",
      "Prec@1 75.000 (71.452)\n",
      "\n",
      "Prec@5 83.333 (90.759)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.108 (0.365)\n",
      "\n",
      "Loss 1.5636 (1.4947)\n",
      "\n",
      "Prec@1 75.000 (70.315)\n",
      "\n",
      "Prec@5 91.667 (90.091)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.108 (0.341)\n",
      "\n",
      "Loss 1.8011 (1.5396)\n",
      "\n",
      "Prec@1 66.667 (69.214)\n",
      "\n",
      "Prec@5 91.667 (90.144)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [14][0/1334]\t\\Time 0.318 (0.318)\tData 0.262 (0.262)\tLoss 0.0252 (0.0252)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1334]\t\\Time 0.237 (0.328)\tData 0.208 (0.294)\tLoss 0.0443 (0.0188)\tPrec@1 100.000 (99.917)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/1334]\t\\Time 0.266 (0.309)\tData 0.229 (0.276)\tLoss 0.0073 (0.0274)\tPrec@1 100.000 (99.461)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][300/1334]\t\\Time 0.348 (0.307)\tData 0.315 (0.275)\tLoss 0.0438 (0.0322)\tPrec@1 100.000 (99.225)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][400/1334]\t\\Time 0.348 (0.306)\tData 0.313 (0.274)\tLoss 0.0004 (0.0316)\tPrec@1 100.000 (99.148)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][500/1334]\t\\Time 0.288 (0.304)\tData 0.253 (0.271)\tLoss 0.0482 (0.0311)\tPrec@1 100.000 (99.218)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][600/1334]\t\\Time 0.345 (0.310)\tData 0.311 (0.277)\tLoss 0.0119 (0.0312)\tPrec@1 100.000 (99.196)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][700/1334]\t\\Time 0.291 (0.307)\tData 0.262 (0.275)\tLoss 0.1842 (0.0319)\tPrec@1 91.667 (99.192)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][800/1334]\t\\Time 0.261 (0.306)\tData 0.230 (0.274)\tLoss 0.0048 (0.0318)\tPrec@1 100.000 (99.209)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][900/1334]\t\\Time 0.243 (0.309)\tData 0.214 (0.276)\tLoss 0.0431 (0.0335)\tPrec@1 100.000 (99.177)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.281 (0.308)\tData 0.253 (0.275)\tLoss 0.0082 (0.0332)\tPrec@1 100.000 (99.192)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.274 (0.307)\tData 0.241 (0.274)\tLoss 0.0664 (0.0341)\tPrec@1 100.000 (99.152)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.286 (0.305)\tData 0.253 (0.272)\tLoss 0.0205 (0.0349)\tPrec@1 100.000 (99.112)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.322 (0.306)\tData 0.294 (0.274)\tLoss 0.0031 (0.0356)\tPrec@1 100.000 (99.116)\tPrec@5 100.000 (99.987)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.283 (0.283)\n",
      "\n",
      "Loss 0.7842 (0.7842)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.426 (0.390)\n",
      "\n",
      "Loss 2.4813 (1.3845)\n",
      "\n",
      "Prec@1 66.667 (72.525)\n",
      "\n",
      "Prec@5 83.333 (90.512)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.108 (0.360)\n",
      "\n",
      "Loss 1.5532 (1.4438)\n",
      "\n",
      "Prec@1 75.000 (71.103)\n",
      "\n",
      "Prec@5 91.667 (90.008)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.121 (0.338)\n",
      "\n",
      "Loss 1.2236 (1.4916)\n",
      "\n",
      "Prec@1 75.000 (69.934)\n",
      "\n",
      "Prec@5 91.667 (90.089)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Adjusted Learning rate resume from best model\n",
      "=> loading checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet101_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 15)\n",
      "Epoch: [15][0/1334]\t\\Time 0.346 (0.346)\tData 0.292 (0.292)\tLoss 0.0046 (0.0046)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.313 (0.332)\tData 0.282 (0.299)\tLoss 0.0121 (0.0306)\tPrec@1 100.000 (98.927)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/1334]\t\\Time 0.305 (0.332)\tData 0.275 (0.299)\tLoss 0.0171 (0.0306)\tPrec@1 100.000 (99.005)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/1334]\t\\Time 0.300 (0.324)\tData 0.269 (0.291)\tLoss 0.0010 (0.0286)\tPrec@1 100.000 (99.225)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][400/1334]\t\\Time 0.299 (0.335)\tData 0.268 (0.301)\tLoss 0.0133 (0.0273)\tPrec@1 100.000 (99.293)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][500/1334]\t\\Time 0.295 (0.335)\tData 0.265 (0.301)\tLoss 0.0121 (0.0266)\tPrec@1 100.000 (99.385)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][600/1334]\t\\Time 0.433 (0.343)\tData 0.402 (0.309)\tLoss 0.0564 (0.0260)\tPrec@1 100.000 (99.418)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][700/1334]\t\\Time 0.275 (0.347)\tData 0.244 (0.312)\tLoss 0.0027 (0.0256)\tPrec@1 100.000 (99.429)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][800/1334]\t\\Time 0.328 (0.345)\tData 0.297 (0.310)\tLoss 0.0161 (0.0255)\tPrec@1 100.000 (99.428)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][900/1334]\t\\Time 0.333 (0.342)\tData 0.301 (0.307)\tLoss 0.0330 (0.0262)\tPrec@1 100.000 (99.408)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.316 (0.339)\tData 0.284 (0.304)\tLoss 0.0839 (0.0271)\tPrec@1 100.000 (99.401)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.342 (0.338)\tData 0.308 (0.304)\tLoss 0.0083 (0.0273)\tPrec@1 100.000 (99.364)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.331 (0.337)\tData 0.300 (0.303)\tLoss 0.0346 (0.0276)\tPrec@1 100.000 (99.369)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.275 (0.335)\tData 0.245 (0.301)\tLoss 0.0131 (0.0277)\tPrec@1 100.000 (99.353)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.292 (0.292)\n",
      "\n",
      "Loss 0.9953 (0.9953)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.843 (0.412)\n",
      "\n",
      "Loss 2.3918 (1.4242)\n",
      "\n",
      "Prec@1 75.000 (72.195)\n",
      "\n",
      "Prec@5 83.333 (91.254)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.164 (0.378)\n",
      "\n",
      "Loss 1.5623 (1.4812)\n",
      "\n",
      "Prec@1 75.000 (71.144)\n",
      "\n",
      "Prec@5 91.667 (90.464)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.122 (0.352)\n",
      "\n",
      "Loss 1.2820 (1.5149)\n",
      "\n",
      "Prec@1 75.000 (70.072)\n",
      "\n",
      "Prec@5 91.667 (90.532)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Epoch: [16][0/1334]\t\\Time 0.404 (0.404)\tData 0.311 (0.311)\tLoss 0.0194 (0.0194)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.304 (0.319)\tData 0.272 (0.286)\tLoss 0.0473 (0.0244)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/1334]\t\\Time 0.226 (0.315)\tData 0.196 (0.282)\tLoss 0.0051 (0.0237)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [16][300/1334]\t\\Time 0.404 (0.326)\tData 0.370 (0.293)\tLoss 0.0042 (0.0254)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [16][400/1334]\t\\Time 0.329 (0.336)\tData 0.295 (0.302)\tLoss 0.0114 (0.0267)\tPrec@1 100.000 (99.439)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][500/1334]\t\\Time 0.342 (0.361)\tData 0.308 (0.325)\tLoss 0.0027 (0.0253)\tPrec@1 100.000 (99.468)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [16][600/1334]\t\\Time 0.345 (0.360)\tData 0.309 (0.324)\tLoss 0.0330 (0.0272)\tPrec@1 100.000 (99.418)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [16][700/1334]\t\\Time 0.241 (0.356)\tData 0.209 (0.321)\tLoss 0.0116 (0.0269)\tPrec@1 100.000 (99.417)\tPrec@5 100.000 (99.976)\n",
      "Epoch: [16][800/1334]\t\\Time 0.320 (0.356)\tData 0.286 (0.320)\tLoss 0.0057 (0.0275)\tPrec@1 100.000 (99.397)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][900/1334]\t\\Time 0.252 (0.354)\tData 0.217 (0.319)\tLoss 0.0248 (0.0267)\tPrec@1 100.000 (99.427)\tPrec@5 100.000 (99.982)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.377 (0.352)\tData 0.344 (0.317)\tLoss 0.0427 (0.0262)\tPrec@1 100.000 (99.442)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.285 (0.349)\tData 0.257 (0.314)\tLoss 0.0153 (0.0264)\tPrec@1 100.000 (99.440)\tPrec@5 100.000 (99.985)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.312 (0.347)\tData 0.280 (0.313)\tLoss 0.0199 (0.0262)\tPrec@1 100.000 (99.452)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.307 (0.345)\tData 0.275 (0.311)\tLoss 0.0268 (0.0261)\tPrec@1 100.000 (99.449)\tPrec@5 100.000 (99.981)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.594 (0.594)\n",
      "\n",
      "Loss 0.6903 (0.6903)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.424 (0.430)\n",
      "\n",
      "Loss 2.7134 (1.4368)\n",
      "\n",
      "Prec@1 75.000 (73.102)\n",
      "\n",
      "Prec@5 83.333 (91.007)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.119 (0.402)\n",
      "\n",
      "Loss 1.6344 (1.5093)\n",
      "\n",
      "Prec@1 75.000 (71.476)\n",
      "\n",
      "Prec@5 91.667 (90.547)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.124 (0.371)\n",
      "\n",
      "Loss 1.4626 (1.5465)\n",
      "\n",
      "Prec@1 66.667 (70.460)\n",
      "\n",
      "Prec@5 91.667 (90.615)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# model = torchvision.models.vgg16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    " \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    \n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "        \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            print('Adjusted Learning rate resume from best model')\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.location_fc2.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.location_fc.parameters():\n",
    "#     param.requires_grad = True   \n",
    "# for param in model.linear_add.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2145859e-c5e2-46e6-aaad-3b741101643b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [0][0/1334]\t\\Time 5.086 (5.086)\tData 4.428 (4.428)\tLoss 4.7167 (4.7167)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/1334]\t\\Time 0.321 (0.347)\tData 0.271 (0.287)\tLoss 4.6161 (4.6231)\tPrec@1 0.000 (1.073)\tPrec@5 16.667 (5.693)\n",
      "Epoch: [0][200/1334]\t\\Time 0.375 (0.329)\tData 0.322 (0.272)\tLoss 4.5833 (4.6158)\tPrec@1 0.000 (1.202)\tPrec@5 8.333 (5.680)\n",
      "Epoch: [0][300/1334]\t\\Time 0.366 (0.327)\tData 0.307 (0.272)\tLoss 4.5972 (4.6150)\tPrec@1 8.333 (1.246)\tPrec@5 16.667 (5.537)\n",
      "Epoch: [0][400/1334]\t\\Time 0.280 (0.326)\tData 0.230 (0.271)\tLoss 4.6235 (4.6135)\tPrec@1 0.000 (1.060)\tPrec@5 0.000 (5.237)\n",
      "Epoch: [0][500/1334]\t\\Time 0.304 (0.327)\tData 0.255 (0.272)\tLoss 4.6412 (4.6085)\tPrec@1 0.000 (1.031)\tPrec@5 0.000 (5.539)\n",
      "Epoch: [0][600/1334]\t\\Time 0.345 (0.325)\tData 0.292 (0.271)\tLoss 4.5959 (4.6032)\tPrec@1 0.000 (1.248)\tPrec@5 0.000 (6.240)\n",
      "Epoch: [0][700/1334]\t\\Time 0.340 (0.325)\tData 0.280 (0.271)\tLoss 4.5854 (4.6049)\tPrec@1 0.000 (1.213)\tPrec@5 8.333 (6.110)\n",
      "Epoch: [0][800/1334]\t\\Time 0.390 (0.325)\tData 0.340 (0.270)\tLoss 4.4706 (4.5998)\tPrec@1 0.000 (1.259)\tPrec@5 8.333 (6.232)\n",
      "Epoch: [0][900/1334]\t\\Time 0.381 (0.324)\tData 0.331 (0.270)\tLoss 4.6504 (4.5970)\tPrec@1 0.000 (1.286)\tPrec@5 0.000 (6.363)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.384 (0.328)\tData 0.330 (0.274)\tLoss 4.5528 (4.5886)\tPrec@1 0.000 (1.374)\tPrec@5 0.000 (6.760)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.321 (0.333)\tData 0.261 (0.279)\tLoss 4.3499 (4.5814)\tPrec@1 0.000 (1.453)\tPrec@5 8.333 (7.054)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.331 (0.333)\tData 0.281 (0.279)\tLoss 4.4550 (4.5670)\tPrec@1 0.000 (1.582)\tPrec@5 8.333 (7.466)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.351 (0.332)\tData 0.291 (0.278)\tLoss 4.1125 (4.5502)\tPrec@1 8.333 (1.832)\tPrec@5 33.333 (8.180)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.379 (0.379)\n",
      "\n",
      "Loss 4.3636 (4.3636)\n",
      "\n",
      "Prec@1 0.000 (0.000)\n",
      "\n",
      "Prec@5 16.667 (16.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.344 (0.344)\n",
      "\n",
      "Loss 4.2683 (4.3240)\n",
      "\n",
      "Prec@1 16.667 (4.538)\n",
      "\n",
      "Prec@5 16.667 (15.759)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.320 (0.346)\n",
      "\n",
      "Loss 4.3559 (4.3427)\n",
      "\n",
      "Prec@1 0.000 (4.436)\n",
      "\n",
      "Prec@5 8.333 (15.216)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.310 (0.345)\n",
      "\n",
      "Loss 4.2801 (4.3380)\n",
      "\n",
      "Prec@1 8.333 (4.679)\n",
      "\n",
      "Prec@5 16.667 (15.753)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/1334]\t\\Time 0.421 (0.421)\tData 0.251 (0.251)\tLoss 4.2510 (4.2510)\tPrec@1 8.333 (8.333)\tPrec@5 25.000 (25.000)\n",
      "Epoch: [1][100/1334]\t\\Time 0.360 (0.325)\tData 0.310 (0.271)\tLoss 4.2966 (4.2872)\tPrec@1 0.000 (4.703)\tPrec@5 25.000 (18.152)\n",
      "Epoch: [1][200/1334]\t\\Time 0.341 (0.319)\tData 0.290 (0.266)\tLoss 4.2936 (4.2417)\tPrec@1 0.000 (4.561)\tPrec@5 16.667 (18.864)\n",
      "Epoch: [1][300/1334]\t\\Time 0.316 (0.318)\tData 0.260 (0.264)\tLoss 3.7352 (4.1960)\tPrec@1 16.667 (4.956)\tPrec@5 33.333 (20.349)\n",
      "Epoch: [1][400/1334]\t\\Time 0.361 (0.317)\tData 0.311 (0.264)\tLoss 4.4451 (4.1303)\tPrec@1 8.333 (5.860)\tPrec@5 16.667 (22.423)\n",
      "Epoch: [1][500/1334]\t\\Time 0.250 (0.317)\tData 0.190 (0.264)\tLoss 3.9169 (4.0745)\tPrec@1 0.000 (6.337)\tPrec@5 25.000 (24.135)\n",
      "Epoch: [1][600/1334]\t\\Time 0.252 (0.317)\tData 0.202 (0.263)\tLoss 3.8271 (4.0365)\tPrec@1 8.333 (6.586)\tPrec@5 25.000 (25.361)\n",
      "Epoch: [1][700/1334]\t\\Time 0.300 (0.316)\tData 0.246 (0.263)\tLoss 4.0451 (3.9965)\tPrec@1 8.333 (6.954)\tPrec@5 25.000 (26.522)\n",
      "Epoch: [1][800/1334]\t\\Time 0.270 (0.316)\tData 0.220 (0.263)\tLoss 3.7644 (3.9680)\tPrec@1 0.000 (7.314)\tPrec@5 33.333 (27.528)\n",
      "Epoch: [1][900/1334]\t\\Time 0.280 (0.316)\tData 0.220 (0.263)\tLoss 3.4532 (3.9317)\tPrec@1 8.333 (7.695)\tPrec@5 50.000 (28.829)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.335 (0.317)\tData 0.282 (0.264)\tLoss 3.7449 (3.9040)\tPrec@1 16.667 (8.200)\tPrec@5 41.667 (29.695)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.324 (0.317)\tData 0.270 (0.264)\tLoss 3.9742 (3.8674)\tPrec@1 8.333 (8.644)\tPrec@5 25.000 (30.828)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.310 (0.318)\tData 0.250 (0.264)\tLoss 3.0943 (3.8427)\tPrec@1 33.333 (8.986)\tPrec@5 50.000 (31.661)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.272 (0.318)\tData 0.222 (0.264)\tLoss 3.1969 (3.8116)\tPrec@1 8.333 (9.211)\tPrec@5 33.333 (32.565)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.355 (0.355)\n",
      "\n",
      "Loss 3.3289 (3.3289)\n",
      "\n",
      "Prec@1 16.667 (16.667)\n",
      "\n",
      "Prec@5 41.667 (41.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.370 (0.345)\n",
      "\n",
      "Loss 2.9648 (3.3317)\n",
      "\n",
      "Prec@1 0.000 (15.594)\n",
      "\n",
      "Prec@5 58.333 (45.875)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.320 (0.349)\n",
      "\n",
      "Loss 3.2290 (3.3314)\n",
      "\n",
      "Prec@1 25.000 (16.003)\n",
      "\n",
      "Prec@5 50.000 (46.642)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.300 (0.348)\n",
      "\n",
      "Loss 3.2928 (3.3413)\n",
      "\n",
      "Prec@1 16.667 (15.698)\n",
      "\n",
      "Prec@5 41.667 (46.346)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1334]\t\\Time 0.351 (0.351)\tData 0.181 (0.181)\tLoss 3.5425 (3.5425)\tPrec@1 8.333 (8.333)\tPrec@5 16.667 (16.667)\n",
      "Epoch: [2][100/1334]\t\\Time 0.343 (0.316)\tData 0.289 (0.261)\tLoss 3.7656 (3.4023)\tPrec@1 8.333 (15.099)\tPrec@5 41.667 (45.792)\n",
      "Epoch: [2][200/1334]\t\\Time 0.270 (0.316)\tData 0.220 (0.263)\tLoss 3.3463 (3.3927)\tPrec@1 0.000 (15.630)\tPrec@5 41.667 (46.103)\n",
      "Epoch: [2][300/1334]\t\\Time 0.375 (0.317)\tData 0.320 (0.263)\tLoss 3.1546 (3.3766)\tPrec@1 16.667 (15.919)\tPrec@5 58.333 (46.733)\n",
      "Epoch: [2][400/1334]\t\\Time 0.345 (0.316)\tData 0.300 (0.262)\tLoss 3.0639 (3.3862)\tPrec@1 16.667 (16.168)\tPrec@5 66.667 (46.737)\n",
      "Epoch: [2][500/1334]\t\\Time 0.323 (0.316)\tData 0.273 (0.262)\tLoss 3.5971 (3.3834)\tPrec@1 8.333 (15.985)\tPrec@5 25.000 (46.557)\n",
      "Epoch: [2][600/1334]\t\\Time 0.399 (0.316)\tData 0.344 (0.262)\tLoss 3.4765 (3.3888)\tPrec@1 0.000 (15.835)\tPrec@5 41.667 (46.076)\n",
      "Epoch: [2][700/1334]\t\\Time 0.261 (0.316)\tData 0.221 (0.263)\tLoss 3.7613 (3.3722)\tPrec@1 8.333 (16.262)\tPrec@5 25.000 (46.493)\n",
      "Epoch: [2][800/1334]\t\\Time 0.300 (0.317)\tData 0.241 (0.263)\tLoss 3.4105 (3.3593)\tPrec@1 16.667 (16.635)\tPrec@5 41.667 (46.879)\n",
      "Epoch: [2][900/1334]\t\\Time 0.366 (0.317)\tData 0.314 (0.263)\tLoss 3.1405 (3.3466)\tPrec@1 0.000 (16.741)\tPrec@5 50.000 (47.355)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.331 (0.316)\tData 0.281 (0.263)\tLoss 3.7411 (3.3327)\tPrec@1 8.333 (17.000)\tPrec@5 33.333 (47.644)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.290 (0.316)\tData 0.241 (0.263)\tLoss 3.3058 (3.3145)\tPrec@1 8.333 (17.348)\tPrec@5 58.333 (48.221)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.341 (0.316)\tData 0.291 (0.263)\tLoss 2.4630 (3.3003)\tPrec@1 8.333 (17.603)\tPrec@5 83.333 (48.598)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.281 (0.316)\tData 0.231 (0.263)\tLoss 2.8899 (3.2922)\tPrec@1 25.000 (17.730)\tPrec@5 75.000 (48.847)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 2.9904 (2.9904)\n",
      "\n",
      "Prec@1 16.667 (16.667)\n",
      "\n",
      "Prec@5 50.000 (50.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.332 (0.346)\n",
      "\n",
      "Loss 3.1325 (3.4579)\n",
      "\n",
      "Prec@1 8.333 (16.997)\n",
      "\n",
      "Prec@5 58.333 (48.185)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.332 (0.347)\n",
      "\n",
      "Loss 3.2778 (3.4215)\n",
      "\n",
      "Prec@1 8.333 (17.081)\n",
      "\n",
      "Prec@5 41.667 (48.964)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.312 (0.346)\n",
      "\n",
      "Loss 3.8303 (3.4263)\n",
      "\n",
      "Prec@1 25.000 (16.833)\n",
      "\n",
      "Prec@5 50.000 (48.616)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1334]\t\\Time 0.407 (0.407)\tData 0.236 (0.236)\tLoss 3.4408 (3.4408)\tPrec@1 0.000 (0.000)\tPrec@5 58.333 (58.333)\n",
      "Epoch: [3][100/1334]\t\\Time 0.291 (0.322)\tData 0.241 (0.268)\tLoss 2.9163 (3.0792)\tPrec@1 8.333 (21.865)\tPrec@5 66.667 (55.116)\n",
      "Epoch: [3][200/1334]\t\\Time 0.295 (0.321)\tData 0.250 (0.268)\tLoss 2.6454 (3.0333)\tPrec@1 25.000 (23.010)\tPrec@5 75.000 (55.929)\n",
      "Epoch: [3][300/1334]\t\\Time 0.298 (0.320)\tData 0.248 (0.267)\tLoss 2.8783 (3.0207)\tPrec@1 33.333 (22.647)\tPrec@5 58.333 (56.257)\n",
      "Epoch: [3][400/1334]\t\\Time 0.304 (0.319)\tData 0.253 (0.265)\tLoss 2.3326 (3.0037)\tPrec@1 16.667 (22.943)\tPrec@5 83.333 (56.712)\n",
      "Epoch: [3][500/1334]\t\\Time 0.299 (0.319)\tData 0.242 (0.266)\tLoss 3.9799 (3.0046)\tPrec@1 8.333 (22.971)\tPrec@5 16.667 (56.653)\n",
      "Epoch: [3][600/1334]\t\\Time 0.249 (0.318)\tData 0.196 (0.264)\tLoss 2.8441 (2.9988)\tPrec@1 8.333 (23.211)\tPrec@5 75.000 (56.877)\n",
      "Epoch: [3][700/1334]\t\\Time 0.312 (0.318)\tData 0.262 (0.264)\tLoss 2.5865 (2.9785)\tPrec@1 25.000 (23.419)\tPrec@5 50.000 (57.454)\n",
      "Epoch: [3][800/1334]\t\\Time 0.291 (0.318)\tData 0.231 (0.265)\tLoss 4.1938 (2.9785)\tPrec@1 8.333 (23.627)\tPrec@5 16.667 (57.595)\n",
      "Epoch: [3][900/1334]\t\\Time 0.307 (0.318)\tData 0.251 (0.265)\tLoss 2.5269 (2.9658)\tPrec@1 33.333 (23.724)\tPrec@5 75.000 (57.936)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.322 (0.318)\tData 0.272 (0.265)\tLoss 3.6658 (2.9573)\tPrec@1 8.333 (23.859)\tPrec@5 41.667 (58.308)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.294 (0.318)\tData 0.241 (0.265)\tLoss 2.3224 (2.9489)\tPrec@1 25.000 (24.031)\tPrec@5 83.333 (58.364)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.362 (0.318)\tData 0.305 (0.265)\tLoss 2.5875 (2.9446)\tPrec@1 33.333 (24.320)\tPrec@5 75.000 (58.410)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.291 (0.318)\tData 0.241 (0.265)\tLoss 2.8032 (2.9456)\tPrec@1 25.000 (24.219)\tPrec@5 66.667 (58.378)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.319 (0.319)\n",
      "\n",
      "Loss 2.8028 (2.8028)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 50.000 (50.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.347 (0.345)\n",
      "\n",
      "Loss 1.5321 (2.7475)\n",
      "\n",
      "Prec@1 66.667 (26.568)\n",
      "\n",
      "Prec@5 75.000 (62.954)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.342 (0.347)\n",
      "\n",
      "Loss 2.8533 (2.7522)\n",
      "\n",
      "Prec@1 16.667 (27.695)\n",
      "\n",
      "Prec@5 50.000 (62.231)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.320 (0.347)\n",
      "\n",
      "Loss 3.5285 (2.7627)\n",
      "\n",
      "Prec@1 8.333 (27.575)\n",
      "\n",
      "Prec@5 41.667 (62.292)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1334]\t\\Time 0.321 (0.321)\tData 0.180 (0.180)\tLoss 2.6786 (2.6786)\tPrec@1 25.000 (25.000)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [4][100/1334]\t\\Time 0.354 (0.352)\tData 0.294 (0.297)\tLoss 2.9391 (2.6707)\tPrec@1 16.667 (28.465)\tPrec@5 75.000 (64.934)\n",
      "Epoch: [4][200/1334]\t\\Time 0.427 (0.346)\tData 0.375 (0.292)\tLoss 2.5254 (2.7001)\tPrec@1 16.667 (28.192)\tPrec@5 66.667 (65.755)\n",
      "Epoch: [4][300/1334]\t\\Time 0.342 (0.337)\tData 0.291 (0.283)\tLoss 2.0039 (2.7209)\tPrec@1 33.333 (28.212)\tPrec@5 83.333 (64.784)\n",
      "Epoch: [4][400/1334]\t\\Time 0.368 (0.333)\tData 0.318 (0.279)\tLoss 3.0327 (2.7185)\tPrec@1 16.667 (28.221)\tPrec@5 58.333 (64.547)\n",
      "Epoch: [4][500/1334]\t\\Time 0.222 (0.330)\tData 0.160 (0.276)\tLoss 3.5969 (2.7491)\tPrec@1 16.667 (28.027)\tPrec@5 41.667 (63.739)\n",
      "Epoch: [4][600/1334]\t\\Time 0.290 (0.327)\tData 0.250 (0.274)\tLoss 2.8266 (2.7706)\tPrec@1 41.667 (27.759)\tPrec@5 50.000 (63.034)\n",
      "Epoch: [4][700/1334]\t\\Time 0.310 (0.326)\tData 0.260 (0.273)\tLoss 1.9687 (2.7715)\tPrec@1 41.667 (27.972)\tPrec@5 75.000 (63.029)\n",
      "Epoch: [4][800/1334]\t\\Time 0.345 (0.325)\tData 0.291 (0.272)\tLoss 2.4254 (2.7681)\tPrec@1 41.667 (27.903)\tPrec@5 58.333 (63.109)\n",
      "Epoch: [4][900/1334]\t\\Time 0.270 (0.325)\tData 0.220 (0.271)\tLoss 2.6184 (2.7725)\tPrec@1 25.000 (27.960)\tPrec@5 75.000 (63.050)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.300 (0.324)\tData 0.250 (0.271)\tLoss 2.0432 (2.7790)\tPrec@1 41.667 (27.889)\tPrec@5 83.333 (62.796)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.390 (0.323)\tData 0.340 (0.270)\tLoss 2.8285 (2.7712)\tPrec@1 25.000 (28.171)\tPrec@5 66.667 (62.875)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.342 (0.322)\tData 0.280 (0.269)\tLoss 3.7769 (2.7692)\tPrec@1 0.000 (28.143)\tPrec@5 50.000 (62.934)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.350 (0.321)\tData 0.300 (0.268)\tLoss 3.0005 (2.7759)\tPrec@1 25.000 (28.094)\tPrec@5 58.333 (62.715)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.337 (0.337)\n",
      "\n",
      "Loss 2.6532 (2.6532)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.350 (0.343)\n",
      "\n",
      "Loss 1.9299 (2.7391)\n",
      "\n",
      "Prec@1 50.000 (28.630)\n",
      "\n",
      "Prec@5 83.333 (63.449)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.311 (0.343)\n",
      "\n",
      "Loss 2.3225 (2.7201)\n",
      "\n",
      "Prec@1 50.000 (29.892)\n",
      "\n",
      "Prec@5 75.000 (62.894)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.344)\n",
      "\n",
      "Loss 2.9855 (2.7369)\n",
      "\n",
      "Prec@1 0.000 (29.291)\n",
      "\n",
      "Prec@5 58.333 (62.957)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1334]\t\\Time 0.401 (0.401)\tData 0.261 (0.261)\tLoss 2.5993 (2.5993)\tPrec@1 41.667 (41.667)\tPrec@5 66.667 (66.667)\n",
      "Epoch: [5][100/1334]\t\\Time 0.383 (0.319)\tData 0.333 (0.265)\tLoss 1.7054 (2.4824)\tPrec@1 50.000 (35.479)\tPrec@5 83.333 (68.069)\n",
      "Epoch: [5][200/1334]\t\\Time 0.358 (0.318)\tData 0.308 (0.265)\tLoss 1.8217 (2.5271)\tPrec@1 41.667 (33.914)\tPrec@5 75.000 (67.413)\n",
      "Epoch: [5][300/1334]\t\\Time 0.247 (0.315)\tData 0.190 (0.262)\tLoss 3.6606 (2.5356)\tPrec@1 16.667 (33.610)\tPrec@5 33.333 (67.525)\n",
      "Epoch: [5][400/1334]\t\\Time 0.322 (0.313)\tData 0.262 (0.260)\tLoss 2.7495 (2.5235)\tPrec@1 25.000 (33.375)\tPrec@5 66.667 (67.685)\n",
      "Epoch: [5][500/1334]\t\\Time 0.341 (0.313)\tData 0.290 (0.260)\tLoss 2.2735 (2.5449)\tPrec@1 25.000 (33.184)\tPrec@5 66.667 (67.382)\n",
      "Epoch: [5][600/1334]\t\\Time 0.352 (0.313)\tData 0.290 (0.260)\tLoss 2.5661 (2.5426)\tPrec@1 33.333 (33.306)\tPrec@5 66.667 (67.485)\n",
      "Epoch: [5][700/1334]\t\\Time 0.302 (0.315)\tData 0.252 (0.262)\tLoss 2.7994 (2.5526)\tPrec@1 25.000 (32.953)\tPrec@5 50.000 (67.677)\n",
      "Epoch: [5][800/1334]\t\\Time 0.266 (0.314)\tData 0.214 (0.262)\tLoss 2.8731 (2.5534)\tPrec@1 25.000 (32.969)\tPrec@5 66.667 (67.343)\n",
      "Epoch: [5][900/1334]\t\\Time 0.283 (0.315)\tData 0.233 (0.262)\tLoss 1.5093 (2.5432)\tPrec@1 58.333 (33.102)\tPrec@5 83.333 (67.656)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.284 (0.316)\tData 0.230 (0.263)\tLoss 2.7007 (2.5466)\tPrec@1 16.667 (33.025)\tPrec@5 58.333 (67.557)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.370 (0.316)\tData 0.310 (0.263)\tLoss 2.2655 (2.5486)\tPrec@1 50.000 (32.970)\tPrec@5 75.000 (67.757)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.356 (0.316)\tData 0.303 (0.264)\tLoss 2.8842 (2.5592)\tPrec@1 8.333 (32.862)\tPrec@5 66.667 (67.472)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.331 (0.316)\tData 0.281 (0.263)\tLoss 2.9112 (2.5669)\tPrec@1 25.000 (32.808)\tPrec@5 33.333 (67.314)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.336 (0.336)\n",
      "\n",
      "Loss 2.9355 (2.9355)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 50.000 (50.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.331 (0.344)\n",
      "\n",
      "Loss 2.8917 (2.7483)\n",
      "\n",
      "Prec@1 16.667 (30.611)\n",
      "\n",
      "Prec@5 58.333 (61.964)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.335 (0.345)\n",
      "\n",
      "Loss 1.7650 (2.7300)\n",
      "\n",
      "Prec@1 50.000 (31.136)\n",
      "\n",
      "Prec@5 83.333 (62.438)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.293 (0.344)\n",
      "\n",
      "Loss 2.7719 (2.7319)\n",
      "\n",
      "Prec@1 16.667 (31.008)\n",
      "\n",
      "Prec@5 58.333 (62.458)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1334]\t\\Time 0.453 (0.453)\tData 0.291 (0.291)\tLoss 2.9780 (2.9780)\tPrec@1 33.333 (33.333)\tPrec@5 58.333 (58.333)\n",
      "Epoch: [6][100/1334]\t\\Time 0.262 (0.321)\tData 0.210 (0.266)\tLoss 2.1363 (2.4514)\tPrec@1 33.333 (36.304)\tPrec@5 83.333 (69.884)\n",
      "Epoch: [6][200/1334]\t\\Time 0.282 (0.319)\tData 0.222 (0.266)\tLoss 2.3432 (2.3412)\tPrec@1 33.333 (38.474)\tPrec@5 83.333 (71.227)\n",
      "Epoch: [6][300/1334]\t\\Time 0.300 (0.318)\tData 0.244 (0.264)\tLoss 2.0329 (2.3685)\tPrec@1 50.000 (37.209)\tPrec@5 66.667 (71.041)\n",
      "Epoch: [6][400/1334]\t\\Time 0.350 (0.315)\tData 0.303 (0.262)\tLoss 2.6305 (2.3530)\tPrec@1 16.667 (37.677)\tPrec@5 66.667 (71.363)\n",
      "Epoch: [6][500/1334]\t\\Time 0.291 (0.314)\tData 0.241 (0.261)\tLoss 1.5595 (2.3606)\tPrec@1 41.667 (37.575)\tPrec@5 100.000 (71.257)\n",
      "Epoch: [6][600/1334]\t\\Time 0.272 (0.315)\tData 0.219 (0.262)\tLoss 2.9036 (2.3769)\tPrec@1 33.333 (37.465)\tPrec@5 50.000 (71.048)\n",
      "Epoch: [6][700/1334]\t\\Time 0.244 (0.316)\tData 0.190 (0.263)\tLoss 2.5722 (2.3949)\tPrec@1 50.000 (37.114)\tPrec@5 66.667 (70.685)\n",
      "Epoch: [6][800/1334]\t\\Time 0.257 (0.315)\tData 0.202 (0.262)\tLoss 2.3198 (2.3957)\tPrec@1 33.333 (37.079)\tPrec@5 66.667 (70.766)\n",
      "Epoch: [6][900/1334]\t\\Time 0.385 (0.316)\tData 0.321 (0.263)\tLoss 3.0802 (2.3931)\tPrec@1 33.333 (37.070)\tPrec@5 58.333 (70.745)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.318 (0.316)\tData 0.257 (0.263)\tLoss 1.6346 (2.3964)\tPrec@1 41.667 (36.822)\tPrec@5 83.333 (70.721)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.299 (0.316)\tData 0.242 (0.263)\tLoss 2.0907 (2.4126)\tPrec@1 50.000 (36.474)\tPrec@5 83.333 (70.421)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.291 (0.316)\tData 0.234 (0.263)\tLoss 2.0186 (2.4143)\tPrec@1 33.333 (36.511)\tPrec@5 83.333 (70.351)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.364 (0.317)\tData 0.305 (0.264)\tLoss 2.5360 (2.4200)\tPrec@1 33.333 (36.485)\tPrec@5 66.667 (70.350)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.340 (0.340)\n",
      "\n",
      "Loss 2.3280 (2.3280)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.324 (0.345)\n",
      "\n",
      "Loss 2.0753 (2.6940)\n",
      "\n",
      "Prec@1 41.667 (29.620)\n",
      "\n",
      "Prec@5 66.667 (64.356)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.337 (0.348)\n",
      "\n",
      "Loss 2.9010 (2.6990)\n",
      "\n",
      "Prec@1 25.000 (30.597)\n",
      "\n",
      "Prec@5 41.667 (63.599)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.321 (0.347)\n",
      "\n",
      "Loss 3.1805 (2.7205)\n",
      "\n",
      "Prec@1 0.000 (30.066)\n",
      "\n",
      "Prec@5 58.333 (63.483)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1334]\t\\Time 0.426 (0.426)\tData 0.292 (0.292)\tLoss 2.1996 (2.1996)\tPrec@1 33.333 (33.333)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [7][100/1334]\t\\Time 0.355 (0.311)\tData 0.305 (0.258)\tLoss 1.7583 (2.0676)\tPrec@1 58.333 (44.884)\tPrec@5 66.667 (76.320)\n",
      "Epoch: [7][200/1334]\t\\Time 0.375 (0.313)\tData 0.320 (0.260)\tLoss 2.3787 (2.1514)\tPrec@1 25.000 (42.745)\tPrec@5 58.333 (75.788)\n",
      "Epoch: [7][300/1334]\t\\Time 0.261 (0.313)\tData 0.211 (0.260)\tLoss 1.9153 (2.1512)\tPrec@1 58.333 (42.553)\tPrec@5 83.333 (75.858)\n",
      "Epoch: [7][400/1334]\t\\Time 0.326 (0.313)\tData 0.281 (0.260)\tLoss 2.5813 (2.1639)\tPrec@1 25.000 (42.290)\tPrec@5 66.667 (75.686)\n",
      "Epoch: [7][500/1334]\t\\Time 0.244 (0.313)\tData 0.194 (0.260)\tLoss 1.8176 (2.1829)\tPrec@1 50.000 (41.850)\tPrec@5 91.667 (75.449)\n",
      "Epoch: [7][600/1334]\t\\Time 0.383 (0.314)\tData 0.331 (0.261)\tLoss 2.2935 (2.1987)\tPrec@1 41.667 (41.334)\tPrec@5 83.333 (74.931)\n",
      "Epoch: [7][700/1334]\t\\Time 0.345 (0.314)\tData 0.295 (0.261)\tLoss 2.0348 (2.2034)\tPrec@1 58.333 (41.144)\tPrec@5 66.667 (74.762)\n",
      "Epoch: [7][800/1334]\t\\Time 0.344 (0.317)\tData 0.294 (0.264)\tLoss 2.8188 (2.2195)\tPrec@1 16.667 (40.751)\tPrec@5 66.667 (74.345)\n",
      "Epoch: [7][900/1334]\t\\Time 0.361 (0.317)\tData 0.311 (0.264)\tLoss 2.1116 (2.2202)\tPrec@1 50.000 (40.696)\tPrec@5 75.000 (74.427)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.336 (0.317)\tData 0.277 (0.264)\tLoss 2.4667 (2.2205)\tPrec@1 16.667 (40.709)\tPrec@5 83.333 (74.401)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.401 (0.317)\tData 0.349 (0.264)\tLoss 2.5161 (2.2355)\tPrec@1 41.667 (40.486)\tPrec@5 66.667 (74.092)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.292 (0.318)\tData 0.242 (0.265)\tLoss 1.6758 (2.2407)\tPrec@1 50.000 (40.237)\tPrec@5 83.333 (74.036)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.301 (0.318)\tData 0.251 (0.264)\tLoss 2.6213 (2.2520)\tPrec@1 16.667 (39.969)\tPrec@5 83.333 (73.738)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.351 (0.351)\n",
      "\n",
      "Loss 2.6135 (2.6135)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.342 (0.348)\n",
      "\n",
      "Loss 1.9082 (2.5844)\n",
      "\n",
      "Prec@1 50.000 (31.353)\n",
      "\n",
      "Prec@5 83.333 (66.584)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.330 (0.347)\n",
      "\n",
      "Loss 2.2921 (2.5695)\n",
      "\n",
      "Prec@1 33.333 (32.255)\n",
      "\n",
      "Prec@5 66.667 (67.206)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.339 (0.346)\n",
      "\n",
      "Loss 3.0919 (2.5784)\n",
      "\n",
      "Prec@1 8.333 (32.558)\n",
      "\n",
      "Prec@5 58.333 (67.525)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1334]\t\\Time 0.422 (0.422)\tData 0.270 (0.270)\tLoss 1.6641 (1.6641)\tPrec@1 58.333 (58.333)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [8][100/1334]\t\\Time 0.322 (0.315)\tData 0.271 (0.262)\tLoss 1.8944 (1.8636)\tPrec@1 41.667 (49.587)\tPrec@5 66.667 (81.023)\n",
      "Epoch: [8][200/1334]\t\\Time 0.281 (0.318)\tData 0.229 (0.265)\tLoss 1.9172 (1.9558)\tPrec@1 33.333 (47.927)\tPrec@5 75.000 (78.400)\n",
      "Epoch: [8][300/1334]\t\\Time 0.272 (0.318)\tData 0.217 (0.264)\tLoss 2.2744 (1.9805)\tPrec@1 33.333 (47.315)\tPrec@5 91.667 (78.350)\n",
      "Epoch: [8][400/1334]\t\\Time 0.297 (0.318)\tData 0.244 (0.265)\tLoss 1.9527 (2.0009)\tPrec@1 41.667 (46.737)\tPrec@5 75.000 (77.660)\n",
      "Epoch: [8][500/1334]\t\\Time 0.290 (0.320)\tData 0.240 (0.267)\tLoss 2.8208 (2.0392)\tPrec@1 33.333 (45.542)\tPrec@5 58.333 (77.013)\n",
      "Epoch: [8][600/1334]\t\\Time 0.287 (0.321)\tData 0.237 (0.268)\tLoss 2.4414 (2.0379)\tPrec@1 41.667 (45.355)\tPrec@5 75.000 (77.246)\n",
      "Epoch: [8][700/1334]\t\\Time 0.366 (0.321)\tData 0.309 (0.267)\tLoss 2.2301 (2.0532)\tPrec@1 25.000 (44.864)\tPrec@5 75.000 (77.282)\n",
      "Epoch: [8][800/1334]\t\\Time 0.252 (0.321)\tData 0.193 (0.268)\tLoss 1.4650 (2.0564)\tPrec@1 50.000 (44.632)\tPrec@5 83.333 (77.289)\n",
      "Epoch: [8][900/1334]\t\\Time 0.281 (0.322)\tData 0.227 (0.269)\tLoss 2.4950 (2.0932)\tPrec@1 25.000 (44.044)\tPrec@5 66.667 (76.730)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.287 (0.323)\tData 0.237 (0.270)\tLoss 1.4739 (2.1206)\tPrec@1 50.000 (43.357)\tPrec@5 91.667 (76.299)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.372 (0.323)\tData 0.315 (0.270)\tLoss 2.5842 (2.1254)\tPrec@1 25.000 (43.067)\tPrec@5 66.667 (76.241)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.360 (0.323)\tData 0.306 (0.270)\tLoss 1.6295 (2.1331)\tPrec@1 41.667 (42.839)\tPrec@5 83.333 (76.089)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.409 (0.324)\tData 0.352 (0.271)\tLoss 3.1130 (2.1406)\tPrec@1 16.667 (42.666)\tPrec@5 50.000 (75.980)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.362 (0.362)\n",
      "\n",
      "Loss 2.5621 (2.5621)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 50.000 (50.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.334 (0.348)\n",
      "\n",
      "Loss 1.8932 (2.5333)\n",
      "\n",
      "Prec@1 50.000 (33.828)\n",
      "\n",
      "Prec@5 83.333 (68.317)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.316 (0.350)\n",
      "\n",
      "Loss 2.7367 (2.4926)\n",
      "\n",
      "Prec@1 58.333 (35.033)\n",
      "\n",
      "Prec@5 75.000 (68.532)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.323 (0.349)\n",
      "\n",
      "Loss 2.8836 (2.5172)\n",
      "\n",
      "Prec@1 50.000 (34.884)\n",
      "\n",
      "Prec@5 58.333 (67.636)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1334]\t\\Time 0.417 (0.417)\tData 0.265 (0.265)\tLoss 1.0590 (1.0590)\tPrec@1 91.667 (91.667)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [9][100/1334]\t\\Time 0.281 (0.320)\tData 0.228 (0.267)\tLoss 1.9010 (1.8394)\tPrec@1 58.333 (49.257)\tPrec@5 75.000 (82.178)\n",
      "Epoch: [9][200/1334]\t\\Time 0.319 (0.321)\tData 0.267 (0.267)\tLoss 1.7394 (1.8860)\tPrec@1 50.000 (48.507)\tPrec@5 75.000 (80.348)\n",
      "Epoch: [9][300/1334]\t\\Time 0.320 (0.322)\tData 0.270 (0.269)\tLoss 2.0826 (1.9356)\tPrec@1 33.333 (47.038)\tPrec@5 91.667 (79.319)\n",
      "Epoch: [9][400/1334]\t\\Time 0.259 (0.320)\tData 0.203 (0.267)\tLoss 2.0211 (1.9575)\tPrec@1 41.667 (46.841)\tPrec@5 100.000 (79.406)\n",
      "Epoch: [9][500/1334]\t\\Time 0.252 (0.322)\tData 0.201 (0.268)\tLoss 1.8632 (1.9770)\tPrec@1 41.667 (46.740)\tPrec@5 83.333 (79.325)\n",
      "Epoch: [9][600/1334]\t\\Time 0.302 (0.322)\tData 0.241 (0.269)\tLoss 0.9040 (1.9831)\tPrec@1 75.000 (46.534)\tPrec@5 91.667 (79.146)\n",
      "Epoch: [9][700/1334]\t\\Time 0.361 (0.322)\tData 0.307 (0.268)\tLoss 1.7052 (1.9902)\tPrec@1 41.667 (46.446)\tPrec@5 75.000 (79.030)\n",
      "Epoch: [9][800/1334]\t\\Time 0.438 (0.323)\tData 0.384 (0.269)\tLoss 1.9780 (1.9939)\tPrec@1 50.000 (46.359)\tPrec@5 66.667 (78.901)\n",
      "Epoch: [9][900/1334]\t\\Time 0.210 (0.323)\tData 0.140 (0.270)\tLoss 1.2002 (2.0083)\tPrec@1 58.333 (46.014)\tPrec@5 91.667 (78.496)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.374 (0.323)\tData 0.324 (0.270)\tLoss 1.1930 (2.0171)\tPrec@1 75.000 (45.871)\tPrec@5 100.000 (78.122)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.255 (0.323)\tData 0.200 (0.270)\tLoss 2.3460 (2.0322)\tPrec@1 41.667 (45.534)\tPrec@5 91.667 (77.891)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.316 (0.324)\tData 0.262 (0.270)\tLoss 2.0937 (2.0409)\tPrec@1 41.667 (45.309)\tPrec@5 75.000 (77.713)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.291 (0.323)\tData 0.241 (0.270)\tLoss 2.3611 (2.0422)\tPrec@1 25.000 (45.331)\tPrec@5 66.667 (77.645)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.341 (0.341)\n",
      "\n",
      "Loss 2.3964 (2.3964)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.343 (0.351)\n",
      "\n",
      "Loss 1.6101 (2.5929)\n",
      "\n",
      "Prec@1 41.667 (33.003)\n",
      "\n",
      "Prec@5 91.667 (66.832)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.310 (0.352)\n",
      "\n",
      "Loss 1.9714 (2.5833)\n",
      "\n",
      "Prec@1 33.333 (33.789)\n",
      "\n",
      "Prec@5 75.000 (67.662)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.310 (0.352)\n",
      "\n",
      "Loss 3.3461 (2.6110)\n",
      "\n",
      "Prec@1 16.667 (33.527)\n",
      "\n",
      "Prec@5 58.333 (67.303)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Adjusted Learning rate resume from best model\n",
      "=> loading checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 9)\n",
      "Epoch: [10][0/1334]\t\\Time 0.363 (0.363)\tData 0.281 (0.281)\tLoss 1.0727 (1.0727)\tPrec@1 66.667 (66.667)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [10][100/1334]\t\\Time 0.361 (0.314)\tData 0.311 (0.261)\tLoss 1.7048 (1.5384)\tPrec@1 50.000 (57.343)\tPrec@5 83.333 (86.304)\n",
      "Epoch: [10][200/1334]\t\\Time 0.264 (0.321)\tData 0.214 (0.268)\tLoss 1.2817 (1.4424)\tPrec@1 75.000 (60.033)\tPrec@5 83.333 (87.189)\n",
      "Epoch: [10][300/1334]\t\\Time 0.271 (0.318)\tData 0.217 (0.265)\tLoss 0.5472 (1.3627)\tPrec@1 83.333 (61.739)\tPrec@5 100.000 (87.846)\n",
      "Epoch: [10][400/1334]\t\\Time 0.346 (0.322)\tData 0.297 (0.269)\tLoss 0.9793 (1.3292)\tPrec@1 83.333 (62.406)\tPrec@5 100.000 (88.238)\n",
      "Epoch: [10][500/1334]\t\\Time 0.318 (0.322)\tData 0.269 (0.269)\tLoss 1.0424 (1.3037)\tPrec@1 66.667 (63.257)\tPrec@5 91.667 (88.390)\n",
      "Epoch: [10][600/1334]\t\\Time 0.295 (0.322)\tData 0.244 (0.270)\tLoss 0.9684 (1.2746)\tPrec@1 66.667 (64.088)\tPrec@5 91.667 (88.727)\n",
      "Epoch: [10][700/1334]\t\\Time 0.345 (0.322)\tData 0.294 (0.269)\tLoss 1.0682 (1.2502)\tPrec@1 58.333 (64.658)\tPrec@5 91.667 (88.909)\n",
      "Epoch: [10][800/1334]\t\\Time 0.346 (0.323)\tData 0.282 (0.270)\tLoss 1.3751 (1.2260)\tPrec@1 58.333 (65.345)\tPrec@5 83.333 (89.149)\n",
      "Epoch: [10][900/1334]\t\\Time 0.340 (0.322)\tData 0.295 (0.270)\tLoss 0.1922 (1.2161)\tPrec@1 91.667 (65.733)\tPrec@5 100.000 (89.169)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.251 (0.323)\tData 0.200 (0.270)\tLoss 0.3863 (1.2026)\tPrec@1 100.000 (66.034)\tPrec@5 100.000 (89.461)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.321 (0.323)\tData 0.269 (0.270)\tLoss 1.2807 (1.1842)\tPrec@1 58.333 (66.417)\tPrec@5 91.667 (89.790)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.392 (0.323)\tData 0.337 (0.271)\tLoss 0.5531 (1.1700)\tPrec@1 83.333 (66.819)\tPrec@5 91.667 (89.911)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.366 (0.324)\tData 0.313 (0.271)\tLoss 1.0852 (1.1577)\tPrec@1 75.000 (67.205)\tPrec@5 83.333 (90.123)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.343 (0.343)\n",
      "\n",
      "Loss 1.7182 (1.7182)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.328 (0.353)\n",
      "\n",
      "Loss 1.1566 (2.0415)\n",
      "\n",
      "Prec@1 66.667 (45.792)\n",
      "\n",
      "Prec@5 83.333 (77.970)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.354 (0.353)\n",
      "\n",
      "Loss 2.5379 (1.9951)\n",
      "\n",
      "Prec@1 50.000 (47.098)\n",
      "\n",
      "Prec@5 66.667 (78.109)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.291 (0.351)\n",
      "\n",
      "Loss 2.2136 (2.0023)\n",
      "\n",
      "Prec@1 50.000 (47.093)\n",
      "\n",
      "Prec@5 75.000 (77.962)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [11][0/1334]\t\\Time 0.438 (0.438)\tData 0.287 (0.287)\tLoss 0.9664 (0.9664)\tPrec@1 75.000 (75.000)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [11][100/1334]\t\\Time 0.267 (0.322)\tData 0.213 (0.267)\tLoss 0.5352 (0.7977)\tPrec@1 83.333 (78.218)\tPrec@5 100.000 (93.894)\n",
      "Epoch: [11][200/1334]\t\\Time 0.379 (0.321)\tData 0.323 (0.268)\tLoss 0.5694 (0.7941)\tPrec@1 83.333 (77.529)\tPrec@5 91.667 (94.113)\n",
      "Epoch: [11][300/1334]\t\\Time 0.363 (0.325)\tData 0.313 (0.272)\tLoss 0.4435 (0.7886)\tPrec@1 75.000 (77.353)\tPrec@5 100.000 (93.992)\n",
      "Epoch: [11][400/1334]\t\\Time 0.400 (0.323)\tData 0.349 (0.269)\tLoss 0.8926 (0.7818)\tPrec@1 75.000 (77.307)\tPrec@5 91.667 (94.036)\n",
      "Epoch: [11][500/1334]\t\\Time 0.324 (0.323)\tData 0.272 (0.270)\tLoss 0.3678 (0.7884)\tPrec@1 83.333 (77.412)\tPrec@5 100.000 (94.079)\n",
      "Epoch: [11][600/1334]\t\\Time 0.362 (0.324)\tData 0.312 (0.270)\tLoss 0.9929 (0.7861)\tPrec@1 58.333 (77.343)\tPrec@5 91.667 (94.260)\n",
      "Epoch: [11][700/1334]\t\\Time 0.328 (0.324)\tData 0.278 (0.270)\tLoss 0.6280 (0.7793)\tPrec@1 83.333 (77.437)\tPrec@5 91.667 (94.258)\n",
      "Epoch: [11][800/1334]\t\\Time 0.278 (0.324)\tData 0.217 (0.270)\tLoss 0.7457 (0.7833)\tPrec@1 75.000 (77.206)\tPrec@5 91.667 (94.216)\n",
      "Epoch: [11][900/1334]\t\\Time 0.322 (0.324)\tData 0.270 (0.271)\tLoss 0.7051 (0.7848)\tPrec@1 83.333 (77.016)\tPrec@5 91.667 (94.229)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.345 (0.324)\tData 0.296 (0.271)\tLoss 1.4008 (0.7796)\tPrec@1 66.667 (77.223)\tPrec@5 83.333 (94.289)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.354 (0.324)\tData 0.305 (0.271)\tLoss 1.2148 (0.7762)\tPrec@1 66.667 (77.377)\tPrec@5 75.000 (94.399)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.315 (0.324)\tData 0.262 (0.271)\tLoss 0.1353 (0.7743)\tPrec@1 100.000 (77.359)\tPrec@5 100.000 (94.407)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.267 (0.324)\tData 0.215 (0.270)\tLoss 1.2819 (0.7713)\tPrec@1 66.667 (77.408)\tPrec@5 75.000 (94.459)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.357 (0.357)\n",
      "\n",
      "Loss 1.7609 (1.7609)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.333 (0.352)\n",
      "\n",
      "Loss 1.0952 (2.1280)\n",
      "\n",
      "Prec@1 58.333 (47.525)\n",
      "\n",
      "Prec@5 83.333 (78.548)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.337 (0.351)\n",
      "\n",
      "Loss 2.4814 (2.0614)\n",
      "\n",
      "Prec@1 50.000 (48.839)\n",
      "\n",
      "Prec@5 83.333 (79.104)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.338 (0.351)\n",
      "\n",
      "Loss 2.7590 (2.0632)\n",
      "\n",
      "Prec@1 33.333 (48.865)\n",
      "\n",
      "Prec@5 66.667 (78.904)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [12][0/1334]\t\\Time 0.436 (0.436)\tData 0.287 (0.287)\tLoss 0.7523 (0.7523)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.231 (0.318)\tData 0.180 (0.264)\tLoss 0.9717 (0.5565)\tPrec@1 75.000 (84.241)\tPrec@5 75.000 (96.370)\n",
      "Epoch: [12][200/1334]\t\\Time 0.321 (0.319)\tData 0.260 (0.266)\tLoss 0.0511 (0.5593)\tPrec@1 100.000 (83.665)\tPrec@5 100.000 (96.766)\n",
      "Epoch: [12][300/1334]\t\\Time 0.384 (0.321)\tData 0.334 (0.267)\tLoss 0.3446 (0.5501)\tPrec@1 100.000 (83.333)\tPrec@5 100.000 (96.733)\n",
      "Epoch: [12][400/1334]\t\\Time 0.357 (0.323)\tData 0.307 (0.270)\tLoss 0.1352 (0.5415)\tPrec@1 100.000 (83.811)\tPrec@5 100.000 (96.758)\n",
      "Epoch: [12][500/1334]\t\\Time 0.239 (0.323)\tData 0.178 (0.270)\tLoss 0.9020 (0.5418)\tPrec@1 83.333 (83.849)\tPrec@5 91.667 (96.723)\n",
      "Epoch: [12][600/1334]\t\\Time 0.292 (0.324)\tData 0.244 (0.270)\tLoss 0.0704 (0.5475)\tPrec@1 100.000 (83.694)\tPrec@5 100.000 (96.672)\n",
      "Epoch: [12][700/1334]\t\\Time 0.352 (0.323)\tData 0.306 (0.270)\tLoss 0.6474 (0.5472)\tPrec@1 91.667 (83.785)\tPrec@5 100.000 (96.683)\n",
      "Epoch: [12][800/1334]\t\\Time 0.322 (0.323)\tData 0.271 (0.269)\tLoss 0.7651 (0.5531)\tPrec@1 75.000 (83.656)\tPrec@5 91.667 (96.494)\n",
      "Epoch: [12][900/1334]\t\\Time 0.343 (0.323)\tData 0.290 (0.269)\tLoss 0.3778 (0.5601)\tPrec@1 75.000 (83.204)\tPrec@5 100.000 (96.495)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.392 (0.322)\tData 0.322 (0.269)\tLoss 0.5822 (0.5565)\tPrec@1 83.333 (83.317)\tPrec@5 91.667 (96.512)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.361 (0.323)\tData 0.311 (0.270)\tLoss 0.4268 (0.5569)\tPrec@1 91.667 (83.280)\tPrec@5 91.667 (96.511)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.322 (0.323)\tData 0.262 (0.270)\tLoss 0.2895 (0.5552)\tPrec@1 91.667 (83.292)\tPrec@5 100.000 (96.496)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.287 (0.324)\tData 0.237 (0.270)\tLoss 0.2799 (0.5555)\tPrec@1 91.667 (83.256)\tPrec@5 100.000 (96.515)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.344 (0.344)\n",
      "\n",
      "Loss 2.0994 (2.0994)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.360 (0.349)\n",
      "\n",
      "Loss 1.4407 (2.2864)\n",
      "\n",
      "Prec@1 58.333 (47.855)\n",
      "\n",
      "Prec@5 83.333 (78.135)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.337 (0.355)\n",
      "\n",
      "Loss 3.0884 (2.2107)\n",
      "\n",
      "Prec@1 50.000 (48.839)\n",
      "\n",
      "Prec@5 66.667 (78.773)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.319 (0.356)\n",
      "\n",
      "Loss 2.3048 (2.2041)\n",
      "\n",
      "Prec@1 41.667 (48.837)\n",
      "\n",
      "Prec@5 58.333 (78.821)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [13][0/1334]\t\\Time 0.275 (0.275)\tData 0.195 (0.195)\tLoss 0.2037 (0.2037)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.366 (0.322)\tData 0.314 (0.269)\tLoss 0.4597 (0.3967)\tPrec@1 83.333 (89.026)\tPrec@5 100.000 (98.102)\n",
      "Epoch: [13][200/1334]\t\\Time 0.333 (0.318)\tData 0.290 (0.265)\tLoss 0.7814 (0.3883)\tPrec@1 83.333 (88.640)\tPrec@5 100.000 (98.093)\n",
      "Epoch: [13][300/1334]\t\\Time 0.350 (0.323)\tData 0.292 (0.270)\tLoss 0.1359 (0.3864)\tPrec@1 100.000 (88.372)\tPrec@5 100.000 (98.145)\n",
      "Epoch: [13][400/1334]\t\\Time 0.329 (0.322)\tData 0.279 (0.269)\tLoss 0.0456 (0.3839)\tPrec@1 100.000 (88.612)\tPrec@5 100.000 (98.275)\n",
      "Epoch: [13][500/1334]\t\\Time 0.330 (0.322)\tData 0.280 (0.269)\tLoss 0.2724 (0.3762)\tPrec@1 83.333 (88.523)\tPrec@5 100.000 (98.337)\n",
      "Epoch: [13][600/1334]\t\\Time 0.360 (0.322)\tData 0.295 (0.269)\tLoss 0.2145 (0.3799)\tPrec@1 100.000 (88.214)\tPrec@5 100.000 (98.308)\n",
      "Epoch: [13][700/1334]\t\\Time 0.340 (0.323)\tData 0.286 (0.270)\tLoss 0.3100 (0.3842)\tPrec@1 91.667 (88.112)\tPrec@5 100.000 (98.181)\n",
      "Epoch: [13][800/1334]\t\\Time 0.264 (0.323)\tData 0.204 (0.270)\tLoss 0.0577 (0.3807)\tPrec@1 100.000 (88.275)\tPrec@5 100.000 (98.211)\n",
      "Epoch: [13][900/1334]\t\\Time 0.383 (0.323)\tData 0.332 (0.270)\tLoss 0.4370 (0.3809)\tPrec@1 91.667 (88.115)\tPrec@5 91.667 (98.206)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.312 (0.324)\tData 0.261 (0.271)\tLoss 0.3157 (0.3837)\tPrec@1 83.333 (88.004)\tPrec@5 100.000 (98.202)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.343 (0.324)\tData 0.291 (0.271)\tLoss 0.3751 (0.3867)\tPrec@1 91.667 (87.981)\tPrec@5 100.000 (98.161)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.394 (0.324)\tData 0.344 (0.271)\tLoss 0.7781 (0.3876)\tPrec@1 75.000 (88.003)\tPrec@5 91.667 (98.182)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.336 (0.323)\tData 0.273 (0.270)\tLoss 0.4761 (0.3892)\tPrec@1 91.667 (87.945)\tPrec@5 91.667 (98.142)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.349 (0.349)\n",
      "\n",
      "Loss 2.0245 (2.0245)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.362 (0.354)\n",
      "\n",
      "Loss 1.2996 (2.4899)\n",
      "\n",
      "Prec@1 66.667 (47.360)\n",
      "\n",
      "Prec@5 83.333 (78.135)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.312 (0.354)\n",
      "\n",
      "Loss 3.7895 (2.4295)\n",
      "\n",
      "Prec@1 50.000 (48.507)\n",
      "\n",
      "Prec@5 75.000 (78.483)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.308 (0.353)\n",
      "\n",
      "Loss 2.8570 (2.4057)\n",
      "\n",
      "Prec@1 41.667 (49.114)\n",
      "\n",
      "Prec@5 66.667 (78.544)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [14][0/1334]\t\\Time 0.513 (0.513)\tData 0.363 (0.363)\tLoss 0.8972 (0.8972)\tPrec@1 75.000 (75.000)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [14][100/1334]\t\\Time 0.250 (0.333)\tData 0.196 (0.279)\tLoss 0.0281 (0.2848)\tPrec@1 100.000 (91.089)\tPrec@5 100.000 (99.092)\n",
      "Epoch: [14][200/1334]\t\\Time 0.294 (0.328)\tData 0.244 (0.275)\tLoss 0.0882 (0.2649)\tPrec@1 100.000 (91.791)\tPrec@5 100.000 (99.254)\n",
      "Epoch: [14][300/1334]\t\\Time 0.358 (0.327)\tData 0.308 (0.274)\tLoss 0.3086 (0.2678)\tPrec@1 83.333 (91.750)\tPrec@5 100.000 (99.197)\n",
      "Epoch: [14][400/1334]\t\\Time 0.440 (0.326)\tData 0.388 (0.273)\tLoss 0.1834 (0.2670)\tPrec@1 91.667 (91.750)\tPrec@5 100.000 (99.106)\n",
      "Epoch: [14][500/1334]\t\\Time 0.346 (0.326)\tData 0.291 (0.273)\tLoss 0.1921 (0.2643)\tPrec@1 91.667 (91.883)\tPrec@5 100.000 (99.135)\n",
      "Epoch: [14][600/1334]\t\\Time 0.288 (0.327)\tData 0.242 (0.274)\tLoss 0.1675 (0.2682)\tPrec@1 100.000 (91.958)\tPrec@5 100.000 (99.057)\n",
      "Epoch: [14][700/1334]\t\\Time 0.354 (0.327)\tData 0.301 (0.274)\tLoss 0.2208 (0.2679)\tPrec@1 91.667 (91.821)\tPrec@5 100.000 (99.037)\n",
      "Epoch: [14][800/1334]\t\\Time 0.361 (0.326)\tData 0.310 (0.273)\tLoss 0.2783 (0.2664)\tPrec@1 91.667 (91.906)\tPrec@5 100.000 (99.064)\n",
      "Epoch: [14][900/1334]\t\\Time 0.408 (0.326)\tData 0.350 (0.273)\tLoss 0.2786 (0.2660)\tPrec@1 91.667 (91.870)\tPrec@5 100.000 (99.084)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.320 (0.326)\tData 0.260 (0.273)\tLoss 0.3791 (0.2695)\tPrec@1 75.000 (91.767)\tPrec@5 100.000 (99.068)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.328 (0.326)\tData 0.272 (0.273)\tLoss 0.7521 (0.2678)\tPrec@1 75.000 (91.795)\tPrec@5 100.000 (99.107)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.426 (0.326)\tData 0.372 (0.273)\tLoss 0.4641 (0.2715)\tPrec@1 91.667 (91.715)\tPrec@5 91.667 (99.098)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.395 (0.326)\tData 0.338 (0.273)\tLoss 0.6343 (0.2696)\tPrec@1 91.667 (91.788)\tPrec@5 91.667 (99.110)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.364 (0.364)\n",
      "\n",
      "Loss 2.7627 (2.7627)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.342 (0.358)\n",
      "\n",
      "Loss 1.6340 (2.7526)\n",
      "\n",
      "Prec@1 50.000 (46.700)\n",
      "\n",
      "Prec@5 83.333 (78.135)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.324 (0.356)\n",
      "\n",
      "Loss 4.1266 (2.6474)\n",
      "\n",
      "Prec@1 50.000 (48.300)\n",
      "\n",
      "Prec@5 66.667 (78.358)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.306 (0.356)\n",
      "\n",
      "Loss 2.8268 (2.6381)\n",
      "\n",
      "Prec@1 41.667 (48.367)\n",
      "\n",
      "Prec@5 75.000 (78.322)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Adjusted Learning rate resume from best model\n",
      "=> loading checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 14)\n",
      "Epoch: [15][0/1334]\t\\Time 0.371 (0.371)\tData 0.281 (0.281)\tLoss 0.0467 (0.0467)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.331 (0.315)\tData 0.281 (0.262)\tLoss 0.1049 (0.2584)\tPrec@1 100.000 (92.244)\tPrec@5 100.000 (99.257)\n",
      "Epoch: [15][200/1334]\t\\Time 0.393 (0.319)\tData 0.333 (0.266)\tLoss 0.0083 (0.2578)\tPrec@1 100.000 (92.413)\tPrec@5 100.000 (99.254)\n",
      "Epoch: [15][300/1334]\t\\Time 0.294 (0.319)\tData 0.237 (0.266)\tLoss 0.0399 (0.2580)\tPrec@1 100.000 (92.386)\tPrec@5 100.000 (99.169)\n",
      "Epoch: [15][400/1334]\t\\Time 0.422 (0.321)\tData 0.372 (0.268)\tLoss 0.0245 (0.2581)\tPrec@1 100.000 (92.456)\tPrec@5 100.000 (99.190)\n",
      "Epoch: [15][500/1334]\t\\Time 0.273 (0.321)\tData 0.213 (0.267)\tLoss 0.1232 (0.2588)\tPrec@1 100.000 (92.332)\tPrec@5 100.000 (99.185)\n",
      "Epoch: [15][600/1334]\t\\Time 0.273 (0.322)\tData 0.223 (0.269)\tLoss 0.0172 (0.2601)\tPrec@1 100.000 (92.263)\tPrec@5 100.000 (99.168)\n",
      "Epoch: [15][700/1334]\t\\Time 0.301 (0.323)\tData 0.251 (0.270)\tLoss 0.1880 (0.2596)\tPrec@1 91.667 (92.166)\tPrec@5 100.000 (99.144)\n",
      "Epoch: [15][800/1334]\t\\Time 0.300 (0.323)\tData 0.250 (0.269)\tLoss 0.4206 (0.2600)\tPrec@1 83.333 (92.208)\tPrec@5 100.000 (99.105)\n",
      "Epoch: [15][900/1334]\t\\Time 0.353 (0.322)\tData 0.301 (0.269)\tLoss 0.0085 (0.2586)\tPrec@1 100.000 (92.194)\tPrec@5 100.000 (99.121)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.352 (0.323)\tData 0.291 (0.269)\tLoss 0.1780 (0.2565)\tPrec@1 91.667 (92.366)\tPrec@5 100.000 (99.109)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.315 (0.323)\tData 0.255 (0.270)\tLoss 0.3137 (0.2538)\tPrec@1 83.333 (92.386)\tPrec@5 100.000 (99.145)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.265 (0.324)\tData 0.211 (0.271)\tLoss 0.3735 (0.2529)\tPrec@1 83.333 (92.388)\tPrec@5 100.000 (99.133)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.350 (0.324)\tData 0.300 (0.271)\tLoss 0.0485 (0.2519)\tPrec@1 100.000 (92.487)\tPrec@5 100.000 (99.142)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.353 (0.353)\n",
      "\n",
      "Loss 2.3551 (2.3551)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.340 (0.354)\n",
      "\n",
      "Loss 1.4108 (2.5297)\n",
      "\n",
      "Prec@1 50.000 (47.855)\n",
      "\n",
      "Prec@5 83.333 (79.043)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.333 (0.352)\n",
      "\n",
      "Loss 3.6894 (2.4549)\n",
      "\n",
      "Prec@1 50.000 (49.295)\n",
      "\n",
      "Prec@5 75.000 (79.270)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.320 (0.353)\n",
      "\n",
      "Loss 2.7808 (2.4344)\n",
      "\n",
      "Prec@1 50.000 (49.502)\n",
      "\n",
      "Prec@5 66.667 (79.042)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Epoch: [16][0/1334]\t\\Time 0.430 (0.430)\tData 0.276 (0.276)\tLoss 0.1982 (0.1982)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.302 (0.321)\tData 0.250 (0.266)\tLoss 0.2464 (0.2284)\tPrec@1 83.333 (93.482)\tPrec@5 100.000 (99.257)\n",
      "Epoch: [16][200/1334]\t\\Time 0.290 (0.321)\tData 0.240 (0.268)\tLoss 0.0426 (0.2249)\tPrec@1 100.000 (93.698)\tPrec@5 100.000 (99.295)\n",
      "Epoch: [16][300/1334]\t\\Time 0.384 (0.320)\tData 0.333 (0.266)\tLoss 0.0807 (0.2131)\tPrec@1 100.000 (94.103)\tPrec@5 100.000 (99.446)\n",
      "Epoch: [16][400/1334]\t\\Time 0.326 (0.323)\tData 0.276 (0.269)\tLoss 0.0390 (0.2145)\tPrec@1 100.000 (93.849)\tPrec@5 100.000 (99.439)\n",
      "Epoch: [16][500/1334]\t\\Time 0.404 (0.322)\tData 0.343 (0.269)\tLoss 0.1062 (0.2190)\tPrec@1 100.000 (93.613)\tPrec@5 100.000 (99.434)\n",
      "Epoch: [16][600/1334]\t\\Time 0.312 (0.323)\tData 0.254 (0.270)\tLoss 0.0625 (0.2216)\tPrec@1 100.000 (93.636)\tPrec@5 100.000 (99.293)\n",
      "Epoch: [16][700/1334]\t\\Time 0.331 (0.324)\tData 0.281 (0.271)\tLoss 0.3455 (0.2218)\tPrec@1 91.667 (93.616)\tPrec@5 100.000 (99.311)\n",
      "Epoch: [16][800/1334]\t\\Time 0.302 (0.323)\tData 0.252 (0.270)\tLoss 0.1929 (0.2229)\tPrec@1 91.667 (93.571)\tPrec@5 100.000 (99.303)\n",
      "Epoch: [16][900/1334]\t\\Time 0.326 (0.324)\tData 0.275 (0.271)\tLoss 0.0418 (0.2219)\tPrec@1 100.000 (93.581)\tPrec@5 100.000 (99.260)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.323 (0.325)\tData 0.270 (0.272)\tLoss 0.3077 (0.2223)\tPrec@1 75.000 (93.540)\tPrec@5 100.000 (99.267)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.324 (0.324)\tData 0.272 (0.271)\tLoss 0.2199 (0.2217)\tPrec@1 91.667 (93.619)\tPrec@5 100.000 (99.273)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.367 (0.325)\tData 0.313 (0.272)\tLoss 0.1723 (0.2234)\tPrec@1 91.667 (93.505)\tPrec@5 100.000 (99.251)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.312 (0.325)\tData 0.261 (0.272)\tLoss 0.1452 (0.2226)\tPrec@1 91.667 (93.524)\tPrec@5 100.000 (99.238)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.345 (0.345)\n",
      "\n",
      "Loss 2.3657 (2.3657)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.337 (0.345)\n",
      "\n",
      "Loss 1.4354 (2.5962)\n",
      "\n",
      "Prec@1 50.000 (47.525)\n",
      "\n",
      "Prec@5 83.333 (79.125)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.320 (0.351)\n",
      "\n",
      "Loss 3.8311 (2.5155)\n",
      "\n",
      "Prec@1 50.000 (49.254)\n",
      "\n",
      "Prec@5 75.000 (79.022)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.306 (0.347)\n",
      "\n",
      "Loss 2.8020 (2.4932)\n",
      "\n",
      "Prec@1 50.000 (49.502)\n",
      "\n",
      "Prec@5 66.667 (79.097)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 17)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000010\n",
      "Adjusted Learning rate resume from best model\n",
      "=> loading checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/vgg19_v4_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 17)\n",
      "Epoch: [17][0/1334]\t\\Time 0.331 (0.331)\tData 0.251 (0.251)\tLoss 0.1205 (0.1205)\tPrec@1 91.667 (91.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [17][100/1334]\t\\Time 0.260 (0.316)\tData 0.210 (0.263)\tLoss 0.0898 (0.2224)\tPrec@1 100.000 (93.399)\tPrec@5 100.000 (99.092)\n",
      "Epoch: [17][200/1334]\t\\Time 0.274 (0.317)\tData 0.220 (0.264)\tLoss 0.1237 (0.2101)\tPrec@1 100.000 (94.030)\tPrec@5 100.000 (99.337)\n",
      "Epoch: [17][300/1334]\t\\Time 0.321 (0.316)\tData 0.270 (0.263)\tLoss 0.0284 (0.2116)\tPrec@1 100.000 (93.826)\tPrec@5 100.000 (99.391)\n",
      "Epoch: [17][400/1334]\t\\Time 0.360 (0.317)\tData 0.310 (0.263)\tLoss 0.0238 (0.2103)\tPrec@1 100.000 (93.849)\tPrec@5 100.000 (99.356)\n",
      "Epoch: [17][500/1334]\t\\Time 0.341 (0.316)\tData 0.291 (0.263)\tLoss 0.1163 (0.2078)\tPrec@1 91.667 (93.929)\tPrec@5 100.000 (99.351)\n",
      "Epoch: [17][600/1334]\t\\Time 0.400 (0.316)\tData 0.341 (0.263)\tLoss 0.3355 (0.2053)\tPrec@1 91.667 (94.079)\tPrec@5 100.000 (99.404)\n",
      "Epoch: [17][700/1334]\t\\Time 0.290 (0.316)\tData 0.240 (0.263)\tLoss 0.3545 (0.2053)\tPrec@1 83.333 (94.032)\tPrec@5 100.000 (99.382)\n",
      "Epoch: [17][800/1334]\t\\Time 0.251 (0.316)\tData 0.201 (0.263)\tLoss 0.1971 (0.2036)\tPrec@1 91.667 (94.112)\tPrec@5 100.000 (99.407)\n",
      "Epoch: [17][900/1334]\t\\Time 0.345 (0.315)\tData 0.285 (0.262)\tLoss 0.0361 (0.2020)\tPrec@1 100.000 (94.293)\tPrec@5 100.000 (99.417)\n",
      "Epoch: [17][1000/1334]\t\\Time 0.342 (0.315)\tData 0.297 (0.262)\tLoss 0.1253 (0.2014)\tPrec@1 100.000 (94.339)\tPrec@5 100.000 (99.384)\n",
      "Epoch: [17][1100/1334]\t\\Time 0.251 (0.315)\tData 0.204 (0.262)\tLoss 0.1067 (0.2033)\tPrec@1 100.000 (94.255)\tPrec@5 100.000 (99.387)\n",
      "Epoch: [17][1200/1334]\t\\Time 0.335 (0.315)\tData 0.281 (0.262)\tLoss 0.0651 (0.2020)\tPrec@1 100.000 (94.296)\tPrec@5 100.000 (99.376)\n",
      "Epoch: [17][1300/1334]\t\\Time 0.450 (0.316)\tData 0.400 (0.263)\tLoss 0.3942 (0.2021)\tPrec@1 83.333 (94.306)\tPrec@5 100.000 (99.404)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.332 (0.332)\n",
      "\n",
      "Loss 2.3904 (2.3904)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.316 (0.340)\n",
      "\n",
      "Loss 1.4413 (2.6049)\n",
      "\n",
      "Prec@1 50.000 (47.690)\n",
      "\n",
      "Prec@5 83.333 (78.878)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.311 (0.343)\n",
      "\n",
      "Loss 3.8547 (2.5235)\n",
      "\n",
      "Prec@1 50.000 (49.212)\n",
      "\n",
      "Prec@5 75.000 (78.814)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.310 (0.343)\n",
      "\n",
      "Loss 2.7925 (2.5001)\n",
      "\n",
      "Prec@1 41.667 (49.502)\n",
      "\n",
      "Prec@5 66.667 (78.876)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000010\n",
      "Epoch: [18][0/1334]\t\\Time 0.387 (0.387)\tData 0.254 (0.254)\tLoss 0.0876 (0.0876)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [18][100/1334]\t\\Time 0.343 (0.313)\tData 0.293 (0.260)\tLoss 0.0545 (0.2034)\tPrec@1 100.000 (94.472)\tPrec@5 100.000 (99.010)\n",
      "Epoch: [18][200/1334]\t\\Time 0.392 (0.313)\tData 0.333 (0.260)\tLoss 0.0383 (0.2108)\tPrec@1 100.000 (94.113)\tPrec@5 100.000 (99.254)\n",
      "Epoch: [18][300/1334]\t\\Time 0.301 (0.314)\tData 0.240 (0.260)\tLoss 0.0648 (0.2004)\tPrec@1 100.000 (94.574)\tPrec@5 100.000 (99.308)\n",
      "Epoch: [18][400/1334]\t\\Time 0.255 (0.313)\tData 0.200 (0.260)\tLoss 0.4991 (0.2018)\tPrec@1 91.667 (94.431)\tPrec@5 100.000 (99.314)\n",
      "Epoch: [18][500/1334]\t\\Time 0.289 (0.314)\tData 0.239 (0.261)\tLoss 0.1292 (0.2028)\tPrec@1 100.000 (94.345)\tPrec@5 100.000 (99.318)\n",
      "Epoch: [18][600/1334]\t\\Time 0.380 (0.314)\tData 0.323 (0.261)\tLoss 0.1713 (0.2056)\tPrec@1 91.667 (94.218)\tPrec@5 100.000 (99.321)\n",
      "Epoch: [18][700/1334]\t\\Time 0.330 (0.315)\tData 0.280 (0.262)\tLoss 0.2832 (0.2045)\tPrec@1 91.667 (94.258)\tPrec@5 100.000 (99.358)\n",
      "Epoch: [18][800/1334]\t\\Time 0.371 (0.315)\tData 0.321 (0.262)\tLoss 0.1012 (0.2016)\tPrec@1 100.000 (94.309)\tPrec@5 100.000 (99.397)\n",
      "Epoch: [18][900/1334]\t\\Time 0.370 (0.316)\tData 0.310 (0.263)\tLoss 0.4876 (0.2057)\tPrec@1 83.333 (94.155)\tPrec@5 100.000 (99.380)\n",
      "Epoch: [18][1000/1334]\t\\Time 0.291 (0.317)\tData 0.241 (0.263)\tLoss 0.3967 (0.2053)\tPrec@1 83.333 (94.156)\tPrec@5 100.000 (99.392)\n",
      "Epoch: [18][1100/1334]\t\\Time 0.375 (0.317)\tData 0.314 (0.264)\tLoss 0.0519 (0.2026)\tPrec@1 100.000 (94.217)\tPrec@5 100.000 (99.440)\n",
      "Epoch: [18][1200/1334]\t\\Time 0.261 (0.317)\tData 0.211 (0.264)\tLoss 0.2032 (0.2058)\tPrec@1 91.667 (94.116)\tPrec@5 100.000 (99.403)\n",
      "Epoch: [18][1300/1334]\t\\Time 0.276 (0.317)\tData 0.224 (0.264)\tLoss 0.0324 (0.2078)\tPrec@1 100.000 (94.030)\tPrec@5 100.000 (99.398)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.340 (0.340)\n",
      "\n",
      "Loss 2.3867 (2.3867)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.330 (0.342)\n",
      "\n",
      "Loss 1.4414 (2.6115)\n",
      "\n",
      "Prec@1 50.000 (47.607)\n",
      "\n",
      "Prec@5 83.333 (79.290)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.330 (0.344)\n",
      "\n",
      "Loss 3.8607 (2.5287)\n",
      "\n",
      "Prec@1 50.000 (49.212)\n",
      "\n",
      "Prec@5 75.000 (79.104)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.300 (0.345)\n",
      "\n",
      "Loss 2.7873 (2.5053)\n",
      "\n",
      "Prec@1 41.667 (49.446)\n",
      "\n",
      "Prec@5 66.667 (79.097)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "'combined_location_image_df_top100.csv'\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "# model = torchvision.models.vit_b_16(weights = 'VGG16_Weights.IMAGENET1K_V1')\n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "model = torchvision.models.vgg19(weights = 'VGG19_Weights.IMAGENET1K_V1')\n",
    "\n",
    "model.classifier[-1] = nn.Linear(4096 , 100, bias = True)\n",
    "model.name = f'vgg19_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            print('Adjusted Learning rate resume from best model')\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)\n",
    "train_model(model,LEARNING_RATE = 1e-5,NUM_EPOCHS = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ac22ec-4a31-4db3-9bd8-bd15be3e9944",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [0][0/1334]\t\\Time 0.352 (0.352)\tData 0.271 (0.271)\tLoss 4.6459 (4.6459)\tPrec@1 0.000 (0.000)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [0][100/1334]\t\\Time 0.312 (0.295)\tData 0.284 (0.266)\tLoss 4.6430 (4.6786)\tPrec@1 0.000 (2.475)\tPrec@5 0.000 (9.983)\n",
      "Epoch: [0][200/1334]\t\\Time 0.334 (0.294)\tData 0.304 (0.265)\tLoss 3.9758 (4.4698)\tPrec@1 8.333 (3.400)\tPrec@5 25.000 (14.552)\n",
      "Epoch: [0][300/1334]\t\\Time 0.318 (0.295)\tData 0.290 (0.266)\tLoss 3.1925 (4.2892)\tPrec@1 25.000 (5.482)\tPrec@5 33.333 (19.435)\n",
      "Epoch: [0][400/1334]\t\\Time 0.262 (0.296)\tData 0.231 (0.268)\tLoss 3.9803 (4.1321)\tPrec@1 16.667 (7.066)\tPrec@5 25.000 (23.608)\n",
      "Epoch: [0][500/1334]\t\\Time 0.280 (0.297)\tData 0.251 (0.269)\tLoss 3.3985 (3.9903)\tPrec@1 8.333 (8.683)\tPrec@5 50.000 (27.329)\n",
      "Epoch: [0][600/1334]\t\\Time 0.324 (0.297)\tData 0.295 (0.269)\tLoss 4.0070 (3.8744)\tPrec@1 16.667 (10.136)\tPrec@5 25.000 (30.574)\n",
      "Epoch: [0][700/1334]\t\\Time 0.311 (0.298)\tData 0.282 (0.269)\tLoss 3.7201 (3.7874)\tPrec@1 16.667 (11.543)\tPrec@5 33.333 (33.060)\n",
      "Epoch: [0][800/1334]\t\\Time 0.359 (0.298)\tData 0.329 (0.269)\tLoss 3.4586 (3.7067)\tPrec@1 16.667 (12.755)\tPrec@5 41.667 (35.456)\n",
      "Epoch: [0][900/1334]\t\\Time 0.363 (0.299)\tData 0.334 (0.270)\tLoss 3.7015 (3.6313)\tPrec@1 8.333 (13.994)\tPrec@5 33.333 (37.662)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.277 (0.299)\tData 0.250 (0.270)\tLoss 3.2682 (3.5621)\tPrec@1 25.000 (15.043)\tPrec@5 41.667 (39.585)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.321 (0.299)\tData 0.292 (0.270)\tLoss 2.3881 (3.4998)\tPrec@1 50.000 (16.160)\tPrec@5 66.667 (41.462)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.348 (0.304)\tData 0.317 (0.275)\tLoss 2.4214 (3.4360)\tPrec@1 41.667 (17.111)\tPrec@5 66.667 (43.381)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.333 (0.307)\tData 0.303 (0.278)\tLoss 2.6334 (3.3780)\tPrec@1 33.333 (18.082)\tPrec@5 58.333 (44.940)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.336 (0.336)\n",
      "\n",
      "Loss 1.7242 (1.7242)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.342 (0.343)\n",
      "\n",
      "Loss 1.8666 (2.5143)\n",
      "\n",
      "Prec@1 33.333 (34.158)\n",
      "\n",
      "Prec@5 75.000 (69.967)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.322 (0.345)\n",
      "\n",
      "Loss 2.1432 (2.5235)\n",
      "\n",
      "Prec@1 41.667 (34.660)\n",
      "\n",
      "Prec@5 83.333 (69.486)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.346)\n",
      "\n",
      "Loss 2.8800 (2.5446)\n",
      "\n",
      "Prec@1 16.667 (33.527)\n",
      "\n",
      "Prec@5 41.667 (68.771)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/1334]\t\\Time 0.354 (0.354)\tData 0.270 (0.270)\tLoss 2.8500 (2.8500)\tPrec@1 8.333 (8.333)\tPrec@5 66.667 (66.667)\n",
      "Epoch: [1][100/1334]\t\\Time 0.329 (0.301)\tData 0.301 (0.271)\tLoss 3.6172 (2.5671)\tPrec@1 25.000 (33.416)\tPrec@5 58.333 (66.914)\n",
      "Epoch: [1][200/1334]\t\\Time 0.315 (0.297)\tData 0.286 (0.267)\tLoss 2.6439 (2.5153)\tPrec@1 25.000 (33.624)\tPrec@5 83.333 (67.620)\n",
      "Epoch: [1][300/1334]\t\\Time 0.300 (0.294)\tData 0.271 (0.265)\tLoss 2.0332 (2.4810)\tPrec@1 33.333 (33.859)\tPrec@5 91.667 (69.269)\n",
      "Epoch: [1][400/1334]\t\\Time 0.306 (0.293)\tData 0.276 (0.264)\tLoss 2.0184 (2.4555)\tPrec@1 50.000 (34.830)\tPrec@5 83.333 (69.971)\n",
      "Epoch: [1][500/1334]\t\\Time 0.199 (0.293)\tData 0.172 (0.264)\tLoss 2.1904 (2.4186)\tPrec@1 50.000 (35.163)\tPrec@5 75.000 (70.426)\n",
      "Epoch: [1][600/1334]\t\\Time 0.232 (0.292)\tData 0.204 (0.263)\tLoss 2.1774 (2.4083)\tPrec@1 58.333 (35.566)\tPrec@5 75.000 (70.507)\n",
      "Epoch: [1][700/1334]\t\\Time 0.280 (0.290)\tData 0.253 (0.261)\tLoss 2.6114 (2.3824)\tPrec@1 16.667 (36.175)\tPrec@5 75.000 (70.994)\n",
      "Epoch: [1][800/1334]\t\\Time 0.259 (0.290)\tData 0.231 (0.261)\tLoss 3.2767 (2.3709)\tPrec@1 25.000 (36.538)\tPrec@5 58.333 (71.317)\n",
      "Epoch: [1][900/1334]\t\\Time 0.257 (0.290)\tData 0.228 (0.261)\tLoss 1.9025 (2.3470)\tPrec@1 41.667 (37.051)\tPrec@5 83.333 (71.763)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.322 (0.292)\tData 0.295 (0.263)\tLoss 2.2859 (2.3351)\tPrec@1 33.333 (37.479)\tPrec@5 58.333 (71.903)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.303 (0.292)\tData 0.275 (0.264)\tLoss 2.3312 (2.3244)\tPrec@1 41.667 (37.776)\tPrec@5 66.667 (72.131)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.275 (0.293)\tData 0.247 (0.264)\tLoss 2.3619 (2.3052)\tPrec@1 33.333 (38.253)\tPrec@5 66.667 (72.558)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.260 (0.294)\tData 0.229 (0.265)\tLoss 2.0364 (2.2918)\tPrec@1 33.333 (38.631)\tPrec@5 75.000 (72.867)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.316 (0.316)\n",
      "\n",
      "Loss 1.7117 (1.7117)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.332 (0.337)\n",
      "\n",
      "Loss 1.3587 (2.1223)\n",
      "\n",
      "Prec@1 50.000 (44.472)\n",
      "\n",
      "Prec@5 91.667 (75.660)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.320 (0.341)\n",
      "\n",
      "Loss 1.7118 (2.1129)\n",
      "\n",
      "Prec@1 50.000 (44.610)\n",
      "\n",
      "Prec@5 75.000 (75.539)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.308 (0.343)\n",
      "\n",
      "Loss 3.0632 (2.1227)\n",
      "\n",
      "Prec@1 16.667 (44.020)\n",
      "\n",
      "Prec@5 66.667 (75.748)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1334]\t\\Time 0.263 (0.263)\tData 0.177 (0.177)\tLoss 2.4887 (2.4887)\tPrec@1 25.000 (25.000)\tPrec@5 66.667 (66.667)\n",
      "Epoch: [2][100/1334]\t\\Time 0.301 (0.282)\tData 0.273 (0.253)\tLoss 1.4165 (1.8772)\tPrec@1 66.667 (49.422)\tPrec@5 91.667 (80.281)\n",
      "Epoch: [2][200/1334]\t\\Time 0.247 (0.283)\tData 0.213 (0.254)\tLoss 1.7360 (1.9399)\tPrec@1 58.333 (47.512)\tPrec@5 75.000 (78.856)\n",
      "Epoch: [2][300/1334]\t\\Time 0.355 (0.284)\tData 0.325 (0.255)\tLoss 1.4752 (1.9299)\tPrec@1 50.000 (47.342)\tPrec@5 91.667 (79.264)\n",
      "Epoch: [2][400/1334]\t\\Time 0.303 (0.283)\tData 0.275 (0.254)\tLoss 1.4583 (1.9142)\tPrec@1 25.000 (47.735)\tPrec@5 100.000 (79.593)\n",
      "Epoch: [2][500/1334]\t\\Time 0.272 (0.283)\tData 0.241 (0.254)\tLoss 1.3783 (1.9141)\tPrec@1 58.333 (48.104)\tPrec@5 91.667 (79.591)\n",
      "Epoch: [2][600/1334]\t\\Time 0.348 (0.283)\tData 0.320 (0.255)\tLoss 2.5780 (1.9104)\tPrec@1 25.000 (48.211)\tPrec@5 83.333 (79.520)\n",
      "Epoch: [2][700/1334]\t\\Time 0.231 (0.284)\tData 0.203 (0.256)\tLoss 2.1346 (1.9009)\tPrec@1 58.333 (48.336)\tPrec@5 83.333 (79.696)\n",
      "Epoch: [2][800/1334]\t\\Time 0.244 (0.286)\tData 0.215 (0.257)\tLoss 1.5872 (1.8974)\tPrec@1 33.333 (48.491)\tPrec@5 91.667 (79.786)\n",
      "Epoch: [2][900/1334]\t\\Time 0.345 (0.287)\tData 0.316 (0.258)\tLoss 2.0144 (1.8891)\tPrec@1 41.667 (48.714)\tPrec@5 75.000 (79.948)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.326 (0.287)\tData 0.298 (0.259)\tLoss 1.9690 (1.8820)\tPrec@1 41.667 (48.710)\tPrec@5 91.667 (80.195)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.272 (0.288)\tData 0.242 (0.260)\tLoss 1.5709 (1.8747)\tPrec@1 58.333 (48.955)\tPrec@5 91.667 (80.465)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.335 (0.289)\tData 0.304 (0.261)\tLoss 1.2173 (1.8720)\tPrec@1 66.667 (49.077)\tPrec@5 91.667 (80.523)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.269 (0.290)\tData 0.245 (0.261)\tLoss 1.0636 (1.8657)\tPrec@1 83.333 (49.199)\tPrec@5 83.333 (80.502)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.326 (0.326)\n",
      "\n",
      "Loss 1.9995 (1.9995)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.330 (0.342)\n",
      "\n",
      "Loss 1.5716 (2.0706)\n",
      "\n",
      "Prec@1 58.333 (46.535)\n",
      "\n",
      "Prec@5 91.667 (78.300)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.272 (0.344)\n",
      "\n",
      "Loss 1.7859 (1.9998)\n",
      "\n",
      "Prec@1 41.667 (47.512)\n",
      "\n",
      "Prec@5 83.333 (79.022)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.317 (0.344)\n",
      "\n",
      "Loss 1.9456 (2.0210)\n",
      "\n",
      "Prec@1 41.667 (47.204)\n",
      "\n",
      "Prec@5 83.333 (78.987)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1334]\t\\Time 0.325 (0.325)\tData 0.240 (0.240)\tLoss 0.9568 (0.9568)\tPrec@1 75.000 (75.000)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [3][100/1334]\t\\Time 0.263 (0.290)\tData 0.236 (0.261)\tLoss 1.4475 (1.5681)\tPrec@1 50.000 (57.178)\tPrec@5 83.333 (85.231)\n",
      "Epoch: [3][200/1334]\t\\Time 0.281 (0.286)\tData 0.254 (0.257)\tLoss 1.1740 (1.5329)\tPrec@1 50.000 (58.167)\tPrec@5 100.000 (85.572)\n",
      "Epoch: [3][300/1334]\t\\Time 0.269 (0.284)\tData 0.240 (0.256)\tLoss 1.7460 (1.5960)\tPrec@1 41.667 (56.423)\tPrec@5 83.333 (84.635)\n",
      "Epoch: [3][400/1334]\t\\Time 0.265 (0.283)\tData 0.238 (0.254)\tLoss 1.5482 (1.5808)\tPrec@1 66.667 (56.962)\tPrec@5 91.667 (84.726)\n",
      "Epoch: [3][500/1334]\t\\Time 0.281 (0.284)\tData 0.252 (0.255)\tLoss 1.2486 (1.6036)\tPrec@1 41.667 (56.487)\tPrec@5 100.000 (84.065)\n",
      "Epoch: [3][600/1334]\t\\Time 0.227 (0.283)\tData 0.198 (0.254)\tLoss 1.4596 (1.5998)\tPrec@1 50.000 (56.115)\tPrec@5 100.000 (84.221)\n",
      "Epoch: [3][700/1334]\t\\Time 0.286 (0.283)\tData 0.257 (0.254)\tLoss 1.3796 (1.5991)\tPrec@1 58.333 (56.051)\tPrec@5 91.667 (84.284)\n",
      "Epoch: [3][800/1334]\t\\Time 0.260 (0.285)\tData 0.233 (0.256)\tLoss 2.5760 (1.6099)\tPrec@1 41.667 (55.857)\tPrec@5 66.667 (84.103)\n",
      "Epoch: [3][900/1334]\t\\Time 0.271 (0.286)\tData 0.243 (0.257)\tLoss 1.7964 (1.5963)\tPrec@1 66.667 (56.243)\tPrec@5 75.000 (84.193)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.291 (0.287)\tData 0.263 (0.258)\tLoss 1.7148 (1.5881)\tPrec@1 50.000 (56.477)\tPrec@5 91.667 (84.399)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.285 (0.288)\tData 0.256 (0.259)\tLoss 1.4069 (1.5858)\tPrec@1 66.667 (56.449)\tPrec@5 91.667 (84.567)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.350 (0.289)\tData 0.321 (0.260)\tLoss 1.6330 (1.5821)\tPrec@1 50.000 (56.460)\tPrec@5 83.333 (84.679)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.288 (0.289)\tData 0.260 (0.260)\tLoss 0.6812 (1.5807)\tPrec@1 83.333 (56.476)\tPrec@5 100.000 (84.717)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.304 (0.304)\n",
      "\n",
      "Loss 2.3645 (2.3645)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.335 (0.341)\n",
      "\n",
      "Loss 1.4928 (2.3207)\n",
      "\n",
      "Prec@1 50.000 (43.399)\n",
      "\n",
      "Prec@5 83.333 (75.495)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.316 (0.343)\n",
      "\n",
      "Loss 2.1354 (2.3230)\n",
      "\n",
      "Prec@1 33.333 (43.823)\n",
      "\n",
      "Prec@5 66.667 (74.378)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.308 (0.344)\n",
      "\n",
      "Loss 4.1540 (2.3390)\n",
      "\n",
      "Prec@1 25.000 (43.189)\n",
      "\n",
      "Prec@5 41.667 (73.837)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1334]\t\\Time 0.288 (0.288)\tData 0.186 (0.186)\tLoss 0.9467 (0.9467)\tPrec@1 66.667 (66.667)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [4][100/1334]\t\\Time 0.288 (0.283)\tData 0.259 (0.254)\tLoss 1.3602 (1.2388)\tPrec@1 75.000 (63.779)\tPrec@5 83.333 (90.099)\n",
      "Epoch: [4][200/1334]\t\\Time 0.321 (0.282)\tData 0.291 (0.253)\tLoss 0.8877 (1.2574)\tPrec@1 83.333 (63.640)\tPrec@5 91.667 (89.179)\n",
      "Epoch: [4][300/1334]\t\\Time 0.301 (0.280)\tData 0.272 (0.251)\tLoss 1.0233 (1.2677)\tPrec@1 50.000 (63.621)\tPrec@5 100.000 (89.480)\n",
      "Epoch: [4][400/1334]\t\\Time 0.293 (0.281)\tData 0.264 (0.253)\tLoss 1.5102 (1.2693)\tPrec@1 41.667 (63.259)\tPrec@5 100.000 (89.401)\n",
      "Epoch: [4][500/1334]\t\\Time 0.193 (0.281)\tData 0.166 (0.253)\tLoss 1.4325 (1.2964)\tPrec@1 66.667 (62.458)\tPrec@5 83.333 (89.055)\n",
      "Epoch: [4][600/1334]\t\\Time 0.264 (0.281)\tData 0.236 (0.252)\tLoss 1.7546 (1.3008)\tPrec@1 41.667 (62.646)\tPrec@5 91.667 (89.060)\n",
      "Epoch: [4][700/1334]\t\\Time 0.291 (0.282)\tData 0.263 (0.253)\tLoss 0.3351 (1.3106)\tPrec@1 91.667 (62.185)\tPrec@5 100.000 (89.051)\n",
      "Epoch: [4][800/1334]\t\\Time 0.285 (0.283)\tData 0.255 (0.254)\tLoss 1.1130 (1.3063)\tPrec@1 50.000 (62.360)\tPrec@5 91.667 (88.931)\n",
      "Epoch: [4][900/1334]\t\\Time 0.239 (0.284)\tData 0.209 (0.255)\tLoss 1.3935 (1.3058)\tPrec@1 58.333 (62.486)\tPrec@5 83.333 (88.901)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.294 (0.285)\tData 0.264 (0.257)\tLoss 0.7708 (1.3186)\tPrec@1 66.667 (62.196)\tPrec@5 100.000 (88.711)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.369 (0.287)\tData 0.334 (0.258)\tLoss 0.8210 (1.3206)\tPrec@1 83.333 (62.254)\tPrec@5 100.000 (88.677)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.316 (0.287)\tData 0.287 (0.259)\tLoss 1.7373 (1.3251)\tPrec@1 50.000 (62.177)\tPrec@5 75.000 (88.704)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.338 (0.288)\tData 0.309 (0.259)\tLoss 1.0425 (1.3370)\tPrec@1 58.333 (61.965)\tPrec@5 91.667 (88.509)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.312 (0.312)\n",
      "\n",
      "Loss 1.2195 (1.2195)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.342 (0.341)\n",
      "\n",
      "Loss 1.4067 (1.8072)\n",
      "\n",
      "Prec@1 66.667 (52.970)\n",
      "\n",
      "Prec@5 83.333 (82.178)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.266 (0.345)\n",
      "\n",
      "Loss 1.5662 (1.8104)\n",
      "\n",
      "Prec@1 58.333 (53.773)\n",
      "\n",
      "Prec@5 91.667 (82.338)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.344)\n",
      "\n",
      "Loss 1.5043 (1.8242)\n",
      "\n",
      "Prec@1 50.000 (52.962)\n",
      "\n",
      "Prec@5 100.000 (82.475)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1334]\t\\Time 0.456 (0.456)\tData 0.278 (0.278)\tLoss 1.3501 (1.3501)\tPrec@1 58.333 (58.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [5][100/1334]\t\\Time 0.365 (0.286)\tData 0.333 (0.256)\tLoss 0.5355 (1.0125)\tPrec@1 83.333 (70.462)\tPrec@5 91.667 (92.244)\n",
      "Epoch: [5][200/1334]\t\\Time 0.322 (0.282)\tData 0.295 (0.252)\tLoss 1.1404 (1.0300)\tPrec@1 75.000 (69.776)\tPrec@5 91.667 (92.537)\n",
      "Epoch: [5][300/1334]\t\\Time 0.237 (0.278)\tData 0.209 (0.249)\tLoss 1.5289 (1.0731)\tPrec@1 58.333 (68.494)\tPrec@5 91.667 (91.944)\n",
      "Epoch: [5][400/1334]\t\\Time 0.276 (0.276)\tData 0.248 (0.246)\tLoss 1.1296 (1.0741)\tPrec@1 66.667 (68.329)\tPrec@5 91.667 (91.978)\n",
      "Epoch: [5][500/1334]\t\\Time 0.291 (0.277)\tData 0.263 (0.248)\tLoss 1.1134 (1.0888)\tPrec@1 66.667 (68.097)\tPrec@5 91.667 (91.700)\n",
      "Epoch: [5][600/1334]\t\\Time 0.298 (0.278)\tData 0.270 (0.249)\tLoss 1.7821 (1.0962)\tPrec@1 50.000 (67.818)\tPrec@5 75.000 (91.583)\n",
      "Epoch: [5][700/1334]\t\\Time 0.274 (0.281)\tData 0.245 (0.253)\tLoss 1.5252 (1.1055)\tPrec@1 50.000 (67.475)\tPrec@5 75.000 (91.607)\n",
      "Epoch: [5][800/1334]\t\\Time 0.240 (0.283)\tData 0.220 (0.254)\tLoss 0.8225 (1.1149)\tPrec@1 75.000 (67.291)\tPrec@5 100.000 (91.469)\n",
      "Epoch: [5][900/1334]\t\\Time 0.262 (0.285)\tData 0.230 (0.256)\tLoss 1.7390 (1.1162)\tPrec@1 50.000 (67.370)\tPrec@5 83.333 (91.371)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.257 (0.286)\tData 0.229 (0.258)\tLoss 0.8824 (1.1203)\tPrec@1 58.333 (67.241)\tPrec@5 100.000 (91.375)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.333 (0.287)\tData 0.303 (0.259)\tLoss 1.2467 (1.1235)\tPrec@1 58.333 (67.181)\tPrec@5 91.667 (91.349)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.327 (0.289)\tData 0.298 (0.260)\tLoss 1.2760 (1.1271)\tPrec@1 58.333 (67.027)\tPrec@5 91.667 (91.299)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.312 (0.289)\tData 0.282 (0.261)\tLoss 1.4201 (1.1365)\tPrec@1 50.000 (66.724)\tPrec@5 91.667 (91.205)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.322 (0.322)\n",
      "\n",
      "Loss 1.8910 (1.8910)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.323 (0.343)\n",
      "\n",
      "Loss 1.0074 (1.6962)\n",
      "\n",
      "Prec@1 66.667 (58.993)\n",
      "\n",
      "Prec@5 100.000 (84.818)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.315 (0.345)\n",
      "\n",
      "Loss 2.0087 (1.7380)\n",
      "\n",
      "Prec@1 58.333 (58.624)\n",
      "\n",
      "Prec@5 83.333 (83.997)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.316 (0.346)\n",
      "\n",
      "Loss 1.6684 (1.7650)\n",
      "\n",
      "Prec@1 66.667 (58.029)\n",
      "\n",
      "Prec@5 91.667 (83.776)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1334]\t\\Time 0.476 (0.476)\tData 0.294 (0.294)\tLoss 0.6731 (0.6731)\tPrec@1 75.000 (75.000)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [6][100/1334]\t\\Time 0.246 (0.292)\tData 0.217 (0.262)\tLoss 0.9195 (0.9176)\tPrec@1 58.333 (71.782)\tPrec@5 100.000 (93.647)\n",
      "Epoch: [6][200/1334]\t\\Time 0.238 (0.285)\tData 0.210 (0.256)\tLoss 0.4536 (0.9354)\tPrec@1 83.333 (71.973)\tPrec@5 100.000 (93.574)\n",
      "Epoch: [6][300/1334]\t\\Time 0.292 (0.283)\tData 0.261 (0.254)\tLoss 0.6285 (0.9201)\tPrec@1 66.667 (72.508)\tPrec@5 91.667 (93.826)\n",
      "Epoch: [6][400/1334]\t\\Time 0.279 (0.282)\tData 0.251 (0.253)\tLoss 0.7752 (0.9410)\tPrec@1 83.333 (72.091)\tPrec@5 91.667 (93.495)\n",
      "Epoch: [6][500/1334]\t\\Time 0.320 (0.281)\tData 0.292 (0.252)\tLoss 0.9685 (0.9418)\tPrec@1 66.667 (72.039)\tPrec@5 91.667 (93.580)\n",
      "Epoch: [6][600/1334]\t\\Time 0.266 (0.281)\tData 0.239 (0.253)\tLoss 0.7474 (0.9603)\tPrec@1 83.333 (71.755)\tPrec@5 91.667 (93.331)\n",
      "Epoch: [6][700/1334]\t\\Time 0.235 (0.282)\tData 0.206 (0.254)\tLoss 0.7955 (0.9656)\tPrec@1 66.667 (71.743)\tPrec@5 100.000 (93.283)\n",
      "Epoch: [6][800/1334]\t\\Time 0.227 (0.282)\tData 0.198 (0.254)\tLoss 0.8388 (0.9763)\tPrec@1 75.000 (71.712)\tPrec@5 91.667 (93.123)\n",
      "Epoch: [6][900/1334]\t\\Time 0.370 (0.284)\tData 0.342 (0.256)\tLoss 1.1142 (0.9751)\tPrec@1 66.667 (71.754)\tPrec@5 83.333 (93.110)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.306 (0.286)\tData 0.274 (0.257)\tLoss 0.8510 (0.9828)\tPrec@1 75.000 (71.637)\tPrec@5 91.667 (93.024)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.285 (0.287)\tData 0.256 (0.259)\tLoss 0.7148 (0.9934)\tPrec@1 91.667 (71.359)\tPrec@5 100.000 (92.916)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.266 (0.288)\tData 0.237 (0.259)\tLoss 1.0936 (0.9924)\tPrec@1 58.333 (71.392)\tPrec@5 83.333 (92.930)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.326 (0.289)\tData 0.299 (0.261)\tLoss 1.5119 (0.9976)\tPrec@1 50.000 (71.311)\tPrec@5 83.333 (92.845)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.307 (0.307)\n",
      "\n",
      "Loss 2.0851 (2.0851)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.332 (0.339)\n",
      "\n",
      "Loss 1.6918 (1.8615)\n",
      "\n",
      "Prec@1 41.667 (53.135)\n",
      "\n",
      "Prec@5 91.667 (81.518)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.319 (0.344)\n",
      "\n",
      "Loss 1.6417 (1.8393)\n",
      "\n",
      "Prec@1 58.333 (54.353)\n",
      "\n",
      "Prec@5 83.333 (81.177)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.344)\n",
      "\n",
      "Loss 2.8870 (1.8213)\n",
      "\n",
      "Prec@1 25.000 (54.596)\n",
      "\n",
      "Prec@5 58.333 (81.506)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1334]\t\\Time 0.347 (0.347)\tData 0.263 (0.263)\tLoss 0.6122 (0.6122)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/1334]\t\\Time 0.325 (0.288)\tData 0.297 (0.258)\tLoss 0.7166 (0.8113)\tPrec@1 75.000 (76.485)\tPrec@5 100.000 (94.884)\n",
      "Epoch: [7][200/1334]\t\\Time 0.359 (0.285)\tData 0.329 (0.255)\tLoss 1.1001 (0.8184)\tPrec@1 58.333 (75.622)\tPrec@5 91.667 (95.274)\n",
      "Epoch: [7][300/1334]\t\\Time 0.231 (0.283)\tData 0.202 (0.253)\tLoss 1.1374 (0.8032)\tPrec@1 58.333 (76.274)\tPrec@5 91.667 (95.210)\n",
      "Epoch: [7][400/1334]\t\\Time 0.286 (0.281)\tData 0.258 (0.252)\tLoss 1.9071 (0.8081)\tPrec@1 50.000 (75.914)\tPrec@5 66.667 (95.012)\n",
      "Epoch: [7][500/1334]\t\\Time 0.213 (0.281)\tData 0.184 (0.252)\tLoss 0.5917 (0.8134)\tPrec@1 83.333 (76.081)\tPrec@5 100.000 (94.960)\n",
      "Epoch: [7][600/1334]\t\\Time 0.343 (0.283)\tData 0.314 (0.254)\tLoss 1.2086 (0.8272)\tPrec@1 66.667 (75.527)\tPrec@5 100.000 (94.939)\n",
      "Epoch: [7][700/1334]\t\\Time 0.320 (0.284)\tData 0.291 (0.255)\tLoss 1.1381 (0.8396)\tPrec@1 66.667 (75.357)\tPrec@5 91.667 (94.793)\n",
      "Epoch: [7][800/1334]\t\\Time 0.330 (0.287)\tData 0.301 (0.258)\tLoss 1.4578 (0.8438)\tPrec@1 58.333 (75.166)\tPrec@5 83.333 (94.829)\n",
      "Epoch: [7][900/1334]\t\\Time 0.356 (0.288)\tData 0.328 (0.259)\tLoss 0.7226 (0.8547)\tPrec@1 75.000 (74.898)\tPrec@5 91.667 (94.663)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.295 (0.288)\tData 0.266 (0.259)\tLoss 0.8822 (0.8673)\tPrec@1 75.000 (74.692)\tPrec@5 91.667 (94.447)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.352 (0.289)\tData 0.324 (0.260)\tLoss 0.5020 (0.8740)\tPrec@1 91.667 (74.387)\tPrec@5 100.000 (94.331)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.247 (0.290)\tData 0.218 (0.261)\tLoss 0.5249 (0.8793)\tPrec@1 83.333 (74.258)\tPrec@5 100.000 (94.199)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.274 (0.290)\tData 0.247 (0.261)\tLoss 0.3602 (0.8807)\tPrec@1 83.333 (74.251)\tPrec@5 100.000 (94.216)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.325 (0.325)\n",
      "\n",
      "Loss 1.9682 (1.9682)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.351 (0.339)\n",
      "\n",
      "Loss 0.9150 (1.9133)\n",
      "\n",
      "Prec@1 75.000 (53.135)\n",
      "\n",
      "Prec@5 91.667 (81.766)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.330 (0.344)\n",
      "\n",
      "Loss 1.9307 (1.8909)\n",
      "\n",
      "Prec@1 41.667 (54.022)\n",
      "\n",
      "Prec@5 83.333 (81.468)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.243 (0.344)\n",
      "\n",
      "Loss 1.5249 (1.8769)\n",
      "\n",
      "Prec@1 58.333 (53.821)\n",
      "\n",
      "Prec@5 91.667 (81.506)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1334]\t\\Time 0.363 (0.363)\tData 0.271 (0.271)\tLoss 0.4991 (0.4991)\tPrec@1 66.667 (66.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/1334]\t\\Time 0.277 (0.277)\tData 0.248 (0.248)\tLoss 0.3628 (0.6172)\tPrec@1 91.667 (81.848)\tPrec@5 100.000 (96.617)\n",
      "Epoch: [8][200/1334]\t\\Time 0.254 (0.279)\tData 0.226 (0.249)\tLoss 0.2987 (0.6446)\tPrec@1 91.667 (81.053)\tPrec@5 100.000 (96.352)\n",
      "Epoch: [8][300/1334]\t\\Time 0.220 (0.279)\tData 0.193 (0.250)\tLoss 0.4349 (0.6545)\tPrec@1 83.333 (80.676)\tPrec@5 100.000 (96.262)\n",
      "Epoch: [8][400/1334]\t\\Time 0.253 (0.280)\tData 0.226 (0.251)\tLoss 0.6763 (0.6851)\tPrec@1 83.333 (79.655)\tPrec@5 91.667 (96.010)\n",
      "Epoch: [8][500/1334]\t\\Time 0.267 (0.282)\tData 0.238 (0.253)\tLoss 0.6650 (0.6992)\tPrec@1 75.000 (79.075)\tPrec@5 91.667 (95.925)\n",
      "Epoch: [8][600/1334]\t\\Time 0.258 (0.282)\tData 0.231 (0.253)\tLoss 0.9780 (0.7043)\tPrec@1 75.000 (78.841)\tPrec@5 91.667 (95.923)\n",
      "Epoch: [8][700/1334]\t\\Time 0.330 (0.282)\tData 0.300 (0.254)\tLoss 0.8900 (0.7171)\tPrec@1 75.000 (78.483)\tPrec@5 100.000 (95.887)\n",
      "Epoch: [8][800/1334]\t\\Time 0.235 (0.283)\tData 0.206 (0.254)\tLoss 0.7498 (0.7212)\tPrec@1 75.000 (78.277)\tPrec@5 100.000 (95.891)\n",
      "Epoch: [8][900/1334]\t\\Time 0.262 (0.284)\tData 0.233 (0.256)\tLoss 0.7259 (0.7226)\tPrec@1 83.333 (78.293)\tPrec@5 100.000 (95.838)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.266 (0.286)\tData 0.237 (0.257)\tLoss 0.4452 (0.7326)\tPrec@1 83.333 (77.922)\tPrec@5 100.000 (95.788)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.318 (0.288)\tData 0.289 (0.259)\tLoss 0.9341 (0.7424)\tPrec@1 75.000 (77.695)\tPrec@5 100.000 (95.724)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.322 (0.289)\tData 0.295 (0.260)\tLoss 0.3630 (0.7500)\tPrec@1 83.333 (77.470)\tPrec@5 100.000 (95.677)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.392 (0.290)\tData 0.361 (0.261)\tLoss 0.8757 (0.7599)\tPrec@1 66.667 (77.127)\tPrec@5 91.667 (95.606)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.332 (0.332)\n",
      "\n",
      "Loss 1.3518 (1.3518)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.337 (0.344)\n",
      "\n",
      "Loss 1.6521 (1.6953)\n",
      "\n",
      "Prec@1 33.333 (57.673)\n",
      "\n",
      "Prec@5 91.667 (86.716)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.320 (0.346)\n",
      "\n",
      "Loss 1.7897 (1.7028)\n",
      "\n",
      "Prec@1 50.000 (58.624)\n",
      "\n",
      "Prec@5 83.333 (85.365)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.318 (0.347)\n",
      "\n",
      "Loss 1.0592 (1.6993)\n",
      "\n",
      "Prec@1 83.333 (59.081)\n",
      "\n",
      "Prec@5 91.667 (85.161)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1334]\t\\Time 0.382 (0.382)\tData 0.250 (0.250)\tLoss 0.4814 (0.4814)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/1334]\t\\Time 0.270 (0.285)\tData 0.239 (0.256)\tLoss 0.2718 (0.5373)\tPrec@1 91.667 (82.921)\tPrec@5 100.000 (98.102)\n",
      "Epoch: [9][200/1334]\t\\Time 0.303 (0.283)\tData 0.274 (0.254)\tLoss 0.4829 (0.5548)\tPrec@1 66.667 (82.090)\tPrec@5 100.000 (98.051)\n",
      "Epoch: [9][300/1334]\t\\Time 0.296 (0.284)\tData 0.267 (0.255)\tLoss 0.3058 (0.5657)\tPrec@1 83.333 (82.060)\tPrec@5 100.000 (98.117)\n",
      "Epoch: [9][400/1334]\t\\Time 0.229 (0.282)\tData 0.200 (0.253)\tLoss 0.1256 (0.5710)\tPrec@1 100.000 (82.170)\tPrec@5 100.000 (97.797)\n",
      "Epoch: [9][500/1334]\t\\Time 0.225 (0.283)\tData 0.196 (0.255)\tLoss 0.2797 (0.5666)\tPrec@1 91.667 (82.402)\tPrec@5 100.000 (97.821)\n",
      "Epoch: [9][600/1334]\t\\Time 0.290 (0.284)\tData 0.263 (0.255)\tLoss 0.4847 (0.5883)\tPrec@1 91.667 (81.697)\tPrec@5 100.000 (97.684)\n",
      "Epoch: [9][700/1334]\t\\Time 0.334 (0.285)\tData 0.307 (0.256)\tLoss 0.5130 (0.5928)\tPrec@1 83.333 (81.491)\tPrec@5 91.667 (97.622)\n",
      "Epoch: [9][800/1334]\t\\Time 0.385 (0.286)\tData 0.358 (0.257)\tLoss 0.4656 (0.6106)\tPrec@1 91.667 (81.086)\tPrec@5 91.667 (97.326)\n",
      "Epoch: [9][900/1334]\t\\Time 0.133 (0.287)\tData 0.106 (0.258)\tLoss 0.9021 (0.6253)\tPrec@1 58.333 (80.725)\tPrec@5 91.667 (97.216)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.323 (0.288)\tData 0.294 (0.259)\tLoss 0.3504 (0.6330)\tPrec@1 91.667 (80.561)\tPrec@5 100.000 (97.145)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.231 (0.290)\tData 0.206 (0.261)\tLoss 0.7102 (0.6374)\tPrec@1 83.333 (80.389)\tPrec@5 100.000 (97.056)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.302 (0.291)\tData 0.274 (0.262)\tLoss 0.3606 (0.6432)\tPrec@1 91.667 (80.273)\tPrec@5 100.000 (96.947)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.276 (0.291)\tData 0.244 (0.262)\tLoss 0.7151 (0.6537)\tPrec@1 75.000 (80.060)\tPrec@5 100.000 (96.810)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.315 (0.315)\n",
      "\n",
      "Loss 1.2660 (1.2660)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.351 (0.342)\n",
      "\n",
      "Loss 2.5488 (1.8372)\n",
      "\n",
      "Prec@1 58.333 (57.508)\n",
      "\n",
      "Prec@5 91.667 (84.488)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.316 (0.344)\n",
      "\n",
      "Loss 1.6614 (1.8568)\n",
      "\n",
      "Prec@1 75.000 (56.758)\n",
      "\n",
      "Prec@5 83.333 (83.458)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.326 (0.344)\n",
      "\n",
      "Loss 2.2924 (1.8528)\n",
      "\n",
      "Prec@1 58.333 (56.589)\n",
      "\n",
      "Prec@5 83.333 (83.666)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "=> loading checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 9)\n",
      "Epoch: [10][0/1334]\t\\Time 0.445 (0.445)\tData 0.272 (0.272)\tLoss 0.9637 (0.9637)\tPrec@1 83.333 (83.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [10][100/1334]\t\\Time 0.314 (0.284)\tData 0.287 (0.254)\tLoss 0.5355 (0.5069)\tPrec@1 83.333 (85.396)\tPrec@5 91.667 (97.855)\n",
      "Epoch: [10][200/1334]\t\\Time 0.221 (0.283)\tData 0.191 (0.254)\tLoss 0.1328 (0.4485)\tPrec@1 100.000 (87.189)\tPrec@5 100.000 (98.176)\n",
      "Epoch: [10][300/1334]\t\\Time 0.222 (0.278)\tData 0.192 (0.249)\tLoss 0.1168 (0.4031)\tPrec@1 100.000 (88.566)\tPrec@5 100.000 (98.450)\n",
      "Epoch: [10][400/1334]\t\\Time 0.276 (0.282)\tData 0.247 (0.253)\tLoss 0.1455 (0.3746)\tPrec@1 100.000 (89.381)\tPrec@5 100.000 (98.628)\n",
      "Epoch: [10][500/1334]\t\\Time 0.277 (0.282)\tData 0.248 (0.254)\tLoss 0.5857 (0.3590)\tPrec@1 83.333 (89.804)\tPrec@5 100.000 (98.719)\n",
      "Epoch: [10][600/1334]\t\\Time 0.251 (0.283)\tData 0.222 (0.254)\tLoss 0.0856 (0.3468)\tPrec@1 100.000 (90.155)\tPrec@5 100.000 (98.766)\n",
      "Epoch: [10][700/1334]\t\\Time 0.305 (0.283)\tData 0.278 (0.255)\tLoss 0.1706 (0.3309)\tPrec@1 91.667 (90.668)\tPrec@5 100.000 (98.847)\n",
      "Epoch: [10][800/1334]\t\\Time 0.333 (0.286)\tData 0.304 (0.257)\tLoss 0.0848 (0.3191)\tPrec@1 100.000 (91.032)\tPrec@5 100.000 (98.887)\n",
      "Epoch: [10][900/1334]\t\\Time 0.330 (0.286)\tData 0.300 (0.258)\tLoss 0.3018 (0.3124)\tPrec@1 91.667 (91.130)\tPrec@5 100.000 (98.955)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.207 (0.287)\tData 0.179 (0.258)\tLoss 0.0247 (0.3029)\tPrec@1 100.000 (91.359)\tPrec@5 100.000 (98.968)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.294 (0.288)\tData 0.264 (0.260)\tLoss 0.1682 (0.2944)\tPrec@1 91.667 (91.591)\tPrec@5 100.000 (99.016)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.351 (0.290)\tData 0.321 (0.261)\tLoss 0.0495 (0.2907)\tPrec@1 100.000 (91.715)\tPrec@5 100.000 (98.994)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.327 (0.291)\tData 0.298 (0.262)\tLoss 0.2198 (0.2840)\tPrec@1 91.667 (91.904)\tPrec@5 100.000 (99.065)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.331 (0.331)\n",
      "\n",
      "Loss 1.0287 (1.0287)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.310 (0.344)\n",
      "\n",
      "Loss 0.9664 (1.4093)\n",
      "\n",
      "Prec@1 66.667 (67.327)\n",
      "\n",
      "Prec@5 100.000 (89.274)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.329 (0.346)\n",
      "\n",
      "Loss 1.0598 (1.3884)\n",
      "\n",
      "Prec@1 58.333 (68.740)\n",
      "\n",
      "Prec@5 91.667 (89.386)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.314 (0.345)\n",
      "\n",
      "Loss 0.6001 (1.3947)\n",
      "\n",
      "Prec@1 75.000 (68.466)\n",
      "\n",
      "Prec@5 100.000 (89.313)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [11][0/1334]\t\\Time 0.470 (0.470)\tData 0.300 (0.300)\tLoss 0.1142 (0.1142)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.240 (0.285)\tData 0.218 (0.256)\tLoss 0.1887 (0.1506)\tPrec@1 100.000 (96.535)\tPrec@5 100.000 (99.505)\n",
      "Epoch: [11][200/1334]\t\\Time 0.314 (0.282)\tData 0.286 (0.253)\tLoss 0.1449 (0.1491)\tPrec@1 91.667 (96.227)\tPrec@5 100.000 (99.585)\n",
      "Epoch: [11][300/1334]\t\\Time 0.308 (0.284)\tData 0.279 (0.255)\tLoss 0.1278 (0.1491)\tPrec@1 100.000 (95.875)\tPrec@5 100.000 (99.557)\n",
      "Epoch: [11][400/1334]\t\\Time 0.346 (0.295)\tData 0.318 (0.266)\tLoss 0.3517 (0.1496)\tPrec@1 91.667 (95.657)\tPrec@5 91.667 (99.584)\n",
      "Epoch: [11][500/1334]\t\\Time 0.287 (0.296)\tData 0.259 (0.267)\tLoss 0.0255 (0.1481)\tPrec@1 100.000 (95.725)\tPrec@5 100.000 (99.601)\n",
      "Epoch: [11][600/1334]\t\\Time 0.315 (0.296)\tData 0.286 (0.267)\tLoss 0.3218 (0.1499)\tPrec@1 83.333 (95.618)\tPrec@5 100.000 (99.653)\n",
      "Epoch: [11][700/1334]\t\\Time 0.303 (0.295)\tData 0.275 (0.266)\tLoss 0.2466 (0.1479)\tPrec@1 91.667 (95.613)\tPrec@5 100.000 (99.679)\n",
      "Epoch: [11][800/1334]\t\\Time 0.244 (0.295)\tData 0.215 (0.266)\tLoss 0.0311 (0.1493)\tPrec@1 100.000 (95.547)\tPrec@5 100.000 (99.657)\n",
      "Epoch: [11][900/1334]\t\\Time 0.307 (0.296)\tData 0.277 (0.267)\tLoss 0.0794 (0.1474)\tPrec@1 100.000 (95.597)\tPrec@5 100.000 (99.695)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.325 (0.296)\tData 0.300 (0.267)\tLoss 0.1762 (0.1457)\tPrec@1 100.000 (95.679)\tPrec@5 100.000 (99.684)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.327 (0.297)\tData 0.297 (0.268)\tLoss 0.4270 (0.1447)\tPrec@1 91.667 (95.769)\tPrec@5 91.667 (99.652)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.293 (0.297)\tData 0.264 (0.269)\tLoss 0.1092 (0.1448)\tPrec@1 100.000 (95.754)\tPrec@5 100.000 (99.653)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.248 (0.297)\tData 0.219 (0.269)\tLoss 0.0455 (0.1419)\tPrec@1 100.000 (95.869)\tPrec@5 100.000 (99.648)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.332 (0.332)\n",
      "\n",
      "Loss 1.2859 (1.2859)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.336 (0.340)\n",
      "\n",
      "Loss 1.2305 (1.5023)\n",
      "\n",
      "Prec@1 58.333 (67.739)\n",
      "\n",
      "Prec@5 100.000 (89.439)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.312 (0.341)\n",
      "\n",
      "Loss 1.3279 (1.4783)\n",
      "\n",
      "Prec@1 58.333 (69.237)\n",
      "\n",
      "Prec@5 91.667 (89.303)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.314 (0.343)\n",
      "\n",
      "Loss 0.5691 (1.4859)\n",
      "\n",
      "Prec@1 66.667 (69.324)\n",
      "\n",
      "Prec@5 100.000 (89.396)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [12][0/1334]\t\\Time 0.378 (0.378)\tData 0.284 (0.284)\tLoss 0.0106 (0.0106)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.207 (0.283)\tData 0.178 (0.255)\tLoss 0.0555 (0.1042)\tPrec@1 100.000 (97.195)\tPrec@5 100.000 (99.835)\n",
      "Epoch: [12][200/1334]\t\\Time 0.279 (0.282)\tData 0.249 (0.254)\tLoss 0.0508 (0.1016)\tPrec@1 100.000 (97.181)\tPrec@5 100.000 (99.876)\n",
      "Epoch: [12][300/1334]\t\\Time 0.318 (0.283)\tData 0.289 (0.254)\tLoss 0.0698 (0.0946)\tPrec@1 100.000 (97.536)\tPrec@5 100.000 (99.889)\n",
      "Epoch: [12][400/1334]\t\\Time 0.318 (0.284)\tData 0.290 (0.256)\tLoss 0.1404 (0.0937)\tPrec@1 91.667 (97.652)\tPrec@5 100.000 (99.896)\n",
      "Epoch: [12][500/1334]\t\\Time 0.207 (0.285)\tData 0.178 (0.257)\tLoss 0.1248 (0.0960)\tPrec@1 100.000 (97.555)\tPrec@5 100.000 (99.884)\n",
      "Epoch: [12][600/1334]\t\\Time 0.274 (0.285)\tData 0.245 (0.257)\tLoss 0.0302 (0.0961)\tPrec@1 100.000 (97.546)\tPrec@5 100.000 (99.861)\n",
      "Epoch: [12][700/1334]\t\\Time 0.321 (0.286)\tData 0.295 (0.257)\tLoss 0.0125 (0.0957)\tPrec@1 100.000 (97.551)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [12][800/1334]\t\\Time 0.289 (0.286)\tData 0.260 (0.257)\tLoss 0.0097 (0.0974)\tPrec@1 100.000 (97.462)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [12][900/1334]\t\\Time 0.313 (0.287)\tData 0.281 (0.258)\tLoss 0.1525 (0.0980)\tPrec@1 91.667 (97.447)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.349 (0.287)\tData 0.320 (0.258)\tLoss 0.0377 (0.0965)\tPrec@1 100.000 (97.461)\tPrec@5 100.000 (99.833)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.355 (0.289)\tData 0.327 (0.260)\tLoss 0.0355 (0.0974)\tPrec@1 100.000 (97.374)\tPrec@5 100.000 (99.833)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.308 (0.290)\tData 0.277 (0.262)\tLoss 0.1167 (0.0966)\tPrec@1 91.667 (97.419)\tPrec@5 100.000 (99.840)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.268 (0.291)\tData 0.241 (0.262)\tLoss 0.0034 (0.0963)\tPrec@1 100.000 (97.425)\tPrec@5 100.000 (99.840)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.316 (0.316)\n",
      "\n",
      "Loss 1.0868 (1.0868)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.331 (0.338)\n",
      "\n",
      "Loss 0.9661 (1.5625)\n",
      "\n",
      "Prec@1 66.667 (67.822)\n",
      "\n",
      "Prec@5 100.000 (89.109)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.326 (0.342)\n",
      "\n",
      "Loss 1.6780 (1.5526)\n",
      "\n",
      "Prec@1 58.333 (68.325)\n",
      "\n",
      "Prec@5 91.667 (89.096)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.309 (0.343)\n",
      "\n",
      "Loss 0.7688 (1.5552)\n",
      "\n",
      "Prec@1 75.000 (68.300)\n",
      "\n",
      "Prec@5 100.000 (89.037)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [13][0/1334]\t\\Time 0.293 (0.293)\tData 0.207 (0.207)\tLoss 0.0274 (0.0274)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.309 (0.281)\tData 0.282 (0.252)\tLoss 0.0879 (0.0890)\tPrec@1 100.000 (97.607)\tPrec@5 100.000 (99.752)\n",
      "Epoch: [13][200/1334]\t\\Time 0.309 (0.279)\tData 0.281 (0.250)\tLoss 0.2589 (0.0777)\tPrec@1 83.333 (98.051)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [13][300/1334]\t\\Time 0.309 (0.284)\tData 0.279 (0.255)\tLoss 0.0395 (0.0734)\tPrec@1 100.000 (98.034)\tPrec@5 100.000 (99.889)\n",
      "Epoch: [13][400/1334]\t\\Time 0.288 (0.283)\tData 0.261 (0.255)\tLoss 0.0067 (0.0683)\tPrec@1 100.000 (98.254)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [13][500/1334]\t\\Time 0.268 (0.284)\tData 0.240 (0.255)\tLoss 0.0117 (0.0680)\tPrec@1 100.000 (98.237)\tPrec@5 100.000 (99.933)\n",
      "Epoch: [13][600/1334]\t\\Time 0.330 (0.285)\tData 0.302 (0.256)\tLoss 0.2390 (0.0663)\tPrec@1 83.333 (98.253)\tPrec@5 100.000 (99.945)\n",
      "Epoch: [13][700/1334]\t\\Time 0.287 (0.286)\tData 0.259 (0.257)\tLoss 0.0259 (0.0662)\tPrec@1 100.000 (98.324)\tPrec@5 100.000 (99.929)\n",
      "Epoch: [13][800/1334]\t\\Time 0.228 (0.287)\tData 0.198 (0.259)\tLoss 0.0507 (0.0655)\tPrec@1 100.000 (98.335)\tPrec@5 100.000 (99.927)\n",
      "Epoch: [13][900/1334]\t\\Time 0.340 (0.288)\tData 0.311 (0.259)\tLoss 0.1009 (0.0649)\tPrec@1 100.000 (98.409)\tPrec@5 100.000 (99.935)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.304 (0.289)\tData 0.275 (0.261)\tLoss 0.0435 (0.0658)\tPrec@1 100.000 (98.427)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.327 (0.290)\tData 0.299 (0.262)\tLoss 0.0037 (0.0652)\tPrec@1 100.000 (98.464)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.385 (0.291)\tData 0.356 (0.262)\tLoss 0.0120 (0.0660)\tPrec@1 100.000 (98.439)\tPrec@5 100.000 (99.924)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.301 (0.291)\tData 0.270 (0.262)\tLoss 0.0198 (0.0660)\tPrec@1 100.000 (98.437)\tPrec@5 100.000 (99.930)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.324 (0.324)\n",
      "\n",
      "Loss 1.3890 (1.3890)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.340 (0.342)\n",
      "\n",
      "Loss 1.3043 (1.6133)\n",
      "\n",
      "Prec@1 66.667 (67.904)\n",
      "\n",
      "Prec@5 100.000 (88.861)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.321 (0.345)\n",
      "\n",
      "Loss 1.5766 (1.5915)\n",
      "\n",
      "Prec@1 58.333 (68.947)\n",
      "\n",
      "Prec@5 91.667 (88.972)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.331 (0.346)\n",
      "\n",
      "Loss 0.4402 (1.5930)\n",
      "\n",
      "Prec@1 83.333 (69.048)\n",
      "\n",
      "Prec@5 100.000 (88.953)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [14][0/1334]\t\\Time 0.410 (0.410)\tData 0.333 (0.333)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1334]\t\\Time 0.206 (0.286)\tData 0.181 (0.257)\tLoss 0.0261 (0.0584)\tPrec@1 100.000 (98.597)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [14][200/1334]\t\\Time 0.245 (0.284)\tData 0.217 (0.255)\tLoss 0.0387 (0.0511)\tPrec@1 100.000 (98.839)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [14][300/1334]\t\\Time 0.314 (0.283)\tData 0.285 (0.255)\tLoss 0.0117 (0.0526)\tPrec@1 100.000 (98.754)\tPrec@5 100.000 (99.945)\n",
      "Epoch: [14][400/1334]\t\\Time 0.338 (0.284)\tData 0.311 (0.255)\tLoss 0.0551 (0.0502)\tPrec@1 100.000 (98.857)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [14][500/1334]\t\\Time 0.325 (0.284)\tData 0.298 (0.255)\tLoss 0.0133 (0.0509)\tPrec@1 100.000 (98.852)\tPrec@5 100.000 (99.950)\n",
      "Epoch: [14][600/1334]\t\\Time 0.260 (0.286)\tData 0.231 (0.257)\tLoss 0.0115 (0.0510)\tPrec@1 100.000 (98.877)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [14][700/1334]\t\\Time 0.325 (0.288)\tData 0.296 (0.259)\tLoss 0.0133 (0.0511)\tPrec@1 100.000 (98.847)\tPrec@5 100.000 (99.964)\n",
      "Epoch: [14][800/1334]\t\\Time 0.330 (0.288)\tData 0.301 (0.259)\tLoss 0.0203 (0.0505)\tPrec@1 100.000 (98.876)\tPrec@5 100.000 (99.969)\n",
      "Epoch: [14][900/1334]\t\\Time 0.371 (0.289)\tData 0.334 (0.260)\tLoss 0.0440 (0.0501)\tPrec@1 100.000 (98.909)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.289 (0.290)\tData 0.260 (0.262)\tLoss 0.4133 (0.0501)\tPrec@1 91.667 (98.918)\tPrec@5 100.000 (99.975)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.285 (0.291)\tData 0.267 (0.263)\tLoss 0.0056 (0.0504)\tPrec@1 100.000 (98.880)\tPrec@5 100.000 (99.977)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.420 (0.292)\tData 0.390 (0.263)\tLoss 0.0091 (0.0503)\tPrec@1 100.000 (98.890)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.360 (0.292)\tData 0.332 (0.264)\tLoss 0.1203 (0.0507)\tPrec@1 91.667 (98.873)\tPrec@5 100.000 (99.981)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.317 (0.317)\n",
      "\n",
      "Loss 1.0723 (1.0723)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.335 (0.342)\n",
      "\n",
      "Loss 1.0715 (1.6458)\n",
      "\n",
      "Prec@1 66.667 (68.069)\n",
      "\n",
      "Prec@5 100.000 (88.696)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.263 (0.345)\n",
      "\n",
      "Loss 1.3468 (1.6259)\n",
      "\n",
      "Prec@1 66.667 (68.988)\n",
      "\n",
      "Prec@5 91.667 (88.847)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.320 (0.344)\n",
      "\n",
      "Loss 0.4703 (1.6205)\n",
      "\n",
      "Prec@1 75.000 (69.131)\n",
      "\n",
      "Prec@5 100.000 (88.870)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "=> loading checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet50_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 12)\n",
      "Epoch: [15][0/1334]\t\\Time 0.421 (0.421)\tData 0.257 (0.257)\tLoss 0.1585 (0.1585)\tPrec@1 91.667 (91.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.311 (0.281)\tData 0.283 (0.251)\tLoss 0.0513 (0.0962)\tPrec@1 100.000 (97.112)\tPrec@5 100.000 (99.835)\n",
      "Epoch: [15][200/1334]\t\\Time 0.319 (0.281)\tData 0.291 (0.253)\tLoss 0.0060 (0.0968)\tPrec@1 100.000 (97.347)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [15][300/1334]\t\\Time 0.249 (0.279)\tData 0.216 (0.251)\tLoss 0.0422 (0.0945)\tPrec@1 100.000 (97.425)\tPrec@5 100.000 (99.862)\n",
      "Epoch: [15][400/1334]\t\\Time 0.367 (0.283)\tData 0.337 (0.254)\tLoss 0.0109 (0.0977)\tPrec@1 100.000 (97.236)\tPrec@5 100.000 (99.875)\n",
      "Epoch: [15][500/1334]\t\\Time 0.233 (0.284)\tData 0.205 (0.256)\tLoss 0.0993 (0.1015)\tPrec@1 91.667 (97.139)\tPrec@5 100.000 (99.817)\n",
      "Epoch: [15][600/1334]\t\\Time 0.239 (0.285)\tData 0.209 (0.257)\tLoss 0.0198 (0.1024)\tPrec@1 100.000 (97.088)\tPrec@5 100.000 (99.820)\n",
      "Epoch: [15][700/1334]\t\\Time 0.272 (0.287)\tData 0.244 (0.258)\tLoss 0.0523 (0.0997)\tPrec@1 100.000 (97.194)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [15][800/1334]\t\\Time 0.271 (0.288)\tData 0.243 (0.259)\tLoss 0.0180 (0.0980)\tPrec@1 100.000 (97.264)\tPrec@5 100.000 (99.854)\n",
      "Epoch: [15][900/1334]\t\\Time 0.340 (0.289)\tData 0.309 (0.260)\tLoss 0.0115 (0.0988)\tPrec@1 100.000 (97.244)\tPrec@5 100.000 (99.852)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.338 (0.290)\tData 0.306 (0.261)\tLoss 0.1110 (0.0976)\tPrec@1 100.000 (97.328)\tPrec@5 100.000 (99.858)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.283 (0.291)\tData 0.254 (0.262)\tLoss 0.1513 (0.0973)\tPrec@1 91.667 (97.336)\tPrec@5 100.000 (99.871)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.250 (0.292)\tData 0.222 (0.263)\tLoss 0.0341 (0.0962)\tPrec@1 100.000 (97.349)\tPrec@5 100.000 (99.875)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.323 (0.293)\tData 0.294 (0.264)\tLoss 0.0005 (0.0959)\tPrec@1 100.000 (97.374)\tPrec@5 100.000 (99.872)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.316 (0.316)\n",
      "\n",
      "Loss 1.3797 (1.3797)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.340 (0.344)\n",
      "\n",
      "Loss 1.1568 (1.5068)\n",
      "\n",
      "Prec@1 66.667 (67.574)\n",
      "\n",
      "Prec@5 100.000 (88.861)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.335 (0.346)\n",
      "\n",
      "Loss 1.3009 (1.4833)\n",
      "\n",
      "Prec@1 66.667 (69.113)\n",
      "\n",
      "Prec@5 91.667 (89.013)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.346)\n",
      "\n",
      "Loss 0.6571 (1.4879)\n",
      "\n",
      "Prec@1 75.000 (68.937)\n",
      "\n",
      "Prec@5 100.000 (89.203)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Epoch: [16][0/1334]\t\\Time 0.358 (0.358)\tData 0.276 (0.276)\tLoss 0.0368 (0.0368)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.268 (0.284)\tData 0.240 (0.254)\tLoss 0.0797 (0.0828)\tPrec@1 100.000 (98.102)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [16][200/1334]\t\\Time 0.254 (0.282)\tData 0.224 (0.252)\tLoss 0.1464 (0.0852)\tPrec@1 91.667 (97.720)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [16][300/1334]\t\\Time 0.340 (0.282)\tData 0.312 (0.252)\tLoss 0.0181 (0.0855)\tPrec@1 100.000 (97.757)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [16][400/1334]\t\\Time 0.286 (0.283)\tData 0.260 (0.254)\tLoss 0.0464 (0.0836)\tPrec@1 100.000 (97.860)\tPrec@5 100.000 (99.896)\n",
      "Epoch: [16][500/1334]\t\\Time 0.291 (0.283)\tData 0.261 (0.254)\tLoss 0.0428 (0.0874)\tPrec@1 100.000 (97.688)\tPrec@5 100.000 (99.850)\n",
      "Epoch: [16][600/1334]\t\\Time 0.280 (0.284)\tData 0.252 (0.255)\tLoss 0.0286 (0.0861)\tPrec@1 100.000 (97.698)\tPrec@5 100.000 (99.861)\n",
      "Epoch: [16][700/1334]\t\\Time 0.303 (0.284)\tData 0.274 (0.256)\tLoss 0.0804 (0.0857)\tPrec@1 100.000 (97.729)\tPrec@5 100.000 (99.869)\n",
      "Epoch: [16][800/1334]\t\\Time 0.296 (0.285)\tData 0.268 (0.257)\tLoss 0.0196 (0.0870)\tPrec@1 100.000 (97.701)\tPrec@5 100.000 (99.865)\n",
      "Epoch: [16][900/1334]\t\\Time 0.299 (0.287)\tData 0.270 (0.259)\tLoss 0.0185 (0.0859)\tPrec@1 100.000 (97.734)\tPrec@5 100.000 (99.871)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.295 (0.289)\tData 0.266 (0.260)\tLoss 0.0846 (0.0845)\tPrec@1 100.000 (97.777)\tPrec@5 100.000 (99.883)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.300 (0.290)\tData 0.271 (0.261)\tLoss 0.1170 (0.0833)\tPrec@1 91.667 (97.820)\tPrec@5 100.000 (99.886)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.323 (0.291)\tData 0.298 (0.262)\tLoss 0.0695 (0.0846)\tPrec@1 100.000 (97.766)\tPrec@5 100.000 (99.875)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.269 (0.292)\tData 0.240 (0.263)\tLoss 0.0530 (0.0841)\tPrec@1 100.000 (97.809)\tPrec@5 100.000 (99.878)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.319 (0.319)\n",
      "\n",
      "Loss 1.1539 (1.1539)\n",
      "\n",
      "Prec@1 83.333 (83.333)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.353 (0.342)\n",
      "\n",
      "Loss 0.9963 (1.5235)\n",
      "\n",
      "Prec@1 66.667 (67.079)\n",
      "\n",
      "Prec@5 100.000 (89.026)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.325 (0.344)\n",
      "\n",
      "Loss 1.4186 (1.5071)\n",
      "\n",
      "Prec@1 66.667 (69.113)\n",
      "\n",
      "Prec@5 91.667 (89.262)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.306 (0.345)\n",
      "\n",
      "Loss 0.4185 (1.5069)\n",
      "\n",
      "Prec@1 75.000 (68.909)\n",
      "\n",
      "Prec@5 100.000 (89.341)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = torchvision.models.vit_b_16(weights = 'VGG16_Weights.IMAGENET1K_V1')\n",
    "torch.cuda.empty_cache() \n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# model = torchvision.models.vgg16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet50_v3_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb55aef6-219d-4d1f-af5a-03a3846e1a5f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [0][0/1334]\t\\Time 6.378 (6.378)\tData 5.574 (5.574)\tLoss 4.7821 (4.7821)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/1334]\t\\Time 0.197 (0.347)\tData 0.166 (0.312)\tLoss 4.4415 (4.7731)\tPrec@1 16.667 (4.703)\tPrec@5 25.000 (16.419)\n",
      "Epoch: [0][200/1334]\t\\Time 0.221 (0.322)\tData 0.194 (0.287)\tLoss 3.5840 (4.4738)\tPrec@1 33.333 (6.592)\tPrec@5 41.667 (22.678)\n",
      "Epoch: [0][300/1334]\t\\Time 0.250 (0.304)\tData 0.239 (0.271)\tLoss 4.0377 (4.2284)\tPrec@1 8.333 (8.583)\tPrec@5 25.000 (27.796)\n",
      "Epoch: [0][400/1334]\t\\Time 0.341 (0.292)\tData 0.310 (0.262)\tLoss 2.5727 (4.0462)\tPrec@1 33.333 (10.702)\tPrec@5 58.333 (32.107)\n",
      "Epoch: [0][500/1334]\t\\Time 0.218 (0.288)\tData 0.198 (0.258)\tLoss 3.5704 (3.9070)\tPrec@1 16.667 (12.242)\tPrec@5 50.000 (35.329)\n",
      "Epoch: [0][600/1334]\t\\Time 0.292 (0.285)\tData 0.263 (0.256)\tLoss 4.2605 (3.7993)\tPrec@1 16.667 (13.422)\tPrec@5 50.000 (37.909)\n",
      "Epoch: [0][700/1334]\t\\Time 0.260 (0.284)\tData 0.231 (0.254)\tLoss 1.7526 (3.7081)\tPrec@1 66.667 (14.729)\tPrec@5 91.667 (40.074)\n",
      "Epoch: [0][800/1334]\t\\Time 0.289 (0.282)\tData 0.260 (0.253)\tLoss 3.3070 (3.6259)\tPrec@1 16.667 (16.001)\tPrec@5 58.333 (42.072)\n",
      "Epoch: [0][900/1334]\t\\Time 0.266 (0.281)\tData 0.238 (0.252)\tLoss 1.9300 (3.5509)\tPrec@1 41.667 (16.898)\tPrec@5 66.667 (43.748)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.299 (0.280)\tData 0.267 (0.252)\tLoss 2.9146 (3.4735)\tPrec@1 25.000 (18.173)\tPrec@5 50.000 (45.654)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.252 (0.280)\tData 0.242 (0.252)\tLoss 2.8457 (3.4138)\tPrec@1 33.333 (19.233)\tPrec@5 75.000 (47.131)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.293 (0.279)\tData 0.264 (0.251)\tLoss 3.2183 (3.3567)\tPrec@1 8.333 (20.192)\tPrec@5 58.333 (48.446)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.293 (0.280)\tData 0.266 (0.251)\tLoss 1.6914 (3.3089)\tPrec@1 50.000 (20.952)\tPrec@5 83.333 (49.488)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.348 (0.348)\n",
      "\n",
      "Loss 2.4857 (2.4857)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.345 (0.361)\n",
      "\n",
      "Loss 1.8051 (2.5289)\n",
      "\n",
      "Prec@1 33.333 (36.716)\n",
      "\n",
      "Prec@5 83.333 (68.399)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.307 (0.347)\n",
      "\n",
      "Loss 1.9338 (2.5176)\n",
      "\n",
      "Prec@1 58.333 (36.111)\n",
      "\n",
      "Prec@5 75.000 (69.403)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.294 (0.341)\n",
      "\n",
      "Loss 2.8065 (2.5314)\n",
      "\n",
      "Prec@1 16.667 (35.797)\n",
      "\n",
      "Prec@5 66.667 (69.214)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/1334]\t\\Time 0.346 (0.346)\tData 0.268 (0.268)\tLoss 2.3772 (2.3772)\tPrec@1 33.333 (33.333)\tPrec@5 75.000 (75.000)\n",
      "Epoch: [1][100/1334]\t\\Time 0.202 (0.276)\tData 0.178 (0.249)\tLoss 2.6850 (2.5863)\tPrec@1 25.000 (32.921)\tPrec@5 66.667 (66.007)\n",
      "Epoch: [1][200/1334]\t\\Time 0.191 (0.277)\tData 0.161 (0.248)\tLoss 1.6612 (2.5347)\tPrec@1 58.333 (33.002)\tPrec@5 83.333 (67.620)\n",
      "Epoch: [1][300/1334]\t\\Time 0.286 (0.274)\tData 0.249 (0.246)\tLoss 2.3970 (2.4631)\tPrec@1 41.667 (35.133)\tPrec@5 75.000 (69.186)\n",
      "Epoch: [1][400/1334]\t\\Time 0.330 (0.273)\tData 0.300 (0.245)\tLoss 1.5777 (2.4169)\tPrec@1 66.667 (36.409)\tPrec@5 75.000 (70.033)\n",
      "Epoch: [1][500/1334]\t\\Time 0.220 (0.271)\tData 0.192 (0.243)\tLoss 2.3644 (2.3884)\tPrec@1 41.667 (36.993)\tPrec@5 58.333 (70.426)\n",
      "Epoch: [1][600/1334]\t\\Time 0.293 (0.271)\tData 0.265 (0.242)\tLoss 3.2257 (2.3607)\tPrec@1 33.333 (37.659)\tPrec@5 50.000 (71.159)\n",
      "Epoch: [1][700/1334]\t\\Time 0.262 (0.271)\tData 0.232 (0.243)\tLoss 0.9845 (2.3386)\tPrec@1 75.000 (38.172)\tPrec@5 91.667 (71.481)\n",
      "Epoch: [1][800/1334]\t\\Time 0.300 (0.271)\tData 0.279 (0.242)\tLoss 2.7621 (2.3145)\tPrec@1 41.667 (38.691)\tPrec@5 75.000 (72.077)\n",
      "Epoch: [1][900/1334]\t\\Time 0.258 (0.270)\tData 0.228 (0.242)\tLoss 1.4284 (2.2886)\tPrec@1 50.000 (39.373)\tPrec@5 91.667 (72.355)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.289 (0.271)\tData 0.264 (0.243)\tLoss 1.7861 (2.2501)\tPrec@1 58.333 (40.185)\tPrec@5 83.333 (73.110)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.242 (0.271)\tData 0.222 (0.243)\tLoss 1.9341 (2.2274)\tPrec@1 58.333 (40.705)\tPrec@5 75.000 (73.562)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.281 (0.270)\tData 0.250 (0.242)\tLoss 2.1376 (2.2050)\tPrec@1 41.667 (41.223)\tPrec@5 75.000 (73.980)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.261 (0.270)\tData 0.232 (0.242)\tLoss 1.0416 (2.1918)\tPrec@1 75.000 (41.462)\tPrec@5 91.667 (74.161)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 2.5390 (2.5390)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.314 (0.323)\n",
      "\n",
      "Loss 2.0604 (2.4936)\n",
      "\n",
      "Prec@1 16.667 (39.356)\n",
      "\n",
      "Prec@5 75.000 (70.875)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.298 (0.325)\n",
      "\n",
      "Loss 2.9470 (2.4980)\n",
      "\n",
      "Prec@1 16.667 (38.018)\n",
      "\n",
      "Prec@5 66.667 (70.232)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.298 (0.326)\n",
      "\n",
      "Loss 3.1438 (2.5155)\n",
      "\n",
      "Prec@1 8.333 (37.625)\n",
      "\n",
      "Prec@5 66.667 (69.823)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1334]\t\\Time 0.345 (0.345)\tData 0.266 (0.266)\tLoss 1.9866 (1.9866)\tPrec@1 50.000 (50.000)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [2][100/1334]\t\\Time 0.180 (0.271)\tData 0.150 (0.243)\tLoss 1.9464 (1.9615)\tPrec@1 33.333 (45.875)\tPrec@5 75.000 (78.630)\n",
      "Epoch: [2][200/1334]\t\\Time 0.187 (0.269)\tData 0.161 (0.241)\tLoss 1.4421 (1.9112)\tPrec@1 41.667 (45.854)\tPrec@5 83.333 (79.395)\n",
      "Epoch: [2][300/1334]\t\\Time 0.281 (0.268)\tData 0.252 (0.240)\tLoss 2.2927 (1.8524)\tPrec@1 33.333 (47.370)\tPrec@5 58.333 (80.703)\n",
      "Epoch: [2][400/1334]\t\\Time 0.331 (0.268)\tData 0.301 (0.240)\tLoss 1.5338 (1.8075)\tPrec@1 66.667 (49.314)\tPrec@5 83.333 (81.338)\n",
      "Epoch: [2][500/1334]\t\\Time 0.212 (0.266)\tData 0.182 (0.238)\tLoss 1.9194 (1.7892)\tPrec@1 41.667 (49.884)\tPrec@5 66.667 (81.620)\n",
      "Epoch: [2][600/1334]\t\\Time 0.281 (0.266)\tData 0.254 (0.238)\tLoss 2.7709 (1.7729)\tPrec@1 41.667 (50.180)\tPrec@5 50.000 (82.182)\n",
      "Epoch: [2][700/1334]\t\\Time 0.253 (0.267)\tData 0.230 (0.239)\tLoss 0.5708 (1.7598)\tPrec@1 83.333 (50.582)\tPrec@5 100.000 (82.252)\n",
      "Epoch: [2][800/1334]\t\\Time 0.301 (0.267)\tData 0.282 (0.239)\tLoss 2.7454 (1.7423)\tPrec@1 33.333 (51.176)\tPrec@5 75.000 (82.636)\n",
      "Epoch: [2][900/1334]\t\\Time 0.270 (0.267)\tData 0.240 (0.239)\tLoss 1.5837 (1.7273)\tPrec@1 50.000 (51.517)\tPrec@5 83.333 (82.769)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.290 (0.268)\tData 0.260 (0.240)\tLoss 1.3543 (1.6992)\tPrec@1 58.333 (52.239)\tPrec@5 91.667 (83.117)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.270 (0.268)\tData 0.245 (0.240)\tLoss 1.7775 (1.6865)\tPrec@1 58.333 (52.664)\tPrec@5 91.667 (83.273)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.279 (0.268)\tData 0.249 (0.240)\tLoss 1.7791 (1.6735)\tPrec@1 41.667 (53.102)\tPrec@5 100.000 (83.424)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.270 (0.268)\tData 0.240 (0.240)\tLoss 0.9500 (1.6714)\tPrec@1 75.000 (53.215)\tPrec@5 91.667 (83.436)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.282 (0.282)\n",
      "\n",
      "Loss 2.2320 (2.2320)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.328 (0.321)\n",
      "\n",
      "Loss 1.5083 (2.6342)\n",
      "\n",
      "Prec@1 50.000 (40.347)\n",
      "\n",
      "Prec@5 83.333 (73.020)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.299 (0.323)\n",
      "\n",
      "Loss 1.9735 (2.6361)\n",
      "\n",
      "Prec@1 50.000 (40.879)\n",
      "\n",
      "Prec@5 75.000 (72.886)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.284 (0.324)\n",
      "\n",
      "Loss 2.2499 (2.6688)\n",
      "\n",
      "Prec@1 33.333 (40.089)\n",
      "\n",
      "Prec@5 83.333 (72.398)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1334]\t\\Time 0.348 (0.348)\tData 0.273 (0.273)\tLoss 1.6249 (1.6249)\tPrec@1 58.333 (58.333)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [3][100/1334]\t\\Time 0.190 (0.269)\tData 0.160 (0.243)\tLoss 1.7364 (1.5113)\tPrec@1 41.667 (57.508)\tPrec@5 83.333 (86.056)\n",
      "Epoch: [3][200/1334]\t\\Time 0.184 (0.269)\tData 0.159 (0.242)\tLoss 1.4281 (1.4665)\tPrec@1 50.000 (57.877)\tPrec@5 91.667 (87.231)\n",
      "Epoch: [3][300/1334]\t\\Time 0.283 (0.268)\tData 0.253 (0.240)\tLoss 1.6156 (1.4502)\tPrec@1 66.667 (58.472)\tPrec@5 83.333 (87.680)\n",
      "Epoch: [3][400/1334]\t\\Time 0.325 (0.267)\tData 0.292 (0.239)\tLoss 1.1575 (1.4235)\tPrec@1 83.333 (59.123)\tPrec@5 83.333 (87.822)\n",
      "Epoch: [3][500/1334]\t\\Time 0.210 (0.266)\tData 0.180 (0.238)\tLoss 1.5923 (1.4077)\tPrec@1 41.667 (59.464)\tPrec@5 91.667 (88.124)\n",
      "Epoch: [3][600/1334]\t\\Time 0.271 (0.266)\tData 0.245 (0.239)\tLoss 2.0664 (1.3933)\tPrec@1 33.333 (59.831)\tPrec@5 83.333 (88.367)\n",
      "Epoch: [3][700/1334]\t\\Time 0.271 (0.267)\tData 0.241 (0.239)\tLoss 0.3228 (1.3813)\tPrec@1 83.333 (60.485)\tPrec@5 100.000 (88.528)\n",
      "Epoch: [3][800/1334]\t\\Time 0.300 (0.267)\tData 0.270 (0.239)\tLoss 2.3692 (1.3626)\tPrec@1 41.667 (60.945)\tPrec@5 83.333 (88.754)\n",
      "Epoch: [3][900/1334]\t\\Time 0.264 (0.267)\tData 0.238 (0.239)\tLoss 0.8695 (1.3507)\tPrec@1 50.000 (61.265)\tPrec@5 100.000 (88.772)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.290 (0.268)\tData 0.260 (0.240)\tLoss 1.3739 (1.3354)\tPrec@1 50.000 (61.622)\tPrec@5 91.667 (88.928)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.282 (0.268)\tData 0.257 (0.241)\tLoss 1.4830 (1.3268)\tPrec@1 50.000 (61.883)\tPrec@5 83.333 (89.025)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.283 (0.268)\tData 0.250 (0.240)\tLoss 1.5134 (1.3196)\tPrec@1 58.333 (62.136)\tPrec@5 100.000 (89.141)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.250 (0.268)\tData 0.228 (0.240)\tLoss 0.9729 (1.3192)\tPrec@1 75.000 (62.215)\tPrec@5 91.667 (89.207)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 2.5154 (2.5154)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.312 (0.323)\n",
      "\n",
      "Loss 2.1777 (2.8026)\n",
      "\n",
      "Prec@1 41.667 (41.337)\n",
      "\n",
      "Prec@5 83.333 (74.092)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.301 (0.325)\n",
      "\n",
      "Loss 2.5030 (2.8451)\n",
      "\n",
      "Prec@1 41.667 (41.459)\n",
      "\n",
      "Prec@5 83.333 (73.342)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.301 (0.325)\n",
      "\n",
      "Loss 4.6224 (2.9333)\n",
      "\n",
      "Prec@1 0.000 (40.421)\n",
      "\n",
      "Prec@5 50.000 (72.702)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1334]\t\\Time 0.361 (0.361)\tData 0.283 (0.283)\tLoss 1.1174 (1.1174)\tPrec@1 58.333 (58.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [4][100/1334]\t\\Time 0.192 (0.271)\tData 0.164 (0.244)\tLoss 1.3326 (1.2086)\tPrec@1 66.667 (64.934)\tPrec@5 83.333 (90.182)\n",
      "Epoch: [4][200/1334]\t\\Time 0.190 (0.270)\tData 0.160 (0.243)\tLoss 1.7717 (1.1573)\tPrec@1 25.000 (66.501)\tPrec@5 75.000 (90.506)\n",
      "Epoch: [4][300/1334]\t\\Time 0.280 (0.268)\tData 0.250 (0.241)\tLoss 1.4972 (1.1501)\tPrec@1 50.000 (66.611)\tPrec@5 100.000 (90.975)\n",
      "Epoch: [4][400/1334]\t\\Time 0.320 (0.268)\tData 0.295 (0.240)\tLoss 1.0567 (1.1278)\tPrec@1 58.333 (67.041)\tPrec@5 83.333 (91.397)\n",
      "Epoch: [4][500/1334]\t\\Time 0.218 (0.267)\tData 0.183 (0.239)\tLoss 1.4722 (1.1181)\tPrec@1 66.667 (67.365)\tPrec@5 75.000 (91.683)\n",
      "Epoch: [4][600/1334]\t\\Time 0.282 (0.266)\tData 0.252 (0.238)\tLoss 1.4506 (1.1121)\tPrec@1 66.667 (67.512)\tPrec@5 91.667 (91.778)\n",
      "Epoch: [4][700/1334]\t\\Time 0.266 (0.267)\tData 0.232 (0.239)\tLoss 0.6721 (1.1124)\tPrec@1 66.667 (67.511)\tPrec@5 100.000 (91.833)\n",
      "Epoch: [4][800/1334]\t\\Time 0.306 (0.267)\tData 0.277 (0.239)\tLoss 1.2080 (1.0930)\tPrec@1 58.333 (67.894)\tPrec@5 91.667 (92.114)\n",
      "Epoch: [4][900/1334]\t\\Time 0.254 (0.267)\tData 0.225 (0.239)\tLoss 1.0321 (1.0826)\tPrec@1 75.000 (68.294)\tPrec@5 91.667 (92.240)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.280 (0.268)\tData 0.260 (0.240)\tLoss 0.4450 (1.0619)\tPrec@1 91.667 (68.873)\tPrec@5 100.000 (92.499)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.262 (0.268)\tData 0.231 (0.240)\tLoss 0.5709 (1.0497)\tPrec@1 83.333 (69.316)\tPrec@5 91.667 (92.666)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.257 (0.268)\tData 0.237 (0.240)\tLoss 0.7873 (1.0426)\tPrec@1 66.667 (69.484)\tPrec@5 100.000 (92.735)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.250 (0.268)\tData 0.230 (0.240)\tLoss 0.5461 (1.0386)\tPrec@1 75.000 (69.658)\tPrec@5 91.667 (92.756)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.300 (0.300)\n",
      "\n",
      "Loss 4.9503 (4.9503)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.331 (0.321)\n",
      "\n",
      "Loss 2.3599 (3.6584)\n",
      "\n",
      "Prec@1 25.000 (36.056)\n",
      "\n",
      "Prec@5 83.333 (67.244)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.310 (0.323)\n",
      "\n",
      "Loss 3.5067 (3.6677)\n",
      "\n",
      "Prec@1 33.333 (35.862)\n",
      "\n",
      "Prec@5 66.667 (67.620)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.285 (0.324)\n",
      "\n",
      "Loss 4.5205 (3.7266)\n",
      "\n",
      "Prec@1 25.000 (34.496)\n",
      "\n",
      "Prec@5 58.333 (66.556)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1334]\t\\Time 0.333 (0.333)\tData 0.254 (0.254)\tLoss 0.5877 (0.5877)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [5][100/1334]\t\\Time 0.183 (0.270)\tData 0.162 (0.244)\tLoss 1.4789 (1.0013)\tPrec@1 66.667 (69.967)\tPrec@5 83.333 (93.977)\n",
      "Epoch: [5][200/1334]\t\\Time 0.185 (0.269)\tData 0.155 (0.242)\tLoss 0.5298 (0.9637)\tPrec@1 83.333 (71.642)\tPrec@5 100.000 (94.030)\n",
      "Epoch: [5][300/1334]\t\\Time 0.284 (0.268)\tData 0.250 (0.241)\tLoss 0.6521 (0.9317)\tPrec@1 66.667 (72.425)\tPrec@5 100.000 (94.601)\n",
      "Epoch: [5][400/1334]\t\\Time 0.324 (0.268)\tData 0.290 (0.240)\tLoss 0.3746 (0.9014)\tPrec@1 83.333 (73.109)\tPrec@5 100.000 (94.992)\n",
      "Epoch: [5][500/1334]\t\\Time 0.222 (0.267)\tData 0.192 (0.239)\tLoss 0.9112 (0.8764)\tPrec@1 66.667 (73.719)\tPrec@5 100.000 (95.126)\n",
      "Epoch: [5][600/1334]\t\\Time 0.281 (0.266)\tData 0.251 (0.239)\tLoss 0.7206 (0.8470)\tPrec@1 58.333 (74.529)\tPrec@5 100.000 (95.258)\n",
      "Epoch: [5][700/1334]\t\\Time 0.253 (0.267)\tData 0.223 (0.239)\tLoss 0.2692 (0.8641)\tPrec@1 83.333 (74.037)\tPrec@5 100.000 (95.055)\n",
      "Epoch: [5][800/1334]\t\\Time 0.306 (0.267)\tData 0.275 (0.239)\tLoss 0.3889 (0.8521)\tPrec@1 83.333 (74.397)\tPrec@5 100.000 (95.173)\n",
      "Epoch: [5][900/1334]\t\\Time 0.246 (0.267)\tData 0.215 (0.239)\tLoss 0.7578 (0.8477)\tPrec@1 91.667 (74.649)\tPrec@5 91.667 (95.292)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.281 (0.267)\tData 0.250 (0.240)\tLoss 0.6733 (0.8398)\tPrec@1 83.333 (74.750)\tPrec@5 100.000 (95.413)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.264 (0.268)\tData 0.233 (0.240)\tLoss 1.0008 (0.8365)\tPrec@1 58.333 (74.788)\tPrec@5 83.333 (95.406)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.271 (0.268)\tData 0.241 (0.240)\tLoss 0.4162 (0.8304)\tPrec@1 91.667 (75.000)\tPrec@5 100.000 (95.462)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.255 (0.268)\tData 0.222 (0.240)\tLoss 0.9894 (0.8267)\tPrec@1 75.000 (75.115)\tPrec@5 83.333 (95.465)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.300 (0.300)\n",
      "\n",
      "Loss 3.8433 (3.8433)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.316 (0.324)\n",
      "\n",
      "Loss 1.9153 (2.8715)\n",
      "\n",
      "Prec@1 50.000 (45.792)\n",
      "\n",
      "Prec@5 91.667 (74.917)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.301 (0.325)\n",
      "\n",
      "Loss 3.1205 (2.8318)\n",
      "\n",
      "Prec@1 25.000 (45.937)\n",
      "\n",
      "Prec@5 75.000 (74.834)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.297 (0.325)\n",
      "\n",
      "Loss 2.4114 (2.8656)\n",
      "\n",
      "Prec@1 33.333 (45.404)\n",
      "\n",
      "Prec@5 75.000 (74.003)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1334]\t\\Time 0.348 (0.348)\tData 0.267 (0.267)\tLoss 0.6024 (0.6024)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [6][100/1334]\t\\Time 0.184 (0.270)\tData 0.156 (0.243)\tLoss 0.7933 (0.7282)\tPrec@1 75.000 (77.888)\tPrec@5 91.667 (96.535)\n",
      "Epoch: [6][200/1334]\t\\Time 0.191 (0.268)\tData 0.161 (0.241)\tLoss 0.7859 (0.6639)\tPrec@1 83.333 (80.058)\tPrec@5 91.667 (96.891)\n",
      "Epoch: [6][300/1334]\t\\Time 0.293 (0.267)\tData 0.266 (0.240)\tLoss 0.4673 (0.6783)\tPrec@1 83.333 (79.651)\tPrec@5 100.000 (96.872)\n",
      "Epoch: [6][400/1334]\t\\Time 0.337 (0.267)\tData 0.306 (0.239)\tLoss 0.7373 (0.6670)\tPrec@1 83.333 (80.133)\tPrec@5 91.667 (97.132)\n",
      "Epoch: [6][500/1334]\t\\Time 0.211 (0.265)\tData 0.181 (0.238)\tLoss 0.5441 (0.6656)\tPrec@1 83.333 (79.990)\tPrec@5 100.000 (97.139)\n",
      "Epoch: [6][600/1334]\t\\Time 0.278 (0.265)\tData 0.248 (0.238)\tLoss 1.2372 (0.6654)\tPrec@1 58.333 (79.770)\tPrec@5 100.000 (97.171)\n",
      "Epoch: [6][700/1334]\t\\Time 0.260 (0.266)\tData 0.230 (0.239)\tLoss 0.6450 (0.6577)\tPrec@1 91.667 (80.052)\tPrec@5 100.000 (97.194)\n",
      "Epoch: [6][800/1334]\t\\Time 0.296 (0.266)\tData 0.266 (0.238)\tLoss 0.4826 (0.6535)\tPrec@1 83.333 (80.004)\tPrec@5 100.000 (97.253)\n",
      "Epoch: [6][900/1334]\t\\Time 0.272 (0.266)\tData 0.242 (0.238)\tLoss 0.6481 (0.6491)\tPrec@1 75.000 (80.161)\tPrec@5 100.000 (97.336)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.280 (0.267)\tData 0.257 (0.239)\tLoss 0.0459 (0.6365)\tPrec@1 100.000 (80.320)\tPrec@5 100.000 (97.436)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.269 (0.268)\tData 0.239 (0.240)\tLoss 1.1820 (0.6323)\tPrec@1 75.000 (80.525)\tPrec@5 91.667 (97.419)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.279 (0.267)\tData 0.244 (0.239)\tLoss 0.5387 (0.6272)\tPrec@1 83.333 (80.593)\tPrec@5 100.000 (97.460)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.251 (0.267)\tData 0.221 (0.239)\tLoss 0.4042 (0.6202)\tPrec@1 91.667 (80.784)\tPrec@5 91.667 (97.457)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.287 (0.287)\n",
      "\n",
      "Loss 2.0013 (2.0013)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.312 (0.319)\n",
      "\n",
      "Loss 2.8035 (2.7376)\n",
      "\n",
      "Prec@1 41.667 (49.340)\n",
      "\n",
      "Prec@5 83.333 (76.650)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.298 (0.322)\n",
      "\n",
      "Loss 1.9729 (2.8128)\n",
      "\n",
      "Prec@1 58.333 (47.554)\n",
      "\n",
      "Prec@5 91.667 (76.658)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.285 (0.324)\n",
      "\n",
      "Loss 2.5884 (2.8321)\n",
      "\n",
      "Prec@1 41.667 (46.816)\n",
      "\n",
      "Prec@5 66.667 (75.969)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1334]\t\\Time 0.358 (0.358)\tData 0.258 (0.258)\tLoss 0.3932 (0.3932)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/1334]\t\\Time 0.188 (0.269)\tData 0.161 (0.243)\tLoss 0.3088 (0.5143)\tPrec@1 83.333 (83.251)\tPrec@5 100.000 (98.020)\n",
      "Epoch: [7][200/1334]\t\\Time 0.195 (0.268)\tData 0.167 (0.241)\tLoss 0.8983 (0.5067)\tPrec@1 66.667 (84.038)\tPrec@5 91.667 (98.259)\n",
      "Epoch: [7][300/1334]\t\\Time 0.285 (0.267)\tData 0.261 (0.240)\tLoss 0.2812 (0.4847)\tPrec@1 83.333 (84.773)\tPrec@5 100.000 (98.256)\n",
      "Epoch: [7][400/1334]\t\\Time 0.329 (0.267)\tData 0.299 (0.240)\tLoss 0.5062 (0.4741)\tPrec@1 83.333 (85.017)\tPrec@5 100.000 (98.400)\n",
      "Epoch: [7][500/1334]\t\\Time 0.212 (0.266)\tData 0.192 (0.239)\tLoss 0.4775 (0.4763)\tPrec@1 83.333 (85.180)\tPrec@5 100.000 (98.353)\n",
      "Epoch: [7][600/1334]\t\\Time 0.284 (0.266)\tData 0.254 (0.238)\tLoss 0.1582 (0.4783)\tPrec@1 91.667 (85.094)\tPrec@5 100.000 (98.405)\n",
      "Epoch: [7][700/1334]\t\\Time 0.240 (0.266)\tData 0.213 (0.238)\tLoss 0.0720 (0.4750)\tPrec@1 100.000 (85.330)\tPrec@5 100.000 (98.383)\n",
      "Epoch: [7][800/1334]\t\\Time 0.307 (0.265)\tData 0.277 (0.238)\tLoss 0.1552 (0.4742)\tPrec@1 91.667 (85.341)\tPrec@5 100.000 (98.398)\n",
      "Epoch: [7][900/1334]\t\\Time 0.264 (0.265)\tData 0.230 (0.238)\tLoss 0.6352 (0.4627)\tPrec@1 75.000 (85.609)\tPrec@5 100.000 (98.492)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.272 (0.267)\tData 0.252 (0.239)\tLoss 0.2428 (0.4487)\tPrec@1 91.667 (86.022)\tPrec@5 100.000 (98.593)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.263 (0.267)\tData 0.243 (0.239)\tLoss 0.3078 (0.4484)\tPrec@1 91.667 (86.013)\tPrec@5 100.000 (98.592)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.275 (0.267)\tData 0.255 (0.239)\tLoss 0.0999 (0.4456)\tPrec@1 100.000 (86.137)\tPrec@5 100.000 (98.564)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.263 (0.267)\tData 0.241 (0.239)\tLoss 0.5493 (0.4434)\tPrec@1 83.333 (86.171)\tPrec@5 100.000 (98.578)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.281 (0.281)\n",
      "\n",
      "Loss 2.1231 (2.1231)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.316 (0.321)\n",
      "\n",
      "Loss 2.2162 (2.9662)\n",
      "\n",
      "Prec@1 75.000 (48.680)\n",
      "\n",
      "Prec@5 75.000 (75.165)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.299 (0.323)\n",
      "\n",
      "Loss 2.5596 (2.9642)\n",
      "\n",
      "Prec@1 50.000 (48.466)\n",
      "\n",
      "Prec@5 91.667 (76.244)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.284 (0.323)\n",
      "\n",
      "Loss 4.5780 (2.9801)\n",
      "\n",
      "Prec@1 33.333 (47.841)\n",
      "\n",
      "Prec@5 66.667 (75.775)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1334]\t\\Time 0.359 (0.359)\tData 0.280 (0.280)\tLoss 0.4979 (0.4979)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/1334]\t\\Time 0.197 (0.271)\tData 0.170 (0.244)\tLoss 0.3431 (0.4420)\tPrec@1 83.333 (85.726)\tPrec@5 100.000 (98.927)\n",
      "Epoch: [8][200/1334]\t\\Time 0.180 (0.271)\tData 0.162 (0.244)\tLoss 0.4741 (0.4240)\tPrec@1 75.000 (86.277)\tPrec@5 100.000 (98.798)\n",
      "Epoch: [8][300/1334]\t\\Time 0.290 (0.269)\tData 0.260 (0.241)\tLoss 0.5494 (0.4064)\tPrec@1 75.000 (86.960)\tPrec@5 100.000 (99.031)\n",
      "Epoch: [8][400/1334]\t\\Time 0.312 (0.269)\tData 0.282 (0.242)\tLoss 0.7110 (0.3991)\tPrec@1 91.667 (87.199)\tPrec@5 100.000 (99.127)\n",
      "Epoch: [8][500/1334]\t\\Time 0.222 (0.268)\tData 0.192 (0.241)\tLoss 0.4923 (0.3939)\tPrec@1 91.667 (87.375)\tPrec@5 100.000 (99.168)\n",
      "Epoch: [8][600/1334]\t\\Time 0.286 (0.268)\tData 0.261 (0.240)\tLoss 0.3835 (0.3802)\tPrec@1 83.333 (87.798)\tPrec@5 100.000 (99.224)\n",
      "Epoch: [8][700/1334]\t\\Time 0.260 (0.269)\tData 0.229 (0.241)\tLoss 0.3404 (0.3809)\tPrec@1 91.667 (87.815)\tPrec@5 100.000 (99.215)\n",
      "Epoch: [8][800/1334]\t\\Time 0.300 (0.268)\tData 0.270 (0.240)\tLoss 0.3863 (0.3745)\tPrec@1 83.333 (88.025)\tPrec@5 100.000 (99.209)\n",
      "Epoch: [8][900/1334]\t\\Time 0.257 (0.268)\tData 0.226 (0.241)\tLoss 0.0988 (0.3660)\tPrec@1 100.000 (88.383)\tPrec@5 100.000 (99.223)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.283 (0.269)\tData 0.255 (0.241)\tLoss 0.2022 (0.3576)\tPrec@1 91.667 (88.711)\tPrec@5 100.000 (99.217)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.265 (0.270)\tData 0.238 (0.242)\tLoss 0.0849 (0.3473)\tPrec@1 91.667 (89.033)\tPrec@5 100.000 (99.228)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.266 (0.269)\tData 0.246 (0.241)\tLoss 1.2327 (0.3428)\tPrec@1 66.667 (89.127)\tPrec@5 91.667 (99.251)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.263 (0.269)\tData 0.239 (0.241)\tLoss 0.0295 (0.3408)\tPrec@1 100.000 (89.169)\tPrec@5 100.000 (99.276)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.289 (0.289)\n",
      "\n",
      "Loss 3.0035 (3.0035)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.314 (0.323)\n",
      "\n",
      "Loss 2.8064 (3.0860)\n",
      "\n",
      "Prec@1 50.000 (44.719)\n",
      "\n",
      "Prec@5 83.333 (75.743)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.306 (0.326)\n",
      "\n",
      "Loss 2.8581 (3.1858)\n",
      "\n",
      "Prec@1 41.667 (45.481)\n",
      "\n",
      "Prec@5 91.667 (75.290)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.299 (0.326)\n",
      "\n",
      "Loss 1.5145 (3.2340)\n",
      "\n",
      "Prec@1 58.333 (45.044)\n",
      "\n",
      "Prec@5 91.667 (74.114)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1334]\t\\Time 0.339 (0.339)\tData 0.262 (0.262)\tLoss 0.1599 (0.1599)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/1334]\t\\Time 0.190 (0.270)\tData 0.160 (0.244)\tLoss 0.4535 (0.2942)\tPrec@1 75.000 (90.759)\tPrec@5 100.000 (99.670)\n",
      "Epoch: [9][200/1334]\t\\Time 0.190 (0.269)\tData 0.160 (0.242)\tLoss 0.1101 (0.2981)\tPrec@1 100.000 (91.045)\tPrec@5 100.000 (99.585)\n",
      "Epoch: [9][300/1334]\t\\Time 0.284 (0.269)\tData 0.254 (0.241)\tLoss 0.4252 (0.2783)\tPrec@1 91.667 (91.750)\tPrec@5 100.000 (99.557)\n",
      "Epoch: [9][400/1334]\t\\Time 0.326 (0.269)\tData 0.298 (0.241)\tLoss 0.1540 (0.2651)\tPrec@1 83.333 (91.958)\tPrec@5 100.000 (99.647)\n",
      "Epoch: [9][500/1334]\t\\Time 0.221 (0.268)\tData 0.192 (0.240)\tLoss 0.0642 (0.2598)\tPrec@1 100.000 (91.949)\tPrec@5 100.000 (99.667)\n",
      "Epoch: [9][600/1334]\t\\Time 0.273 (0.267)\tData 0.243 (0.240)\tLoss 0.2975 (0.2474)\tPrec@1 83.333 (92.277)\tPrec@5 100.000 (99.695)\n",
      "Epoch: [9][700/1334]\t\\Time 0.258 (0.268)\tData 0.228 (0.240)\tLoss 0.0469 (0.2417)\tPrec@1 100.000 (92.511)\tPrec@5 100.000 (99.715)\n",
      "Epoch: [9][800/1334]\t\\Time 0.302 (0.268)\tData 0.272 (0.240)\tLoss 0.0309 (0.2377)\tPrec@1 100.000 (92.603)\tPrec@5 100.000 (99.698)\n",
      "Epoch: [9][900/1334]\t\\Time 0.270 (0.268)\tData 0.243 (0.240)\tLoss 0.3521 (0.2332)\tPrec@1 91.667 (92.823)\tPrec@5 100.000 (99.704)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.285 (0.269)\tData 0.256 (0.241)\tLoss 0.1518 (0.2254)\tPrec@1 91.667 (93.099)\tPrec@5 100.000 (99.717)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.259 (0.269)\tData 0.229 (0.241)\tLoss 0.0969 (0.2195)\tPrec@1 100.000 (93.302)\tPrec@5 100.000 (99.712)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.280 (0.269)\tData 0.260 (0.241)\tLoss 0.1034 (0.2192)\tPrec@1 91.667 (93.311)\tPrec@5 100.000 (99.709)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.252 (0.269)\tData 0.230 (0.241)\tLoss 0.0362 (0.2160)\tPrec@1 100.000 (93.403)\tPrec@5 100.000 (99.725)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.291 (0.291)\n",
      "\n",
      "Loss 2.5346 (2.5346)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.302 (0.323)\n",
      "\n",
      "Loss 1.7807 (2.8753)\n",
      "\n",
      "Prec@1 75.000 (51.238)\n",
      "\n",
      "Prec@5 91.667 (78.465)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.308 (0.325)\n",
      "\n",
      "Loss 2.2267 (2.9271)\n",
      "\n",
      "Prec@1 58.333 (50.166)\n",
      "\n",
      "Prec@5 91.667 (77.778)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.298 (0.325)\n",
      "\n",
      "Loss 2.5863 (2.9673)\n",
      "\n",
      "Prec@1 33.333 (49.695)\n",
      "\n",
      "Prec@5 91.667 (77.602)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "=> loading checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 10)\n",
      "Epoch: [10][0/1334]\t\\Time 0.338 (0.338)\tData 0.259 (0.259)\tLoss 0.0331 (0.0331)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/1334]\t\\Time 0.178 (0.269)\tData 0.150 (0.242)\tLoss 0.0146 (0.1742)\tPrec@1 100.000 (94.967)\tPrec@5 100.000 (99.752)\n",
      "Epoch: [10][200/1334]\t\\Time 0.190 (0.269)\tData 0.160 (0.241)\tLoss 0.1286 (0.1487)\tPrec@1 100.000 (95.730)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [10][300/1334]\t\\Time 0.298 (0.269)\tData 0.269 (0.241)\tLoss 0.0063 (0.1446)\tPrec@1 100.000 (95.792)\tPrec@5 100.000 (99.834)\n",
      "Epoch: [10][400/1334]\t\\Time 0.335 (0.268)\tData 0.306 (0.240)\tLoss 0.2537 (0.1311)\tPrec@1 91.667 (96.093)\tPrec@5 100.000 (99.855)\n",
      "Epoch: [10][500/1334]\t\\Time 0.221 (0.267)\tData 0.192 (0.239)\tLoss 0.0219 (0.1251)\tPrec@1 100.000 (96.291)\tPrec@5 100.000 (99.867)\n",
      "Epoch: [10][600/1334]\t\\Time 0.280 (0.267)\tData 0.250 (0.238)\tLoss 0.0562 (0.1167)\tPrec@1 100.000 (96.575)\tPrec@5 100.000 (99.889)\n",
      "Epoch: [10][700/1334]\t\\Time 0.254 (0.268)\tData 0.218 (0.239)\tLoss 0.1402 (0.1088)\tPrec@1 91.667 (96.838)\tPrec@5 100.000 (99.905)\n",
      "Epoch: [10][800/1334]\t\\Time 0.295 (0.267)\tData 0.265 (0.239)\tLoss 0.0161 (0.1017)\tPrec@1 100.000 (97.077)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [10][900/1334]\t\\Time 0.259 (0.268)\tData 0.231 (0.239)\tLoss 0.0931 (0.0964)\tPrec@1 100.000 (97.198)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.287 (0.268)\tData 0.259 (0.240)\tLoss 0.0175 (0.0905)\tPrec@1 100.000 (97.369)\tPrec@5 100.000 (99.925)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.256 (0.269)\tData 0.234 (0.240)\tLoss 0.0167 (0.0857)\tPrec@1 100.000 (97.548)\tPrec@5 100.000 (99.932)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.271 (0.268)\tData 0.241 (0.240)\tLoss 0.0066 (0.0806)\tPrec@1 100.000 (97.703)\tPrec@5 100.000 (99.938)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.260 (0.268)\tData 0.235 (0.239)\tLoss 0.0097 (0.0753)\tPrec@1 100.000 (97.867)\tPrec@5 100.000 (99.942)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.277 (0.277)\n",
      "\n",
      "Loss 1.3318 (1.3318)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.305 (0.322)\n",
      "\n",
      "Loss 1.3199 (2.1216)\n",
      "\n",
      "Prec@1 83.333 (60.231)\n",
      "\n",
      "Prec@5 91.667 (83.003)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.297 (0.324)\n",
      "\n",
      "Loss 1.7905 (2.1019)\n",
      "\n",
      "Prec@1 58.333 (59.826)\n",
      "\n",
      "Prec@5 91.667 (82.919)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.290 (0.324)\n",
      "\n",
      "Loss 1.1833 (2.1212)\n",
      "\n",
      "Prec@1 50.000 (59.219)\n",
      "\n",
      "Prec@5 91.667 (83.112)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [11][0/1334]\t\\Time 0.345 (0.345)\tData 0.267 (0.267)\tLoss 0.0141 (0.0141)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.187 (0.271)\tData 0.158 (0.243)\tLoss 0.0077 (0.0187)\tPrec@1 100.000 (99.835)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][200/1334]\t\\Time 0.189 (0.269)\tData 0.159 (0.241)\tLoss 0.0163 (0.0201)\tPrec@1 100.000 (99.834)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][300/1334]\t\\Time 0.281 (0.268)\tData 0.250 (0.240)\tLoss 0.0029 (0.0190)\tPrec@1 100.000 (99.889)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][400/1334]\t\\Time 0.329 (0.268)\tData 0.300 (0.240)\tLoss 0.0294 (0.0178)\tPrec@1 100.000 (99.917)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][500/1334]\t\\Time 0.228 (0.267)\tData 0.199 (0.238)\tLoss 0.0167 (0.0172)\tPrec@1 100.000 (99.933)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][600/1334]\t\\Time 0.271 (0.266)\tData 0.241 (0.237)\tLoss 0.0163 (0.0164)\tPrec@1 100.000 (99.945)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][700/1334]\t\\Time 0.266 (0.267)\tData 0.236 (0.238)\tLoss 0.0106 (0.0159)\tPrec@1 100.000 (99.952)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][800/1334]\t\\Time 0.304 (0.267)\tData 0.274 (0.238)\tLoss 0.0141 (0.0154)\tPrec@1 100.000 (99.958)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][900/1334]\t\\Time 0.257 (0.267)\tData 0.230 (0.238)\tLoss 0.0089 (0.0150)\tPrec@1 100.000 (99.963)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.284 (0.268)\tData 0.251 (0.239)\tLoss 0.0090 (0.0144)\tPrec@1 100.000 (99.967)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.264 (0.269)\tData 0.235 (0.240)\tLoss 0.0107 (0.0140)\tPrec@1 100.000 (99.970)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.284 (0.268)\tData 0.253 (0.240)\tLoss 0.0035 (0.0134)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.251 (0.268)\tData 0.231 (0.240)\tLoss 0.0047 (0.0128)\tPrec@1 100.000 (99.974)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 1.3120 (1.3120)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.319 (0.321)\n",
      "\n",
      "Loss 1.3472 (2.1201)\n",
      "\n",
      "Prec@1 83.333 (60.396)\n",
      "\n",
      "Prec@5 91.667 (83.251)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.301 (0.324)\n",
      "\n",
      "Loss 1.8046 (2.0965)\n",
      "\n",
      "Prec@1 58.333 (60.116)\n",
      "\n",
      "Prec@5 91.667 (82.919)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.290 (0.324)\n",
      "\n",
      "Loss 1.1719 (2.1140)\n",
      "\n",
      "Prec@1 50.000 (59.413)\n",
      "\n",
      "Prec@5 91.667 (83.167)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [12][0/1334]\t\\Time 0.348 (0.348)\tData 0.252 (0.252)\tLoss 0.0067 (0.0067)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.182 (0.271)\tData 0.156 (0.243)\tLoss 0.0063 (0.0091)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][200/1334]\t\\Time 0.186 (0.270)\tData 0.150 (0.242)\tLoss 0.0102 (0.0106)\tPrec@1 100.000 (99.959)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][300/1334]\t\\Time 0.280 (0.269)\tData 0.250 (0.240)\tLoss 0.0024 (0.0103)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][400/1334]\t\\Time 0.327 (0.269)\tData 0.300 (0.240)\tLoss 0.0152 (0.0099)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][500/1334]\t\\Time 0.218 (0.268)\tData 0.188 (0.239)\tLoss 0.0097 (0.0099)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][600/1334]\t\\Time 0.272 (0.267)\tData 0.244 (0.239)\tLoss 0.0125 (0.0097)\tPrec@1 100.000 (99.986)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][700/1334]\t\\Time 0.253 (0.268)\tData 0.224 (0.239)\tLoss 0.0086 (0.0095)\tPrec@1 100.000 (99.988)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][800/1334]\t\\Time 0.297 (0.268)\tData 0.267 (0.239)\tLoss 0.0101 (0.0094)\tPrec@1 100.000 (99.990)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][900/1334]\t\\Time 0.257 (0.268)\tData 0.227 (0.239)\tLoss 0.0073 (0.0092)\tPrec@1 100.000 (99.991)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.270 (0.269)\tData 0.250 (0.240)\tLoss 0.0073 (0.0090)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.261 (0.269)\tData 0.231 (0.240)\tLoss 0.0083 (0.0088)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.271 (0.269)\tData 0.241 (0.240)\tLoss 0.0029 (0.0085)\tPrec@1 100.000 (99.993)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.255 (0.269)\tData 0.235 (0.240)\tLoss 0.0037 (0.0082)\tPrec@1 100.000 (99.994)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 1.2948 (1.2948)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.314 (0.321)\n",
      "\n",
      "Loss 1.3652 (2.1206)\n",
      "\n",
      "Prec@1 83.333 (60.644)\n",
      "\n",
      "Prec@5 91.667 (83.416)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.309 (0.324)\n",
      "\n",
      "Loss 1.8332 (2.0964)\n",
      "\n",
      "Prec@1 58.333 (60.323)\n",
      "\n",
      "Prec@5 91.667 (83.209)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.298 (0.325)\n",
      "\n",
      "Loss 1.1786 (2.1128)\n",
      "\n",
      "Prec@1 50.000 (59.718)\n",
      "\n",
      "Prec@5 91.667 (83.389)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [13][0/1334]\t\\Time 0.361 (0.361)\tData 0.267 (0.267)\tLoss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.190 (0.269)\tData 0.160 (0.242)\tLoss 0.0053 (0.0073)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][200/1334]\t\\Time 0.190 (0.269)\tData 0.160 (0.241)\tLoss 0.0087 (0.0079)\tPrec@1 100.000 (99.959)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][300/1334]\t\\Time 0.288 (0.268)\tData 0.254 (0.240)\tLoss 0.0021 (0.0078)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][400/1334]\t\\Time 0.315 (0.268)\tData 0.285 (0.239)\tLoss 0.0107 (0.0076)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][500/1334]\t\\Time 0.220 (0.267)\tData 0.190 (0.239)\tLoss 0.0078 (0.0076)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][600/1334]\t\\Time 0.280 (0.267)\tData 0.250 (0.238)\tLoss 0.0104 (0.0075)\tPrec@1 100.000 (99.986)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][700/1334]\t\\Time 0.252 (0.267)\tData 0.220 (0.239)\tLoss 0.0073 (0.0074)\tPrec@1 100.000 (99.988)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][800/1334]\t\\Time 0.302 (0.267)\tData 0.282 (0.239)\tLoss 0.0084 (0.0073)\tPrec@1 100.000 (99.990)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][900/1334]\t\\Time 0.267 (0.267)\tData 0.237 (0.239)\tLoss 0.0063 (0.0072)\tPrec@1 100.000 (99.991)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.282 (0.268)\tData 0.250 (0.240)\tLoss 0.0063 (0.0071)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.257 (0.269)\tData 0.233 (0.240)\tLoss 0.0070 (0.0069)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.275 (0.268)\tData 0.245 (0.240)\tLoss 0.0025 (0.0067)\tPrec@1 100.000 (99.993)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.256 (0.268)\tData 0.228 (0.240)\tLoss 0.0031 (0.0065)\tPrec@1 100.000 (99.994)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 1.2841 (1.2841)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.314 (0.321)\n",
      "\n",
      "Loss 1.3800 (2.1207)\n",
      "\n",
      "Prec@1 83.333 (60.726)\n",
      "\n",
      "Prec@5 91.667 (83.333)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.301 (0.323)\n",
      "\n",
      "Loss 1.8469 (2.0958)\n",
      "\n",
      "Prec@1 58.333 (60.448)\n",
      "\n",
      "Prec@5 91.667 (83.250)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.303 (0.324)\n",
      "\n",
      "Loss 1.1821 (2.1112)\n",
      "\n",
      "Prec@1 50.000 (59.828)\n",
      "\n",
      "Prec@5 91.667 (83.527)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [14][0/1334]\t\\Time 0.364 (0.364)\tData 0.275 (0.275)\tLoss 0.0047 (0.0047)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1334]\t\\Time 0.184 (0.270)\tData 0.156 (0.241)\tLoss 0.0046 (0.0062)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/1334]\t\\Time 0.188 (0.268)\tData 0.157 (0.240)\tLoss 0.0075 (0.0063)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][300/1334]\t\\Time 0.284 (0.267)\tData 0.257 (0.239)\tLoss 0.0020 (0.0064)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][400/1334]\t\\Time 0.321 (0.268)\tData 0.297 (0.239)\tLoss 0.0084 (0.0063)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][500/1334]\t\\Time 0.221 (0.267)\tData 0.194 (0.238)\tLoss 0.0066 (0.0063)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][600/1334]\t\\Time 0.280 (0.267)\tData 0.257 (0.238)\tLoss 0.0091 (0.0062)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][700/1334]\t\\Time 0.254 (0.268)\tData 0.221 (0.239)\tLoss 0.0064 (0.0062)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][800/1334]\t\\Time 0.299 (0.267)\tData 0.268 (0.239)\tLoss 0.0073 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][900/1334]\t\\Time 0.260 (0.267)\tData 0.236 (0.238)\tLoss 0.0056 (0.0060)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.276 (0.268)\tData 0.252 (0.239)\tLoss 0.0057 (0.0059)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.265 (0.268)\tData 0.237 (0.240)\tLoss 0.0061 (0.0058)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.280 (0.268)\tData 0.250 (0.239)\tLoss 0.0022 (0.0057)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.252 (0.268)\tData 0.220 (0.239)\tLoss 0.0028 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 1.2762 (1.2762)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.311 (0.319)\n",
      "\n",
      "Loss 1.3897 (2.1200)\n",
      "\n",
      "Prec@1 83.333 (60.809)\n",
      "\n",
      "Prec@5 91.667 (83.416)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.318 (0.323)\n",
      "\n",
      "Loss 1.8555 (2.0945)\n",
      "\n",
      "Prec@1 58.333 (60.489)\n",
      "\n",
      "Prec@5 91.667 (83.333)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.295 (0.324)\n",
      "\n",
      "Loss 1.1849 (2.1089)\n",
      "\n",
      "Prec@1 50.000 (59.828)\n",
      "\n",
      "Prec@5 91.667 (83.610)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "=> loading checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet18_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 15)\n",
      "Epoch: [15][0/1334]\t\\Time 0.361 (0.361)\tData 0.281 (0.281)\tLoss 0.0042 (0.0042)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.193 (0.267)\tData 0.160 (0.240)\tLoss 0.0043 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/1334]\t\\Time 0.180 (0.268)\tData 0.160 (0.240)\tLoss 0.0067 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/1334]\t\\Time 0.281 (0.267)\tData 0.252 (0.239)\tLoss 0.0019 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][400/1334]\t\\Time 0.323 (0.267)\tData 0.295 (0.238)\tLoss 0.0067 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][500/1334]\t\\Time 0.225 (0.266)\tData 0.196 (0.238)\tLoss 0.0061 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][600/1334]\t\\Time 0.280 (0.266)\tData 0.250 (0.238)\tLoss 0.0079 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][700/1334]\t\\Time 0.240 (0.267)\tData 0.220 (0.238)\tLoss 0.0057 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][800/1334]\t\\Time 0.306 (0.267)\tData 0.277 (0.238)\tLoss 0.0063 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][900/1334]\t\\Time 0.258 (0.267)\tData 0.228 (0.238)\tLoss 0.0052 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.284 (0.268)\tData 0.255 (0.239)\tLoss 0.0052 (0.0052)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.266 (0.268)\tData 0.236 (0.240)\tLoss 0.0056 (0.0051)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.274 (0.268)\tData 0.240 (0.239)\tLoss 0.0020 (0.0050)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.255 (0.268)\tData 0.227 (0.239)\tLoss 0.0025 (0.0049)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.279 (0.279)\n",
      "\n",
      "Loss 1.2753 (1.2753)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.315 (0.320)\n",
      "\n",
      "Loss 1.3910 (2.1200)\n",
      "\n",
      "Prec@1 83.333 (60.809)\n",
      "\n",
      "Prec@5 91.667 (83.498)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.315 (0.324)\n",
      "\n",
      "Loss 1.8572 (2.0947)\n",
      "\n",
      "Prec@1 58.333 (60.489)\n",
      "\n",
      "Prec@5 91.667 (83.375)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.289 (0.325)\n",
      "\n",
      "Loss 1.1853 (2.1089)\n",
      "\n",
      "Prec@1 50.000 (59.773)\n",
      "\n",
      "Prec@5 91.667 (83.638)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Epoch: [16][0/1334]\t\\Time 0.345 (0.345)\tData 0.262 (0.262)\tLoss 0.0042 (0.0042)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.172 (0.269)\tData 0.143 (0.242)\tLoss 0.0042 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/1334]\t\\Time 0.182 (0.268)\tData 0.152 (0.241)\tLoss 0.0066 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][300/1334]\t\\Time 0.288 (0.268)\tData 0.258 (0.240)\tLoss 0.0019 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][400/1334]\t\\Time 0.310 (0.267)\tData 0.290 (0.239)\tLoss 0.0066 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][500/1334]\t\\Time 0.210 (0.267)\tData 0.190 (0.239)\tLoss 0.0060 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][600/1334]\t\\Time 0.283 (0.266)\tData 0.253 (0.238)\tLoss 0.0079 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][700/1334]\t\\Time 0.260 (0.267)\tData 0.230 (0.239)\tLoss 0.0057 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][800/1334]\t\\Time 0.303 (0.267)\tData 0.274 (0.238)\tLoss 0.0062 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][900/1334]\t\\Time 0.261 (0.267)\tData 0.231 (0.238)\tLoss 0.0051 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.277 (0.267)\tData 0.252 (0.239)\tLoss 0.0051 (0.0052)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.271 (0.268)\tData 0.241 (0.240)\tLoss 0.0055 (0.0051)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.279 (0.268)\tData 0.253 (0.239)\tLoss 0.0020 (0.0049)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.256 (0.268)\tData 0.226 (0.239)\tLoss 0.0025 (0.0048)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.291 (0.291)\n",
      "\n",
      "Loss 1.2747 (1.2747)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.317 (0.323)\n",
      "\n",
      "Loss 1.3920 (2.1200)\n",
      "\n",
      "Prec@1 83.333 (60.809)\n",
      "\n",
      "Prec@5 91.667 (83.498)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.308 (0.325)\n",
      "\n",
      "Loss 1.8581 (2.0945)\n",
      "\n",
      "Prec@1 58.333 (60.531)\n",
      "\n",
      "Prec@5 91.667 (83.333)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.295 (0.326)\n",
      "\n",
      "Loss 1.1855 (2.1087)\n",
      "\n",
      "Prec@1 50.000 (59.828)\n",
      "\n",
      "Prec@5 91.667 (83.638)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "# model = torchvision.models.vit_b_16(weights = 'VGG16_Weights.IMAGENET1K_V1')\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# model = torchvision.models.vgg16(weights = True)\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet18_v3_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=12, shuffle=False, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74af490a-0141-48e7-b843-f816367af591",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [0][0/1334]\t\\Time 0.405 (0.405)\tData 0.248 (0.248)\tLoss 4.8029 (4.8029)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "Epoch: [0][100/1334]\t\\Time 0.187 (0.273)\tData 0.160 (0.245)\tLoss 4.8459 (4.7995)\tPrec@1 0.000 (2.393)\tPrec@5 0.000 (8.663)\n",
      "Epoch: [0][200/1334]\t\\Time 0.179 (0.270)\tData 0.159 (0.243)\tLoss 3.7237 (4.5778)\tPrec@1 16.667 (3.524)\tPrec@5 41.667 (13.060)\n",
      "Epoch: [0][300/1334]\t\\Time 0.290 (0.270)\tData 0.260 (0.243)\tLoss 4.1381 (4.4134)\tPrec@1 0.000 (4.790)\tPrec@5 41.667 (17.027)\n",
      "Epoch: [0][400/1334]\t\\Time 0.337 (0.269)\tData 0.307 (0.242)\tLoss 3.5281 (4.2871)\tPrec@1 16.667 (5.777)\tPrec@5 33.333 (20.116)\n",
      "Epoch: [0][500/1334]\t\\Time 0.219 (0.268)\tData 0.185 (0.241)\tLoss 4.2634 (4.1720)\tPrec@1 8.333 (7.019)\tPrec@5 25.000 (23.470)\n",
      "Epoch: [0][600/1334]\t\\Time 0.292 (0.268)\tData 0.262 (0.241)\tLoss 4.5319 (4.0778)\tPrec@1 0.000 (7.848)\tPrec@5 25.000 (26.165)\n",
      "Epoch: [0][700/1334]\t\\Time 0.254 (0.269)\tData 0.231 (0.242)\tLoss 2.6400 (3.9952)\tPrec@1 33.333 (8.761)\tPrec@5 66.667 (28.412)\n",
      "Epoch: [0][800/1334]\t\\Time 0.300 (0.269)\tData 0.271 (0.241)\tLoss 3.7878 (3.9071)\tPrec@1 8.333 (10.029)\tPrec@5 41.667 (31.107)\n",
      "Epoch: [0][900/1334]\t\\Time 0.260 (0.269)\tData 0.230 (0.242)\tLoss 2.7460 (3.8505)\tPrec@1 16.667 (10.599)\tPrec@5 66.667 (32.566)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.287 (0.269)\tData 0.260 (0.242)\tLoss 3.1134 (3.7743)\tPrec@1 8.333 (11.722)\tPrec@5 58.333 (34.765)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.262 (0.270)\tData 0.234 (0.243)\tLoss 3.0559 (3.7109)\tPrec@1 8.333 (12.708)\tPrec@5 66.667 (36.596)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.308 (0.270)\tData 0.281 (0.243)\tLoss 3.1568 (3.6551)\tPrec@1 16.667 (13.558)\tPrec@5 50.000 (38.170)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.273 (0.271)\tData 0.243 (0.244)\tLoss 2.3139 (3.6023)\tPrec@1 33.333 (14.495)\tPrec@5 66.667 (39.521)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.305 (0.305)\n",
      "\n",
      "Loss 2.7348 (2.7348)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.344 (0.317)\n",
      "\n",
      "Loss 2.1268 (2.6422)\n",
      "\n",
      "Prec@1 25.000 (30.858)\n",
      "\n",
      "Prec@5 66.667 (65.677)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.283 (0.316)\n",
      "\n",
      "Loss 1.9954 (2.6071)\n",
      "\n",
      "Prec@1 33.333 (30.763)\n",
      "\n",
      "Prec@5 75.000 (66.750)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.271 (0.316)\n",
      "\n",
      "Loss 3.0154 (2.6254)\n",
      "\n",
      "Prec@1 16.667 (30.343)\n",
      "\n",
      "Prec@5 58.333 (66.334)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/1334]\t\\Time 0.321 (0.321)\tData 0.256 (0.256)\tLoss 2.3403 (2.3403)\tPrec@1 41.667 (41.667)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [1][100/1334]\t\\Time 0.185 (0.271)\tData 0.155 (0.245)\tLoss 2.8719 (2.8715)\tPrec@1 16.667 (24.422)\tPrec@5 66.667 (60.149)\n",
      "Epoch: [1][200/1334]\t\\Time 0.189 (0.270)\tData 0.159 (0.243)\tLoss 2.4440 (2.8555)\tPrec@1 50.000 (24.834)\tPrec@5 83.333 (60.697)\n",
      "Epoch: [1][300/1334]\t\\Time 0.290 (0.269)\tData 0.261 (0.243)\tLoss 3.4309 (2.7667)\tPrec@1 8.333 (26.855)\tPrec@5 58.333 (62.818)\n",
      "Epoch: [1][400/1334]\t\\Time 0.335 (0.269)\tData 0.308 (0.242)\tLoss 1.8572 (2.7013)\tPrec@1 33.333 (28.658)\tPrec@5 91.667 (64.464)\n",
      "Epoch: [1][500/1334]\t\\Time 0.223 (0.268)\tData 0.195 (0.241)\tLoss 2.8316 (2.6611)\tPrec@1 33.333 (29.624)\tPrec@5 50.000 (65.286)\n",
      "Epoch: [1][600/1334]\t\\Time 0.291 (0.268)\tData 0.265 (0.241)\tLoss 3.4281 (2.6367)\tPrec@1 41.667 (30.574)\tPrec@5 41.667 (65.807)\n",
      "Epoch: [1][700/1334]\t\\Time 0.266 (0.268)\tData 0.240 (0.241)\tLoss 1.2823 (2.6171)\tPrec@1 66.667 (31.003)\tPrec@5 83.333 (66.060)\n",
      "Epoch: [1][800/1334]\t\\Time 0.300 (0.268)\tData 0.270 (0.241)\tLoss 2.9107 (2.5848)\tPrec@1 50.000 (31.835)\tPrec@5 66.667 (66.719)\n",
      "Epoch: [1][900/1334]\t\\Time 0.261 (0.268)\tData 0.237 (0.241)\tLoss 2.0459 (2.5622)\tPrec@1 16.667 (32.140)\tPrec@5 83.333 (67.157)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.281 (0.269)\tData 0.261 (0.242)\tLoss 1.8351 (2.5280)\tPrec@1 41.667 (33.017)\tPrec@5 83.333 (67.907)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.267 (0.269)\tData 0.237 (0.242)\tLoss 2.4916 (2.4992)\tPrec@1 25.000 (33.924)\tPrec@5 83.333 (68.445)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.283 (0.269)\tData 0.257 (0.242)\tLoss 2.1542 (2.4743)\tPrec@1 50.000 (34.575)\tPrec@5 66.667 (68.915)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.260 (0.269)\tData 0.230 (0.242)\tLoss 1.5774 (2.4506)\tPrec@1 58.333 (35.101)\tPrec@5 75.000 (69.370)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 2.4146 (2.4146)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.351 (0.309)\n",
      "\n",
      "Loss 1.5191 (2.1657)\n",
      "\n",
      "Prec@1 41.667 (43.482)\n",
      "\n",
      "Prec@5 91.667 (75.413)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.273 (0.312)\n",
      "\n",
      "Loss 1.5469 (2.1085)\n",
      "\n",
      "Prec@1 41.667 (44.030)\n",
      "\n",
      "Prec@5 83.333 (76.700)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.279 (0.313)\n",
      "\n",
      "Loss 2.6646 (2.1383)\n",
      "\n",
      "Prec@1 33.333 (43.134)\n",
      "\n",
      "Prec@5 75.000 (76.052)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1334]\t\\Time 0.374 (0.374)\tData 0.264 (0.264)\tLoss 1.7907 (1.7907)\tPrec@1 66.667 (66.667)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [2][100/1334]\t\\Time 0.181 (0.272)\tData 0.161 (0.245)\tLoss 2.3163 (2.0782)\tPrec@1 33.333 (42.327)\tPrec@5 66.667 (76.155)\n",
      "Epoch: [2][200/1334]\t\\Time 0.190 (0.271)\tData 0.161 (0.244)\tLoss 1.9636 (2.0953)\tPrec@1 58.333 (42.247)\tPrec@5 75.000 (76.824)\n",
      "Epoch: [2][300/1334]\t\\Time 0.280 (0.270)\tData 0.260 (0.243)\tLoss 2.6770 (2.0325)\tPrec@1 25.000 (44.048)\tPrec@5 66.667 (77.990)\n",
      "Epoch: [2][400/1334]\t\\Time 0.330 (0.270)\tData 0.310 (0.243)\tLoss 1.1472 (1.9796)\tPrec@1 75.000 (45.428)\tPrec@5 91.667 (78.969)\n",
      "Epoch: [2][500/1334]\t\\Time 0.221 (0.268)\tData 0.191 (0.242)\tLoss 1.9297 (1.9587)\tPrec@1 41.667 (46.091)\tPrec@5 75.000 (79.158)\n",
      "Epoch: [2][600/1334]\t\\Time 0.281 (0.268)\tData 0.251 (0.241)\tLoss 2.4285 (1.9331)\tPrec@1 41.667 (46.852)\tPrec@5 83.333 (79.576)\n",
      "Epoch: [2][700/1334]\t\\Time 0.260 (0.269)\tData 0.240 (0.242)\tLoss 0.7088 (1.9290)\tPrec@1 83.333 (47.159)\tPrec@5 100.000 (79.577)\n",
      "Epoch: [2][800/1334]\t\\Time 0.300 (0.269)\tData 0.270 (0.242)\tLoss 2.2480 (1.9079)\tPrec@1 58.333 (47.711)\tPrec@5 75.000 (79.952)\n",
      "Epoch: [2][900/1334]\t\\Time 0.261 (0.269)\tData 0.236 (0.242)\tLoss 1.0590 (1.8907)\tPrec@1 58.333 (48.076)\tPrec@5 91.667 (80.124)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.280 (0.270)\tData 0.260 (0.243)\tLoss 1.3457 (1.8695)\tPrec@1 66.667 (48.718)\tPrec@5 91.667 (80.453)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.273 (0.270)\tData 0.243 (0.243)\tLoss 1.7725 (1.8513)\tPrec@1 50.000 (49.160)\tPrec@5 91.667 (80.631)\n",
      "Epoch: [2][1200/1334]\t\\Time 0.279 (0.270)\tData 0.254 (0.243)\tLoss 1.9530 (1.8335)\tPrec@1 50.000 (49.639)\tPrec@5 66.667 (80.835)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.280 (0.270)\tData 0.250 (0.243)\tLoss 1.2156 (1.8202)\tPrec@1 75.000 (49.949)\tPrec@5 75.000 (81.027)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.310 (0.310)\n",
      "\n",
      "Loss 2.0211 (2.0211)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.305 (0.327)\n",
      "\n",
      "Loss 1.6694 (2.1936)\n",
      "\n",
      "Prec@1 41.667 (45.132)\n",
      "\n",
      "Prec@5 83.333 (75.330)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.274 (0.322)\n",
      "\n",
      "Loss 1.9705 (2.1793)\n",
      "\n",
      "Prec@1 58.333 (45.149)\n",
      "\n",
      "Prec@5 83.333 (75.498)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.283 (0.319)\n",
      "\n",
      "Loss 2.8026 (2.2004)\n",
      "\n",
      "Prec@1 33.333 (44.020)\n",
      "\n",
      "Prec@5 58.333 (74.972)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1334]\t\\Time 0.313 (0.313)\tData 0.257 (0.257)\tLoss 1.3596 (1.3596)\tPrec@1 58.333 (58.333)\tPrec@5 83.333 (83.333)\n",
      "Epoch: [3][100/1334]\t\\Time 0.190 (0.270)\tData 0.160 (0.244)\tLoss 2.4647 (1.5669)\tPrec@1 16.667 (56.023)\tPrec@5 58.333 (85.149)\n",
      "Epoch: [3][200/1334]\t\\Time 0.180 (0.269)\tData 0.160 (0.243)\tLoss 1.2723 (1.5961)\tPrec@1 75.000 (54.478)\tPrec@5 91.667 (84.784)\n",
      "Epoch: [3][300/1334]\t\\Time 0.280 (0.269)\tData 0.250 (0.242)\tLoss 1.5124 (1.5275)\tPrec@1 58.333 (55.925)\tPrec@5 75.000 (85.659)\n",
      "Epoch: [3][400/1334]\t\\Time 0.332 (0.269)\tData 0.305 (0.242)\tLoss 1.1802 (1.4771)\tPrec@1 58.333 (57.190)\tPrec@5 91.667 (86.388)\n",
      "Epoch: [3][500/1334]\t\\Time 0.221 (0.267)\tData 0.191 (0.240)\tLoss 1.6223 (1.4803)\tPrec@1 50.000 (57.119)\tPrec@5 75.000 (86.211)\n",
      "Epoch: [3][600/1334]\t\\Time 0.283 (0.268)\tData 0.253 (0.240)\tLoss 2.2441 (1.4666)\tPrec@1 41.667 (57.598)\tPrec@5 75.000 (86.522)\n",
      "Epoch: [3][700/1334]\t\\Time 0.261 (0.268)\tData 0.231 (0.241)\tLoss 0.5820 (1.4676)\tPrec@1 91.667 (57.822)\tPrec@5 91.667 (86.519)\n",
      "Epoch: [3][800/1334]\t\\Time 0.310 (0.268)\tData 0.280 (0.241)\tLoss 2.2793 (1.4570)\tPrec@1 50.000 (58.344)\tPrec@5 75.000 (86.746)\n",
      "Epoch: [3][900/1334]\t\\Time 0.254 (0.268)\tData 0.231 (0.241)\tLoss 1.1366 (1.4493)\tPrec@1 66.667 (58.611)\tPrec@5 91.667 (86.802)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.290 (0.269)\tData 0.260 (0.242)\tLoss 0.8161 (1.4367)\tPrec@1 66.667 (59.049)\tPrec@5 100.000 (86.971)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.272 (0.270)\tData 0.245 (0.242)\tLoss 1.5611 (1.4280)\tPrec@1 66.667 (59.378)\tPrec@5 91.667 (87.050)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.301 (0.270)\tData 0.271 (0.243)\tLoss 1.1750 (1.4176)\tPrec@1 58.333 (59.666)\tPrec@5 100.000 (87.247)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.276 (0.271)\tData 0.246 (0.244)\tLoss 0.6833 (1.4075)\tPrec@1 75.000 (59.967)\tPrec@5 100.000 (87.510)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.308 (0.308)\n",
      "\n",
      "Loss 2.1330 (2.1330)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 58.333 (58.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.300 (0.314)\n",
      "\n",
      "Loss 1.8575 (2.2453)\n",
      "\n",
      "Prec@1 50.000 (43.812)\n",
      "\n",
      "Prec@5 75.000 (75.743)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.283 (0.313)\n",
      "\n",
      "Loss 1.5041 (2.2190)\n",
      "\n",
      "Prec@1 50.000 (45.854)\n",
      "\n",
      "Prec@5 91.667 (76.036)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.254 (0.312)\n",
      "\n",
      "Loss 2.8596 (2.2623)\n",
      "\n",
      "Prec@1 25.000 (44.767)\n",
      "\n",
      "Prec@5 58.333 (75.388)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1334]\t\\Time 0.385 (0.385)\tData 0.275 (0.275)\tLoss 0.9839 (0.9839)\tPrec@1 66.667 (66.667)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [4][100/1334]\t\\Time 0.189 (0.273)\tData 0.162 (0.247)\tLoss 1.6173 (1.3424)\tPrec@1 41.667 (60.891)\tPrec@5 83.333 (87.706)\n",
      "Epoch: [4][200/1334]\t\\Time 0.201 (0.271)\tData 0.171 (0.245)\tLoss 1.0873 (1.3174)\tPrec@1 75.000 (61.940)\tPrec@5 100.000 (88.930)\n",
      "Epoch: [4][300/1334]\t\\Time 0.283 (0.270)\tData 0.260 (0.243)\tLoss 1.5460 (1.2679)\tPrec@1 58.333 (63.427)\tPrec@5 83.333 (89.895)\n",
      "Epoch: [4][400/1334]\t\\Time 0.326 (0.269)\tData 0.293 (0.243)\tLoss 0.6415 (1.2233)\tPrec@1 83.333 (64.464)\tPrec@5 100.000 (90.648)\n",
      "Epoch: [4][500/1334]\t\\Time 0.228 (0.268)\tData 0.198 (0.242)\tLoss 1.4491 (1.2171)\tPrec@1 66.667 (64.371)\tPrec@5 83.333 (90.685)\n",
      "Epoch: [4][600/1334]\t\\Time 0.281 (0.268)\tData 0.262 (0.241)\tLoss 2.1385 (1.1964)\tPrec@1 41.667 (65.003)\tPrec@5 58.333 (90.904)\n",
      "Epoch: [4][700/1334]\t\\Time 0.260 (0.269)\tData 0.230 (0.242)\tLoss 0.3682 (1.1983)\tPrec@1 83.333 (65.157)\tPrec@5 100.000 (90.763)\n",
      "Epoch: [4][800/1334]\t\\Time 0.305 (0.268)\tData 0.275 (0.242)\tLoss 1.5696 (1.1782)\tPrec@1 58.333 (65.772)\tPrec@5 91.667 (90.897)\n",
      "Epoch: [4][900/1334]\t\\Time 0.273 (0.268)\tData 0.245 (0.242)\tLoss 0.8089 (1.1687)\tPrec@1 66.667 (66.038)\tPrec@5 100.000 (91.001)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.281 (0.269)\tData 0.251 (0.242)\tLoss 0.4199 (1.1546)\tPrec@1 83.333 (66.400)\tPrec@5 100.000 (91.184)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.257 (0.270)\tData 0.230 (0.243)\tLoss 1.3698 (1.1535)\tPrec@1 75.000 (66.417)\tPrec@5 91.667 (91.235)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.290 (0.269)\tData 0.263 (0.243)\tLoss 1.1042 (1.1473)\tPrec@1 66.667 (66.694)\tPrec@5 100.000 (91.306)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.281 (0.270)\tData 0.250 (0.243)\tLoss 0.5062 (1.1401)\tPrec@1 91.667 (66.859)\tPrec@5 91.667 (91.404)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.311 (0.311)\n",
      "\n",
      "Loss 2.7212 (2.7212)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.285 (0.322)\n",
      "\n",
      "Loss 1.8315 (2.4966)\n",
      "\n",
      "Prec@1 41.667 (44.059)\n",
      "\n",
      "Prec@5 91.667 (74.340)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.290 (0.317)\n",
      "\n",
      "Loss 2.0891 (2.4414)\n",
      "\n",
      "Prec@1 50.000 (44.652)\n",
      "\n",
      "Prec@5 66.667 (75.124)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.286 (0.315)\n",
      "\n",
      "Loss 2.6195 (2.4699)\n",
      "\n",
      "Prec@1 25.000 (43.051)\n",
      "\n",
      "Prec@5 66.667 (74.806)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1334]\t\\Time 0.316 (0.316)\tData 0.253 (0.253)\tLoss 1.2552 (1.2552)\tPrec@1 58.333 (58.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [5][100/1334]\t\\Time 0.182 (0.271)\tData 0.162 (0.244)\tLoss 1.3451 (1.0394)\tPrec@1 58.333 (69.884)\tPrec@5 91.667 (91.749)\n",
      "Epoch: [5][200/1334]\t\\Time 0.190 (0.271)\tData 0.170 (0.244)\tLoss 0.7823 (0.9925)\tPrec@1 83.333 (70.647)\tPrec@5 100.000 (92.620)\n",
      "Epoch: [5][300/1334]\t\\Time 0.281 (0.269)\tData 0.251 (0.242)\tLoss 1.2368 (0.9643)\tPrec@1 75.000 (71.207)\tPrec@5 91.667 (93.134)\n",
      "Epoch: [5][400/1334]\t\\Time 0.323 (0.269)\tData 0.296 (0.242)\tLoss 0.7469 (0.9272)\tPrec@1 75.000 (72.195)\tPrec@5 100.000 (93.662)\n",
      "Epoch: [5][500/1334]\t\\Time 0.224 (0.268)\tData 0.197 (0.240)\tLoss 1.0306 (0.9203)\tPrec@1 66.667 (72.422)\tPrec@5 91.667 (93.812)\n",
      "Epoch: [5][600/1334]\t\\Time 0.289 (0.267)\tData 0.264 (0.240)\tLoss 1.0388 (0.9113)\tPrec@1 75.000 (72.601)\tPrec@5 91.667 (94.190)\n",
      "Epoch: [5][700/1334]\t\\Time 0.263 (0.268)\tData 0.234 (0.241)\tLoss 0.3137 (0.9075)\tPrec@1 91.667 (72.908)\tPrec@5 100.000 (94.139)\n",
      "Epoch: [5][800/1334]\t\\Time 0.300 (0.268)\tData 0.269 (0.241)\tLoss 0.5313 (0.8982)\tPrec@1 83.333 (73.148)\tPrec@5 100.000 (94.257)\n",
      "Epoch: [5][900/1334]\t\\Time 0.270 (0.268)\tData 0.240 (0.241)\tLoss 0.5924 (0.8945)\tPrec@1 83.333 (73.289)\tPrec@5 100.000 (94.321)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.282 (0.269)\tData 0.255 (0.242)\tLoss 0.9905 (0.8888)\tPrec@1 66.667 (73.460)\tPrec@5 100.000 (94.381)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.271 (0.270)\tData 0.240 (0.243)\tLoss 0.8734 (0.8868)\tPrec@1 83.333 (73.524)\tPrec@5 91.667 (94.384)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.273 (0.269)\tData 0.252 (0.243)\tLoss 1.2515 (0.8834)\tPrec@1 58.333 (73.591)\tPrec@5 91.667 (94.449)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.262 (0.269)\tData 0.235 (0.243)\tLoss 0.8946 (0.8849)\tPrec@1 83.333 (73.604)\tPrec@5 83.333 (94.491)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.297 (0.297)\n",
      "\n",
      "Loss 2.6739 (2.6739)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.283 (0.311)\n",
      "\n",
      "Loss 2.1103 (2.7595)\n",
      "\n",
      "Prec@1 50.000 (43.977)\n",
      "\n",
      "Prec@5 83.333 (75.825)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.282 (0.313)\n",
      "\n",
      "Loss 2.5299 (2.7364)\n",
      "\n",
      "Prec@1 50.000 (44.735)\n",
      "\n",
      "Prec@5 75.000 (75.041)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.270 (0.313)\n",
      "\n",
      "Loss 3.2286 (2.7895)\n",
      "\n",
      "Prec@1 41.667 (44.241)\n",
      "\n",
      "Prec@5 58.333 (74.612)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1334]\t\\Time 0.330 (0.330)\tData 0.267 (0.267)\tLoss 0.9224 (0.9224)\tPrec@1 66.667 (66.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [6][100/1334]\t\\Time 0.191 (0.270)\tData 0.161 (0.245)\tLoss 0.7591 (0.7883)\tPrec@1 75.000 (75.660)\tPrec@5 100.000 (95.380)\n",
      "Epoch: [6][200/1334]\t\\Time 0.184 (0.269)\tData 0.161 (0.243)\tLoss 0.7200 (0.7597)\tPrec@1 75.000 (77.156)\tPrec@5 100.000 (95.730)\n",
      "Epoch: [6][300/1334]\t\\Time 0.290 (0.269)\tData 0.260 (0.242)\tLoss 1.2998 (0.7490)\tPrec@1 66.667 (77.298)\tPrec@5 91.667 (96.013)\n",
      "Epoch: [6][400/1334]\t\\Time 0.320 (0.269)\tData 0.290 (0.242)\tLoss 0.3853 (0.7343)\tPrec@1 83.333 (77.702)\tPrec@5 100.000 (96.322)\n",
      "Epoch: [6][500/1334]\t\\Time 0.220 (0.268)\tData 0.194 (0.241)\tLoss 0.9739 (0.7354)\tPrec@1 75.000 (77.761)\tPrec@5 83.333 (96.324)\n",
      "Epoch: [6][600/1334]\t\\Time 0.290 (0.268)\tData 0.270 (0.241)\tLoss 1.1399 (0.7266)\tPrec@1 66.667 (78.023)\tPrec@5 91.667 (96.256)\n",
      "Epoch: [6][700/1334]\t\\Time 0.260 (0.269)\tData 0.240 (0.242)\tLoss 0.4320 (0.7250)\tPrec@1 75.000 (78.257)\tPrec@5 100.000 (96.184)\n",
      "Epoch: [6][800/1334]\t\\Time 0.299 (0.268)\tData 0.278 (0.241)\tLoss 0.5831 (0.7188)\tPrec@1 75.000 (78.340)\tPrec@5 100.000 (96.307)\n",
      "Epoch: [6][900/1334]\t\\Time 0.272 (0.269)\tData 0.242 (0.242)\tLoss 0.4750 (0.7151)\tPrec@1 75.000 (78.468)\tPrec@5 100.000 (96.384)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.304 (0.272)\tData 0.274 (0.245)\tLoss 0.3586 (0.7037)\tPrec@1 91.667 (78.780)\tPrec@5 100.000 (96.537)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.261 (0.273)\tData 0.236 (0.246)\tLoss 0.9743 (0.7013)\tPrec@1 75.000 (78.928)\tPrec@5 83.333 (96.473)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.280 (0.272)\tData 0.251 (0.245)\tLoss 0.4838 (0.7009)\tPrec@1 83.333 (78.948)\tPrec@5 100.000 (96.420)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.260 (0.272)\tData 0.240 (0.245)\tLoss 0.5094 (0.6934)\tPrec@1 83.333 (79.195)\tPrec@5 100.000 (96.509)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.290 (0.290)\n",
      "\n",
      "Loss 4.0972 (4.0972)\n",
      "\n",
      "Prec@1 33.333 (33.333)\n",
      "\n",
      "Prec@5 41.667 (41.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.292 (0.312)\n",
      "\n",
      "Loss 2.1613 (3.0449)\n",
      "\n",
      "Prec@1 50.000 (42.492)\n",
      "\n",
      "Prec@5 83.333 (75.083)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.281 (0.313)\n",
      "\n",
      "Loss 3.0401 (3.0461)\n",
      "\n",
      "Prec@1 33.333 (44.900)\n",
      "\n",
      "Prec@5 75.000 (75.290)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.287 (0.314)\n",
      "\n",
      "Loss 4.1024 (3.0809)\n",
      "\n",
      "Prec@1 41.667 (44.435)\n",
      "\n",
      "Prec@5 66.667 (74.336)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1334]\t\\Time 0.348 (0.348)\tData 0.286 (0.286)\tLoss 0.2562 (0.2562)\tPrec@1 91.667 (91.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/1334]\t\\Time 0.193 (0.270)\tData 0.166 (0.245)\tLoss 0.7326 (0.6394)\tPrec@1 66.667 (80.941)\tPrec@5 91.667 (97.607)\n",
      "Epoch: [7][200/1334]\t\\Time 0.190 (0.270)\tData 0.160 (0.243)\tLoss 1.0470 (0.6393)\tPrec@1 66.667 (81.053)\tPrec@5 100.000 (97.554)\n",
      "Epoch: [7][300/1334]\t\\Time 0.282 (0.269)\tData 0.258 (0.243)\tLoss 0.6057 (0.6055)\tPrec@1 75.000 (81.977)\tPrec@5 100.000 (97.647)\n",
      "Epoch: [7][400/1334]\t\\Time 0.322 (0.269)\tData 0.292 (0.242)\tLoss 0.3855 (0.5817)\tPrec@1 83.333 (82.502)\tPrec@5 100.000 (97.797)\n",
      "Epoch: [7][500/1334]\t\\Time 0.213 (0.268)\tData 0.192 (0.241)\tLoss 0.4713 (0.5767)\tPrec@1 91.667 (82.618)\tPrec@5 91.667 (97.738)\n",
      "Epoch: [7][600/1334]\t\\Time 0.282 (0.268)\tData 0.257 (0.241)\tLoss 0.9877 (0.5619)\tPrec@1 66.667 (82.917)\tPrec@5 100.000 (97.823)\n",
      "Epoch: [7][700/1334]\t\\Time 0.260 (0.269)\tData 0.230 (0.242)\tLoss 0.1377 (0.5590)\tPrec@1 100.000 (83.167)\tPrec@5 100.000 (97.801)\n",
      "Epoch: [7][800/1334]\t\\Time 0.296 (0.269)\tData 0.271 (0.242)\tLoss 0.5519 (0.5507)\tPrec@1 83.333 (83.292)\tPrec@5 100.000 (97.888)\n",
      "Epoch: [7][900/1334]\t\\Time 0.260 (0.269)\tData 0.236 (0.242)\tLoss 0.2084 (0.5427)\tPrec@1 91.667 (83.555)\tPrec@5 100.000 (97.956)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.294 (0.270)\tData 0.270 (0.243)\tLoss 0.0868 (0.5394)\tPrec@1 100.000 (83.775)\tPrec@5 100.000 (97.985)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.289 (0.271)\tData 0.262 (0.244)\tLoss 0.8613 (0.5397)\tPrec@1 75.000 (83.772)\tPrec@5 100.000 (98.055)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.292 (0.272)\tData 0.272 (0.245)\tLoss 0.5009 (0.5388)\tPrec@1 83.333 (83.680)\tPrec@5 100.000 (98.092)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.256 (0.272)\tData 0.232 (0.245)\tLoss 0.5091 (0.5356)\tPrec@1 91.667 (83.769)\tPrec@5 100.000 (98.110)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.281 (0.281)\n",
      "\n",
      "Loss 2.8940 (2.8940)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.282 (0.312)\n",
      "\n",
      "Loss 2.4351 (2.5108)\n",
      "\n",
      "Prec@1 41.667 (49.340)\n",
      "\n",
      "Prec@5 75.000 (79.455)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.334 (0.313)\n",
      "\n",
      "Loss 2.3256 (2.5467)\n",
      "\n",
      "Prec@1 50.000 (48.715)\n",
      "\n",
      "Prec@5 75.000 (79.768)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.286 (0.313)\n",
      "\n",
      "Loss 2.3979 (2.5837)\n",
      "\n",
      "Prec@1 66.667 (48.560)\n",
      "\n",
      "Prec@5 75.000 (78.987)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1334]\t\\Time 0.317 (0.317)\tData 0.260 (0.260)\tLoss 0.3673 (0.3673)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/1334]\t\\Time 0.179 (0.271)\tData 0.159 (0.244)\tLoss 0.6134 (0.4368)\tPrec@1 83.333 (85.974)\tPrec@5 100.000 (98.927)\n",
      "Epoch: [8][200/1334]\t\\Time 0.179 (0.271)\tData 0.154 (0.244)\tLoss 0.4069 (0.4244)\tPrec@1 83.333 (86.443)\tPrec@5 100.000 (98.964)\n",
      "Epoch: [8][300/1334]\t\\Time 0.280 (0.270)\tData 0.250 (0.243)\tLoss 0.0890 (0.4084)\tPrec@1 100.000 (86.849)\tPrec@5 100.000 (98.948)\n",
      "Epoch: [8][400/1334]\t\\Time 0.333 (0.270)\tData 0.310 (0.243)\tLoss 0.2801 (0.4014)\tPrec@1 91.667 (86.991)\tPrec@5 100.000 (99.086)\n",
      "Epoch: [8][500/1334]\t\\Time 0.223 (0.268)\tData 0.189 (0.241)\tLoss 0.2998 (0.3944)\tPrec@1 91.667 (87.242)\tPrec@5 100.000 (99.102)\n",
      "Epoch: [8][600/1334]\t\\Time 0.290 (0.268)\tData 0.260 (0.241)\tLoss 0.4881 (0.3968)\tPrec@1 91.667 (87.313)\tPrec@5 91.667 (99.071)\n",
      "Epoch: [8][700/1334]\t\\Time 0.261 (0.269)\tData 0.231 (0.242)\tLoss 0.5185 (0.4087)\tPrec@1 91.667 (87.090)\tPrec@5 100.000 (98.990)\n",
      "Epoch: [8][800/1334]\t\\Time 0.303 (0.269)\tData 0.273 (0.242)\tLoss 0.0947 (0.4020)\tPrec@1 91.667 (87.412)\tPrec@5 100.000 (98.949)\n",
      "Epoch: [8][900/1334]\t\\Time 0.267 (0.268)\tData 0.242 (0.242)\tLoss 0.1193 (0.4028)\tPrec@1 100.000 (87.320)\tPrec@5 100.000 (98.946)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.285 (0.269)\tData 0.261 (0.242)\tLoss 0.1615 (0.4023)\tPrec@1 100.000 (87.379)\tPrec@5 100.000 (98.968)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.274 (0.270)\tData 0.240 (0.243)\tLoss 1.3361 (0.3995)\tPrec@1 66.667 (87.557)\tPrec@5 91.667 (98.971)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.282 (0.270)\tData 0.252 (0.243)\tLoss 0.3100 (0.3999)\tPrec@1 91.667 (87.552)\tPrec@5 100.000 (98.973)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.274 (0.270)\tData 0.249 (0.243)\tLoss 0.1545 (0.3966)\tPrec@1 100.000 (87.676)\tPrec@5 100.000 (99.001)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.319 (0.319)\n",
      "\n",
      "Loss 3.6089 (3.6089)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.298 (0.325)\n",
      "\n",
      "Loss 2.0724 (3.0156)\n",
      "\n",
      "Prec@1 66.667 (47.277)\n",
      "\n",
      "Prec@5 91.667 (76.073)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.333 (0.320)\n",
      "\n",
      "Loss 2.4588 (3.0042)\n",
      "\n",
      "Prec@1 50.000 (47.430)\n",
      "\n",
      "Prec@5 75.000 (76.368)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.284 (0.318)\n",
      "\n",
      "Loss 3.1418 (3.0959)\n",
      "\n",
      "Prec@1 41.667 (46.124)\n",
      "\n",
      "Prec@5 83.333 (75.748)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1334]\t\\Time 0.325 (0.325)\tData 0.263 (0.263)\tLoss 0.0342 (0.0342)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/1334]\t\\Time 0.190 (0.271)\tData 0.160 (0.245)\tLoss 0.1081 (0.3532)\tPrec@1 100.000 (88.944)\tPrec@5 100.000 (99.340)\n",
      "Epoch: [9][200/1334]\t\\Time 0.190 (0.270)\tData 0.170 (0.243)\tLoss 0.0624 (0.3236)\tPrec@1 100.000 (89.884)\tPrec@5 100.000 (99.461)\n",
      "Epoch: [9][300/1334]\t\\Time 0.280 (0.269)\tData 0.251 (0.242)\tLoss 0.5822 (0.3177)\tPrec@1 83.333 (89.756)\tPrec@5 100.000 (99.446)\n",
      "Epoch: [9][400/1334]\t\\Time 0.324 (0.269)\tData 0.299 (0.242)\tLoss 0.5795 (0.3157)\tPrec@1 75.000 (89.859)\tPrec@5 91.667 (99.439)\n",
      "Epoch: [9][500/1334]\t\\Time 0.222 (0.268)\tData 0.201 (0.241)\tLoss 0.1452 (0.3221)\tPrec@1 100.000 (89.770)\tPrec@5 100.000 (99.318)\n",
      "Epoch: [9][600/1334]\t\\Time 0.291 (0.268)\tData 0.261 (0.240)\tLoss 0.1205 (0.3103)\tPrec@1 100.000 (90.058)\tPrec@5 100.000 (99.376)\n",
      "Epoch: [9][700/1334]\t\\Time 0.260 (0.268)\tData 0.231 (0.241)\tLoss 0.0402 (0.3132)\tPrec@1 100.000 (90.038)\tPrec@5 100.000 (99.346)\n",
      "Epoch: [9][800/1334]\t\\Time 0.302 (0.268)\tData 0.272 (0.241)\tLoss 0.2042 (0.3108)\tPrec@1 91.667 (90.127)\tPrec@5 100.000 (99.397)\n",
      "Epoch: [9][900/1334]\t\\Time 0.261 (0.268)\tData 0.231 (0.241)\tLoss 0.1490 (0.3115)\tPrec@1 91.667 (90.094)\tPrec@5 100.000 (99.390)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.280 (0.269)\tData 0.260 (0.242)\tLoss 0.2961 (0.3048)\tPrec@1 91.667 (90.410)\tPrec@5 100.000 (99.409)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.263 (0.270)\tData 0.230 (0.243)\tLoss 0.2132 (0.3043)\tPrec@1 91.667 (90.418)\tPrec@5 100.000 (99.432)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.290 (0.270)\tData 0.260 (0.243)\tLoss 0.0447 (0.3036)\tPrec@1 100.000 (90.418)\tPrec@5 100.000 (99.424)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.271 (0.271)\tData 0.244 (0.244)\tLoss 0.0286 (0.3013)\tPrec@1 100.000 (90.559)\tPrec@5 100.000 (99.424)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.315 (0.315)\n",
      "\n",
      "Loss 2.7673 (2.7673)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 83.333 (83.333)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.316 (0.319)\n",
      "\n",
      "Loss 1.7174 (2.7736)\n",
      "\n",
      "Prec@1 66.667 (50.330)\n",
      "\n",
      "Prec@5 83.333 (79.785)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.338 (0.317)\n",
      "\n",
      "Loss 2.6787 (2.6868)\n",
      "\n",
      "Prec@1 50.000 (50.415)\n",
      "\n",
      "Prec@5 75.000 (80.017)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.267 (0.316)\n",
      "\n",
      "Loss 4.2337 (2.7622)\n",
      "\n",
      "Prec@1 25.000 (49.945)\n",
      "\n",
      "Prec@5 58.333 (79.097)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "=> loading checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 10)\n",
      "Epoch: [10][0/1334]\t\\Time 0.292 (0.292)\tData 0.241 (0.241)\tLoss 0.3256 (0.3256)\tPrec@1 91.667 (91.667)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [10][100/1334]\t\\Time 0.182 (39.493)\tData 0.153 (0.235)\tLoss 0.6157 (0.2658)\tPrec@1 75.000 (91.419)\tPrec@5 100.000 (99.422)\n",
      "Epoch: [10][200/1334]\t\\Time 0.179 (19.974)\tData 0.151 (0.234)\tLoss 0.1489 (0.2345)\tPrec@1 91.667 (92.289)\tPrec@5 100.000 (99.585)\n",
      "Epoch: [10][300/1334]\t\\Time 0.258 (13.424)\tData 0.231 (0.233)\tLoss 0.2100 (0.2156)\tPrec@1 91.667 (93.217)\tPrec@5 100.000 (99.612)\n",
      "Epoch: [10][400/1334]\t\\Time 0.319 (10.141)\tData 0.291 (0.233)\tLoss 0.0431 (0.1997)\tPrec@1 100.000 (93.807)\tPrec@5 100.000 (99.709)\n",
      "Epoch: [10][500/1334]\t\\Time 0.225 (8.170)\tData 0.203 (0.234)\tLoss 0.1768 (0.1894)\tPrec@1 91.667 (94.195)\tPrec@5 100.000 (99.750)\n",
      "Epoch: [10][600/1334]\t\\Time 0.267 (6.854)\tData 0.245 (0.234)\tLoss 0.1121 (0.1733)\tPrec@1 100.000 (94.814)\tPrec@5 100.000 (99.778)\n",
      "Epoch: [10][700/1334]\t\\Time 0.254 (5.916)\tData 0.227 (0.236)\tLoss 0.0388 (0.1642)\tPrec@1 100.000 (95.174)\tPrec@5 100.000 (99.786)\n",
      "Epoch: [10][800/1334]\t\\Time 0.318 (5.212)\tData 0.289 (0.237)\tLoss 0.3634 (0.1549)\tPrec@1 83.333 (95.485)\tPrec@5 100.000 (99.813)\n",
      "Epoch: [10][900/1334]\t\\Time 0.277 (4.663)\tData 0.250 (0.238)\tLoss 0.0057 (0.1462)\tPrec@1 100.000 (95.745)\tPrec@5 100.000 (99.824)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.289 (4.227)\tData 0.262 (0.241)\tLoss 0.0287 (0.1381)\tPrec@1 100.000 (95.971)\tPrec@5 100.000 (99.833)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.253 (3.867)\tData 0.229 (0.240)\tLoss 0.0431 (0.1306)\tPrec@1 100.000 (96.208)\tPrec@5 100.000 (99.841)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.304 (3.567)\tData 0.273 (0.240)\tLoss 0.0082 (0.1220)\tPrec@1 100.000 (96.503)\tPrec@5 100.000 (99.854)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.266 (3.314)\tData 0.246 (0.241)\tLoss 0.0018 (0.1144)\tPrec@1 100.000 (96.752)\tPrec@5 100.000 (99.865)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.254 (0.254)\n",
      "\n",
      "Loss 1.0783 (1.0783)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.308 (0.306)\n",
      "\n",
      "Loss 0.6865 (1.8987)\n",
      "\n",
      "Prec@1 75.000 (61.799)\n",
      "\n",
      "Prec@5 100.000 (85.809)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.273 (0.309)\n",
      "\n",
      "Loss 1.5799 (1.8881)\n",
      "\n",
      "Prec@1 75.000 (62.106)\n",
      "\n",
      "Prec@5 83.333 (86.070)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.280 (0.309)\n",
      "\n",
      "Loss 2.7283 (1.9333)\n",
      "\n",
      "Prec@1 41.667 (60.770)\n",
      "\n",
      "Prec@5 75.000 (85.271)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [11][0/1334]\t\\Time 0.330 (0.330)\tData 0.270 (0.270)\tLoss 0.0530 (0.0530)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.180 (0.278)\tData 0.150 (0.250)\tLoss 0.0301 (0.0354)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][200/1334]\t\\Time 0.189 (0.274)\tData 0.161 (0.246)\tLoss 0.0670 (0.0321)\tPrec@1 100.000 (99.668)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][300/1334]\t\\Time 0.286 (0.271)\tData 0.262 (0.243)\tLoss 0.0083 (0.0316)\tPrec@1 100.000 (99.695)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [11][400/1334]\t\\Time 0.319 (0.271)\tData 0.291 (0.244)\tLoss 0.0079 (0.0297)\tPrec@1 100.000 (99.771)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [11][500/1334]\t\\Time 0.215 (0.267)\tData 0.186 (0.240)\tLoss 0.0140 (0.0291)\tPrec@1 100.000 (99.734)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [11][600/1334]\t\\Time 0.281 (0.267)\tData 0.251 (0.240)\tLoss 0.0119 (0.0275)\tPrec@1 100.000 (99.778)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [11][700/1334]\t\\Time 0.262 (0.268)\tData 0.232 (0.241)\tLoss 0.0113 (0.0263)\tPrec@1 100.000 (99.798)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [11][800/1334]\t\\Time 0.271 (0.268)\tData 0.251 (0.241)\tLoss 0.1053 (0.0256)\tPrec@1 100.000 (99.823)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [11][900/1334]\t\\Time 0.264 (0.268)\tData 0.234 (0.241)\tLoss 0.0049 (0.0246)\tPrec@1 100.000 (99.843)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.271 (0.269)\tData 0.241 (0.241)\tLoss 0.0131 (0.0236)\tPrec@1 100.000 (99.858)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.262 (0.269)\tData 0.229 (0.242)\tLoss 0.0281 (0.0229)\tPrec@1 100.000 (99.864)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.276 (0.269)\tData 0.241 (0.242)\tLoss 0.0058 (0.0218)\tPrec@1 100.000 (99.875)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.262 (0.269)\tData 0.239 (0.242)\tLoss 0.0015 (0.0209)\tPrec@1 100.000 (99.885)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.271 (0.271)\n",
      "\n",
      "Loss 1.0665 (1.0665)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.348 (0.308)\n",
      "\n",
      "Loss 0.6385 (1.9054)\n",
      "\n",
      "Prec@1 75.000 (62.129)\n",
      "\n",
      "Prec@5 100.000 (85.809)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.276 (0.311)\n",
      "\n",
      "Loss 1.5274 (1.9032)\n",
      "\n",
      "Prec@1 66.667 (62.355)\n",
      "\n",
      "Prec@5 83.333 (85.821)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.273 (0.312)\n",
      "\n",
      "Loss 2.8158 (1.9498)\n",
      "\n",
      "Prec@1 41.667 (60.714)\n",
      "\n",
      "Prec@5 75.000 (85.078)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [12][0/1334]\t\\Time 0.325 (0.325)\tData 0.248 (0.248)\tLoss 0.0143 (0.0143)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.186 (0.273)\tData 0.154 (0.246)\tLoss 0.0201 (0.0150)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][200/1334]\t\\Time 0.193 (0.271)\tData 0.165 (0.243)\tLoss 0.0359 (0.0150)\tPrec@1 100.000 (99.959)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][300/1334]\t\\Time 0.290 (0.271)\tData 0.260 (0.243)\tLoss 0.0065 (0.0160)\tPrec@1 100.000 (99.945)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [12][400/1334]\t\\Time 0.318 (0.270)\tData 0.297 (0.242)\tLoss 0.0067 (0.0157)\tPrec@1 100.000 (99.958)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [12][500/1334]\t\\Time 0.221 (0.268)\tData 0.191 (0.241)\tLoss 0.0103 (0.0155)\tPrec@1 100.000 (99.967)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [12][600/1334]\t\\Time 0.282 (0.268)\tData 0.252 (0.240)\tLoss 0.0089 (0.0150)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [12][700/1334]\t\\Time 0.261 (0.269)\tData 0.242 (0.241)\tLoss 0.0083 (0.0145)\tPrec@1 100.000 (99.976)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [12][800/1334]\t\\Time 0.307 (0.268)\tData 0.270 (0.241)\tLoss 0.0424 (0.0144)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [12][900/1334]\t\\Time 0.262 (0.268)\tData 0.243 (0.241)\tLoss 0.0044 (0.0140)\tPrec@1 100.000 (99.982)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.290 (0.269)\tData 0.262 (0.242)\tLoss 0.0088 (0.0136)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.259 (0.270)\tData 0.231 (0.242)\tLoss 0.0204 (0.0134)\tPrec@1 100.000 (99.977)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.292 (0.269)\tData 0.264 (0.242)\tLoss 0.0046 (0.0129)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.261 (0.269)\tData 0.231 (0.242)\tLoss 0.0013 (0.0125)\tPrec@1 100.000 (99.981)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.280 (0.280)\n",
      "\n",
      "Loss 1.0357 (1.0357)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.343 (0.307)\n",
      "\n",
      "Loss 0.6129 (1.9160)\n",
      "\n",
      "Prec@1 75.000 (62.294)\n",
      "\n",
      "Prec@5 100.000 (85.809)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.288 (0.309)\n",
      "\n",
      "Loss 1.5089 (1.9170)\n",
      "\n",
      "Prec@1 66.667 (62.521)\n",
      "\n",
      "Prec@5 91.667 (86.153)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.271 (0.310)\n",
      "\n",
      "Loss 2.8125 (1.9632)\n",
      "\n",
      "Prec@1 41.667 (61.074)\n",
      "\n",
      "Prec@5 83.333 (85.354)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [13][0/1334]\t\\Time 0.368 (0.368)\tData 0.261 (0.261)\tLoss 0.0113 (0.0113)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.196 (0.271)\tData 0.167 (0.246)\tLoss 0.0153 (0.0112)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][200/1334]\t\\Time 0.191 (0.271)\tData 0.161 (0.245)\tLoss 0.0252 (0.0112)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][300/1334]\t\\Time 0.279 (0.270)\tData 0.251 (0.244)\tLoss 0.0057 (0.0122)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [13][400/1334]\t\\Time 0.341 (0.270)\tData 0.311 (0.243)\tLoss 0.0060 (0.0119)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [13][500/1334]\t\\Time 0.222 (0.269)\tData 0.193 (0.242)\tLoss 0.0084 (0.0118)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [13][600/1334]\t\\Time 0.286 (0.268)\tData 0.264 (0.242)\tLoss 0.0074 (0.0114)\tPrec@1 100.000 (99.986)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [13][700/1334]\t\\Time 0.240 (0.268)\tData 0.210 (0.242)\tLoss 0.0066 (0.0111)\tPrec@1 100.000 (99.988)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [13][800/1334]\t\\Time 0.311 (0.268)\tData 0.283 (0.242)\tLoss 0.0268 (0.0110)\tPrec@1 100.000 (99.990)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [13][900/1334]\t\\Time 0.259 (0.268)\tData 0.228 (0.242)\tLoss 0.0038 (0.0108)\tPrec@1 100.000 (99.991)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.280 (0.269)\tData 0.250 (0.242)\tLoss 0.0068 (0.0105)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.262 (0.269)\tData 0.232 (0.243)\tLoss 0.0162 (0.0103)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.272 (0.269)\tData 0.250 (0.242)\tLoss 0.0039 (0.0100)\tPrec@1 100.000 (99.993)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.252 (0.269)\tData 0.232 (0.242)\tLoss 0.0011 (0.0096)\tPrec@1 100.000 (99.994)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.282 (0.282)\n",
      "\n",
      "Loss 1.0157 (1.0157)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.299 (0.310)\n",
      "\n",
      "Loss 0.5969 (1.9236)\n",
      "\n",
      "Prec@1 83.333 (62.624)\n",
      "\n",
      "Prec@5 100.000 (85.809)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.326 (0.312)\n",
      "\n",
      "Loss 1.4946 (1.9267)\n",
      "\n",
      "Prec@1 66.667 (62.769)\n",
      "\n",
      "Prec@5 91.667 (86.235)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.268 (0.311)\n",
      "\n",
      "Loss 2.8069 (1.9726)\n",
      "\n",
      "Prec@1 41.667 (61.296)\n",
      "\n",
      "Prec@5 83.333 (85.410)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [14][0/1334]\t\\Time 0.331 (0.331)\tData 0.268 (0.268)\tLoss 0.0093 (0.0093)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1334]\t\\Time 0.190 (0.272)\tData 0.160 (0.245)\tLoss 0.0124 (0.0092)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/1334]\t\\Time 0.191 (0.270)\tData 0.161 (0.244)\tLoss 0.0197 (0.0091)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][300/1334]\t\\Time 0.273 (0.269)\tData 0.246 (0.242)\tLoss 0.0053 (0.0100)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [14][400/1334]\t\\Time 0.323 (0.268)\tData 0.293 (0.242)\tLoss 0.0054 (0.0098)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [14][500/1334]\t\\Time 0.223 (0.267)\tData 0.201 (0.241)\tLoss 0.0072 (0.0096)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [14][600/1334]\t\\Time 0.282 (0.267)\tData 0.253 (0.241)\tLoss 0.0064 (0.0093)\tPrec@1 100.000 (99.986)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [14][700/1334]\t\\Time 0.263 (0.268)\tData 0.233 (0.241)\tLoss 0.0056 (0.0091)\tPrec@1 100.000 (99.988)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [14][800/1334]\t\\Time 0.313 (0.268)\tData 0.283 (0.241)\tLoss 0.0196 (0.0090)\tPrec@1 100.000 (99.990)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [14][900/1334]\t\\Time 0.256 (0.268)\tData 0.223 (0.241)\tLoss 0.0033 (0.0089)\tPrec@1 100.000 (99.991)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.301 (0.269)\tData 0.275 (0.242)\tLoss 0.0056 (0.0086)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.286 (0.271)\tData 0.255 (0.244)\tLoss 0.0135 (0.0085)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.273 (0.272)\tData 0.241 (0.245)\tLoss 0.0034 (0.0082)\tPrec@1 100.000 (99.993)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.260 (0.271)\tData 0.230 (0.245)\tLoss 0.0010 (0.0080)\tPrec@1 100.000 (99.994)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.283 (0.283)\n",
      "\n",
      "Loss 1.0012 (1.0012)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.287 (0.309)\n",
      "\n",
      "Loss 0.5839 (1.9296)\n",
      "\n",
      "Prec@1 83.333 (62.706)\n",
      "\n",
      "Prec@5 100.000 (85.891)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.341 (0.311)\n",
      "\n",
      "Loss 1.4814 (1.9342)\n",
      "\n",
      "Prec@1 66.667 (62.728)\n",
      "\n",
      "Prec@5 91.667 (86.318)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.284 (0.311)\n",
      "\n",
      "Loss 2.7993 (1.9796)\n",
      "\n",
      "Prec@1 50.000 (61.323)\n",
      "\n",
      "Prec@5 83.333 (85.520)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "=> loading checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet34_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 15)\n",
      "Epoch: [15][0/1334]\t\\Time 0.320 (0.320)\tData 0.264 (0.264)\tLoss 0.0080 (0.0080)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.192 (0.270)\tData 0.163 (0.244)\tLoss 0.0112 (0.0079)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/1334]\t\\Time 0.187 (0.269)\tData 0.159 (0.243)\tLoss 0.0160 (0.0078)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/1334]\t\\Time 0.291 (0.268)\tData 0.261 (0.242)\tLoss 0.0049 (0.0086)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [15][400/1334]\t\\Time 0.322 (0.268)\tData 0.292 (0.242)\tLoss 0.0047 (0.0084)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [15][500/1334]\t\\Time 0.222 (0.267)\tData 0.192 (0.241)\tLoss 0.0064 (0.0083)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [15][600/1334]\t\\Time 0.283 (0.267)\tData 0.253 (0.240)\tLoss 0.0059 (0.0080)\tPrec@1 100.000 (99.986)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [15][700/1334]\t\\Time 0.257 (0.267)\tData 0.231 (0.241)\tLoss 0.0049 (0.0078)\tPrec@1 100.000 (99.988)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [15][800/1334]\t\\Time 0.302 (0.267)\tData 0.277 (0.241)\tLoss 0.0150 (0.0078)\tPrec@1 100.000 (99.990)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [15][900/1334]\t\\Time 0.252 (0.267)\tData 0.232 (0.241)\tLoss 0.0031 (0.0076)\tPrec@1 100.000 (99.991)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.282 (0.268)\tData 0.252 (0.241)\tLoss 0.0051 (0.0075)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.261 (0.269)\tData 0.232 (0.242)\tLoss 0.0111 (0.0073)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.301 (0.270)\tData 0.274 (0.243)\tLoss 0.0031 (0.0071)\tPrec@1 100.000 (99.993)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.268 (0.271)\tData 0.239 (0.244)\tLoss 0.0010 (0.0069)\tPrec@1 100.000 (99.994)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.282 (0.282)\n",
      "\n",
      "Loss 0.9999 (0.9999)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.289 (0.311)\n",
      "\n",
      "Loss 0.5837 (1.9300)\n",
      "\n",
      "Prec@1 83.333 (62.871)\n",
      "\n",
      "Prec@5 100.000 (85.891)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.284 (0.311)\n",
      "\n",
      "Loss 1.4785 (1.9348)\n",
      "\n",
      "Prec@1 66.667 (62.769)\n",
      "\n",
      "Prec@5 91.667 (86.318)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.269 (0.311)\n",
      "\n",
      "Loss 2.8002 (1.9801)\n",
      "\n",
      "Prec@1 50.000 (61.351)\n",
      "\n",
      "Prec@5 83.333 (85.548)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Epoch: [16][0/1334]\t\\Time 0.315 (0.315)\tData 0.253 (0.253)\tLoss 0.0079 (0.0079)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.191 (0.271)\tData 0.171 (0.245)\tLoss 0.0109 (0.0078)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][200/1334]\t\\Time 0.186 (0.270)\tData 0.160 (0.244)\tLoss 0.0157 (0.0077)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][300/1334]\t\\Time 0.281 (0.269)\tData 0.252 (0.243)\tLoss 0.0049 (0.0085)\tPrec@1 100.000 (99.972)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [16][400/1334]\t\\Time 0.335 (0.269)\tData 0.305 (0.243)\tLoss 0.0047 (0.0083)\tPrec@1 100.000 (99.979)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][500/1334]\t\\Time 0.221 (0.268)\tData 0.192 (0.242)\tLoss 0.0063 (0.0081)\tPrec@1 100.000 (99.983)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [16][600/1334]\t\\Time 0.288 (0.268)\tData 0.258 (0.241)\tLoss 0.0058 (0.0079)\tPrec@1 100.000 (99.986)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [16][700/1334]\t\\Time 0.266 (0.269)\tData 0.241 (0.242)\tLoss 0.0048 (0.0077)\tPrec@1 100.000 (99.988)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [16][800/1334]\t\\Time 0.303 (0.268)\tData 0.279 (0.242)\tLoss 0.0147 (0.0077)\tPrec@1 100.000 (99.990)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [16][900/1334]\t\\Time 0.261 (0.268)\tData 0.231 (0.242)\tLoss 0.0031 (0.0075)\tPrec@1 100.000 (99.991)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.273 (0.269)\tData 0.253 (0.242)\tLoss 0.0050 (0.0074)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.257 (0.269)\tData 0.228 (0.242)\tLoss 0.0109 (0.0072)\tPrec@1 100.000 (99.992)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.291 (0.270)\tData 0.270 (0.243)\tLoss 0.0031 (0.0070)\tPrec@1 100.000 (99.993)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.274 (0.271)\tData 0.254 (0.244)\tLoss 0.0010 (0.0068)\tPrec@1 100.000 (99.994)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.314 (0.314)\n",
      "\n",
      "Loss 0.9991 (0.9991)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.304 (0.312)\n",
      "\n",
      "Loss 0.5822 (1.9305)\n",
      "\n",
      "Prec@1 83.333 (62.871)\n",
      "\n",
      "Prec@5 100.000 (85.891)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.325 (0.310)\n",
      "\n",
      "Loss 1.4768 (1.9354)\n",
      "\n",
      "Prec@1 66.667 (62.769)\n",
      "\n",
      "Prec@5 91.667 (86.318)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.260 (0.309)\n",
      "\n",
      "Loss 2.7994 (1.9807)\n",
      "\n",
      "Prec@1 50.000 (61.379)\n",
      "\n",
      "Prec@5 83.333 (85.548)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "# model = torchvision.models.vit_b_16(weights = 'VGG16_Weights.IMAGENET1K_V1')\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# model = torchvision.models.vgg16(weights = True)\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet34_v3_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=12, shuffle=False, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.location_fc2.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.location_fc.parameters():\n",
    "#     param.requires_grad = True   \n",
    "# for param in model.linear_add.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a564575-883c-4af6-b034-517716c5c05b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vjosv/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vjosv\\anaconda3\\envs\\cuda_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [0][0/1334]\t\\Time 0.358 (0.358)\tData 0.277 (0.277)\tLoss 4.7197 (4.7197)\tPrec@1 8.333 (8.333)\tPrec@5 8.333 (8.333)\n",
      "Epoch: [0][100/1334]\t\\Time 0.440 (0.324)\tData 0.396 (0.277)\tLoss 4.6716 (4.6716)\tPrec@1 8.333 (4.538)\tPrec@5 25.000 (15.759)\n",
      "Epoch: [0][200/1334]\t\\Time 0.544 (0.334)\tData 0.503 (0.287)\tLoss 3.9841 (4.3811)\tPrec@1 8.333 (6.592)\tPrec@5 25.000 (21.559)\n",
      "Epoch: [0][300/1334]\t\\Time 0.339 (0.334)\tData 0.295 (0.287)\tLoss 3.2374 (4.1539)\tPrec@1 16.667 (8.527)\tPrec@5 58.333 (27.132)\n",
      "Epoch: [0][400/1334]\t\\Time 0.302 (0.348)\tData 0.255 (0.301)\tLoss 3.8924 (4.0048)\tPrec@1 16.667 (9.435)\tPrec@5 41.667 (30.258)\n",
      "Epoch: [0][500/1334]\t\\Time 0.320 (0.348)\tData 0.266 (0.301)\tLoss 3.3025 (3.8536)\tPrec@1 8.333 (11.411)\tPrec@5 25.000 (34.065)\n",
      "Epoch: [0][600/1334]\t\\Time 0.382 (0.345)\tData 0.335 (0.298)\tLoss 3.9442 (3.7427)\tPrec@1 8.333 (12.715)\tPrec@5 16.667 (36.952)\n",
      "Epoch: [0][700/1334]\t\\Time 0.366 (0.344)\tData 0.317 (0.297)\tLoss 2.9204 (3.6479)\tPrec@1 25.000 (14.384)\tPrec@5 58.333 (39.456)\n",
      "Epoch: [0][800/1334]\t\\Time 0.370 (0.343)\tData 0.324 (0.297)\tLoss 3.2067 (3.5533)\tPrec@1 25.000 (15.855)\tPrec@5 50.000 (41.958)\n",
      "Epoch: [0][900/1334]\t\\Time 1.250 (0.352)\tData 1.153 (0.305)\tLoss 3.3474 (3.4929)\tPrec@1 25.000 (16.935)\tPrec@5 50.000 (43.452)\n",
      "Epoch: [0][1000/1334]\t\\Time 0.351 (0.390)\tData 0.298 (0.340)\tLoss 3.1880 (3.4365)\tPrec@1 33.333 (17.899)\tPrec@5 50.000 (44.972)\n",
      "Epoch: [0][1100/1334]\t\\Time 0.367 (0.394)\tData 0.326 (0.343)\tLoss 2.5041 (3.3711)\tPrec@1 33.333 (18.998)\tPrec@5 75.000 (46.708)\n",
      "Epoch: [0][1200/1334]\t\\Time 0.383 (0.393)\tData 0.333 (0.342)\tLoss 2.5537 (3.3147)\tPrec@1 25.000 (19.865)\tPrec@5 75.000 (48.231)\n",
      "Epoch: [0][1300/1334]\t\\Time 0.343 (0.392)\tData 0.298 (0.341)\tLoss 2.5727 (3.2571)\tPrec@1 33.333 (20.881)\tPrec@5 75.000 (49.673)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.329 (0.329)\n",
      "\n",
      "Loss 2.3050 (2.3050)\n",
      "\n",
      "Prec@1 25.000 (25.000)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.325 (0.331)\n",
      "\n",
      "Loss 2.2454 (3.2436)\n",
      "\n",
      "Prec@1 41.667 (30.528)\n",
      "\n",
      "Prec@5 75.000 (64.851)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.332 (0.343)\n",
      "\n",
      "Loss 2.9707 (3.3476)\n",
      "\n",
      "Prec@1 16.667 (29.270)\n",
      "\n",
      "Prec@5 83.333 (63.640)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.319 (0.366)\n",
      "\n",
      "Loss 2.7829 (3.3835)\n",
      "\n",
      "Prec@1 33.333 (29.291)\n",
      "\n",
      "Prec@5 58.333 (63.344)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [1][0/1334]\t\\Time 0.702 (0.702)\tData 0.368 (0.368)\tLoss 2.4687 (2.4687)\tPrec@1 33.333 (33.333)\tPrec@5 75.000 (75.000)\n",
      "Epoch: [1][100/1334]\t\\Time 0.660 (0.413)\tData 0.606 (0.360)\tLoss 3.2077 (2.4458)\tPrec@1 33.333 (35.479)\tPrec@5 33.333 (69.389)\n",
      "Epoch: [1][200/1334]\t\\Time 0.341 (0.371)\tData 0.300 (0.322)\tLoss 2.6662 (2.4246)\tPrec@1 33.333 (34.784)\tPrec@5 75.000 (69.859)\n",
      "Epoch: [1][300/1334]\t\\Time 0.315 (0.352)\tData 0.265 (0.305)\tLoss 1.8221 (2.3960)\tPrec@1 41.667 (36.130)\tPrec@5 91.667 (70.875)\n",
      "Epoch: [1][400/1334]\t\\Time 0.357 (0.346)\tData 0.312 (0.299)\tLoss 2.0157 (2.3599)\tPrec@1 41.667 (37.552)\tPrec@5 91.667 (71.467)\n",
      "Epoch: [1][500/1334]\t\\Time 0.245 (0.344)\tData 0.200 (0.298)\tLoss 2.2669 (2.3284)\tPrec@1 50.000 (38.090)\tPrec@5 75.000 (72.023)\n",
      "Epoch: [1][600/1334]\t\\Time 0.266 (0.342)\tData 0.223 (0.296)\tLoss 2.2566 (2.3366)\tPrec@1 25.000 (37.965)\tPrec@5 58.333 (71.728)\n",
      "Epoch: [1][700/1334]\t\\Time 0.313 (0.340)\tData 0.272 (0.294)\tLoss 3.2066 (2.4190)\tPrec@1 16.667 (36.079)\tPrec@5 58.333 (69.532)\n",
      "Epoch: [1][800/1334]\t\\Time 0.299 (0.339)\tData 0.259 (0.293)\tLoss 3.5671 (2.4597)\tPrec@1 16.667 (35.112)\tPrec@5 50.000 (68.581)\n",
      "Epoch: [1][900/1334]\t\\Time 0.326 (0.339)\tData 0.282 (0.293)\tLoss 2.2008 (2.4670)\tPrec@1 58.333 (35.146)\tPrec@5 75.000 (68.498)\n",
      "Epoch: [1][1000/1334]\t\\Time 0.353 (0.343)\tData 0.304 (0.297)\tLoss 2.3590 (2.4714)\tPrec@1 41.667 (35.057)\tPrec@5 66.667 (68.332)\n",
      "Epoch: [1][1100/1334]\t\\Time 0.379 (0.342)\tData 0.335 (0.296)\tLoss 2.6991 (2.4748)\tPrec@1 25.000 (35.051)\tPrec@5 66.667 (68.332)\n",
      "Epoch: [1][1200/1334]\t\\Time 0.307 (0.342)\tData 0.264 (0.296)\tLoss 2.6202 (2.4647)\tPrec@1 41.667 (35.401)\tPrec@5 66.667 (68.492)\n",
      "Epoch: [1][1300/1334]\t\\Time 0.286 (0.341)\tData 0.240 (0.295)\tLoss 1.7179 (2.4485)\tPrec@1 50.000 (35.870)\tPrec@5 83.333 (68.825)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.326 (0.326)\n",
      "\n",
      "Loss 2.2743 (2.2743)\n",
      "\n",
      "Prec@1 41.667 (41.667)\n",
      "\n",
      "Prec@5 75.000 (75.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.326 (0.346)\n",
      "\n",
      "Loss 1.7717 (2.4999)\n",
      "\n",
      "Prec@1 66.667 (36.634)\n",
      "\n",
      "Prec@5 83.333 (70.710)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.322 (0.347)\n",
      "\n",
      "Loss 1.9983 (2.4280)\n",
      "\n",
      "Prec@1 41.667 (37.562)\n",
      "\n",
      "Prec@5 66.667 (71.725)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.318 (0.349)\n",
      "\n",
      "Loss 2.7346 (2.4559)\n",
      "\n",
      "Prec@1 33.333 (37.708)\n",
      "\n",
      "Prec@5 66.667 (71.069)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [2][0/1334]\t\\Time 0.312 (0.312)\tData 0.209 (0.209)\tLoss 2.5729 (2.5729)\tPrec@1 33.333 (33.333)\tPrec@5 58.333 (58.333)\n",
      "Epoch: [2][100/1334]\t\\Time 0.349 (0.330)\tData 0.306 (0.284)\tLoss 1.4512 (2.0022)\tPrec@1 75.000 (46.865)\tPrec@5 83.333 (79.538)\n",
      "Epoch: [2][200/1334]\t\\Time 0.300 (0.332)\tData 0.252 (0.286)\tLoss 1.7926 (1.9888)\tPrec@1 50.000 (46.517)\tPrec@5 83.333 (78.648)\n",
      "Epoch: [2][300/1334]\t\\Time 0.370 (0.331)\tData 0.327 (0.285)\tLoss 1.7334 (1.9780)\tPrec@1 50.000 (46.622)\tPrec@5 83.333 (78.821)\n",
      "Epoch: [2][400/1334]\t\\Time 0.366 (0.333)\tData 0.316 (0.287)\tLoss 1.5885 (1.9696)\tPrec@1 41.667 (46.779)\tPrec@5 83.333 (78.948)\n",
      "Epoch: [2][500/1334]\t\\Time 0.326 (0.332)\tData 0.282 (0.286)\tLoss 1.6276 (1.9667)\tPrec@1 58.333 (46.823)\tPrec@5 83.333 (79.042)\n",
      "Epoch: [2][600/1334]\t\\Time 0.405 (0.331)\tData 0.361 (0.286)\tLoss 3.1812 (1.9609)\tPrec@1 16.667 (46.922)\tPrec@5 83.333 (79.035)\n",
      "Epoch: [2][700/1334]\t\\Time 0.279 (0.332)\tData 0.234 (0.287)\tLoss 1.6456 (1.9450)\tPrec@1 41.667 (47.004)\tPrec@5 91.667 (79.161)\n",
      "Epoch: [2][800/1334]\t\\Time 0.293 (0.333)\tData 0.253 (0.288)\tLoss 1.7892 (1.9393)\tPrec@1 50.000 (47.482)\tPrec@5 83.333 (79.286)\n",
      "Epoch: [2][900/1334]\t\\Time 0.377 (0.335)\tData 0.332 (0.290)\tLoss 1.5390 (1.9275)\tPrec@1 50.000 (47.919)\tPrec@5 100.000 (79.440)\n",
      "Epoch: [2][1000/1334]\t\\Time 0.453 (0.335)\tData 0.389 (0.290)\tLoss 1.9089 (1.9269)\tPrec@1 50.000 (48.002)\tPrec@5 75.000 (79.462)\n",
      "Epoch: [2][1100/1334]\t\\Time 0.386 (0.339)\tData 0.325 (0.293)\tLoss 1.8245 (1.9236)\tPrec@1 66.667 (48.138)\tPrec@5 83.333 (79.466)\n",
      "Epoch: [2][1200/1334]\t\\Time 1.232 (0.352)\tData 1.098 (0.306)\tLoss 1.2999 (1.9197)\tPrec@1 58.333 (48.349)\tPrec@5 83.333 (79.468)\n",
      "Epoch: [2][1300/1334]\t\\Time 0.289 (0.358)\tData 0.249 (0.312)\tLoss 1.0141 (1.9171)\tPrec@1 75.000 (48.392)\tPrec@5 100.000 (79.516)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.343 (0.343)\n",
      "\n",
      "Loss 19.0185 (19.0185)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 66.667 (66.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.331 (0.341)\n",
      "\n",
      "Loss 24.7116 (48.3859)\n",
      "\n",
      "Prec@1 41.667 (33.746)\n",
      "\n",
      "Prec@5 58.333 (60.644)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.333 (0.347)\n",
      "\n",
      "Loss 54.0585 (50.3960)\n",
      "\n",
      "Prec@1 41.667 (34.701)\n",
      "\n",
      "Prec@5 58.333 (60.945)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.347)\n",
      "\n",
      "Loss 27.9554 (49.0193)\n",
      "\n",
      "Prec@1 33.333 (34.496)\n",
      "\n",
      "Prec@5 58.333 (60.742)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [3][0/1334]\t\\Time 0.364 (0.364)\tData 0.260 (0.260)\tLoss 1.2877 (1.2877)\tPrec@1 66.667 (66.667)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [3][100/1334]\t\\Time 0.288 (0.333)\tData 0.247 (0.287)\tLoss 1.2511 (1.6021)\tPrec@1 50.000 (57.013)\tPrec@5 91.667 (83.003)\n",
      "Epoch: [3][200/1334]\t\\Time 0.299 (0.330)\tData 0.253 (0.284)\tLoss 1.2633 (1.5668)\tPrec@1 58.333 (57.131)\tPrec@5 83.333 (84.038)\n",
      "Epoch: [3][300/1334]\t\\Time 0.293 (0.330)\tData 0.254 (0.285)\tLoss 1.9560 (1.5908)\tPrec@1 41.667 (56.063)\tPrec@5 58.333 (83.998)\n",
      "Epoch: [3][400/1334]\t\\Time 0.310 (0.328)\tData 0.264 (0.283)\tLoss 1.2967 (1.5756)\tPrec@1 50.000 (56.505)\tPrec@5 91.667 (84.331)\n",
      "Epoch: [3][500/1334]\t\\Time 0.310 (0.329)\tData 0.262 (0.284)\tLoss 1.3460 (1.5900)\tPrec@1 75.000 (56.437)\tPrec@5 83.333 (84.049)\n",
      "Epoch: [3][600/1334]\t\\Time 0.258 (0.328)\tData 0.212 (0.283)\tLoss 1.4904 (1.5935)\tPrec@1 75.000 (56.364)\tPrec@5 83.333 (83.999)\n",
      "Epoch: [3][700/1334]\t\\Time 0.329 (0.328)\tData 0.292 (0.283)\tLoss 1.6743 (1.5803)\tPrec@1 25.000 (56.693)\tPrec@5 91.667 (84.403)\n",
      "Epoch: [3][800/1334]\t\\Time 0.311 (0.329)\tData 0.251 (0.284)\tLoss 2.2206 (1.5885)\tPrec@1 33.333 (56.586)\tPrec@5 75.000 (84.311)\n",
      "Epoch: [3][900/1334]\t\\Time 0.316 (0.329)\tData 0.273 (0.285)\tLoss 1.9449 (1.5720)\tPrec@1 66.667 (56.780)\tPrec@5 75.000 (84.665)\n",
      "Epoch: [3][1000/1334]\t\\Time 0.329 (0.329)\tData 0.280 (0.285)\tLoss 2.0464 (1.5631)\tPrec@1 25.000 (56.876)\tPrec@5 75.000 (84.840)\n",
      "Epoch: [3][1100/1334]\t\\Time 0.317 (0.330)\tData 0.264 (0.285)\tLoss 1.2936 (1.5598)\tPrec@1 41.667 (56.941)\tPrec@5 83.333 (84.938)\n",
      "Epoch: [3][1200/1334]\t\\Time 0.364 (0.330)\tData 0.316 (0.285)\tLoss 1.9552 (1.5595)\tPrec@1 41.667 (57.015)\tPrec@5 83.333 (85.012)\n",
      "Epoch: [3][1300/1334]\t\\Time 0.306 (0.331)\tData 0.266 (0.286)\tLoss 0.6680 (1.5598)\tPrec@1 91.667 (56.899)\tPrec@5 100.000 (85.005)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.362 (0.362)\n",
      "\n",
      "Loss 1.1826 (1.1826)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.333 (0.356)\n",
      "\n",
      "Loss 1.1389 (1.7419)\n",
      "\n",
      "Prec@1 66.667 (54.785)\n",
      "\n",
      "Prec@5 91.667 (83.086)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.316 (0.354)\n",
      "\n",
      "Loss 1.3979 (1.6751)\n",
      "\n",
      "Prec@1 58.333 (55.556)\n",
      "\n",
      "Prec@5 91.667 (83.997)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.305 (0.353)\n",
      "\n",
      "Loss 2.9618 (1.6839)\n",
      "\n",
      "Prec@1 16.667 (55.316)\n",
      "\n",
      "Prec@5 66.667 (83.776)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [4][0/1334]\t\\Time 0.411 (0.411)\tData 0.272 (0.272)\tLoss 1.2115 (1.2115)\tPrec@1 58.333 (58.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [4][100/1334]\t\\Time 0.319 (0.331)\tData 0.281 (0.283)\tLoss 1.4598 (1.1753)\tPrec@1 75.000 (66.419)\tPrec@5 75.000 (90.759)\n",
      "Epoch: [4][200/1334]\t\\Time 0.519 (0.332)\tData 0.460 (0.286)\tLoss 0.9103 (1.2109)\tPrec@1 83.333 (66.294)\tPrec@5 83.333 (89.760)\n",
      "Epoch: [4][300/1334]\t\\Time 0.316 (0.330)\tData 0.276 (0.284)\tLoss 0.9690 (1.2205)\tPrec@1 58.333 (66.141)\tPrec@5 91.667 (89.673)\n",
      "Epoch: [4][400/1334]\t\\Time 0.332 (0.333)\tData 0.291 (0.287)\tLoss 1.0628 (1.2194)\tPrec@1 75.000 (65.544)\tPrec@5 100.000 (89.838)\n",
      "Epoch: [4][500/1334]\t\\Time 0.224 (0.334)\tData 0.180 (0.288)\tLoss 1.4329 (1.2332)\tPrec@1 58.333 (65.220)\tPrec@5 83.333 (89.587)\n",
      "Epoch: [4][600/1334]\t\\Time 0.354 (0.335)\tData 0.306 (0.289)\tLoss 1.4189 (1.2427)\tPrec@1 58.333 (64.947)\tPrec@5 91.667 (89.517)\n",
      "Epoch: [4][700/1334]\t\\Time 0.334 (0.336)\tData 0.285 (0.291)\tLoss 0.5664 (1.2559)\tPrec@1 91.667 (64.396)\tPrec@5 100.000 (89.503)\n",
      "Epoch: [4][800/1334]\t\\Time 0.327 (0.343)\tData 0.284 (0.296)\tLoss 1.2724 (1.2467)\tPrec@1 58.333 (64.576)\tPrec@5 100.000 (89.607)\n",
      "Epoch: [4][900/1334]\t\\Time 0.264 (0.344)\tData 0.217 (0.298)\tLoss 1.0027 (1.2533)\tPrec@1 83.333 (64.345)\tPrec@5 83.333 (89.604)\n",
      "Epoch: [4][1000/1334]\t\\Time 0.307 (0.342)\tData 0.261 (0.296)\tLoss 0.6777 (1.2681)\tPrec@1 91.667 (64.019)\tPrec@5 100.000 (89.411)\n",
      "Epoch: [4][1100/1334]\t\\Time 0.368 (0.343)\tData 0.323 (0.297)\tLoss 0.7303 (1.2731)\tPrec@1 75.000 (63.912)\tPrec@5 100.000 (89.282)\n",
      "Epoch: [4][1200/1334]\t\\Time 0.331 (0.345)\tData 0.286 (0.299)\tLoss 1.2979 (1.2836)\tPrec@1 66.667 (63.655)\tPrec@5 100.000 (89.224)\n",
      "Epoch: [4][1300/1334]\t\\Time 0.339 (0.344)\tData 0.295 (0.298)\tLoss 0.7145 (1.2925)\tPrec@1 75.000 (63.464)\tPrec@5 100.000 (89.111)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.538 (0.538)\n",
      "\n",
      "Loss 1.3642 (1.3642)\n",
      "\n",
      "Prec@1 50.000 (50.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.317 (0.336)\n",
      "\n",
      "Loss 1.1468 (1.7254)\n",
      "\n",
      "Prec@1 83.333 (54.620)\n",
      "\n",
      "Prec@5 83.333 (82.756)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.308 (0.330)\n",
      "\n",
      "Loss 1.1074 (1.7020)\n",
      "\n",
      "Prec@1 66.667 (55.307)\n",
      "\n",
      "Prec@5 91.667 (82.546)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.452 (0.332)\n",
      "\n",
      "Loss 2.4645 (1.7218)\n",
      "\n",
      "Prec@1 16.667 (54.568)\n",
      "\n",
      "Prec@5 75.000 (82.918)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [5][0/1334]\t\\Time 0.390 (0.390)\tData 0.262 (0.262)\tLoss 1.2893 (1.2893)\tPrec@1 66.667 (66.667)\tPrec@5 75.000 (75.000)\n",
      "Epoch: [5][100/1334]\t\\Time 0.469 (0.313)\tData 0.412 (0.267)\tLoss 0.6554 (0.9685)\tPrec@1 83.333 (71.205)\tPrec@5 91.667 (92.822)\n",
      "Epoch: [5][200/1334]\t\\Time 0.368 (0.323)\tData 0.318 (0.277)\tLoss 1.5417 (0.9752)\tPrec@1 58.333 (71.808)\tPrec@5 83.333 (92.703)\n",
      "Epoch: [5][300/1334]\t\\Time 0.265 (0.323)\tData 0.214 (0.276)\tLoss 1.2095 (1.0192)\tPrec@1 66.667 (70.515)\tPrec@5 100.000 (92.386)\n",
      "Epoch: [5][400/1334]\t\\Time 0.346 (0.335)\tData 0.303 (0.288)\tLoss 0.7977 (1.0331)\tPrec@1 75.000 (70.096)\tPrec@5 100.000 (92.249)\n",
      "Epoch: [5][500/1334]\t\\Time 0.349 (0.336)\tData 0.299 (0.290)\tLoss 0.9814 (1.0311)\tPrec@1 66.667 (70.110)\tPrec@5 91.667 (92.382)\n",
      "Epoch: [5][600/1334]\t\\Time 0.335 (0.339)\tData 0.290 (0.292)\tLoss 1.2322 (1.0360)\tPrec@1 66.667 (69.884)\tPrec@5 91.667 (92.402)\n",
      "Epoch: [5][700/1334]\t\\Time 0.324 (0.341)\tData 0.282 (0.294)\tLoss 2.3367 (1.0482)\tPrec@1 41.667 (69.484)\tPrec@5 66.667 (92.356)\n",
      "Epoch: [5][800/1334]\t\\Time 0.302 (0.342)\tData 0.258 (0.296)\tLoss 1.2449 (1.0547)\tPrec@1 58.333 (69.320)\tPrec@5 83.333 (92.187)\n",
      "Epoch: [5][900/1334]\t\\Time 0.297 (0.343)\tData 0.248 (0.296)\tLoss 1.0629 (1.0528)\tPrec@1 66.667 (69.571)\tPrec@5 83.333 (92.157)\n",
      "Epoch: [5][1000/1334]\t\\Time 0.300 (0.343)\tData 0.258 (0.297)\tLoss 1.1096 (1.0532)\tPrec@1 66.667 (69.464)\tPrec@5 83.333 (92.174)\n",
      "Epoch: [5][1100/1334]\t\\Time 0.361 (0.344)\tData 0.312 (0.298)\tLoss 1.2805 (1.0555)\tPrec@1 66.667 (69.444)\tPrec@5 91.667 (92.144)\n",
      "Epoch: [5][1200/1334]\t\\Time 0.440 (0.346)\tData 0.387 (0.299)\tLoss 1.2852 (1.0626)\tPrec@1 66.667 (69.234)\tPrec@5 83.333 (92.062)\n",
      "Epoch: [5][1300/1334]\t\\Time 0.392 (0.349)\tData 0.332 (0.302)\tLoss 1.6263 (1.0695)\tPrec@1 66.667 (69.203)\tPrec@5 83.333 (91.929)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.308 (0.308)\n",
      "\n",
      "Loss 1.6418 (1.6418)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.383 (0.347)\n",
      "\n",
      "Loss 0.8677 (1.6399)\n",
      "\n",
      "Prec@1 66.667 (56.683)\n",
      "\n",
      "Prec@5 100.000 (85.561)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.316 (0.354)\n",
      "\n",
      "Loss 1.7145 (1.6168)\n",
      "\n",
      "Prec@1 50.000 (57.836)\n",
      "\n",
      "Prec@5 83.333 (85.116)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.315 (0.352)\n",
      "\n",
      "Loss 2.2843 (1.6313)\n",
      "\n",
      "Prec@1 41.667 (57.060)\n",
      "\n",
      "Prec@5 83.333 (85.050)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [6][0/1334]\t\\Time 0.427 (0.427)\tData 0.308 (0.308)\tLoss 0.6864 (0.6864)\tPrec@1 83.333 (83.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [6][100/1334]\t\\Time 0.275 (0.330)\tData 0.233 (0.283)\tLoss 0.5438 (0.7988)\tPrec@1 91.667 (76.485)\tPrec@5 100.000 (95.050)\n",
      "Epoch: [6][200/1334]\t\\Time 0.286 (0.328)\tData 0.239 (0.282)\tLoss 0.7904 (0.8107)\tPrec@1 66.667 (75.788)\tPrec@5 100.000 (94.859)\n",
      "Epoch: [6][300/1334]\t\\Time 0.311 (0.332)\tData 0.270 (0.286)\tLoss 0.7321 (0.8227)\tPrec@1 66.667 (75.748)\tPrec@5 100.000 (94.878)\n",
      "Epoch: [6][400/1334]\t\\Time 0.356 (0.331)\tData 0.309 (0.284)\tLoss 1.0576 (0.8304)\tPrec@1 75.000 (75.145)\tPrec@5 83.333 (94.680)\n",
      "Epoch: [6][500/1334]\t\\Time 0.334 (0.341)\tData 0.282 (0.294)\tLoss 0.5724 (0.8350)\tPrec@1 83.333 (74.933)\tPrec@5 100.000 (94.578)\n",
      "Epoch: [6][600/1334]\t\\Time 0.392 (0.348)\tData 0.330 (0.301)\tLoss 0.6987 (0.8660)\tPrec@1 91.667 (74.237)\tPrec@5 91.667 (94.204)\n",
      "Epoch: [6][700/1334]\t\\Time 0.781 (0.353)\tData 0.714 (0.305)\tLoss 0.9709 (0.8741)\tPrec@1 75.000 (74.108)\tPrec@5 91.667 (94.080)\n",
      "Epoch: [6][800/1334]\t\\Time 0.253 (0.353)\tData 0.217 (0.306)\tLoss 1.0128 (0.8804)\tPrec@1 83.333 (74.095)\tPrec@5 91.667 (94.080)\n",
      "Epoch: [6][900/1334]\t\\Time 0.379 (0.353)\tData 0.329 (0.306)\tLoss 1.1277 (0.8876)\tPrec@1 83.333 (73.825)\tPrec@5 83.333 (94.016)\n",
      "Epoch: [6][1000/1334]\t\\Time 0.339 (0.352)\tData 0.282 (0.305)\tLoss 0.8742 (0.8952)\tPrec@1 83.333 (73.668)\tPrec@5 91.667 (93.973)\n",
      "Epoch: [6][1100/1334]\t\\Time 0.277 (0.353)\tData 0.235 (0.306)\tLoss 0.7246 (0.9006)\tPrec@1 83.333 (73.486)\tPrec@5 100.000 (94.005)\n",
      "Epoch: [6][1200/1334]\t\\Time 0.269 (0.354)\tData 0.225 (0.307)\tLoss 0.7724 (0.8997)\tPrec@1 66.667 (73.605)\tPrec@5 100.000 (93.949)\n",
      "Epoch: [6][1300/1334]\t\\Time 0.341 (0.353)\tData 0.296 (0.305)\tLoss 1.2462 (0.9089)\tPrec@1 50.000 (73.418)\tPrec@5 91.667 (93.851)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.312 (0.312)\n",
      "\n",
      "Loss 1.1624 (1.1624)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.310 (0.399)\n",
      "\n",
      "Loss 0.8796 (1.7356)\n",
      "\n",
      "Prec@1 75.000 (57.013)\n",
      "\n",
      "Prec@5 100.000 (83.663)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.349 (0.387)\n",
      "\n",
      "Loss 1.0861 (1.6941)\n",
      "\n",
      "Prec@1 66.667 (57.919)\n",
      "\n",
      "Prec@5 91.667 (84.080)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.332 (0.378)\n",
      "\n",
      "Loss 2.3504 (1.6633)\n",
      "\n",
      "Prec@1 41.667 (58.499)\n",
      "\n",
      "Prec@5 75.000 (84.635)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [7][0/1334]\t\\Time 0.395 (0.395)\tData 0.296 (0.296)\tLoss 0.5570 (0.5570)\tPrec@1 75.000 (75.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [7][100/1334]\t\\Time 0.480 (0.361)\tData 0.434 (0.314)\tLoss 0.4435 (0.6451)\tPrec@1 83.333 (81.683)\tPrec@5 91.667 (96.782)\n",
      "Epoch: [7][200/1334]\t\\Time 0.412 (0.382)\tData 0.369 (0.333)\tLoss 0.9916 (0.6812)\tPrec@1 75.000 (80.265)\tPrec@5 83.333 (96.393)\n",
      "Epoch: [7][300/1334]\t\\Time 0.283 (0.375)\tData 0.237 (0.326)\tLoss 0.7625 (0.6766)\tPrec@1 66.667 (80.149)\tPrec@5 91.667 (96.539)\n",
      "Epoch: [7][400/1334]\t\\Time 0.356 (0.367)\tData 0.308 (0.319)\tLoss 1.7386 (0.6847)\tPrec@1 58.333 (80.008)\tPrec@5 91.667 (96.467)\n",
      "Epoch: [7][500/1334]\t\\Time 0.265 (0.362)\tData 0.222 (0.314)\tLoss 0.3879 (0.7000)\tPrec@1 91.667 (79.541)\tPrec@5 100.000 (96.374)\n",
      "Epoch: [7][600/1334]\t\\Time 0.403 (0.357)\tData 0.360 (0.309)\tLoss 0.2545 (0.7139)\tPrec@1 91.667 (79.007)\tPrec@5 100.000 (96.201)\n",
      "Epoch: [7][700/1334]\t\\Time 0.378 (0.353)\tData 0.327 (0.306)\tLoss 0.8097 (0.7215)\tPrec@1 75.000 (78.721)\tPrec@5 91.667 (96.101)\n",
      "Epoch: [7][800/1334]\t\\Time 0.366 (0.352)\tData 0.326 (0.305)\tLoss 0.9571 (0.7275)\tPrec@1 75.000 (78.589)\tPrec@5 91.667 (96.099)\n",
      "Epoch: [7][900/1334]\t\\Time 0.419 (0.350)\tData 0.388 (0.304)\tLoss 0.5046 (0.7345)\tPrec@1 83.333 (78.367)\tPrec@5 100.000 (95.940)\n",
      "Epoch: [7][1000/1334]\t\\Time 0.325 (0.348)\tData 0.281 (0.301)\tLoss 0.7591 (0.7452)\tPrec@1 66.667 (78.180)\tPrec@5 100.000 (95.804)\n",
      "Epoch: [7][1100/1334]\t\\Time 0.403 (0.347)\tData 0.360 (0.300)\tLoss 1.2454 (0.7560)\tPrec@1 75.000 (77.846)\tPrec@5 83.333 (95.610)\n",
      "Epoch: [7][1200/1334]\t\\Time 0.277 (0.345)\tData 0.232 (0.299)\tLoss 0.3746 (0.7636)\tPrec@1 100.000 (77.526)\tPrec@5 100.000 (95.545)\n",
      "Epoch: [7][1300/1334]\t\\Time 0.331 (0.344)\tData 0.299 (0.298)\tLoss 0.5880 (0.7664)\tPrec@1 91.667 (77.453)\tPrec@5 100.000 (95.484)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.337 (0.337)\n",
      "\n",
      "Loss 1.2209 (1.2209)\n",
      "\n",
      "Prec@1 58.333 (58.333)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.318 (0.342)\n",
      "\n",
      "Loss 1.3071 (1.9642)\n",
      "\n",
      "Prec@1 66.667 (54.043)\n",
      "\n",
      "Prec@5 91.667 (82.591)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.313 (0.344)\n",
      "\n",
      "Loss 1.9990 (1.9616)\n",
      "\n",
      "Prec@1 75.000 (53.939)\n",
      "\n",
      "Prec@5 83.333 (82.297)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.307 (0.344)\n",
      "\n",
      "Loss 3.1624 (1.9620)\n",
      "\n",
      "Prec@1 25.000 (53.682)\n",
      "\n",
      "Prec@5 75.000 (82.004)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [8][0/1334]\t\\Time 0.377 (0.377)\tData 0.281 (0.281)\tLoss 0.6863 (0.6863)\tPrec@1 83.333 (83.333)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [8][100/1334]\t\\Time 0.323 (0.320)\tData 0.276 (0.276)\tLoss 0.1014 (0.5610)\tPrec@1 100.000 (83.911)\tPrec@5 100.000 (97.607)\n",
      "Epoch: [8][200/1334]\t\\Time 0.290 (0.320)\tData 0.248 (0.276)\tLoss 0.2708 (0.5665)\tPrec@1 83.333 (83.085)\tPrec@5 100.000 (97.678)\n",
      "Epoch: [8][300/1334]\t\\Time 0.262 (0.321)\tData 0.221 (0.276)\tLoss 0.3230 (0.5756)\tPrec@1 91.667 (82.780)\tPrec@5 100.000 (97.591)\n",
      "Epoch: [8][400/1334]\t\\Time 0.264 (0.320)\tData 0.221 (0.276)\tLoss 0.3107 (0.5887)\tPrec@1 100.000 (82.502)\tPrec@5 100.000 (97.485)\n",
      "Epoch: [8][500/1334]\t\\Time 0.300 (0.323)\tData 0.262 (0.278)\tLoss 0.4568 (0.5967)\tPrec@1 91.667 (82.319)\tPrec@5 100.000 (97.455)\n",
      "Epoch: [8][600/1334]\t\\Time 0.286 (0.323)\tData 0.239 (0.278)\tLoss 1.1934 (0.5990)\tPrec@1 75.000 (82.155)\tPrec@5 91.667 (97.407)\n",
      "Epoch: [8][700/1334]\t\\Time 0.383 (0.324)\tData 0.335 (0.279)\tLoss 1.1074 (0.6088)\tPrec@1 58.333 (81.645)\tPrec@5 100.000 (97.373)\n",
      "Epoch: [8][800/1334]\t\\Time 0.275 (0.324)\tData 0.229 (0.280)\tLoss 1.5516 (0.6160)\tPrec@1 66.667 (81.492)\tPrec@5 91.667 (97.326)\n",
      "Epoch: [8][900/1334]\t\\Time 0.289 (0.325)\tData 0.237 (0.280)\tLoss 1.1376 (0.6182)\tPrec@1 66.667 (81.391)\tPrec@5 83.333 (97.253)\n",
      "Epoch: [8][1000/1334]\t\\Time 0.296 (0.325)\tData 0.249 (0.280)\tLoss 0.3337 (0.6245)\tPrec@1 91.667 (81.227)\tPrec@5 100.000 (97.136)\n",
      "Epoch: [8][1100/1334]\t\\Time 0.361 (0.326)\tData 0.303 (0.281)\tLoss 1.0249 (0.6342)\tPrec@1 58.333 (80.904)\tPrec@5 100.000 (97.071)\n",
      "Epoch: [8][1200/1334]\t\\Time 0.341 (0.326)\tData 0.294 (0.281)\tLoss 0.1899 (0.6460)\tPrec@1 100.000 (80.655)\tPrec@5 100.000 (96.933)\n",
      "Epoch: [8][1300/1334]\t\\Time 0.405 (0.326)\tData 0.363 (0.282)\tLoss 0.7941 (0.6547)\tPrec@1 75.000 (80.387)\tPrec@5 91.667 (96.836)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.330 (0.330)\n",
      "\n",
      "Loss 1.4520 (1.4520)\n",
      "\n",
      "Prec@1 66.667 (66.667)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.340 (0.342)\n",
      "\n",
      "Loss 0.8360 (1.8043)\n",
      "\n",
      "Prec@1 66.667 (57.261)\n",
      "\n",
      "Prec@5 91.667 (84.571)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.320 (0.345)\n",
      "\n",
      "Loss 2.7174 (1.7942)\n",
      "\n",
      "Prec@1 41.667 (57.960)\n",
      "\n",
      "Prec@5 75.000 (85.033)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.311 (0.345)\n",
      "\n",
      "Loss 2.3136 (1.8001)\n",
      "\n",
      "Prec@1 41.667 (57.475)\n",
      "\n",
      "Prec@5 75.000 (84.939)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.010000\n",
      "Epoch: [9][0/1334]\t\\Time 0.382 (0.382)\tData 0.274 (0.274)\tLoss 0.3374 (0.3374)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [9][100/1334]\t\\Time 0.284 (0.316)\tData 0.247 (0.272)\tLoss 0.2476 (0.4771)\tPrec@1 100.000 (85.396)\tPrec@5 100.000 (98.185)\n",
      "Epoch: [9][200/1334]\t\\Time 0.361 (0.320)\tData 0.318 (0.276)\tLoss 0.1937 (0.4869)\tPrec@1 100.000 (85.075)\tPrec@5 100.000 (97.927)\n",
      "Epoch: [9][300/1334]\t\\Time 0.342 (0.324)\tData 0.298 (0.279)\tLoss 0.2537 (0.4919)\tPrec@1 91.667 (85.188)\tPrec@5 100.000 (98.117)\n",
      "Epoch: [9][400/1334]\t\\Time 0.278 (0.322)\tData 0.232 (0.278)\tLoss 0.1554 (0.5024)\tPrec@1 91.667 (84.809)\tPrec@5 100.000 (98.192)\n",
      "Epoch: [9][500/1334]\t\\Time 0.269 (0.324)\tData 0.223 (0.279)\tLoss 0.7307 (0.5044)\tPrec@1 75.000 (84.631)\tPrec@5 100.000 (98.220)\n",
      "Epoch: [9][600/1334]\t\\Time 0.325 (0.325)\tData 0.280 (0.280)\tLoss 1.0222 (0.5249)\tPrec@1 66.667 (83.902)\tPrec@5 100.000 (98.045)\n",
      "Epoch: [9][700/1334]\t\\Time 0.367 (0.325)\tData 0.319 (0.280)\tLoss 0.4315 (0.5257)\tPrec@1 83.333 (83.821)\tPrec@5 100.000 (98.050)\n",
      "Epoch: [9][800/1334]\t\\Time 0.430 (0.326)\tData 0.385 (0.281)\tLoss 0.8905 (0.5343)\tPrec@1 75.000 (83.541)\tPrec@5 91.667 (97.940)\n",
      "Epoch: [9][900/1334]\t\\Time 0.185 (0.326)\tData 0.124 (0.282)\tLoss 0.5256 (0.5417)\tPrec@1 83.333 (83.361)\tPrec@5 100.000 (97.863)\n",
      "Epoch: [9][1000/1334]\t\\Time 0.370 (0.327)\tData 0.326 (0.282)\tLoss 0.7298 (0.5425)\tPrec@1 83.333 (83.450)\tPrec@5 100.000 (97.869)\n",
      "Epoch: [9][1100/1334]\t\\Time 0.261 (0.327)\tData 0.221 (0.282)\tLoss 0.1837 (0.5418)\tPrec@1 100.000 (83.507)\tPrec@5 100.000 (97.843)\n",
      "Epoch: [9][1200/1334]\t\\Time 0.319 (0.329)\tData 0.276 (0.284)\tLoss 0.7483 (0.5532)\tPrec@1 75.000 (83.146)\tPrec@5 100.000 (97.766)\n",
      "Epoch: [9][1300/1334]\t\\Time 0.304 (0.329)\tData 0.262 (0.284)\tLoss 0.8185 (0.5650)\tPrec@1 75.000 (82.834)\tPrec@5 91.667 (97.675)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.323 (0.323)\n",
      "\n",
      "Loss 0.7485 (0.7485)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.334 (0.342)\n",
      "\n",
      "Loss 1.4373 (1.4868)\n",
      "\n",
      "Prec@1 66.667 (62.706)\n",
      "\n",
      "Prec@5 91.667 (87.211)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.324 (0.345)\n",
      "\n",
      "Loss 1.4013 (1.5037)\n",
      "\n",
      "Prec@1 66.667 (62.852)\n",
      "\n",
      "Prec@5 83.333 (86.899)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.335 (0.344)\n",
      "\n",
      "Loss 1.7413 (1.5229)\n",
      "\n",
      "Prec@1 50.000 (62.625)\n",
      "\n",
      "Prec@5 91.667 (86.656)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 10)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "=> loading checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 10)\n",
      "Epoch: [10][0/1334]\t\\Time 0.379 (0.379)\tData 0.280 (0.280)\tLoss 0.6634 (0.6634)\tPrec@1 83.333 (83.333)\tPrec@5 91.667 (91.667)\n",
      "Epoch: [10][100/1334]\t\\Time 0.376 (0.321)\tData 0.335 (0.277)\tLoss 0.0550 (0.3100)\tPrec@1 100.000 (91.172)\tPrec@5 100.000 (99.340)\n",
      "Epoch: [10][200/1334]\t\\Time 0.270 (0.327)\tData 0.228 (0.283)\tLoss 0.0678 (0.2877)\tPrec@1 100.000 (91.915)\tPrec@5 100.000 (99.378)\n",
      "Epoch: [10][300/1334]\t\\Time 0.268 (0.326)\tData 0.219 (0.281)\tLoss 0.0309 (0.2561)\tPrec@1 100.000 (93.300)\tPrec@5 100.000 (99.474)\n",
      "Epoch: [10][400/1334]\t\\Time 0.317 (0.330)\tData 0.272 (0.285)\tLoss 0.1622 (0.2355)\tPrec@1 100.000 (93.890)\tPrec@5 100.000 (99.584)\n",
      "Epoch: [10][500/1334]\t\\Time 0.336 (0.329)\tData 0.285 (0.284)\tLoss 0.0597 (0.2241)\tPrec@1 100.000 (94.095)\tPrec@5 100.000 (99.651)\n",
      "Epoch: [10][600/1334]\t\\Time 0.304 (0.330)\tData 0.258 (0.285)\tLoss 0.2223 (0.2128)\tPrec@1 91.667 (94.370)\tPrec@5 100.000 (99.681)\n",
      "Epoch: [10][700/1334]\t\\Time 0.351 (0.330)\tData 0.312 (0.285)\tLoss 0.1475 (0.2036)\tPrec@1 91.667 (94.627)\tPrec@5 100.000 (99.679)\n",
      "Epoch: [10][800/1334]\t\\Time 0.371 (0.333)\tData 0.322 (0.288)\tLoss 0.2630 (0.1992)\tPrec@1 91.667 (94.705)\tPrec@5 100.000 (99.667)\n",
      "Epoch: [10][900/1334]\t\\Time 0.344 (0.339)\tData 0.297 (0.293)\tLoss 0.0195 (0.1942)\tPrec@1 100.000 (94.784)\tPrec@5 100.000 (99.695)\n",
      "Epoch: [10][1000/1334]\t\\Time 0.240 (0.339)\tData 0.192 (0.293)\tLoss 0.0321 (0.1886)\tPrec@1 100.000 (94.913)\tPrec@5 100.000 (99.700)\n",
      "Epoch: [10][1100/1334]\t\\Time 0.329 (0.339)\tData 0.284 (0.293)\tLoss 0.0596 (0.1822)\tPrec@1 100.000 (95.080)\tPrec@5 100.000 (99.720)\n",
      "Epoch: [10][1200/1334]\t\\Time 0.410 (0.339)\tData 0.348 (0.293)\tLoss 0.0485 (0.1782)\tPrec@1 100.000 (95.185)\tPrec@5 100.000 (99.709)\n",
      "Epoch: [10][1300/1334]\t\\Time 0.398 (0.341)\tData 0.352 (0.295)\tLoss 0.0007 (0.1732)\tPrec@1 100.000 (95.292)\tPrec@5 100.000 (99.731)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.339 (0.339)\n",
      "\n",
      "Loss 0.8084 (0.8084)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.314 (0.346)\n",
      "\n",
      "Loss 0.9684 (1.3797)\n",
      "\n",
      "Prec@1 75.000 (68.812)\n",
      "\n",
      "Prec@5 100.000 (89.934)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.332 (0.348)\n",
      "\n",
      "Loss 1.2005 (1.4017)\n",
      "\n",
      "Prec@1 75.000 (69.569)\n",
      "\n",
      "Prec@5 91.667 (89.428)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.313 (0.346)\n",
      "\n",
      "Loss 2.4758 (1.4163)\n",
      "\n",
      "Prec@1 66.667 (69.075)\n",
      "\n",
      "Prec@5 75.000 (89.646)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [11][0/1334]\t\\Time 0.484 (0.484)\tData 0.350 (0.350)\tLoss 0.0607 (0.0607)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [11][100/1334]\t\\Time 0.264 (0.328)\tData 0.217 (0.282)\tLoss 0.0451 (0.0856)\tPrec@1 100.000 (97.525)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [11][200/1334]\t\\Time 0.385 (0.332)\tData 0.340 (0.285)\tLoss 0.0236 (0.0808)\tPrec@1 100.000 (97.968)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [11][300/1334]\t\\Time 0.354 (0.336)\tData 0.314 (0.289)\tLoss 0.0485 (0.0815)\tPrec@1 100.000 (97.868)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [11][400/1334]\t\\Time 0.427 (0.332)\tData 0.373 (0.286)\tLoss 0.0240 (0.0787)\tPrec@1 100.000 (97.943)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [11][500/1334]\t\\Time 0.318 (0.335)\tData 0.276 (0.289)\tLoss 0.0038 (0.0788)\tPrec@1 100.000 (97.971)\tPrec@5 100.000 (99.967)\n",
      "Epoch: [11][600/1334]\t\\Time 0.354 (0.338)\tData 0.309 (0.292)\tLoss 0.3788 (0.0771)\tPrec@1 91.667 (98.087)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [11][700/1334]\t\\Time 0.349 (0.338)\tData 0.302 (0.292)\tLoss 0.1945 (0.0769)\tPrec@1 91.667 (98.098)\tPrec@5 100.000 (99.941)\n",
      "Epoch: [11][800/1334]\t\\Time 0.291 (0.337)\tData 0.246 (0.291)\tLoss 0.0237 (0.0761)\tPrec@1 100.000 (98.075)\tPrec@5 100.000 (99.948)\n",
      "Epoch: [11][900/1334]\t\\Time 0.343 (0.337)\tData 0.297 (0.291)\tLoss 0.0045 (0.0752)\tPrec@1 100.000 (98.048)\tPrec@5 100.000 (99.954)\n",
      "Epoch: [11][1000/1334]\t\\Time 0.359 (0.336)\tData 0.312 (0.290)\tLoss 0.3187 (0.0728)\tPrec@1 75.000 (98.135)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [11][1100/1334]\t\\Time 0.371 (0.336)\tData 0.325 (0.290)\tLoss 0.4461 (0.0724)\tPrec@1 83.333 (98.138)\tPrec@5 100.000 (99.962)\n",
      "Epoch: [11][1200/1334]\t\\Time 0.298 (0.335)\tData 0.250 (0.290)\tLoss 0.0914 (0.0715)\tPrec@1 91.667 (98.154)\tPrec@5 100.000 (99.958)\n",
      "Epoch: [11][1300/1334]\t\\Time 0.260 (0.335)\tData 0.218 (0.289)\tLoss 0.0468 (0.0708)\tPrec@1 100.000 (98.181)\tPrec@5 100.000 (99.955)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.345 (0.345)\n",
      "\n",
      "Loss 0.7669 (0.7669)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.349 (0.349)\n",
      "\n",
      "Loss 0.5584 (1.4939)\n",
      "\n",
      "Prec@1 83.333 (69.719)\n",
      "\n",
      "Prec@5 100.000 (90.264)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.328 (0.348)\n",
      "\n",
      "Loss 1.3124 (1.5199)\n",
      "\n",
      "Prec@1 66.667 (70.398)\n",
      "\n",
      "Prec@5 91.667 (89.925)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.300 (0.347)\n",
      "\n",
      "Loss 2.7147 (1.5228)\n",
      "\n",
      "Prec@1 66.667 (70.044)\n",
      "\n",
      "Prec@5 75.000 (89.867)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [12][0/1334]\t\\Time 0.408 (0.408)\tData 0.283 (0.283)\tLoss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [12][100/1334]\t\\Time 0.243 (0.316)\tData 0.202 (0.271)\tLoss 0.0172 (0.0404)\tPrec@1 100.000 (99.092)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [12][200/1334]\t\\Time 0.318 (0.319)\tData 0.276 (0.274)\tLoss 0.0005 (0.0478)\tPrec@1 100.000 (98.673)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [12][300/1334]\t\\Time 0.380 (0.321)\tData 0.336 (0.276)\tLoss 0.0187 (0.0457)\tPrec@1 100.000 (98.699)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [12][400/1334]\t\\Time 0.366 (0.323)\tData 0.324 (0.279)\tLoss 0.0094 (0.0476)\tPrec@1 100.000 (98.608)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [12][500/1334]\t\\Time 0.241 (0.324)\tData 0.197 (0.280)\tLoss 0.0057 (0.0494)\tPrec@1 100.000 (98.586)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [12][600/1334]\t\\Time 0.306 (0.325)\tData 0.262 (0.280)\tLoss 0.0211 (0.0468)\tPrec@1 100.000 (98.710)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [12][700/1334]\t\\Time 0.359 (0.325)\tData 0.310 (0.281)\tLoss 0.0004 (0.0455)\tPrec@1 100.000 (98.811)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [12][800/1334]\t\\Time 0.323 (0.325)\tData 0.275 (0.280)\tLoss 0.0043 (0.0455)\tPrec@1 100.000 (98.835)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [12][900/1334]\t\\Time 0.356 (0.324)\tData 0.300 (0.279)\tLoss 0.0064 (0.0450)\tPrec@1 100.000 (98.899)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [12][1000/1334]\t\\Time 0.370 (0.324)\tData 0.327 (0.279)\tLoss 0.0270 (0.0441)\tPrec@1 100.000 (98.901)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [12][1100/1334]\t\\Time 0.382 (0.325)\tData 0.328 (0.280)\tLoss 0.1111 (0.0450)\tPrec@1 100.000 (98.827)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [12][1200/1334]\t\\Time 0.336 (0.326)\tData 0.291 (0.281)\tLoss 0.0101 (0.0445)\tPrec@1 100.000 (98.841)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [12][1300/1334]\t\\Time 0.291 (0.327)\tData 0.253 (0.282)\tLoss 0.0022 (0.0444)\tPrec@1 100.000 (98.834)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.328 (0.328)\n",
      "\n",
      "Loss 0.7480 (0.7480)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.340 (0.345)\n",
      "\n",
      "Loss 0.5797 (1.5758)\n",
      "\n",
      "Prec@1 83.333 (69.389)\n",
      "\n",
      "Prec@5 100.000 (90.182)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.317 (0.348)\n",
      "\n",
      "Loss 1.5125 (1.6043)\n",
      "\n",
      "Prec@1 66.667 (69.776)\n",
      "\n",
      "Prec@5 91.667 (90.008)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.292 (0.345)\n",
      "\n",
      "Loss 2.6912 (1.6135)\n",
      "\n",
      "Prec@1 66.667 (69.546)\n",
      "\n",
      "Prec@5 75.000 (89.950)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [13][0/1334]\t\\Time 0.294 (0.294)\tData 0.187 (0.187)\tLoss 0.0079 (0.0079)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][100/1334]\t\\Time 0.365 (0.323)\tData 0.317 (0.279)\tLoss 0.0949 (0.0401)\tPrec@1 91.667 (99.092)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][200/1334]\t\\Time 0.348 (0.324)\tData 0.294 (0.279)\tLoss 0.1654 (0.0428)\tPrec@1 91.667 (98.881)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][300/1334]\t\\Time 0.341 (0.328)\tData 0.295 (0.283)\tLoss 0.0033 (0.0390)\tPrec@1 100.000 (99.031)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][400/1334]\t\\Time 0.333 (0.327)\tData 0.293 (0.282)\tLoss 0.0034 (0.0350)\tPrec@1 100.000 (99.169)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][500/1334]\t\\Time 0.326 (0.327)\tData 0.283 (0.282)\tLoss 0.0299 (0.0346)\tPrec@1 100.000 (99.218)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][600/1334]\t\\Time 0.355 (0.327)\tData 0.313 (0.283)\tLoss 0.0655 (0.0333)\tPrec@1 100.000 (99.279)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][700/1334]\t\\Time 0.329 (0.328)\tData 0.287 (0.283)\tLoss 0.0336 (0.0329)\tPrec@1 100.000 (99.299)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][800/1334]\t\\Time 0.251 (0.329)\tData 0.206 (0.284)\tLoss 0.0147 (0.0320)\tPrec@1 100.000 (99.313)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][900/1334]\t\\Time 0.377 (0.329)\tData 0.329 (0.284)\tLoss 0.0023 (0.0326)\tPrec@1 100.000 (99.242)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [13][1000/1334]\t\\Time 0.340 (0.329)\tData 0.305 (0.284)\tLoss 0.0695 (0.0334)\tPrec@1 100.000 (99.251)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [13][1100/1334]\t\\Time 0.357 (0.329)\tData 0.315 (0.285)\tLoss 0.0849 (0.0337)\tPrec@1 100.000 (99.228)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [13][1200/1334]\t\\Time 0.415 (0.330)\tData 0.365 (0.285)\tLoss 0.0056 (0.0328)\tPrec@1 100.000 (99.271)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [13][1300/1334]\t\\Time 0.340 (0.329)\tData 0.295 (0.284)\tLoss 0.0134 (0.0327)\tPrec@1 100.000 (99.251)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.321 (0.321)\n",
      "\n",
      "Loss 0.8277 (0.8277)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.334 (0.343)\n",
      "\n",
      "Loss 1.0706 (1.5961)\n",
      "\n",
      "Prec@1 75.000 (69.389)\n",
      "\n",
      "Prec@5 100.000 (89.851)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.319 (0.344)\n",
      "\n",
      "Loss 1.1484 (1.6057)\n",
      "\n",
      "Prec@1 66.667 (69.942)\n",
      "\n",
      "Prec@5 91.667 (90.091)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.270 (0.341)\n",
      "\n",
      "Loss 2.6234 (1.6191)\n",
      "\n",
      "Prec@1 66.667 (70.044)\n",
      "\n",
      "Prec@5 75.000 (90.144)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.001000\n",
      "Epoch: [14][0/1334]\t\\Time 0.439 (0.439)\tData 0.338 (0.338)\tLoss 0.0025 (0.0025)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][100/1334]\t\\Time 0.236 (0.313)\tData 0.197 (0.268)\tLoss 0.0055 (0.0291)\tPrec@1 100.000 (99.092)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][200/1334]\t\\Time 0.309 (0.320)\tData 0.262 (0.275)\tLoss 0.0394 (0.0292)\tPrec@1 100.000 (99.254)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][300/1334]\t\\Time 0.322 (0.317)\tData 0.285 (0.273)\tLoss 0.0079 (0.0286)\tPrec@1 100.000 (99.308)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][400/1334]\t\\Time 0.388 (0.318)\tData 0.346 (0.273)\tLoss 0.0188 (0.0266)\tPrec@1 100.000 (99.397)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][500/1334]\t\\Time 0.337 (0.318)\tData 0.293 (0.274)\tLoss 0.0269 (0.0266)\tPrec@1 100.000 (99.318)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][600/1334]\t\\Time 0.317 (0.320)\tData 0.266 (0.276)\tLoss 0.0198 (0.0257)\tPrec@1 100.000 (99.390)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][700/1334]\t\\Time 0.352 (0.322)\tData 0.307 (0.278)\tLoss 0.0115 (0.0255)\tPrec@1 100.000 (99.406)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][800/1334]\t\\Time 0.360 (0.322)\tData 0.327 (0.278)\tLoss 0.0175 (0.0246)\tPrec@1 100.000 (99.438)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][900/1334]\t\\Time 0.384 (0.322)\tData 0.339 (0.278)\tLoss 0.0366 (0.0249)\tPrec@1 100.000 (99.427)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1000/1334]\t\\Time 0.320 (0.323)\tData 0.278 (0.279)\tLoss 0.1246 (0.0247)\tPrec@1 91.667 (99.434)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1100/1334]\t\\Time 0.309 (0.324)\tData 0.268 (0.280)\tLoss 0.0069 (0.0246)\tPrec@1 100.000 (99.455)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1200/1334]\t\\Time 0.425 (0.324)\tData 0.379 (0.280)\tLoss 0.0051 (0.0245)\tPrec@1 100.000 (99.445)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [14][1300/1334]\t\\Time 0.369 (0.324)\tData 0.325 (0.280)\tLoss 0.0288 (0.0243)\tPrec@1 100.000 (99.462)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.315 (0.315)\n",
      "\n",
      "Loss 0.7486 (0.7486)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 100.000 (100.000)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.326 (0.337)\n",
      "\n",
      "Loss 0.9233 (1.6452)\n",
      "\n",
      "Prec@1 75.000 (69.637)\n",
      "\n",
      "Prec@5 100.000 (89.604)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.321 (0.342)\n",
      "\n",
      "Loss 1.4418 (1.6502)\n",
      "\n",
      "Prec@1 66.667 (70.066)\n",
      "\n",
      "Prec@5 91.667 (89.345)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.294 (0.339)\n",
      "\n",
      "Loss 2.5161 (1.6544)\n",
      "\n",
      "Prec@1 75.000 (70.432)\n",
      "\n",
      "Prec@5 75.000 (89.480)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "=> loading checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_checkpoint.pth.tar' (epoch 15)\n",
      "\n",
      "[INFO] Training Started\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "=> loading checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar'\n",
      "=> loaded checkpoint 'saved_models/resnet152_v3_100targets_weights_seed1711_split8020_attempt2_model_best.pth.tar' (epoch 15)\n",
      "Epoch: [15][0/1334]\t\\Time 0.366 (0.366)\tData 0.254 (0.254)\tLoss 0.0212 (0.0212)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][100/1334]\t\\Time 0.341 (0.314)\tData 0.291 (0.270)\tLoss 0.0224 (0.0261)\tPrec@1 100.000 (99.340)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][200/1334]\t\\Time 0.356 (0.316)\tData 0.316 (0.272)\tLoss 0.0011 (0.0216)\tPrec@1 100.000 (99.420)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][300/1334]\t\\Time 0.283 (0.317)\tData 0.239 (0.273)\tLoss 0.0502 (0.0211)\tPrec@1 100.000 (99.474)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][400/1334]\t\\Time 0.396 (0.319)\tData 0.353 (0.275)\tLoss 0.0015 (0.0202)\tPrec@1 100.000 (99.543)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][500/1334]\t\\Time 0.269 (0.320)\tData 0.225 (0.276)\tLoss 0.0166 (0.0203)\tPrec@1 100.000 (99.518)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][600/1334]\t\\Time 0.273 (0.322)\tData 0.230 (0.278)\tLoss 0.0009 (0.0209)\tPrec@1 100.000 (99.529)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][700/1334]\t\\Time 0.306 (0.324)\tData 0.260 (0.279)\tLoss 0.0020 (0.0206)\tPrec@1 100.000 (99.548)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][800/1334]\t\\Time 0.300 (0.324)\tData 0.259 (0.279)\tLoss 0.0097 (0.0206)\tPrec@1 100.000 (99.573)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][900/1334]\t\\Time 0.363 (0.324)\tData 0.321 (0.279)\tLoss 0.0005 (0.0207)\tPrec@1 100.000 (99.565)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1000/1334]\t\\Time 0.360 (0.325)\tData 0.315 (0.280)\tLoss 0.0052 (0.0202)\tPrec@1 100.000 (99.584)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1100/1334]\t\\Time 0.321 (0.325)\tData 0.276 (0.280)\tLoss 0.0224 (0.0202)\tPrec@1 100.000 (99.599)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1200/1334]\t\\Time 0.272 (0.325)\tData 0.229 (0.280)\tLoss 0.0065 (0.0195)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [15][1300/1334]\t\\Time 0.346 (0.326)\tData 0.302 (0.281)\tLoss 0.0000 (0.0194)\tPrec@1 100.000 (99.628)\tPrec@5 100.000 (100.000)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.329 (0.329)\n",
      "\n",
      "Loss 0.7611 (0.7611)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.332 (0.340)\n",
      "\n",
      "Loss 0.9536 (1.6272)\n",
      "\n",
      "Prec@1 75.000 (69.637)\n",
      "\n",
      "Prec@5 100.000 (89.521)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.325 (0.342)\n",
      "\n",
      "Loss 1.3159 (1.6292)\n",
      "\n",
      "Prec@1 66.667 (70.481)\n",
      "\n",
      "Prec@5 91.667 (89.677)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.291 (0.338)\n",
      "\n",
      "Loss 2.8145 (1.6388)\n",
      "\n",
      "Prec@1 66.667 (70.432)\n",
      "\n",
      "Prec@5 75.000 (89.535)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to model_best.pth.tar\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n",
      "\n",
      "[Learning Rate] 0.000100\n",
      "Epoch: [16][0/1334]\t\\Time 0.380 (0.380)\tData 0.265 (0.265)\tLoss 0.0013 (0.0013)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
      "Epoch: [16][100/1334]\t\\Time 0.299 (0.320)\tData 0.258 (0.275)\tLoss 0.0055 (0.0164)\tPrec@1 100.000 (99.835)\tPrec@5 100.000 (99.917)\n",
      "Epoch: [16][200/1334]\t\\Time 0.279 (0.321)\tData 0.242 (0.277)\tLoss 0.0040 (0.0189)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.959)\n",
      "Epoch: [16][300/1334]\t\\Time 0.367 (0.321)\tData 0.322 (0.277)\tLoss 0.0026 (0.0184)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.972)\n",
      "Epoch: [16][400/1334]\t\\Time 0.336 (0.323)\tData 0.302 (0.279)\tLoss 0.0062 (0.0174)\tPrec@1 100.000 (99.751)\tPrec@5 100.000 (99.979)\n",
      "Epoch: [16][500/1334]\t\\Time 0.369 (0.323)\tData 0.317 (0.278)\tLoss 0.0067 (0.0177)\tPrec@1 100.000 (99.734)\tPrec@5 100.000 (99.983)\n",
      "Epoch: [16][600/1334]\t\\Time 0.306 (0.324)\tData 0.256 (0.280)\tLoss 0.0124 (0.0174)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (99.986)\n",
      "Epoch: [16][700/1334]\t\\Time 0.330 (0.325)\tData 0.283 (0.280)\tLoss 0.0137 (0.0180)\tPrec@1 100.000 (99.703)\tPrec@5 100.000 (99.988)\n",
      "Epoch: [16][800/1334]\t\\Time 0.325 (0.324)\tData 0.274 (0.280)\tLoss 0.0039 (0.0174)\tPrec@1 100.000 (99.730)\tPrec@5 100.000 (99.990)\n",
      "Epoch: [16][900/1334]\t\\Time 0.313 (0.325)\tData 0.268 (0.280)\tLoss 0.0073 (0.0172)\tPrec@1 100.000 (99.732)\tPrec@5 100.000 (99.991)\n",
      "Epoch: [16][1000/1334]\t\\Time 0.326 (0.326)\tData 0.286 (0.281)\tLoss 0.0035 (0.0169)\tPrec@1 100.000 (99.734)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [16][1100/1334]\t\\Time 0.328 (0.326)\tData 0.286 (0.281)\tLoss 0.0363 (0.0166)\tPrec@1 100.000 (99.750)\tPrec@5 100.000 (99.992)\n",
      "Epoch: [16][1200/1334]\t\\Time 0.373 (0.326)\tData 0.320 (0.281)\tLoss 0.0163 (0.0175)\tPrec@1 100.000 (99.709)\tPrec@5 100.000 (99.993)\n",
      "Epoch: [16][1300/1334]\t\\Time 0.316 (0.326)\tData 0.271 (0.281)\tLoss 0.0040 (0.0177)\tPrec@1 100.000 (99.705)\tPrec@5 100.000 (99.994)\n",
      "Test: [0/334]\n",
      "\n",
      "Time 0.334 (0.334)\n",
      "\n",
      "Loss 0.8653 (0.8653)\n",
      "\n",
      "Prec@1 75.000 (75.000)\n",
      "\n",
      "Prec@5 91.667 (91.667)\n",
      "\n",
      "Test: [100/334]\n",
      "\n",
      "Time 0.341 (0.341)\n",
      "\n",
      "Loss 0.5650 (1.6600)\n",
      "\n",
      "Prec@1 75.000 (69.554)\n",
      "\n",
      "Prec@5 100.000 (89.851)\n",
      "\n",
      "Test: [200/334]\n",
      "\n",
      "Time 0.312 (0.346)\n",
      "\n",
      "Loss 1.6195 (1.6732)\n",
      "\n",
      "Prec@1 66.667 (70.191)\n",
      "\n",
      "Prec@5 91.667 (89.635)\n",
      "\n",
      "Test: [300/334]\n",
      "\n",
      "Time 0.294 (0.340)\n",
      "\n",
      "Loss 2.8178 (1.6828)\n",
      "\n",
      "Prec@1 66.667 (69.906)\n",
      "\n",
      "Prec@5 83.333 (89.673)\n",
      "\n",
      "\n",
      "[INFO] Saved Model to leafsnap_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# model = torchvision.models.vgg16(weights = True)\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet152_v3_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "\n",
    "train_image_dataset = ImagesWithLocationDataset(train_path,'s',transform=composed)\n",
    "test_image_dataset = ImagesWithLocationDataset(test_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(test_image_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "\n",
    "    \n",
    "@long_running\n",
    "def train_model(model,LEARNING_RATE = LEARNING_RATE,NUM_EPOCHS = NUM_EPOCHS):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    train_loader = torch.utils.data.DataLoader(data_train, batch_size=12, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(data_val, batch_size=12, shuffle=False, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                          momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    args_resume = f'saved_models/{model.name}_checkpoint.pth.tar'\n",
    "    if args_resume:\n",
    "        if os.path.isfile(args_resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args_resume))\n",
    "\n",
    "            start_epoch = 0\n",
    "            best_prec1 = 0\n",
    "    print('\\n[INFO] Training Started')\n",
    "    five_epochs_since_best = False\n",
    "    epochs_since_best = 0\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS ):\n",
    "        \n",
    "        if epochs_since_best >4:\n",
    "            five_epochs_since_best = True\n",
    "            \n",
    "        adjusted_rate,LEARNING_RATE = adjust_learning_rate(optimizer, epoch, five_epochs_since_best,LEARNING_RATE)\n",
    "        \n",
    "        if adjusted_rate:\n",
    "            args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "            print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "            checkpoint = torch.load(args_resume)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args_resume, checkpoint['epoch']))\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion,epoch,save_output=True)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, model)\n",
    "        print('\\n[INFO] Saved Model to leafsnap_model.pth')\n",
    "        # torch.save(model, f'{model.name}_checkpoint.pth.tar')\n",
    "        if is_best:\n",
    "            epochs_since_best = 0\n",
    "        else:\n",
    "            epochs_since_best+=1\n",
    "            \n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in model.location_fc2.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.location_fc.parameters():\n",
    "#     param.requires_grad = True   \n",
    "# for param in model.linear_add.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 10)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ef6c6-ca38-4b0f-85da-d7ca61866f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baa6025e-63c3-4ab8-bf64-91996eccf9bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#### geo on species observation models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbac762-695d-4d0a-80a8-abb0e09483e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [T.ToTensor(),T.Resize((INPUT_SIZE,INPUT_SIZE))]\n",
    "\n",
    "composed = T.Compose(transforms)\n",
    "\n",
    "\n",
    "class ImagesWithLocationDataset(Dataset):\n",
    "    \"\"\"Plant images with location data.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "    \n",
    "\n",
    "        self.location_dataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.location_dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.location_dataframe['path'].iloc[idx]\n",
    "        \n",
    "        id_ = self.location_dataframe['Id'].iloc[idx]\n",
    "        image = io.imread(img_name)\n",
    "        path = img_name\n",
    "        \n",
    "\n",
    "        target = np.array(self.location_dataframe['target'].iloc[idx])\n",
    "\n",
    "        sample = {'image': image, 'target':target, 'path':path, 'Id': id_}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            sample['target'] = torch.from_numpy(sample['target'])\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def name(self):\n",
    "        return 'ImagesWithLocationDataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7636c54-ecc2-429d-b2bb-b3243aca6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_path ='dataset/image_data/csv/combined_location_top_100_images_csv_train.csv'\n",
    "test_path='dataset/image_data/csv/combined_location_top_100_images_csv_test.csv'\n",
    "validation_path = 'dataset/image_data/csv/combined_location_top_100_images_csv_validation.csv'\n",
    "\n",
    "test_dat = pd.read_csv(test_path)\n",
    "test_dat.columns\n",
    "train_dat =  pd.read_csv(train_path)\n",
    "test_dat_path = test_path\n",
    "\n",
    "validation_dat = pd.read_csv(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a919d1-3d44-49a1-bba6-7159c87fa0a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import platform\n",
    "\n",
    "ES_CONTINUOUS = 0x80000000\n",
    "ES_SYSTEM_REQUIRED = 0x00000001\n",
    "\n",
    "\n",
    "def _set_thread_execution(state):\n",
    "    ctypes.windll.kernel32.SetThreadExecutionState(state)\n",
    "\n",
    "\n",
    "def prevent_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS | ES_SYSTEM_REQUIRED)\n",
    "\n",
    "\n",
    "def allow_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS)\n",
    "\n",
    "\n",
    "def long_running(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        prevent_standby()\n",
    "        result = func(*args, **kwargs)\n",
    "        allow_standby()\n",
    "        return result\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e0e8-91aa-4f4a-9663-a48dc002489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = output.shape[1]\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734029e-b361-43d8-beca-983d83142f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(image_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# model = torchvision.models.vgg16(weights = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=100, bias=True)\n",
    "\n",
    "model.name = f'resnet101_v4_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "# if USE_CUDA:\n",
    "#     model.cuda()\n",
    "\n",
    "args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "if args_resume:\n",
    "    if os.path.isfile(args_resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "        checkpoint = torch.load(args_resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args_resume, checkpoint['epoch']))\n",
    "        start_epoch = checkpoint['epoch']\n",
    "if USE_CUDA:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba82d5-8cc5-4ca7-b38a-c83ca1ccad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([test_dat,train_dat,validation_dat]) \n",
    "combined_df.columns\n",
    "\n",
    "combined_df['height'] = combined_df['height'].fillna(combined_df['height'].mean())\n",
    "combined_df['Nordkoordinat'] = combined_df['Nordkoordinat'].fillna(round(combined_df['Nordkoordinat'].mean(),0))\n",
    "\n",
    "combined_df = combined_df[~combined_df['height'].isnull()]\n",
    "\n",
    "ids = combined_df['Id']\n",
    "\n",
    "list_h  = combined_df['height'].to_list()\n",
    "list_n  = combined_df['Nordkoordinat'].to_list()\n",
    "h_category = []\n",
    "heigt_c = [100,300,600,900,1900]\n",
    "\n",
    "for i in list_h:\n",
    "    for j,k in enumerate(heigt_c):\n",
    "        if i <k:\n",
    "            h_category.append(j)\n",
    "            break\n",
    "combined_df['height_category'] = h_category\n",
    "\n",
    "n_category = []\n",
    "north_c = [6449347 +1*(2318191/5),6449347 +2*(2318191/5),6449347 +3*(2318191/5),6449347 +4*(2318191/5),6449347+10 +5*(2318191/5)]\n",
    "\n",
    "for i in list_n:\n",
    "    for j,k in enumerate(north_c):\n",
    "        a = True\n",
    "        if i <k:\n",
    "            n_category.append(j)\n",
    "            a=False\n",
    "            break\n",
    "    if a:\n",
    "        print(i)\n",
    "\n",
    "combined_df['north_category'] = n_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d16aba2-e53e-4517-9104-94f41178a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat.columns\n",
    "\n",
    "\n",
    "\n",
    "ids = combined_df['Id']\n",
    "landscape = pd.get_dummies(combined_df['landscape'],drop_first =True)\n",
    "treeline  = pd.get_dummies(combined_df['treeline'],drop_first =True)\n",
    "arskogbon = pd.get_dummies(combined_df['arskogbon'],drop_first =True)\n",
    "artreslag = pd.get_dummies(combined_df['artreslag'],drop_first =True)\n",
    "   \n",
    "\n",
    "arjordbr = pd.get_dummies(combined_df['arjordbr'],drop_first =True)\n",
    "arveget  = pd.get_dummies(combined_df['arveget'],drop_first =True)\n",
    "Fylke = pd.get_dummies(combined_df['Fylke'],drop_first =True)\n",
    "north_category = pd.get_dummies(combined_df['north_category'],drop_first =True)\n",
    "height_category = pd.get_dummies(combined_df['height_category'],drop_first =True)\n",
    "landscape_subtype = pd.get_dummies(combined_df['landscape_subtype'],drop_first =True)\n",
    "\n",
    "df = pd.concat([ids,landscape,treeline,arskogbon,artreslag,arjordbr,arveget,Fylke,landscape_subtype,height_category,north_category],axis=1)\n",
    "\n",
    "df.columns = df.columns.astype(str)\n",
    "\n",
    "\n",
    "multinomial_logisticmodel = pickle.load(open('multinomial_logisticmodel1.sav', 'rb'))\n",
    "# multinomial_logisticmodel = pickle.load(open('multinomial_logisticmodel1_validate.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311628d-922b-40b0-876a-cfb5b61870bf",
   "metadata": {},
   "source": [
    "### Run this square for ViT model, skip if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f483f3c-837d-4047-9edb-8d937aadb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ViT model\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "model = torchvision.models.vit_b_16(weights = 'ViT_B_16_Weights.IMAGENET1K_V1')\n",
    "\n",
    "seed =1711\n",
    "split_train =80\n",
    "split_val =100-split_train\n",
    "numb_targets = 100\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "model.heads[0] =nn.Linear(768 , 100, bias = True)\n",
    "model.name = f'vit_b_16_v5_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "#new version\n",
    "model.name = f'vit_b_16_v7_{numb_targets}targets_weights_seed{seed}_split{split_train}{split_val}_attempt2'\n",
    "\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# args_resume = f'C:/Users/vjosv/master/Deep-Leafsnap/saved_models/{model.name}_model_best.pth.tar'\n",
    "# print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "# checkpoint = torch.load(args_resume)\n",
    "# best_prec1 = checkpoint['best_prec1']\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "#       .format(args_resume, checkpoint['epoch']))\n",
    "# epoch = checkpoint['epoch']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "args_resume = f'saved_models/{model.name}_model_best.pth.tar'\n",
    "if args_resume:\n",
    "    if os.path.isfile(args_resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args_resume))\n",
    "        checkpoint = torch.load(args_resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args_resume, checkpoint['epoch']))\n",
    "        start_epoch = checkpoint['epoch']\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "\n",
    "# image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(image_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28de564-2557-4999-b8cf-cf299afcc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(image_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "better_1_org = {}\n",
    "better_5 = {}\n",
    "better_10 = {}\n",
    "\n",
    "\n",
    "print(model.name)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "top10 = AverageMeter()\n",
    "\n",
    "top1_aug = AverageMeter()\n",
    "top5_aug = AverageMeter()\n",
    "top10_aug = AverageMeter()\n",
    "\n",
    "\n",
    "\n",
    "above_10_list = [0, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 23, 24, 25, 27, 29, 30, 31, 32, 35, 40, 41, 42, 43, 44, 46, 47, 50, 52, 53, 55, 57, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 83, 86, 87]\n",
    "for i,input in enumerate(tqdm(val_loader)):\n",
    "    \n",
    "\n",
    "    # print(i)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        image = input['image'].cuda(non_blocking=True)\n",
    "        target = input['target'].cuda(non_blocking=True)\n",
    "        # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "        # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "    else:\n",
    "        image = input['image']\n",
    "        target = input['target']\n",
    "        # location_data = input['location_data']\n",
    "        # map_square = input['map_square']\n",
    "    input_var = torch.autograd.Variable(image)\n",
    "    target_var = torch.autograd.Variable(target)\n",
    "    # location_data_var = torch.autograd.Variable(location_data)\n",
    "    # map_square_var = torch.autograd.Variable(map_square)\n",
    "    # compute output\n",
    "    # output = model(input_var,map_square)\n",
    "    output = model(input_var)\n",
    "    \n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    original_prediction = accuracy(output.data, target, topk=(1, 5,10))\n",
    "    \n",
    "    top1.update(original_prediction[0].item(), image.size(0))\n",
    "    top5.update(original_prediction[1].item(), image.size(0))\n",
    "    top10.update(original_prediction[2].item(), image.size(0))\n",
    "    original_prediction = [int(op) for op in original_prediction[:-1]]\n",
    "    original_prediction\n",
    "    # for mul in [0.1,0.2,0.3,0.4,0.5]:\n",
    "    \n",
    "    for mul in [0.9,0.8,0.7]:#,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:# ['in_100', 'in_200', 'in_500', 'in_1000', 'in_1500']:\n",
    "        output_aug = output #torch.nn.functional.softmax(output, dim=1)\n",
    "        if mul not in better_1_org:\n",
    "            better_1_org[mul] = [AverageMeter(),AverageMeter(),AverageMeter()]\n",
    "\n",
    "        id_ = input['Id']\n",
    "\n",
    "        # output_aug[0] = output_aug[0]+ (0.45/2)*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "        \n",
    "        \n",
    "        a= torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_200'].values[0]))).cuda()\n",
    "        for i in range(len(a)):\n",
    "            if a[i]==0:\n",
    "                a[i]=mul\n",
    "        output_aug[0] = output_aug[0]*a\n",
    "        output_aug = nn.functional.normalize(output_aug)\n",
    "        # mul_log = multinomial_logisticmodel.predict_proba(df[df['Id']==int(id_)].loc[:, df.columns != 'Id'])[0]\n",
    "        \n",
    "        # ones = np.zeros(100)\n",
    "        # null_val = np.argsort(mul_log)[:mul]\n",
    "        # null_val = [i for i in null_val if i not in above_10_list]\n",
    "        # ones[null_val]=0\n",
    "\n",
    "        # output_aug[0][null_val]=0\n",
    "        # mul_log[null_val]=0\n",
    "        # output_aug[0] = output_aug[0]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        augmented_prediction = accuracy(output_aug.data, target, topk=(1, 5, 10))\n",
    "        top1_aug.update(augmented_prediction[0].item(), image.size(0))\n",
    "        top5_aug.update(augmented_prediction[1].item(), image.size(0))\n",
    "        top10_aug.update(augmented_prediction[2].item(), image.size(0))\n",
    "        \n",
    "        better_1_org[mul][0].update(augmented_prediction[0].item(), image.size(0))\n",
    "        better_1_org[mul][1].update(augmented_prediction[1].item(), image.size(0))\n",
    "        better_1_org[mul][2].update(augmented_prediction[2].item(), image.size(0))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7fb609-1a86-4017-9357-985d75e6ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing result of augmented model\n",
    "print(top1.avg)\n",
    "print(top5.avg)\n",
    "print(top10.avg)\n",
    "print('--------')\n",
    "for k in better_1_org:\n",
    "    print(k)\n",
    "    # for s in better_1_org[k]:\n",
    "    print('&'+' 1','& ',round(better_1_org[k][0].avg,3),' & ',round(round(better_1_org[k][0].avg,3)-round(top1.avg,3),3),\"\\\\\\\\\")\n",
    "    print('&'+' 5','& ',round(better_1_org[k][1].avg,3),' & ',round(round(better_1_org[k][1].avg,3)-round(top5.avg,3),3),\"\\\\\\\\\")\n",
    "    print('&'+' 10','& ',round(better_1_org[k][2].avg,3),'&',round(round(better_1_org[k][2].avg,3)-round(top10.avg,3),3),\"\\\\\\\\\")\n",
    "    print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f7e98-690a-4275-b2a6-d6ba8410e53f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Trying to weight with relative frequency in the area around the observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5853958-884f-4dda-94a5-b86f3fe09fb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In Area with Floor multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3b4d9-0213-4af3-b8ee-4fbb4a52f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "better_1_1 = {}\n",
    "better_5 = {}\n",
    "better_10 = {}\n",
    "\n",
    "# accuracy_per_target\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "top10 = AverageMeter()\n",
    "\n",
    "top1_aug = AverageMeter()\n",
    "top5_aug = AverageMeter()\n",
    "top10_aug = AverageMeter()\n",
    "\n",
    "for i,input in enumerate(tqdm(val_loader)):\n",
    "    \n",
    "\n",
    "    # print(i)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        image = input['image'].cuda(non_blocking=True)\n",
    "        target = input['target'].cuda(non_blocking=True)\n",
    "        # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "        # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "    else:\n",
    "        image = input['image']\n",
    "        target = input['target']\n",
    "        # location_data = input['location_data']\n",
    "        # map_square = input['map_square']\n",
    "    input_var = torch.autograd.Variable(image)\n",
    "    target_var = torch.autograd.Variable(target)\n",
    "\n",
    "    output = model(input_var)\n",
    "    \n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    original_prediction = accuracy(output.data, target, topk=(1, 5,10))\n",
    "    \n",
    "    top1.update(original_prediction[0].item(), image.size(0))\n",
    "    top5.update(original_prediction[1].item(), image.size(0))\n",
    "    top10.update(original_prediction[2].item(), image.size(0))\n",
    "    original_prediction = [int(op) for op in original_prediction[:-1]]\n",
    "    original_prediction\n",
    "    # for mul in [0.1,0.2,0.3,0.4,0.5]:\n",
    "    for in_val in ['in_500','in_1000','in_1500']:\n",
    "        if in_val not in better_1_1:\n",
    "            better_1_1[in_val]={}\n",
    "        for mul in [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0]:#0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            if mul not in better_1_1[in_val]:\n",
    "                better_1_1[in_val][mul] = [AverageMeter(),AverageMeter(),AverageMeter()]\n",
    "\n",
    "            id_ = input['Id']\n",
    "            output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            # output_aug[0] = output_aug[0]+ 0.5*0.45*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "\n",
    "            a= torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]][in_val].values[0]))).cuda()\n",
    "            for i in range(len(a)):\n",
    "                if a[i]==0:\n",
    "                    a[i]=mul\n",
    "            output_aug[0] = output_aug[0]*a\n",
    "            output_aug = nn.functional.normalize(output_aug)\n",
    "\n",
    "            # mul_log = multinomial_logisticmodel.predict_proba(df[df['Id']==int(id_)].loc[:, df.columns != 'Id'])[0]\n",
    "\n",
    "            ones = np.zeros(100)\n",
    "            # null_val = np.argsort(mul_log)[60:]\n",
    "            # null_val = [i for i in null_val if i in above_10_list]\n",
    "            # ones[null_val]=1\n",
    "            # output_aug[0] = output_aug[0]+ mul*torch.from_numpy(mul_log).cuda()\n",
    "\n",
    "            # freq_square = test_dat[test_dat['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "            # freq_square = test_dat[test_dat['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "\n",
    "\n",
    "            # list_surrounding_squares = list(get_sourounding_squares(freq_square,square_res,test_dat)[square_res].unique())\n",
    "            # try:\n",
    "\n",
    "    #         freq_square_l = list(get_sourounding_squares(freq_square,square_res,test_dat)[square_res].unique())                \n",
    "    #         freq_square_l_new = [f_s_l for f_s_l in freq_square_l if f_s_l in res_dat.columns]\n",
    "\n",
    "    #         np_a = np.zeros(100)\n",
    "    #         for c in res_dat[freq_square_l_new].columns:\n",
    "    #             np_a += np.array(res_dat[freq_square_l_new][c])\n",
    "            # np_freq_square = np.array(res_dat[freq_square])\n",
    "    # \n",
    "            # output_aug[0] = output_aug[0]+ mul*torch.from_numpy(np_a).cuda()\n",
    "\n",
    "\n",
    "            augmented_prediction = accuracy(output_aug.data, target, topk=(1, 5, 10))\n",
    "\n",
    "            better_1_1[in_val][mul][0].update(augmented_prediction[0].item(), image.size(0))\n",
    "            better_1_1[in_val][mul][1].update(augmented_prediction[1].item(), image.size(0))\n",
    "            better_1_1[in_val][mul][2].update(augmented_prediction[2].item(), image.size(0))\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22e566-0267-4332-b671-825e5d33e177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dat[test_dat['Id']==int(input['Id'])][square_res][1]\n",
    "\n",
    "print(top1.avg)\n",
    "print(top5.avg)\n",
    "print(top10.avg)\n",
    "# print(better_1)\n",
    "for s in better_1_1:\n",
    "    print(s)\n",
    "    for k in better_1_1[s]:\n",
    "        print(k,' &'+' 1','& ',round(better_1_1[s][k][0].avg,3),' & ',round(round(better_1_1[s][k][0].avg,3)-round(top1.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 5','& ',round(better_1_1[s][k][1].avg,3),' & ',round(round(better_1_1[s][k][1].avg,3)-round(top5.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 10','& ',round(better_1_1[s][k][2].avg,3),'&',round(round(better_1_1[s][k][2].avg,3)-round(top10.avg,3),3),\"\\\\\\\\\")\n",
    "        print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56961a-4bfd-4b86-9ebb-6b921b4c2f2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Added In Area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c69700-a447-456c-b9fd-785be3facd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "better_1_2 = {}\n",
    "better_5 = {}\n",
    "better_10 = {}\n",
    "\n",
    "# accuracy_per_target\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "print(model.name)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "top10 = AverageMeter()\n",
    "\n",
    "top1_aug = AverageMeter()\n",
    "top5_aug = AverageMeter()\n",
    "top10_aug = AverageMeter()\n",
    "\n",
    "for i,input in enumerate(tqdm(val_loader)):\n",
    "    \n",
    "\n",
    "    # print(i)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        image = input['image'].cuda(non_blocking=True)\n",
    "        target = input['target'].cuda(non_blocking=True)\n",
    "        # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "        # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "    else:\n",
    "        image = input['image']\n",
    "        target = input['target']\n",
    "        # location_data = input['location_data']\n",
    "        # map_square = input['map_square']\n",
    "    input_var = torch.autograd.Variable(image)\n",
    "    target_var = torch.autograd.Variable(target)\n",
    "    # location_data_var = torch.autograd.Variable(location_data)\n",
    "    # map_square_var = torch.autograd.Variable(map_square)\n",
    "    # compute output\n",
    "    # output = model(input_var,map_square)\n",
    "    output = model(input_var)\n",
    "    \n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    original_prediction = accuracy(output.data, target, topk=(1, 5,10))\n",
    "    \n",
    "    top1.update(original_prediction[0].item(), image.size(0))\n",
    "    top5.update(original_prediction[1].item(), image.size(0))\n",
    "    top10.update(original_prediction[2].item(), image.size(0))\n",
    "    original_prediction = [int(op) for op in original_prediction[:-1]]\n",
    "    original_prediction\n",
    "    # for mul in [0.1,0.2,0.3,0.4,0.5]:\n",
    "    for in_val in ['in_200','in_500','in_1000','in_1500']:\n",
    "        if in_val not in better_1_2:\n",
    "            better_1_2[in_val]={}\n",
    "        for mul in [0.6,0.5,0.45,0.4,0.3,0.2,0.1]:#0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            if mul not in better_1_2[in_val]:\n",
    "                better_1_2[in_val][mul] = [AverageMeter(),AverageMeter(),AverageMeter()]\n",
    "\n",
    "            id_ = input['Id']\n",
    "            output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            output_aug[0] = output_aug[0]+ mul*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]][in_val].values[0]))).cuda()\n",
    "\n",
    "  \n",
    "            ones = np.zeros(100)\n",
    "\n",
    "\n",
    "\n",
    "            augmented_prediction = accuracy(output_aug.data, target, topk=(1, 5, 10))\n",
    "\n",
    "            better_1_2[in_val][mul][0].update(augmented_prediction[0].item(), image.size(0))\n",
    "            better_1_2[in_val][mul][1].update(augmented_prediction[1].item(), image.size(0))\n",
    "            better_1_2[in_val][mul][2].update(augmented_prediction[2].item(), image.size(0))\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d6740-0a4b-4f36-9838-f439876757ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top1.avg)\n",
    "print(top5.avg)\n",
    "print(top10.avg)\n",
    "# print(better_1)\n",
    "for s in better_1_2:\n",
    "    print(s)\n",
    "    for k in better_1_2[s]:\n",
    "        print(k,' &'+' 1','& ',round(better_1_2[s][k][0].avg,3),' & ',round(round(better_1_2[s][k][0].avg,3)-round(top1.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 5','& ',round(better_1_2[s][k][1].avg,3),' & ',round(round(better_1_2[s][k][1].avg,3)-round(top5.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 10','& ',round(better_1_2[s][k][2].avg,3),'&',round(round(better_1_2[s][k][2].avg,3)-round(top10.avg,3),3),\"\\\\\\\\\")\n",
    "        print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93364758-d910-44e2-a98c-9783f6532cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb2473-1d44-48bf-8fd6-eb73b7c7ed15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "better_1_3 = {}\n",
    "better_5 = {}\n",
    "better_10 = {}\n",
    "\n",
    "# accuracy_per_target\n",
    "\n",
    "image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(model.name)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "top10 = AverageMeter()\n",
    "\n",
    "top1_aug = AverageMeter()\n",
    "top5_aug = AverageMeter()\n",
    "top10_aug = AverageMeter()\n",
    "\n",
    "for i,input in enumerate(tqdm(val_loader)):\n",
    "    \n",
    "\n",
    "    # print(i)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        image = input['image'].cuda(non_blocking=True)\n",
    "        target = input['target'].cuda(non_blocking=True)\n",
    "        # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "        # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "    else:\n",
    "        image = input['image']\n",
    "        target = input['target']\n",
    "        # location_data = input['location_data']\n",
    "        # map_square = input['map_square']\n",
    "    input_var = torch.autograd.Variable(image)\n",
    "    target_var = torch.autograd.Variable(target)\n",
    "    # location_data_var = torch.autograd.Variable(location_data)\n",
    "    # map_square_var = torch.autograd.Variable(map_square)\n",
    "    # compute output\n",
    "    # output = model(input_var,map_square)\n",
    "    output = model(input_var)\n",
    "    \n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    original_prediction = accuracy(output.data, target, topk=(1, 5,10))\n",
    "    \n",
    "    top1.update(original_prediction[0].item(), image.size(0))\n",
    "    top5.update(original_prediction[1].item(), image.size(0))\n",
    "    top10.update(original_prediction[2].item(), image.size(0))\n",
    "    original_prediction = [int(op) for op in original_prediction[:-1]]\n",
    "    original_prediction\n",
    "    # for mul in [0.1,0.2,0.3,0.4,0.5]:\n",
    "    for in_val in ['in_500']:\n",
    "        if in_val not in better_1_3:\n",
    "            better_1_3[in_val]={}\n",
    "            \n",
    "\n",
    "        for mul in [1.8,2]:# [0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.4,1.5,1.6]:\n",
    "            if mul not in better_1_3[in_val]:\n",
    "                better_1_3[in_val][mul] = [AverageMeter(),AverageMeter(),AverageMeter()]\n",
    "\n",
    "            id_ = input['Id']\n",
    "            output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            # output_aug[0] = output_aug[0]+ mul*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]][in_val].values[0]))).cuda()\n",
    "\n",
    "            # output_aug[0] = output_aug[0]+ (0.45/2)*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            # output_aug = nn.functional.normalize(output_aug)\n",
    "            \n",
    "            ##top-40 logistic\n",
    "            \n",
    "            mul_log = multinomial_logisticmodel.predict_proba(df[df['Id']==int(id_)].loc[:, df.columns != 'Id'])[0]\n",
    "            ones = np.zeros(100)\n",
    "            null_val = np.argsort(mul_log)[60:]\n",
    "            ones[null_val]=1\n",
    "        \n",
    "            output_aug[0] = output_aug[0]+ mul*torch.from_numpy(mul_log).cuda()\n",
    "            \n",
    "\n",
    "            augmented_prediction = accuracy(output_aug.data, target, topk=(1, 5, 10))\n",
    "\n",
    "            better_1_3[in_val][mul][0].update(augmented_prediction[0].item(), image.size(0))\n",
    "            better_1_3[in_val][mul][1].update(augmented_prediction[1].item(), image.size(0))\n",
    "            better_1_3[in_val][mul][2].update(augmented_prediction[2].item(), image.size(0))\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4a55f85-203e-45b8-aac6-766d9e019dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(top1.avg)\n",
    "print(top5.avg)\n",
    "print(top10.avg)\n",
    "# print(better_1)\n",
    "for s in better_1_3:\n",
    "    print(s)\n",
    "    for k in better_1_3[s]:\n",
    "        print(k,' &'+' 1','& ',round(better_1_3[s][k][0].avg,3),' & ',round(round(better_1_3[s][k][0].avg,3)-round(top1.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 5','& ',round(better_1_3[s][k][1].avg,3),' & ',round(round(better_1_3[s][k][1].avg,3)-round(top5.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 10','& ',round(better_1_3[s][k][2].avg,3),'&',round(round(better_1_3[s][k][2].avg,3)-round(top10.avg,3),3),\"\\\\\\\\\")\n",
    "        print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c369d1-c185-4f01-b0b3-0c21fd6e7b30",
   "metadata": {},
   "source": [
    "### Frequency weighted with floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c2921-948b-4c3b-8ec0-f36e8dce2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frequency weighted with floor\n",
    "##\n",
    "##\n",
    "better_1_4 = {}\n",
    "better_5 = {}\n",
    "better_10 = {}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_sourounding_squares(square,resolution, dat):\n",
    "    if isinstance(square, str):\n",
    "        square= literal_eval(square)\n",
    "    \n",
    "    return_list = []\n",
    "    for i in [-1,0,1]:\n",
    "        for j in [-1,0,1]:\n",
    "            return_list.append(str([square[0]+i,square[1]+j]))\n",
    "    \n",
    "    return dat[dat[resolution].isin(return_list)]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "top1_aug = AverageMeter()\n",
    "top5_aug = AverageMeter()\n",
    "top10_aug = AverageMeter()\n",
    "\n",
    "sq = ['square_20x20', 'square_15x15','square_10x10', 'square_30x30', 'square_40x40', 'square_50x50','square_60x60', 'square_70x70', 'square_80x80', 'square_90x90','square_100x100']\n",
    "sq = ['square_150x150','square_200x200']\n",
    "\n",
    "\n",
    "sq = ['squares_8','squares_20','squares_15', 'squares_10', 'squares_30', 'squares_40', 'squares_50','squares_60', 'squares_70', 'squares_80', 'squares_90', 'squares_100']\n",
    "sq = ['squares_60','squares_70', 'squares_80', 'squares_90', 'squares_100']\n",
    "sq =['squares_100']\n",
    "above_10_list = [0, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 23, 24, 25, 27, 29, 30, 31, 32, 35, 40, 41, 42, 43, 44, 46, 47, 50, 52, 53, 55, 57, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 83, 86, 87]\n",
    "for square_res in sq:\n",
    "    better_1_4[square_res] = {}\n",
    "    res_dat = pd.read_csv(f'C:/Users/vjosv/master/Deep-Leafsnap/{square_res}_relative_freq_min.csv')\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    top10 = AverageMeter()\n",
    "\n",
    "    for i,input in enumerate(tqdm(val_loader)):\n",
    "\n",
    "\n",
    "\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "            # location_data = input['location_data'].cuda(non_blocking=True)\n",
    "            # map_square = input['map_square'].cuda(non_blocking=True)\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            # location_data = input['location_data']\n",
    "            # map_square = input['map_square']\n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        # location_data_var = torch.autograd.Variable(location_data)\n",
    "        # map_square_var = torch.autograd.Variable(map_square)\n",
    "        # compute output\n",
    "        # output = model(input_var,map_square)\n",
    "        output = model(input_var)\n",
    "\n",
    "        output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        original_prediction = accuracy(output.data, target, topk=(1, 5,10))\n",
    "\n",
    "        top1.update(original_prediction[0].item(), image.size(0))\n",
    "        top5.update(original_prediction[1].item(), image.size(0))\n",
    "        top10.update(original_prediction[2].item(), image.size(0))\n",
    "        original_prediction = [int(op) for op in original_prediction[:-1]]\n",
    "        original_prediction\n",
    "        # for mul in [0.1,0.2,0.3,0.4,0.5]:\n",
    "\n",
    "        for mul in [100]:\n",
    "            output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "            if mul not in better_1_4[square_res]:\n",
    "                better_1_4[square_res][mul] = [AverageMeter(),AverageMeter(),AverageMeter()]\n",
    "\n",
    "            id_ = int(input['Id'])\n",
    "            \n",
    "            # freq_square = validation_dat[validation_dat['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "            # freq_square = validation_dat[validation_dat['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "            # freq_square = test_dat[test_dat['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "            freq_square = test_dat[test_dat['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "\n",
    "            \n",
    "            list_surrounding_squares = list(get_sourounding_squares(freq_square,square_res,test_dat)[square_res].unique())\n",
    "            # try:\n",
    "                \n",
    "            freq_square_l = list(get_sourounding_squares(freq_square,square_res,test_dat)[square_res].unique())                \n",
    "            freq_square_l_new = [f_s_l for f_s_l in freq_square_l if f_s_l in res_dat.columns]\n",
    "\n",
    "            np_a = np.zeros(100)\n",
    "            for c in res_dat[freq_square_l_new].columns:\n",
    "                np_a += np.array(res_dat[freq_square_l_new][c])\n",
    "            # np_freq_square = np.array(res_dat[freq_square])\n",
    "# \n",
    "            output_aug[0] = output_aug[0]*100*torch.from_numpy(np_a).cuda()\n",
    "            output_aug = nn.functional.normalize(output_aug)\n",
    "            \n",
    "            # except:\n",
    "            #     print('e')\n",
    "            #     pass\n",
    "            # output_aug[0] = output_aug[0]+ (0.45)*torch.from_numpy(np.array(ast.literal_eval(validation_dat[validation_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            # output_aug[0] = output_aug[0]+ (0.45/2)*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            # output_aug = nn.functional.normalize(output_aug)\n",
    "            \n",
    "            ##top-40 logistic\n",
    "            # mul_log = multinomial_logisticmodel.predict_proba(df[df['Id']==int(id_)].loc[:, df.columns != 'Id'])[0]\n",
    "            \n",
    "            # ones = np.zeros(100)\n",
    "            # null_val = np.argsort(mul_log)[60:]\n",
    "            # # null_val = [i for i in null_val if i not in above_10_list]\n",
    "            # ones[null_val]=1\n",
    "            # mul_log[null_val]=0\n",
    "            # output_aug[0] = output_aug[0]+ (0.8/2)*torch.from_numpy(ones).cuda()\n",
    "            # output_aug = nn.functional.normalize(output_aug)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            augmented_prediction = accuracy(output_aug.data, target, topk=(1, 5, 10))\n",
    "            top1_aug.update(augmented_prediction[0].item(), image.size(0))\n",
    "            top5_aug.update(augmented_prediction[1].item(), image.size(0))\n",
    "            top10_aug.update(augmented_prediction[2].item(), image.size(0))\n",
    "            better_1_4[square_res][mul][0].update(augmented_prediction[0].item(), image.size(0))\n",
    "            better_1_4[square_res][mul][1].update(augmented_prediction[1].item(), image.size(0))\n",
    "            better_1_4[square_res][mul][2].update(augmented_prediction[2].item(), image.size(0))\n",
    "#     \n",
    "    for k in better_1_4[square_res]:\n",
    "        print(square_res, k,better_1_4[square_res][k][0].avg)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766e7c5-3921-4bc5-9109-37e9b4952faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top1.avg)\n",
    "print(top5.avg)\n",
    "print(top10.avg)\n",
    "# print(better_1)\n",
    "for s in better_1_4:\n",
    "    for k in better_1_4[s]:\n",
    "        print(s,' &'+' 1','& ',round(better_1_4[s][k][0].avg,3),' & ',round(round(better_1_4[s][k][0].avg,3)-round(top1.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 5','& ',round(better_1_4[s][k][1].avg,3),' & ',round(round(better_1_4[s][k][1].avg,3)-round(top5.avg,3),3),\"\\\\\\\\\")\n",
    "        print('&'+' 10','& ',round(better_1_4[s][k][2].avg,3),' & ',round(round(better_1_4[s][k][2].avg,3)-round(top10.avg,3),3),\"\\\\\\\\\")\n",
    "        print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1d00f-c9a9-4886-a34a-f903ab35415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dict ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e6ef3-32d3-44e1-85ec-98b81d04a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing different models with geo\n",
    "##\n",
    "##'\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "validation_or_test = 'validation'\n",
    "\n",
    "if validation_or_test== 'test':\n",
    "# validation_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images20_see1207_validation.csv'\n",
    "\n",
    "    multinomial_logisticmodel = pickle.load(open('multinomial_logisticmodel1.sav', 'rb'))\n",
    "    # multinomial_logisticmodel = pickle.load(open('multinomial_logisticmodel1_validate.sav', 'rb'))\n",
    "\n",
    "    image_dataset = ImagesWithLocationDataset(test_dat_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(image_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    data_frame = test_dat\n",
    "    \n",
    "if validation_or_test=='validation':\n",
    "\n",
    "    data_frame = validation_dat\n",
    "    multinomial_logisticmodel = pickle.load(open('multinomial_logisticmodel1_validate.sav', 'rb'))\n",
    "\n",
    "    image_dataset = ImagesWithLocationDataset(validation_path,'s',transform=composed)\n",
    "\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(image_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "better_1_4 = {}\n",
    "better_5 = {}\n",
    "better_10 = {}\n",
    "\n",
    "print(model.name)\n",
    "\n",
    "def get_sourounding_squares(square,resolution, dat):\n",
    "    if isinstance(square, str):\n",
    "        square= literal_eval(square)\n",
    "    \n",
    "    return_list = []\n",
    "    for i in [-1,0,1]:\n",
    "        for j in [-1,0,1]:\n",
    "            return_list.append(str([square[0]+i,square[1]+j]))\n",
    "    \n",
    "    return dat[dat[resolution].isin(return_list)]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "top1_aug = AverageMeter()\n",
    "top5_aug = AverageMeter()\n",
    "top10_aug = AverageMeter()\n",
    "\n",
    "sq = ['square_20x20', 'square_15x15','square_10x10', 'square_30x30', 'square_40x40', 'square_50x50','square_60x60', 'square_70x70', 'square_80x80', 'square_90x90','square_100x100']\n",
    "sq = ['square_150x150','square_200x200']\n",
    "\n",
    "\n",
    "resnet_top1_list = []\n",
    "resnet_top1_aug_list = []\n",
    "resnet_top1_id_list = [] \n",
    "\n",
    "sq = ['squares_8','squares_20','squares_15', 'squares_10', 'squares_30', 'squares_40', 'squares_50','squares_60', 'squares_70', 'squares_80', 'squares_90', 'squares_100']\n",
    "in_val = 'in_500'\n",
    "sq = ['squares_100']\n",
    "\n",
    "for square_res in sq:\n",
    "    if square_res not in better_1_4:\n",
    "        better_1_4[square_res] = {}\n",
    "    res_dat = pd.read_csv(f'C:/Users/vjosv/master/Deep-Leafsnap/{square_res}_relative_freq_min.csv')\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    top10 = AverageMeter()\n",
    "\n",
    "    for i,input in enumerate(tqdm(val_loader)):\n",
    "\n",
    "\n",
    "\n",
    "        if USE_CUDA:\n",
    "            image = input['image'].cuda(non_blocking=True)\n",
    "            target = input['target'].cuda(non_blocking=True)\n",
    "\n",
    "        else:\n",
    "            image = input['image']\n",
    "            target = input['target']\n",
    "            \n",
    "        input_var = torch.autograd.Variable(image)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        output = model(input_var)\n",
    "\n",
    "        output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        original_prediction = accuracy(output.data, target, topk=(1, 5,10))\n",
    "\n",
    "        top1.update(original_prediction[0].item(), image.size(0))\n",
    "        top5.update(original_prediction[1].item(), image.size(0))\n",
    "        top10.update(original_prediction[2].item(), image.size(0))\n",
    "        original_prediction = [int(op) for op in original_prediction[:-1]]\n",
    "        original_prediction\n",
    "        # for mul in [0.1,0.2,0.3,0.4,0.5]:\n",
    "\n",
    "        for mul in [5]:#[1,2,3,4,5,6,7,8,10,11,12,13]:\n",
    "            output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "            if mul not in better_1_4[square_res]:\n",
    "                better_1_4[square_res][mul] = [AverageMeter(),AverageMeter(),AverageMeter()]\n",
    "\n",
    "            id_ = int(input['Id'])\n",
    "            \n",
    "\n",
    "               \n",
    "            if mul in [1,2,3,4,5,6,7,8,9,12]:\n",
    "        \n",
    "               \n",
    "   \n",
    "                freq_square = data_frame[data_frame['Id']==int(input['Id'])][square_res].iloc[0]\n",
    "    \n",
    "                freq_square_l = list(get_sourounding_squares(freq_square,square_res,data_frame)[square_res].unique())                \n",
    "                freq_square_l_new = [f_s_l for f_s_l in freq_square_l if f_s_l in res_dat.columns]\n",
    "\n",
    "                np_a = np.zeros(100)\n",
    "                for c in res_dat[freq_square_l_new].columns:\n",
    "                    np_a += np.array(res_dat[freq_square_l_new][c])\n",
    "                # np_freq_square = np.array(res_dat[freq_square])\n",
    "    # \n",
    "                output_aug[0] = output_aug[0]*100*torch.from_numpy(np_a).cuda()\n",
    "                output_aug = nn.functional.normalize(output_aug)\n",
    "            if mul in[1,2,3,4,5,9,10]:\n",
    "                a= torch.from_numpy(np.array(ast.literal_eval(data_frame[data_frame['path']==input['path'][0]][in_val].values[0]))).cuda()\n",
    "                for i in range(len(a)):\n",
    "                    if a[i]==0:\n",
    "                        a[i]=0.1\n",
    "                output_aug[0] = output_aug[0]*a\n",
    "                output_aug = nn.functional.normalize(output_aug)\n",
    "            if mul in[7,11]:\n",
    "                a= torch.from_numpy(np.array(ast.literal_eval(data_frame[data_frame['path']==input['path'][0]]['in_1500'].values[0]))).cuda()\n",
    "                for i in range(len(a)):\n",
    "                    if a[i]==0:\n",
    "                        a[i]=0.1\n",
    "                output_aug[0] = output_aug[0]*a\n",
    "                output_aug = nn.functional.normalize(output_aug)\n",
    "            # except:\n",
    "            #     print('e')\n",
    "            #     pass\n",
    "            # if mul ==2:\n",
    "            #     output_aug[0] = output_aug[0]+ (0.4)*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            # output_aug[0] = output_aug[0]+ (0.45/2)*torch.from_numpy(np.array(ast.literal_eval(test_dat[test_dat['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            # output_aug = nn.functional.normalize(output_aug)\n",
    "            if mul ==2:\n",
    "                output_aug[0] = output_aug[0]+ (0.6)*torch.from_numpy(np.array(ast.literal_eval(data_frame[data_frame['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            if mul in [3,6]:\n",
    "                output_aug[0] = output_aug[0]+ (0.6/2)*torch.from_numpy(np.array(ast.literal_eval(data_frame[data_frame['path']==input['path'][0]]['in_1000'].values[0]))).cuda()\n",
    "            \n",
    "            # output_a\n",
    "            ##top-40 logistic\n",
    "            if mul in [2,5,7,8,9,10,11]:\n",
    "                # try:\n",
    "                mul_log = multinomial_logisticmodel.predict_proba(df[df['Id']==int(id_)].loc[:, df.columns != 'Id'])[0]\n",
    "\n",
    "                ones = np.zeros(100)\n",
    "                null_val = np.argsort(mul_log)[60:]\n",
    "                # null_val = [i for i in null_val if i not in above_10_list]\n",
    "                ones[null_val]=1\n",
    "                output_aug[0] = output_aug[0]+(0.6)*torch.from_numpy(ones).cuda()\n",
    "                #     print('s')\n",
    "                # except:\n",
    "                #     print('f')\n",
    "                #     pass\n",
    "            \n",
    "            if mul in [3,4]:\n",
    "\n",
    "                mul_log = multinomial_logisticmodel.predict_proba(df[df['Id']==int(id_)].loc[:, df.columns != 'Id'])[0]\n",
    "\n",
    "                ones = np.zeros(100)\n",
    "                null_val = np.argsort(mul_log)[60:]\n",
    "                # null_val = [i for i in null_val if i not in above_10_list]\n",
    "                ones[null_val]=1\n",
    "            # mul_log[null_val]=0\n",
    "                output_aug[0] = output_aug[0]+ (0.6/2)*torch.from_numpy(ones).cuda()\n",
    "\n",
    "            # output_aug = nn.functional.normalize(output_aug)\n",
    "\n",
    "            augmented_prediction = accuracy(output_aug.data, target, topk=(1, 5, 10))\n",
    "        \n",
    "            resnet_top1_list.append(original_prediction[0])\n",
    "            resnet_top1_aug_list.append(int(augmented_prediction[0].item()))\n",
    "            resnet_top1_id_list.append(id_)\n",
    "            \n",
    "            top1_aug.update(augmented_prediction[0].item(), image.size(0))\n",
    "            top5_aug.update(augmented_prediction[1].item(), image.size(0))\n",
    "            top10_aug.update(augmented_prediction[2].item(), image.size(0))\n",
    "            better_1_4[square_res][mul][0].update(augmented_prediction[0].item(), image.size(0))\n",
    "            better_1_4[square_res][mul][1].update(augmented_prediction[1].item(), image.size(0))\n",
    "            better_1_4[square_res][mul][2].update(augmented_prediction[2].item(), image.size(0))\n",
    "#     \n",
    "    for k in better_1_4[square_res]:\n",
    "        print(square_res, k,better_1_4[square_res][k][0].avg)\n",
    "        \n",
    "correct_dict['resnet_org']=resnet_top1_list\n",
    "correct_dict['resnet_aug']=resnet_top1_aug_list\n",
    "correct_dict['resnet_ids'] = resnet_top1_id_list\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4a99d-cd45-40b8-a313-699bccdf5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top1.avg)\n",
    "print(top5.avg)\n",
    "print(top10.avg)\n",
    "# print(better_1)\n",
    "for s in better_1_4:\n",
    "    for k in better_1_4[s]:\n",
    "        print(k)\n",
    "        print(' 1','& ',round(better_1_4[s][k][0].avg,3),'& ',round(round(better_1_4[s][k][0].avg,3)-round(top1.avg,3),3),\"\\\\\\\\\")\n",
    "        print(' 5','& ',round(better_1_4[s][k][1].avg,3),'& ',round(round(better_1_4[s][k][1].avg,3)-round(top5.avg,3),3),\"\\\\\\\\\")\n",
    "        print(' 10','& ',round(better_1_4[s][k][2].avg,3),'& ',round(round(better_1_4[s][k][2].avg,3)-round(top10.avg,3),3),\"\\\\\\\\\")\n",
    "        print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98b770-354d-4902-aa40-c11a0a921674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
