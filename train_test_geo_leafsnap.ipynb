{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c31657-e6c7-4732-8a68-ae1972fbe5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117_attempt2_with_loc.csv'\n",
    "\n",
    "\n",
    "temp = 'C:/Users/vjosv/master/top_100_images_with_location_data.csv'\n",
    "import time\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "import ast\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from averagemeter import *\n",
    "from models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 185\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "best_prec1 = 0\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33761e33-6f7e-46b8-83b9-1084d2a4f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import pandas as pd\n",
    "import os\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import imblearn\n",
    "\n",
    "import re\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "#copied from Kevin Barnes/kbarnes3: https://gist.github.com/kbarnes3/3fb7d353e9bdd3efccd5\n",
    "\n",
    "import ctypes\n",
    "import platform\n",
    "\n",
    "ES_CONTINUOUS = 0x80000000\n",
    "ES_SYSTEM_REQUIRED = 0x00000001\n",
    "\n",
    "\n",
    "def _set_thread_execution(state):\n",
    "    ctypes.windll.kernel32.SetThreadExecutionState(state)\n",
    "\n",
    "\n",
    "def prevent_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS | ES_SYSTEM_REQUIRED)\n",
    "\n",
    "\n",
    "def allow_standby():\n",
    "    if platform.system() == 'Windows':\n",
    "        _set_thread_execution(ES_CONTINUOUS)\n",
    "\n",
    "\n",
    "def long_running(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        prevent_standby()\n",
    "        result = func(*args, **kwargs)\n",
    "        allow_standby()\n",
    "        return result\n",
    "    return inner\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import argparse\n",
    "# !pip install opencv-python\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "# !pip install scipy\n",
    "import scipy.misc\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "    # caution: path[0] is reserved for script path (or '' in REPL)\n",
    "# sys.path.insert(1, 'Deep-Leafsnap-master')\n",
    "\n",
    "# !pip install scikit-image\n",
    "# !pip install scikit-learn \n",
    "import utils\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# !pip install imblearn\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from averagemeter import *\n",
    "from models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import warnings\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 185\n",
    "NUM_EPOCHS = 15*3\n",
    "LEARNING_RATE = 1e-2\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "best_prec1 = 0\n",
    "classes = []\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion,epoch,save_output=False):\n",
    "    # global output_aug_kde001, sample_pos, within_square, weight_tensor_kde001,zero_tensor_kde001,tt\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # losses_aug =  AverageMeter()\n",
    "\n",
    "    \n",
    "    conf = AverageMeter()\n",
    "    class_correct = list(0. for i in range(185))\n",
    "    class_total = list(0. for i in range(185))\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        if USE_CUDA:\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        save_output_target_validate(model,output,target,epoch,i)\n",
    "\n",
    "        \n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        \n",
    "\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        \n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        conf.update(conf1,1)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            print('Test: [{0}/{1}]\\n'.format(i, len(val_loader)))\n",
    "            print('Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\n'.format(batch_time=batch_time))\n",
    "            print('Loss {loss.val:.4f} ({loss.avg:.4f})\\n'.format(loss=losses))\n",
    "            print('Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\n'.format(top1=top1))\n",
    "            print('Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\n'.format(top5=top5))\n",
    "\n",
    "            print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "        \n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        if USE_CUDA:\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        # print(output)\n",
    "\n",
    "        loss = criterion(output, target_var)\n",
    "        # print(loss)\n",
    "        # if i >10:\n",
    "        #     break\n",
    "        \n",
    "        # save_output_target(model,output,target_var,epoch,i)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5,conf = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "        \n",
    "        save_output_target_train(model,output,target_var,epoch,i)\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  '\\Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd275a9-9a46-4aca-a9ff-223285a949d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb7426-aa73-4015-a3dc-9f7cd0ba5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dat_images = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/combined_lokasjon_top_100_images200_seed1117.csv')\n",
    "\n",
    "# dat = pd.read_csv('C:/Users/vjosv/master/dataset/images/csv/second_try_lokasjon_top_100_csv.csv')                         \n",
    "\n",
    "# dat_images_id = list(dat_images['Id'])                        \n",
    "                         \n",
    "\n",
    "# dat_images['points']= [[i,j] for i, j in zip(dat_images.Østkoordinat, dat_images.Nordkoordinat)]\n",
    "\n",
    "# dat['points']= [[i,j] for i, j in zip(dat.Østkoordinat, dat.Nordkoordinat)]\n",
    "\n",
    "\n",
    "# dat = dat[~dat['Id'].isin(dat_images_id)]\n",
    "\n",
    "# points = dat[['Østkoordinat','Nordkoordinat']].to_numpy()\n",
    "# # category = dat['target'].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# point_tree = spatial.cKDTree(points)\n",
    "\n",
    "\n",
    "\n",
    "traindir = os.path.join('dataset', 'train')\n",
    "testdir = os.path.join('dataset', 'test')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "data_train = datasets.ImageFolder(traindir, transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize]))\n",
    "data_val = datasets.ImageFolder(testdir, transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize]))\n",
    "classes = data_train.classes\n",
    "\n",
    "data_train = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "data_val = torch.utils.data.DataLoader(data_val, batch_size=64, shuffle=False, num_workers=2)\n",
    "def save_output_target_validate(model,output,target,epoch,batch):\n",
    "        torch.save(output,f'saved_output/{model.name}_validating_output/output_e{epoch}_b{batch}')\n",
    "        torch.save(target,f'saved_output/{model.name}_validating_output/target_b{batch}')\n",
    "        \n",
    "def save_output_target_train(model,output,target,epoch,babtch):\n",
    "        torch.save(output,f'saved_output/{model.name}_training_output/output_e{epoch}_b{batch}')\n",
    "\n",
    "        torch.save(target,f'saved_output/{model.name}_training_output/target_e_{epoch}_b{batch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257b7bc-782d-4b1f-a64d-685b3d0c9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.name = \"resnet18_pretrained2911\"\n",
    "model.fc=nn.Linear(model.fc.in_features, 185)\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    \n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 30)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 45)\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "model.fc=nn.Linear(model.fc.in_features, 185)\n",
    "model.name = \"resnet34_pretrained2911\"\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 30)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 45)\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "model.name = \"resnet50_pretrained2911\"\n",
    "model.fc=nn.Linear(model.fc.in_features, 185)\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 30)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 45)\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.name = \"resnet101_pretrained2911\"\n",
    "model.fc=nn.Linear(model.fc.in_features, 185)\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 30)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 45)\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model.name = \"resnet152_pretrained2911\"\n",
    "model.fc=nn.Linear(model.fc.in_features, 185)\n",
    "\n",
    "\n",
    "if not os.path.isdir(f'saved_output/{model.name}_validating_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_validating_output')\n",
    "if not os.path.isdir(f'saved_output/{model.name}_training_output'):\n",
    "    os.mkdir(f'saved_output/{model.name}_training_output')\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "train_model(model,LEARNING_RATE = 1e-2,NUM_EPOCHS = 15)\n",
    "train_model(model,LEARNING_RATE = 1e-3,NUM_EPOCHS = 30)\n",
    "train_model(model,LEARNING_RATE = 1e-4,NUM_EPOCHS = 45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa00df-0f22-4469-8a9b-09b5814a3b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eb42fca-ddc6-429c-a34d-eb10d1607256",
   "metadata": {},
   "source": [
    "### Create geo samples by running geo_functions_leafsnap.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc354543-f00d-463f-b5a2-e0f4f5cbed0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfda8793-79d6-4741-bb22-eef02a3e6f83",
   "metadata": {},
   "source": [
    "### test geo on leafsnap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de235f-030c-4493-a2fc-9f1cf7142095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    \n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred_t = pred.t()\n",
    "\n",
    "    correct = pred_t.eq(target.view(1, -1).expand_as(pred_t))\n",
    "\n",
    "    nb_classes = 185\n",
    "\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    \n",
    "    # print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    res = []\n",
    "    for k in topk:\n",
    "    \tcorrect_k = torch.sum(torch.reshape(correct[:k],(-1,) ).float()) #.double().sum(0)\n",
    "    \tres.append(correct_k.mul_(100.0 / batch_size))\n",
    "    res.append(confusion_matrix)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce2161-90b1-4599-8301-e17bd9039dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8893c7b4-51c2-418a-be17-7ce6d0eb6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "\n",
    "model_name = \"vgg19_pretrained\"\n",
    "\n",
    "list_outputs = os.listdir(f'saved_output/geo_functions/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c13efe8-450b-4ec5-8204-6ffd359da173",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_outputs = []\n",
    "for lo in list_outputs:\n",
    "    if lo[:3] == 'kde':\n",
    "        kde_outputs.append(lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f4656-8073-4226-8c3a-c2e4796244dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde_outputs[0]\n",
    "\n",
    "side_len = [1000,2000,3000,4000]\n",
    "bandwidth = [500,1000,1500, 2000,3000,4000]\n",
    "configuration =[0,1,2]\n",
    "\n",
    "def augment_output_add(output, augment, add):\n",
    "    output_ = torch.nn.functional.softmax(output, dim=1)\n",
    "    augment = augment/augment.sum(dim=1, keepdim=True)\n",
    "    output_aug = output_ + add*augment\n",
    "    output_aug = output_aug * 1/output_aug.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    return torch.log(output_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7141ba1-aec0-4914-8f3a-d0df2fb9e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name2 =\"resnet101_pretrained\"\n",
    "\n",
    "add = 1.7\n",
    "max_epoch = 44\n",
    "\n",
    "avg_prec1 =[]\n",
    "avg_prec1_temp =[]\n",
    "for e in range(max_epoch+1):#max_e+1):\n",
    "    for b in range(max_b+1):\n",
    "        output = torch.load(f'saved_output/{model_name2}_validating_output/output_e{e}_b{b}')\n",
    "        target = torch.load(f'saved_output/{model_name2}_validating_output/target_b{b}')\n",
    "\n",
    "\n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        avg_prec1_temp.append(prec1.cpu())\n",
    "    avg_prec1.append(np.average(avg_prec1_temp))\n",
    "    avg_prec1_temp =[]\n",
    "\n",
    "\n",
    "best_epoch = np.argmax(avg_prec1)\n",
    "print(best_epoch)\n",
    "print(avg_prec1[best_epoch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011bd90-35af-463b-bfad-f227ef0aad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prec1_list =[]\n",
    "prec1_avg_list_aug = []\n",
    "prec1_avg_list_temp = []\n",
    "\n",
    "\n",
    "\n",
    "prec5_list = []\n",
    "prec5_avg_list_aug = []\n",
    "prec5_avg_list_temp = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "side_len = [1000,2000,3000,4000]\n",
    "bandwidth = [500,1000,1500, 2000,3000,4000]\n",
    "configuration =[0,1,2]\n",
    "\n",
    "model_name =\"resnet18_pretrained\"\n",
    "\n",
    "add = 1.7\n",
    "max_epoch = 44\n",
    "max_b = 92\n",
    "avg_prec1 =[]\n",
    "avg_prec1_temp =[]\n",
    "avg_prec5 =[]\n",
    "avg_prec5_temp =[]\n",
    "for e in range(max_epoch+1):#max_e+1):\n",
    "    for b in range(max_b+1):\n",
    "        output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "        target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "\n",
    "\n",
    "        prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "        avg_prec1_temp.append(prec1.cpu())\n",
    "        avg_prec5_temp.append(prec5.cpu())\n",
    "    avg_prec1.append(np.average(avg_prec1_temp))\n",
    "    avg_prec1_temp =[]\n",
    "    avg_prec5.append(np.average(avg_prec5_temp))\n",
    "    avg_prec5_temp =[]\n",
    "\n",
    "\n",
    "best_epoch = np.argmax(avg_prec1)\n",
    "top1 = avg_prec1[best_epoch]\n",
    "top5=avg_prec5[best_epoch]\n",
    "print(best_epoch ,top1, top5)\n",
    "\n",
    "           # print(dict_df)\n",
    "dict_example = {'Side Length': [],\n",
    "            'Bandwidth': [],\n",
    "            'add':[],\n",
    "             'epoch': [],\n",
    "             'prec1$_a$': [],\n",
    "            'prec1':[],\n",
    "            'prec5':[],\n",
    "            'prec5$_a$':[],\n",
    "           }\n",
    "\n",
    "dict_df = dict_example #[copy.deepcopy(dict_example) for i in range(4)]\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "def augment_output_add(output, augment, add):\n",
    "    output_ = torch.nn.functional.softmax(output, dim=1)\n",
    "    augment = augment/augment.sum(dim=1, keepdim=True)\n",
    "    output_aug = output_ + add*augment\n",
    "    output_aug = output_aug/output_aug.sum(dim=1,keepdim=True)\n",
    "    \n",
    "    return output_aug\n",
    "\n",
    "\n",
    "max_e\n",
    "add_list = [0.1,0.2,0.4,0.6,0.8,1]\n",
    "add = 0.2\n",
    "for add in tqdm(add_list):\n",
    "    \n",
    "    for sl in side_len:\n",
    "        for bw in bandwidth:\n",
    "\n",
    "            prec1_list = []\n",
    "            prec1_list_aug = []\n",
    "            prec1_avg_list_aug = []\n",
    "            prec1_avg_list_aug_temp = []\n",
    "\n",
    "            prec5_list = []\n",
    "            prec5_list_aug = []\n",
    "            prec5_avg_list_aug = []\n",
    "            prec5_avg_list_aug_temp = []\n",
    "\n",
    "            prec5_avg_list = []\n",
    "            prec5_avg_list_temp = []\n",
    "\n",
    "            prec1_avg_list = []\n",
    "            prec1_avg_list_temp=[]\n",
    "\n",
    "            prec1_avg_list = []\n",
    "\n",
    "            e = best_epoch\n",
    "\n",
    "            for b in range(max_b+1):\n",
    "                output = torch.load(f'saved_output/{model_name}_validating_output/output_e{e}_b{b}')\n",
    "                target = torch.load(f'saved_output/{model_name}_validating_output/target_b{b}')\n",
    "\n",
    "                tensor_list = []\n",
    "\n",
    "\n",
    "                load_tensor0 =torch.load( f'saved_output/geo_functions/kde_side_len{sl}m_bandwitdth{bw}_batch{b}_cofiguration{0}')\n",
    "                load_tensor1 =torch.load( f'saved_output/geo_functions/kde_side_len{sl}m_bandwitdth{bw}_batch{b}_cofiguration{1}')\n",
    "                load_tensor2 =torch.load( f'saved_output/geo_functions/kde_side_len{sl}m_bandwitdth{bw}_batch{b}_cofiguration{2}')\n",
    "\n",
    "                try:\n",
    "                    load_tensor0 = load_tensor0*1/torch.sum(load_tensor0)\n",
    "\n",
    "                except:\n",
    "                    print('f')\n",
    "                    pass\n",
    "                try:\n",
    "                    load_tensor1 = load_tensor1*1/torch.sum(load_tensor1)\n",
    "                except:\n",
    "                    print('f')\n",
    "                    pass\n",
    "                try:\n",
    "                    load_tensor2 = load_tensor2*1/torch.sum(load_tensor2)\n",
    "                except:\n",
    "                    print('f')\n",
    "                    pass\n",
    "\n",
    "\n",
    "                output0 = augment_output_add(output,load_tensor0.cuda(),add)\n",
    "                output1 = augment_output_add(output,load_tensor1.cuda(),add)\n",
    "                output2 = augment_output_add(output,load_tensor2.cuda(),add)\n",
    "\n",
    "\n",
    "                prec10, prec50, conf1 = accuracy(output0.data, target, topk=(1, 5))\n",
    "                prec11, prec51, conf1 = accuracy(output1.data, target, topk=(1, 5))\n",
    "                prec12, prec52, conf1 = accuracy(output2.data, target, topk=(1, 5))\n",
    "\n",
    "                prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "                # print(output0)\n",
    "                prec1_avg = (prec10+prec11+prec12)/3\n",
    "                # print(prec1_avg)\n",
    "                # print('...........')\n",
    "                prec5_avg = (prec50+prec51+prec52)/3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                prec1_list.append(prec1_avg.cpu())\n",
    "                prec1_avg_list_temp.append(prec1_avg.cpu())\n",
    "\n",
    "                prec5_list.append(prec5_avg.cpu())\n",
    "                prec5_avg_list_temp.append(prec5_avg.cpu())\n",
    "\n",
    "\n",
    "\n",
    "            print(np.average(prec1_avg_list_temp),sl,bw,add)\n",
    "            prec1_avg_list_aug.append(np.average((prec1_avg_list_temp)))\n",
    "\n",
    "\n",
    "            prec5_avg_list_aug.append(np.average((prec5_avg_list_temp)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       # print(dict_df)\n",
    "            # print(i)\n",
    "            # print(dict_df[i])\n",
    "            dict_df['Side Length'].append(sl)\n",
    "            dict_df['Bandwidth'].append(bw)\n",
    "            dict_df['add'].append(add)\n",
    "            dict_df['epoch'].append(best_epoch)\n",
    "            dict_df['prec1$_a$'].append(np.average(prec1_avg_list_temp))\n",
    "\n",
    "            dict_df['prec1'].append(top1)\n",
    "            dict_df['prec5'].append(top5)\n",
    "            dict_df['prec5$_a$'].append(np.average(prec5_avg_list_temp))\n",
    "\n",
    "\n",
    "            prec5_avg_list_temp = []\n",
    "            prec1_avg_list_temp = []\n",
    "\n",
    "            print(dict_df)\n",
    "\n",
    "   \n",
    "\n",
    "dict_df['prec1$_a$-prec1']= [dict_df['prec1$_a$'][i] - dict_df['prec1'][i] for i in range(len(dict_df['prec1']))]\n",
    "dict_df['prec5$_a$-prec5']= [dict_df['prec5$_a$'][i] - dict_df['prec5'][i] for i in range(len(dict_df['prec1']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a356c5-b316-4960-b507-71ea84f702a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_df                                 \n",
    "b = pd.DataFrame.from_dict(dict_df)\n",
    "# a\n",
    "\n",
    "print(b[['add','Side Length', 'Bandwidth','epoch','prec1$_a$','prec5$_a$','prec1$_a$-prec1','prec5$_a$-prec5' ]].to_latex(index=False))\n",
    "# print(a.to_latex(index=False))\n",
    "# dict_df[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc96c2-2a9e-41d9-9168-e7959dc9d5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5d41f-d345-4f34-a664-e1dbd468ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "prec1_list =[]\n",
    "prec1_avg_list_aug = []\n",
    "prec1_avg_list_temp = []\n",
    "\n",
    "\n",
    "\n",
    "prec5_list = []\n",
    "prec5_avg_list_aug = []\n",
    "prec5_avg_list_temp = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "add = 1.7\n",
    "\n",
    "configurations = [0,1,2]\n",
    "\n",
    "n_list = [25,50,75,100,200,500,1000,1500,2000,2500,3000]\n",
    "\n",
    "\n",
    "\n",
    "temp_list = []\n",
    "prec1_l = []\n",
    "model_2 =\"resnet18_pretrained\"\n",
    "\n",
    "models_ =[\"resnet18_pretrained\",\"resnet34_pretrained\",\"resnet50_pretrained\",\"resnet101_pretrained\",\"vgg16_pretrained\",\"vgg19_pretrained\"]\n",
    "max_e_knn= 44\n",
    "max_b = 92\n",
    "prec1_avg_list = []\n",
    "prec1_avg_list_temp =[]\n",
    "for e in range(max_e+1):\n",
    "    for b in range(max_b+1):\n",
    "        output = torch.load(f'saved_output/{model_2}_validating_output/output_e{e}_b{b}')\n",
    "        target = torch.load(f'saved_output/{model_2}_validating_output/target_b{b}')\n",
    "\n",
    "\n",
    "        prec10, prec50, conf10 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        # print(prec10)\n",
    "        prec1_avg_list_temp.append(prec10.cpu())\n",
    "\n",
    "\n",
    "    prec1_avg_list.append(np.average((prec1_avg_list_temp)))\n",
    "\n",
    "    prec1_avg_list_temp = []\n",
    "\n",
    "\n",
    "best_epoch = np.argmax(prec1_avg_list)\n",
    "print(best_epoch)\n",
    "max_original = prec1_avg_list[best_epoch]\n",
    "print(max_original)\n",
    "\n",
    "#              }\n",
    "dict_example = {'k': [],\n",
    "                'add':[],\n",
    "             'best epoch$_a$': [],\n",
    "             'prec1$_a$': [],\n",
    "            'prec5$_a$':[],\n",
    "            'prec1$_{max}$':[],\n",
    "            'prec5$_{max}$':[],\n",
    "           }\n",
    "\n",
    "dict_df =  dict_example #[copy.deepcopy(dict_example) for i in range(1)]\n",
    "\n",
    "\n",
    "def augment_output_add(output, augment, add):\n",
    "    output_ = torch.nn.functional.softmax(output, dim=1)\n",
    "    augment = augment/augment.sum(dim=1, keepdim=True)\n",
    "    output_aug = output_ + add*augment\n",
    "    output_aug = output_aug/output_aug.sum(dim=1,keepdim=True)\n",
    "    \n",
    "    return output_aug\n",
    "\n",
    "print(best_epoch)\n",
    "e = max_e\n",
    "max_value = 0\n",
    "max_e_knn= 44\n",
    "max_add = 0\n",
    "add_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]#,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2]\n",
    "# best add:\n",
    "add = add_list[5]\n",
    "print('add:',add)\n",
    "\n",
    "\n",
    "for add in tqdm(add_list):\n",
    "    for n in n_list:\n",
    "        prec1_list = []\n",
    "        prec1_avg_list_aug = []\n",
    "        prec1_avg_list_temp = []\n",
    "\n",
    "        prec5_list = []\n",
    "        prec5_avg_list_aug = []\n",
    "        prec5_avg_list_temp = []\n",
    "        prec1_list_original =[]\n",
    "        prec1_list_original_temp = []\n",
    "        prec5_list_original =[]\n",
    "        prec5_list_original_temp = []\n",
    "\n",
    "\n",
    "        e=best_epoch\n",
    "        for b in range(max_b+1):\n",
    "            output = torch.load(f'saved_output/{model_2}_validating_output/output_e{e}_b{b}')\n",
    "            target = torch.load(f'saved_output/{model_2}_validating_output/target_b{b}')\n",
    "\n",
    "            tensor_list = []\n",
    "\n",
    "            load_tensor0 =torch.load( f'saved_output/geo_functions/knn_smote_n_{n}_batch{b}_cofiguration{0}')\n",
    "            load_tensor1 =torch.load( f'saved_output/geo_functions/knn_smote_n_{n}_batch{b}_cofiguration{1}')\n",
    "            load_tensor2 =torch.load( f'saved_output/geo_functions/knn_smote_n_{n}_batch{b}_cofiguration{2}')\n",
    "\n",
    "\n",
    "\n",
    "            output0 = augment_output_add(output,load_tensor0.cuda(),add)\n",
    "            output1 = augment_output_add(output,load_tensor1.cuda(),add)\n",
    "            output2 = augment_output_add(output,load_tensor2.cuda(),add)\n",
    "\n",
    "\n",
    "            prec10, prec50, conf1 = accuracy(output0.data, target, topk=(1, 5))\n",
    "            prec11, prec51, conf1 = accuracy(output1.data, target, topk=(1, 5))\n",
    "            prec12, prec52, conf1 = accuracy(output2.data, target, topk=(1, 5))\n",
    "\n",
    "            prec1, prec5, conf1 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "            prec1_avg = (prec10+prec11+prec12)/3\n",
    "\n",
    "            prec5_avg = (prec50+prec51+prec52)/3\n",
    "\n",
    "            prec1_list.append(prec1_avg.cpu())\n",
    "            prec1_avg_list_temp.append(prec1_avg.cpu())\n",
    "\n",
    "            prec5_list.append(prec5_avg.cpu())\n",
    "            prec5_avg_list_temp.append(prec5_avg.cpu())\n",
    "\n",
    "            prec1_list_original_temp.append(prec1.cpu())\n",
    "            prec5_list_original_temp.append(prec5.cpu())\n",
    "\n",
    "        print(np.average(prec1_avg_list_temp),max_original,n,add)\n",
    "\n",
    "        prec1_avg_list_aug.append(np.average(prec1_avg_list_temp))\n",
    "\n",
    "        prec1_list_original.append(np.average((prec1_list_original_temp)))\n",
    "\n",
    "        prec5_list_original.append(np.average(prec5_list_original_temp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        dict_df['k'].append(n)\n",
    "        dict_df['add'].append(add)\n",
    "        dict_df['best epoch$_a$'].append(best_epoch)\n",
    "        dict_df['prec1$_a$'].append(np.average(prec1_avg_list_temp))\n",
    "        dict_df['prec1$_{max}$'].append(np.average(prec1_list_original_temp))\n",
    "        dict_df['prec5$_a$'].append(np.average(prec5_avg_list_temp))\n",
    "        dict_df['prec5$_{max}$'].append(np.average(prec5_list_original_temp))\n",
    "        print(prec1_avg_list_aug)\n",
    "        print(dict_df)\n",
    "\n",
    "        prec5_avg_list_temp = []\n",
    "        prec1_avg_list_temp = []\n",
    "        prec5_list_original_temp = []\n",
    "        prec1_list_original_temp = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acecdd-50dc-46f1-acae-09c191c1b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df['prec1$_a$-prec1$_{max}$']= [dict_df['prec1$_a$'][i] - dict_df['prec1$_{max}$'][i] for i in range(len(dict_df['prec5$_{max}$']))]\n",
    "dict_df['prec5$_a$-prec5$_{max}$']= [dict_df['prec5$_a$'][i] - dict_df['prec5$_{max}$'][i] for i in range(len(dict_df['prec5$_{max}$']))]\n",
    "# dict_df   \n",
    "\n",
    "\n",
    "b = pd.DataFrame.from_dict(dict_df)\n",
    "# a\n",
    "# print(model_2)\n",
    "print(b[['add','k', 'best epoch$_a$','prec1$_a$','prec5$_a$','prec1$_a$-prec1$_{max}$','prec5$_a$-prec5$_{max}$' ]].to_latex(index=False))\n",
    "# print(a.to_latex(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9e650-925b-4d59-9b5f-f3ed7a347a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [3]:\n",
    "    a = pd.DataFrame.from_dict(dict_df[i])\n",
    "    print(a.to_latex())\n",
    "    \n",
    "    a.to_csv(f'knn_results_configuration{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfca93-80cf-4821-88c1-944e024bbee4",
   "metadata": {},
   "source": [
    "#### In Area weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b776c-f69c-4cda-b8b0-79e5e76d7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_radius = [50,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500]\n",
    "configuration = [i for i in range(20)]\n",
    "# configurations = [0]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66aff7f-1b49-4928-984a-0c1921247594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "model_2 = 'resnet18_pretrained'\n",
    "# model_2 = \"vgg19_pretrained\"\n",
    "max_e = 44\n",
    "max_b = 92\n",
    "def augment_output_multiply(output,augment,mul):\n",
    "    output_aug = torch.nn.functional.softmax(output, dim=1)\n",
    "    # output_aug = torch.nn.functional.normalize(output_aug*augment)\n",
    "    output_aug = output_aug +mul*augment\n",
    "    output_aug = torch.nn.functional.normalize(output_aug)\n",
    "    output_aug = torch.log(output_aug)\n",
    "    \n",
    "    \n",
    "    return output_aug\n",
    "\n",
    "configurations = [i for i in range(20)]\n",
    "prec1_list = [[],[],[],[]]\n",
    "prec1_avg_list_aug = [[],[],[],[]]\n",
    "prec1_avg_list_temp = [[],[],[],[]]\n",
    "\n",
    "prec1_avg_list = []\n",
    "\n",
    "prec5_list = [[],[],[],[]]\n",
    "prec5_avg_list_aug = [[],[],[],[]]\n",
    "prec5_avg_list_temp = [[],[],[],[]]\n",
    "\n",
    "\n",
    "add = 1.7\n",
    "\n",
    "dict_example = {'Sample Radius': [],\n",
    "             'best epoch$_a$': [],\n",
    "            'prec1$_a$': [], \n",
    "            'prec1$_{max}$':[],\n",
    "            'prec5$_{max}$':[],\n",
    "            'prec5$_a$':[],\n",
    "            f'prec1$_a$ at epoch {best_epoch}':[],\n",
    "            f'prec5$_a$ at epoch {best_epoch}':[],\n",
    "             }\n",
    "\n",
    "\n",
    "dict_df = [copy.deepcopy(dict_example) for i in range(21)]\n",
    "\n",
    "\n",
    "\n",
    "add_list = [10]\n",
    "\n",
    "\n",
    "def augment_output_add(output, augment, add):\n",
    "    output_ = torch.nn.functional.softmax(output, dim=1)\n",
    "    augment = augment/augment.sum(dim=1, keepdim=True)\n",
    "    output_aug = output_*augment\n",
    "    output_aug = output_aug/output_aug.sum(dim=1,keepdim=True)\n",
    "    \n",
    "    return output_aug #torch.log(output_aug)\n",
    "\n",
    "\n",
    "prec1_avg_list = []\n",
    "prec1_avg_list_temp = []\n",
    "prec5_avg_list = []\n",
    "prec5_avg_list_temp = []\n",
    "\n",
    "for e in range(max_e+1):\n",
    "\n",
    "    for b in range(max_b+1):\n",
    "        output = torch.load(f'saved_output/{model_2}_validating_output/output_e{e}_b{b}')\n",
    "        target = torch.load(f'saved_output/{model_2}_validating_output/target_b{b}')\n",
    "\n",
    "        # tensor_avg =(tensor_list[0]+tensor_list[1]+tensor_list[2])/3\n",
    "\n",
    "        # output1 = augment_output_add(output,load_tensor.cuda(),add)\n",
    "\n",
    "\n",
    "        # prec1, prec5, conf1 = accuracy(output1.data, target, topk=(1, 5))\n",
    "        prec10, prec50, conf10 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        # print(prec10)\n",
    "        prec1_avg_list_temp.append(prec10.cpu())\n",
    "        prec5_avg_list_temp.append(prec50.cpu())\n",
    "\n",
    "\n",
    "\n",
    "    prec1_avg_list.append(np.average((prec1_avg_list_temp)))\n",
    "    prec5_avg_list.append(np.average((prec5_avg_list_temp)))\n",
    "    prec1_avg_list_temp = []\n",
    "    prec5_avg_list_temp = []\n",
    "\n",
    "best_epoch = np.argmax(prec1_avg_list)\n",
    "print(best_epoch)\n",
    "best_value1 = prec1_avg_list[best_epoch]\n",
    "print(best_value1)\n",
    "best_value5 = prec5_avg_list[best_epoch]\n",
    "\n",
    "\n",
    "for e in range(max_e+1):\n",
    "    for b in range(max_b+1):\n",
    "        output = torch.load(f'saved_output/{model_2}_validating_output/output_e{e}_b{b}')\n",
    "        target = torch.load(f'saved_output/{model_2}_validating_output/target_b{b}')\n",
    "\n",
    "\n",
    "        prec10, prec50, conf10 = accuracy(output.data, target, topk=(1, 5))\n",
    "\n",
    "        # print(prec10)\n",
    "        prec1_avg_list_temp.append(prec10.cpu())\n",
    "\n",
    "\n",
    "    prec1_avg_list.append(np.average((prec1_avg_list_temp)))\n",
    "\n",
    "    prec1_avg_list_temp = []\n",
    "\n",
    "\n",
    "best_epoch = np.argmax(prec1_avg_list)\n",
    "print(best_epoch)\n",
    "max_original = prec1_avg_list[best_epoch]\n",
    "print(max_original)\n",
    "\n",
    "e = max_e\n",
    "add_list = [0.1,0.25,0.5,0.75,1.1,1.2,1.3,1.4,1.5]\n",
    "models_ =[\"resnet18_pretrained\",\"resnet34_pretrained\",\"resnet50_pretrained\",\"resnet101_pretrained\",\"vgg16_new\",\"vgg19_new\"]\n",
    "\n",
    "for model_2 in models_[0:1]:\n",
    "    \n",
    "    max_e = 27\n",
    "\n",
    "\n",
    "\n",
    "    dict_example = {'Sample Radius': [],\n",
    "             'best epoch$_a$': [],\n",
    "            'add':[],\n",
    "            'prec1$_a$': [], \n",
    "            'prec1$_{max}$':[],\n",
    "            'prec5$_{max}$':[],\n",
    "            'prec5$_a$':[],\n",
    "             'prec1$_a$-prec1$_{max}$':[],\n",
    "             'prec5$_a$-prec5$_{max}$' : [],\n",
    "             }\n",
    "\n",
    "\n",
    "    dict_df = dict_example #[copy.deepcopy(dict_example) for i in range(21)]\n",
    "\n",
    "\n",
    "    \n",
    "    for add in add_list:\n",
    "        for i,sr in enumerate([10,20,30,40,50,100,200,300,400,500,1000,2000]):#sample_radius[:1]:\n",
    "            prec1_list = []\n",
    "            prec1_list_aug = []\n",
    "            prec1_avg_list_aug = []\n",
    "            prec1_avg_list_aug_temp = []\n",
    "\n",
    "            prec5_list = []\n",
    "            prec5_list_aug = []\n",
    "            prec5_avg_list_aug = []\n",
    "            prec5_avg_list_aug_temp = []\n",
    "\n",
    "            # prec5_avg_list = []\n",
    "            # prec5_avg_list_temp = []\n",
    "\n",
    "            # prec1_avg_list = []\n",
    "            prec1_avg_list_temp=[]\n",
    "\n",
    "            # prec1_avg_list = []\n",
    "\n",
    "            e= best_epoch\n",
    "            for b in range(max_b+1):\n",
    "                output = torch.load(f'saved_output/{model_2}_validating_output/output_e{e}_b{b}')\n",
    "                target = torch.load(f'saved_output/{model_2}_validating_output/target_b{b}')\n",
    "\n",
    "                tensor_list = []\n",
    "\n",
    "\n",
    "                load_tensors = [torch.load( f'saved_output/geo_functions/sampled_{sr}m_batch{b}_cofiguration{i}') for i in configuration]\n",
    "                # load_tensor = torch.load( f'saved_output/{model_name}_validating_output/sampled_{sr}m_batch{b}_cofiguration{i}')\n",
    "                # print(load_tensors)\n",
    "                output_augs = [augment_output_multiply(output.cuda(),load_tensor.cuda(),add) for load_tensor in load_tensors]\n",
    "\n",
    "                # output_aug = augment_output_multiply(output,load_tensor.cuda(),add)\n",
    "                # print(output_aug)\n",
    "                precs =[(accuracy(output_aug.data, target, topk=(1, 5))) for output_aug in output_augs]\n",
    "\n",
    "                prec10, prec50, conf10 = accuracy(output.data, target, topk=(1, 5))\n",
    "                prec1_avg_list_temp.append(prec10.cpu())\n",
    "                prec5_avg_list_temp.append(prec50.cpu())\n",
    "\n",
    "                prec1s = 0\n",
    "                prec5s = 0\n",
    "\n",
    "                for p15 in precs:\n",
    "     \n",
    "                    prec1s+= p15[0]\n",
    "                    prec5s+= p15[1]\n",
    "                # print(output0)\n",
    "                prec1_avg = prec1s/len(precs)\n",
    "                # print(prec1_avg)\n",
    "                # print('...........')\n",
    "                prec5_avg = prec5s/len(precs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print(prec1_avg)\n",
    "                prec1_list.append(prec1_avg.cpu())\n",
    "                prec1_avg_list_aug_temp.append(prec1_avg.cpu())\n",
    "\n",
    "                prec5_list.append(prec5_avg.cpu())\n",
    "                prec5_avg_list_aug_temp.append(prec5_avg.cpu())\n",
    "\n",
    "\n",
    "    \n",
    "            dict_df['Sample Radius'].append(sr)\n",
    "\n",
    "            # dict_df[i]['best epoch$_a$'].append(np.argmax(prec1_avg_list_aug[i]))\n",
    "            dict_df['best epoch$_a$'].append(e)\n",
    "            dict_df['add'].append(add)   \n",
    "            dict_df['prec1$_a$'].append(np.average(prec1_list))\n",
    "            dict_df['prec1$_{max}$'].append(best_value1)\n",
    "            dict_df['prec5$_{max}$'].append(best_value5)\n",
    "            dict_df['prec5$_a$'].append(np.average(prec5_list))\n",
    "\n",
    " \n",
    "            dict_df['prec1$_a$-prec1$_{max}$'].append(np.average(prec1_list) -best_value1)\n",
    "            dict_df['prec5$_a$-prec5$_{max}$'].append(np.average(prec5_list)-best_value5)\n",
    "            print(dict_df)\n",
    "            prec5_avg_list_aug_temp = []\n",
    "            prec1_avg_list_temp = []\n",
    "            prec1_avg_list_aug_temp = []\n",
    "                               \n",
    "    b = pd.DataFrame.from_dict(dict_df )\n",
    "    # a\n",
    "    print(model_2)\n",
    "    print(b[['Sample Radius', 'best epoch$_a$','prec1$_a$','prec5$_a$','prec1$_a$-prec1$_{max}$','prec5$_a$-prec5$_{max}$' ]].to_latex(index=False))\n",
    "    # print(a.to_latex(index=False))\n",
    "    # dict_df[20]\n",
    "    b.to_csv(f'sample_radius{model_2}_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c13f8-0137-4ad7-857f-a3f434cdf8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame.from_dict(dict_df )\n",
    "b\n",
    "print(b[['Sample Radius', 'add','best epoch$_a$','prec1$_a$','prec5$_a$','prec1$_a$-prec1$_{max}$','prec5$_a$-prec5$_{max}$' ]].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16594c41-856f-43bc-966a-2317a4b8e98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff9b0e-6e57-43db-b479-2b1de397f5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efab4f5-2919-41dd-a987-689e730a4b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d9a27-0992-449a-98bd-7f6e5d9e24f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
